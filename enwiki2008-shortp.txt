
There are many types and traditions of anarchism, not all of which are mutually exclusive. Anarchists hold different views as to the economic and legal organisation of society; some favour collectivist anarchism, anarcho-syndicalism or participatory economics while others support market systems like mutualism, agorism, or anarcho-capitalism. Others, such as anarcho-communists and post left anarchists prefer no solid form of organization. According to The Oxford Companion to Philosophy, "there is no single defining position that all anarchists hold, beyond their rejection of compulsory government, and those considered anarchists at best share a certain family resemblance". Anarchist schools of thought differ fundamentally, supporting anything from extreme individualism to complete collectivism. Some anarchists have opposed coercion, while others have supported it, particularly in the form of violent revolution on the path to anarchy or utopia.
Some claim anarchist themes can be found in the works of Taoist sage Lao Tzu. Diogenes of Sinope and the Cynics and their contemporary, Zeno of Citium, the founder of Stoicism, also introduced similar topics.
Modern anarchism, however, sprung from the secular thought of the Enlightenment, particularly Jean-Jacques Rousseau's arguments for the moral centrality of freedom. Although by the turn of the 19th century the term "anarchist" had an entirely positive connotation, it first entered the English language in 1642 during the English Civil War as a term of abuse used by Royalists to damn those who were fomenting disorder. By the time of the French Revolution some, such as the Enragés, began to use the term positively, in opposition to Jacobin centralisation of power, seeing "revolutionary government" as oxymoronic. From this climate William Godwin developed what many consider the first expression of modern anarchist thought. Godwin was, according to Peter Kropotkin, "the first to formulate the political and economical conceptions of anarchism, even though he did not give that name to the ideas developed in his work." Godwin, a philosophical anarchist, opposed revolutionary action and saw a minimal state as a present "necessary evil" that would become increasingly irrelevant and powerless by the gradual spread of knowledge. Godwin advocated extreme individualism, proposing that all cooperation in labor be eliminated. Godwin felt discrimination on any grounds besides ability was intolerable.
The first to describe himself as anarchist was Pierre-Joseph Proudhon, which led some to call him the founder of modern anarchist theory. Proudhon proposed spontaneous order, whereby organization emerges without central authority, a "positive anarchy" where order arises when everybody does "what he wishes and only what he wishes" and where "business transactions alone produce the social order." Like Godwin, Proudhon opposed violent revolutionary action. He saw anarchy as "a form of government or constitution in which public and private consciousness, formed through the development of science and law, is alone sufficient to maintain order and guarantee all liberties. In it, as a consequence, the institutions of the police, preventive and repressive methods, officialdom, taxation, etc. are reduced to a minimum. In it, more especially, the forms of monarchy and intensive centralization disappear, to be replaced by federal institutions and a pattern of life based on the commune" By "commune", Proudhon meant local self-government or according to literal translation, "municipality", rather than a communist arrangement.
Mutualism began in 18th century English and French labor movements before taking an anarchist form associated with Pierre-Joseph Proudhon in France and others in the United States. Proudhon's ideas were introduced by Charles A. Dana, to individualist anarchists in the United States including Benjamin Tucker and William Batchelder Greene.
Individualist anarchism comprises several traditions which hold that "individual conscience and the pursuit of self-interest should not be constrained by any collective body or public authority." Individualist anarchism is supportive of property being held privately, unlike the social/socialist/collectivist/communitarian wing which advocates common ownership. Individualist anarchism has been espoused by individuals such as William Godwin, Henry David Thoreau, Josiah Warren, and Murray Rothbard.
One of the earliest and best-known proponents of individualist anarchism was Max Stirner, who wrote The Ego and Its Own (1844), a founding text of the philosophy. Stirner's philosophy was an egoist form of individualist anarchism according to which the individual does as he/she pleases, taking no notice of God, state, or moral rules. To Stirner, rights were spooks in the mind, and he held that society does not exist but "the individuals are its reality" — he supported property as possession by might rather than right. Stirner preached self-assertion and foresaw "associations of egoists" where respect for ruthlessness drew people together.
A less radical form of individualist anarchism was advocated by the "Boston anarchists," American individualists who supported private property and a free market. They advocated the protection of liberty and property by private contractors, and endorsed exchange of labor for wages, They did not have a problem that "one man employ another" or that "he direct him," in his labor but demanded that "all natural opportunities requisite to the production of wealth be accessible to all on equal terms and that monopolies arising from special privileges created by law be abolished." They believed state monopoly capitalism (defined as a state-sponsored monopoly) prevented labor from being fully rewarded. Even among the nineteenth century American individualists, there was not a monolithic doctrine, as they disagreed amongst each other on various issues including intellectual property rights and possession versus property in land. A major cleft occurred later in the 19th century when Tucker and some others abandoned natural rights and converted to an "egoism" modeled upon Stirner's philosophy. Some "Boston anarchists", like Tucker, identified themselves as "socialist" – a term which at the time denoted a broad concept – by which he meant a commitment to solving "the labor problem" by radical economic reform.) By the turn of the 20th century, the heyday of individualist anarchism had passed, although it was later revived with modifications by Murray Rothbard and the anarcho-capitalists in the mid-twentieth century, as a current of the broader libertarian movement.
Social anarchism is one of two different broad categories of anarchism, the other category being individualist anarchism. The term social anarchism is often used to identify communitarian forms of anarchism that emphasize cooperation and mutual aid. Social anarchism includes anarcho-collectivism, anarcho-communism, Libertarian socialism, anarcho-syndicalism, social ecology and sometimes mutualism.
Collectivist anarchism (a specific tendency not to be confused with the broad category sometimes called collectivist or communitarian anarchism) is a revolutionary form of anarchism commonly associated with Mikhail Bakunin and with Johann Most. Unlike mutualists, collectivist anarchists oppose all private ownership of the means of production, instead advocating that ownership be collectivized. This was to be initiated by small cohesive elite group through acts of violence, or "propaganda by the deed," which would inspire the workers as a whole to revolt and forcibly collectivize the means of production. However, collectivization was not to be extended to the distribution of income, as workers would be paid according to time worked, rather than receiving goods being distributed "according to need" as in anarcho-communism. Although the collectivist anarchists advocated compensation for labor, some held out the possibility of a post-revolutionary transition to a communist system of distribution according to need. Collectivist anarchism arose contemporaneously with Marxism but opposed the Marxist dictatorship of the proletariat, despite the stated Marxist goal a collectivist stateless society.
Anarchist communists propose that a society composed of a number of self-governing communes with collective use of the means of production and direct democracy as the political organizational form, and related to other communes through federation would be the freest form of social organisation. However, some anarchist communists oppose the majoritarian nature of direct democracy, feeling that it can impede individual liberty and favor consensus democracy. In anarchist communism, individuals would not receive direct compensation for labour (through sharing of profits or payment), but would instead have free access to the resources and surplus of the commune. According to anarchist communist Peter Kropotkin and later Murray Bookchin, the members of such a society would spontaneously perform all necessary labour because they would recognize the benefits of communal enterprise and mutual aid. Kropotkin believed that private property was one of the causes of oppression and exploitation and called for its abolition,advocating instead common ownership.
The status of anarchist communism within anarchism is disputed, because it is seen by individualist anarchists and anarcho-capitalists as incompatible with freedom. Some anarcho-syndicalists, such as the Spanish union CNT. saw an anarcho-communist society as their objective. Platformism is an anarchist communist tendency in the tradition of Nestor Makhno who argued for the "vital need of an organization which, having attracted most of the participants in the anarchist movement, would establish a common tactical and political line for anarchism and thereby serve as a guide for the whole movement." Some forms of anarchist communism are strongly Egoist in nature, and are strongly influenced by radical individualist philosophy, believing that anarcho-communism does not require a communitarian nature at all; anarchist communist Emma Goldman was influenced by both Max Stirner and Kropotkin and blended their philosophies together in her own.
In the early twentieth century anarcho-syndicalism arose as a distinct school of thought within anarchism. With greater focus on the labour movement than previous forms of anarchism, syndicalism posits radical trade unions as a potential force for revolutionary social change, replacing capitalism and the state with a new society, democratically self-managed by the workers. Anarcho-syndicalists seek to abolish the wage system and private ownership of the means of production, which they believe lead to class divisions. Important principles of syndicalism include workers' solidarity, direct action (such as general strikes and workplace recuperations), and workers' self-management. Anarcho-syndicalism and other branches of anarchism are not mutually exclusive: anarcho-syndicalists often subscribe to communist or collectivist anarchist economic systems. Its advocates propose labour organization as a means to create the foundations of a non-hierarchical anarchist society within the current system and bring about social revolution.
Rudolf Rocker was a leading early anarcho-syndicalist thinker who outlined a view of the origins of the movement, what it sought, and why it was important to the future of labour in his 1938 pamphlet Anarchosyndicalism. Although more frequently associated with labor struggles of the early twentieth century (particularly in France and Spain), many syndicalist organizations are active today, united across national borders by membership in the International Workers Association, including the SAC in Sweden, the USI in Italy, and the CNT in Spain.
Anarchism continues to generate many eclectic and syncretic philosophies and movements; since the revival of anarchism in the U.S. in the 1960s, a number of new movements and schools have emerged. Anarcho-capitalism developed out of radical anti-state libertarianism as a rejuvenated form of individualist anarchism, while the burgeoning feminist and environmentalist movements also produced anarchist offshoots.
Post-left anarchy is a tendency which seeks to distance itself from the traditional "left" and to escape the confines of ideology in general. Post-leftists argue that anarchism has been weakened by its long attachment to contrary "leftist" movements and single issue causes and calls for a synthesis of anarchist thought and a specifically anti-authoritarian revolutionary movement outside of the leftist milieu. Post-anarchism is a theoretical move towards a synthesis of classical anarchist theory and poststructuralist thought developed by Saul Newman and associated with thinkers such as Todd May, Gilles Deleuze and Félix Guattari. It draws from a wide range of ideas including autonomism, post-left anarchy, situationism, postcolonialism and Zapatismo. Another recent form of anarchism critical of formal anarchist movements is insurrectionary anarchism which advocates informal organization and active resistance to the state; its proponents include Wolfi Landstreicher and Alfredo M. Bonanno.
Anarcho-capitalism (also free-market anarchism) is "based on a belief in the freedom to own private property, a rejection of any form of governmental authority or intervention, and the upholding of the competitive free market as the main mechanism for social interaction." Because of the historically anti-capitalist nature of most anarchist thought, the status of anarcho-capitalism within anarchism is disputed, particularly by communist anarchists. Anarcho-capitalists distinguish between free market capitalism – peaceful voluntary exchange – from "state capitalism" which Murray Rothbard defined as a collusive partnership between big business and government that uses coercion to subvert the free market. Whether in its natural rights-based or utilitarian formulations, anarcho-capitalism has a theory of legitimacy that supports private property as long as it was obtained by labor, trade, or gift. In an anarcho-capitalist society, its proponents hold, voluntary market processes would result in the provision of social institutions such as law enforcement, defence and infrastructure by competing for-profit firms, charities or voluntary associations. rather than the state. In Rothbardian anarcho-capitalism, law (the non-aggression principle) is enforced by the market but not created by it, while according to the "Chicago School" versionepitomized by David D. Friedman, the law itself is produced by the market.
While the term "anarcho-capitalism" was coined by Rothbard and its origin is attributed to 1960's America, some historians, including Rothbard himself, trace the school as far back as the mid-19th century. Anarcho-capitalism has drawn influence from pro-market theorists such as Gustave de Molinari, Frédéric Bastiat, and Robert Nozick, as well as American individualist thinkers such as Benjamin Tucker and Lysander Spooner. Considered a form of individualist anarchism, it differs from the individualism of the "Boston anarchists" of the 19th century in its rejection of the labor theory of value (and its normative implications) in favor of the neoclassical or Austrian School marginalist view. Anarcho-capitalist ideas have in turn contributed to the development of agorism, autarchism, and crypto-anarchism.
Anarcha-feminism is a synthesis of radical feminism and anarchism that views patriarchy (male domination over women) as a fundamental manifestation of involuntary hierarchy – to which anarchists are opposed. Anarcha-feminism was inspired in the late 19th century by the writings of early feminist anarchists such as Lucy Parsons, Emma Goldman and Voltairine de Cleyre. Anarcha-feminists, like other radical feminists, criticize and advocate the abolition of traditional conceptions of family, education and gender roles. Many Anarcha-feminists are especially critical of marriage for instance the feminist anarchist Emma Goldman has argued that marriage is a purely economic arrangement.. [woman] pays for it with her name, her privacy, her self-respect, her very life.". Anarcha-feminists by contrast view patriarchy as a fundamental problem in society and believe that the feminist struggle against sexism and patriarchy is an essential component of the anarchist struggle against the state and capitalism. L. Susan Brown expressed the sentiment that "as anarchism is a political philosophy that opposes all relationships of power, it is inherently feminist".
Anarcho-primitivism has been cited as a form of anarchism that addresses feminist concerns. Anarcho-primitivists, inspired by the work of anthropologists such as Jared Diamond and Eleanor Leacock - who describe a typically egalitarian relationship between men and women in foraging societies - believe that agriculture not only gave rise to forms of domination such as class distinctions but to patriarchy and sexism as well.
Green anarchism is a school of thought within anarchism which emphasizes natural environment. Primitivist and anti-civilization green anarchists advocate a return to a pre-industrial and usually pre-agricultural society. They critique industrial civilization from the perspective that technology and development have alienated people from the natural world. This strand of green anarchism philosophy develops themes present in the political action of the Luddites and the writings of Jean-Jacques Rousseau, although when primitivism emerged it was influenced more directly by the works of theorists such as the Frankfurt School Marxists Theodor Adorno and Herbert Marcuse; and anthropologists Marshall Sahlins and Richard Borshay Lee. Green anarchists such as Derrick Jensen and John Zerzan, identifying themselves as primitivists, advocate a process of 'rewilding' and a return to nomadic hunter-gatherer lifestyles, though both also advocate the use of permaculture techniques.
 Other forms of green anarchism only wish to see an end to industrial society and do not necessarily oppose domestication or agriculture. Non-primitivist green anarchists, such as anthropologist Brian Morris, often draw influence from the social ecology of Murray Bookchin.
"Anarchism without adjectives", in the words of historian George Richard Esenwein, "referred to an unhyphenated form of anarchism, that is, a doctrine without any qualifying labels such as communist, collectivist, mutualist, or individualist. For others,…[it] was simply understood as an attitude that tolerated the coexistence of different anarchist schools". "Anarchism without adjectives" emphasizes harmony between various anarchist factions and attempts to unite them around their shared anti-authoritarian beliefs.
The position was first adopted in 1889 by Fernando Tarrida del Mármol as a call for toleration, after being troubled by the "bitter debates" between the different anarchist movements. Voltairine de Cleyre, Errico Malatesta, and Fred Woodworth are noteworthy exponents of the view.
Anarchism as a social movement has regularly endured fluctuations in popularity. Its classical period, which scholars demarcate as from 1860 to 1939, is associated with the working-class movements of the nineteenth century and the Spanish Civil War-era struggles against fascism.
In Europe, harsh reaction followed the revolutions of 1848, but in 1864 the International Workingmen's Association (sometimes called the "First International") united diverse revolutionary currents including French followers of Proudhon, Blanquists, Freemasons (Philadelphes), English trade unionists, socialists and social democrats. Due to its links to active workers' movements, the International became a significant organization. Karl Marx became a leading figure in the International and a member of its General Council. Proudhon's followers, the mutualists, opposed Marx's state socialism, advocating political abstentionism and small property holdings. In 1868, following their unsuccessful participation in the League of Peace and Freedom (LPF), Mikhail Bakunin and his associates joined the First International - which had decided not to get involved with the LPF. They allied themselves with the anti-authoritarian socialist sections of the International, who advocated the revolutionary overthrow of the state and the collectivization of property. At first, the collectivists worked with the Marxists to push the First International in a more revolutionary socialist direction. Subsequently, the International became polarized into two camps, with Marx and Bakunin as their respective figureheads. Bakunin characterised Marx's ideas as authoritarian and predicted that, if a Marxist party came to power, its leaders would simply take the place of the ruling class they had fought against. In 1872, the conflict climaxed with a final split between the two groups, when, at the Hague Congress, Marx engineered the expulsion of Bakunin and James Guillaume from the International and had its headquarters transferred to New York. In response, the anti-authoritarian sections formed their own International at the St. Imier Congress, adopting a revolutionary anarchist program.
The anti-authoritarian sections of the First International were the precursors of the anarcho-syndicalists, seeking to "replace the privilege and authority of the State" with the "free and spontaneous organization of labor." In 1907, the International Anarchist Congress of Amsterdam gathered delegates from 14 different countries, among which important figures of the anarchist movement, including Errico Malatesta, Pierre Monatte, Luigi Fabbri, Benoît Broutchoux, Emma Goldman, Rudolf Rocker, Christiaan Cornelissen, etc. Various themes were treated during the Congress, in particular concerning the organisation of the anarchist movement, popular education issues, the general strike or antimilitarism. A central debate concerned the relation between anarchism and syndicalism (or trade unionism). Malatesta and Monatte in particular opposed themselves on this issue, as the latter thought that syndicalism was revolutionary and would create the conditions of a social revolution, while Malatesta considered that syndicalism by itself was not sufficient. Malatesta thought that trade-unions were reformist, and could even be, at times, conservative. Along with Cornelissen, he cited as example US trade-unions, where trade-unions composed of qualified workers sometimes opposed themselves to non-qualified workers in order to defend their relatively privileged position.
The Spanish Workers Federation in 1881 was the first major anarcho-syndicalist movement; anarchist trade union federations were of special importance in Spain. The most successful was the Confederación Nacional del Trabajo (National Confederation of Labour: CNT), founded in 1910. Before the 1940s, the CNT was the major force in Spanish working class politics and played a major role in the Spanish Civil War. The CNT was affiliated with the International Workers Association, a federation of anarcho-syndicalist trade unions founded in 1922, with delegates representing two million workers from 15 countries in Europe and Latin America. The largest organised anarchist movement today is in Spain, in the form of the Confederación General del Trabajo (CGT) and the CNT. CGT membership was estimated to be around 100,000 for the year 2003. Other active syndicalist movements include the US Workers Solidarity Alliance and the UK Solidarity Federation. The revolutionary industrial unionist Industrial Workers of the World, claiming 2,000 paying members, and the International Workers Association, an anarcho-syndicalist successor to the First International, also remain active.
Anarchists participated alongside the Bolsheviks in both February and October revolutions, many anarchists initially supporting the Bolshevik coup. However, the Bolsheviks soon turned against the anarchists and other left-wing opposition, a conflict that culminated in the 1921 Kronstadt rebellion. Anarchists in central Russia were either imprisoned or driven underground or joined the victorious Bolsheviks. In the Ukraine, anarchists fought in the civil war against Whites and then the Bolsheviks as part of the Revolutionary Insurrectionary Army of Ukraine led by Nestor Makhno, who attempted to establish an anarchist society in the region for a number of months.
Expelled American anarchists Emma Goldman and Alexander Berkman were amongst those agitating in response to Bolshevik policy and the suppression of the Kronstadt uprising, before they left Russia. Both wrote accounts of their experiences in Russia, criticizing the amount of control the Bolsheviks exercised. For them, Bakunin's predictions about the consequences of Marxist rule had proved all too true.
The victory of the Bolsheviks in the October Revolution and the resulting Russian Civil War did serious damage to anarchist movements internationally. Many workers and activists saw Bolshevik success as setting an example; Communist parties grew at the expense of anarchism and other socialist movements. In France and the US, for example, certain members of the major syndicalist movements of the CGT and IWW left the organizations and joined the Communist International.
In Paris, the Dielo Truda group of Russian anarchist exiles, which included Nestor Makhno, concluded that anarchists needed to develop new forms of organisation in response to the structures of Bolshevism. Their 1926 manifesto, called the Organizational Platform of the General Union of Anarchists (Draft), was supported by some communist anarchists, though opposed by many others. Platformist groups today include the Workers Solidarity Movement in Ireland and the North Eastern Federation of Anarchist Communists of North America.
In the 1920s and 1930s, the rise of fascism in Europe transformed anarchism's conflict with the state. Italy saw the first struggles between anarchists and fascists. Italian anarchists played a key role in the anti-fascist organisation Arditi del Popolo, which was strongest in areas with anarchist traditions and marked up numerous successful victories, including repelling Blackshirts in the anarchist stronghold of Parma in August 1922. In France, where the far right leagues came close to insurrection in the February 1934 riots, anarchists divided over a united front policy.
In Spain, the CNT initially refused to join a popular front electoral alliance and abstention by CNT supporters led to a right wing election victory. But in 1936, the CNT changed its policy and anarchist votes helped bring the popular front back to power. Months later, the ruling class responded with an attempted coup, and the Spanish Civil War (1936-1939) was underway. In response to the army rebellion, an anarchist-inspired movement of peasants and workers, supported by armed militias, took control of Barcelona and of large areas of rural Spain where they collectivized the land. But even before the eventual fascist victory in 1939, the anarchists were losing ground in a bitter struggle with the Stalinists, who controlled the distribution of military aid to the Republican cause from the Soviet Union. According to George Orwell and other foreign observers, Stalinist-led troops suppressed the collectives and persecuted both dissident Marxists and anarchists.
Anarchism is a philosophy which embodies many diverse and heterogeneous attitudes, tendencies and schools of thought; as such, disagreement over questions of values, ideology and tactics is common. The compatibility of capitalism (which anarchists usually reject, according to The Oxford Companion to Philosophy), nationalism and religion with anarchism is widely disputed. Similarly, anarchism enjoys a complex relationship with ideologies such as Marxism, communism and anarcho-capitalism. Anarchists may be motivated by humanism, divine authority, enlightened self-interest or any number of alternative ethical doctrines.
Phenomena such as civilization, technology (e.g. within primitivism and insurrectionary anarchism), and the democratic process may be sharply criticized within some anarchist tendencies and simultaneously lauded in others. Anarchist attitudes towards race, gender and the environment have changed significantly since the modern origin of the philosophy in the eighteenth century.
On a tactical level, while propaganda of the deed was a tactic used by anarchists in the 19th century (e.g. the Nihilist movement), contemporary anarchists espouse alternative methods such as nonviolence, counter-economics and anti-state cryptography to bring about an anarchist society. The diversity in anarchism has led to widely different use of identical terms among different anarchist traditions, which has led to many definitional concerns in anarchist theory.


Autism is a brain development disorder that impairs social interaction and communication, and causes restricted and repetitive behavior, all starting before a child is three years old. This set of signs distinguishes autism from milder autism spectrum disorders (ASD) such as Asperger syndrome.
Autism is highly heritable, although the genetics of autism are complex and it is generally unclear which genes are responsible. In rare cases, autism is strongly associated with agents that cause birth defects. Other proposed causes, such as childhood vaccines, are controversial and the vaccine hypotheses lack convincing scientific evidence. Most recent reviews estimate a prevalence of one to two cases per 1,000 people for autism, and about six per 1,000 for ASD, with ASD averaging a 4.3:1 male-to-female ratio. The number of people known to have autism has increased dramatically since the 1980s, at least partly due to changes in diagnostic practice; the question of whether actual prevalence has increased is unresolved.
Autism affects many parts of the brain; how this occurs is poorly understood. Parents usually notice signs in the first two years of their child's life. Early behavioral or cognitive intervention can help children gain self-care, social, and communication skills. There is no cure. Few children with autism live independently after reaching adulthood, but some become successful, and an autistic culture has developed, with some seeking a cure and others believing that autism is a condition rather than a disorder.
Autism is a developmental disorder of the human brain that first gives signs during infancy or childhood and follows a steady course without remission or relapse. Impairments result from maturation-related changes in various systems of the brain. Autism is one of the five pervasive developmental disorders (PDD), which are characterized by widespread abnormalities of social interactions and communication, and severely restricted interests and highly repetitive behavior.
Of the other four PDD forms, Asperger syndrome is closest to autism in signs and likely causes; Rett syndrome and childhood disintegrative disorder share several signs with autism, but may have unrelated causes; PDD not otherwise specified (PDD-NOS) is diagnosed when the criteria are not met for a more specific disorder. Unlike autism, Asperger's has no substantial delay in language development. The terminology of autism can be bewildering, with autism, Asperger's and PDD-NOS often called the autism spectrum disorders (ASD) or sometimes the autistic disorders, whereas autism itself is often called autistic disorder, childhood autism, or infantile autism. In this article, autism refers to the classic autistic disorder, while other sources sometimes use autism or the autisms to refer to ASD, or equate ASD with PDD. ASD, in turn, is a subset of the broader autism phenotype (BAP), which describes individuals who may not have ASD but do have autistic-like traits, such as avoiding eye contact.
The manifestations of autism cover a wide spectrum, ranging from individuals with severe impairments—who may be silent, mentally disabled, and locked into hand flapping and rocking—to less impaired individuals who may have active but distinctly odd social approaches, narrowly focused interests, and verbose, pedantic communication. Sometimes the syndrome is divided into low-, medium- and high-functioning autism (LFA, MFA, and HFA), based on IQ thresholds, or on how much support the individual requires in daily life; these subdivisions are not standardized and are controversial. Autism can also be divided into syndromal and non-syndromal autism, where the former is associated with severe or profound mental retardation or a congenital syndrome with physical symptoms, such as tuberous sclerosis. Although individuals with Asperger's tend to perform better cognitively than those with autism, the extent of the overlap between Asperger's, HFA, and non-syndromal autism is unclear.
Some studies have reported diagnoses of autism in children due to a loss of language or social skills after 14 months of age, as opposed to a failure to make progress. Several terms are used for this phenomenon, including regressive autism, setback autism, and developmental stagnation. The validity of this distinction remains controversial; it is possible that regressive autism is a specific subtype.
Autism is distinguished by a pattern of symptoms rather than one single symptom. The main characteristics are impairments in social interaction, impairments in communication, restricted interests and repetitive behavior. Other aspects, such as atypical eating, are also common but are not essential for diagnosis. Individual symptoms of autism occur in the general population and appear not to associate highly, without a sharp line separating pathological severity from common traits.
People with autism have social impairments and often lack the intuition about others that many people take for granted. Noted autistic Temple Grandin described her inability to understand the social communication of neurotypicals as leaving her feeling "like an anthropologist on Mars".
Social impairments become apparent early in childhood and continue through adulthood. Autistic infants show less attention to social stimuli, smile and look at others less often, and respond less to their own name. Autistic toddlers have more striking social deviance; for example, they have less eye contact and anticipatory postures and are less likely to use another person's hand or body as a tool. Three- to five-year-old autistic children are less likely to exhibit social understanding, approach others spontaneously, imitate and respond to emotions, communicate nonverbally, and take turns with others. However, they do form attachments to their primary caregivers. They display moderately less attachment security than usual, although this feature disappears in children with higher mental development or less severe ASD. Older children and adults with ASD perform worse on tests of face and emotion recognition.
Contrary to common belief, autistic children do not prefer to be alone. Making and maintaining friendships often proves to be difficult for those with autism. For them, the quality of friendships, not the number of friends, predicts how lonely they are.
There are many anecdotal reports, but few systematic studies, of aggression and violence in individuals with ASD. The limited data suggest that in children with mental retardation, autism is associated with aggression, destruction of property, and tantrums. Dominick et al. interviewed the parents of 67 children with ASD and reported that about two-thirds of the children had periods of severe tantrums and about one-third had a history of aggression, with tantrums significantly more common than in children with a history of language impairment.
About a third to a half of individuals with autism do not develop enough natural speech to meet their daily communication needs. Differences in communication may be present from the first year of life, and may include delayed onset of babbling, unusual gestures, diminished responsiveness, and the desynchronization of vocal patterns with the caregiver. In the second and third years, autistic children have less frequent and less diverse babbling, consonants, words, and word combinations; their gestures are less often integrated with words. Autistic children are less likely to make requests or share experiences, and are more likely to simply repeat others' words (echolalia) or reverse pronouns. Autistic children may have difficulty with imaginative play and with developing symbols into language. They are more likely to have problems understanding pointing; for example, they may look at a pointing hand instead of the pointed-at object.
In a pair of studies, high-functioning autistic children aged 8–15 performed equally well, and adults better than individually matched controls at basic language tasks involving vocabulary and spelling. Both autistic groups performed worse than controls at complex language tasks such as figurative language, comprehension and inference. As people are often sized up initially from their basic language skills, these studies suggest that people speaking to autistic individuals are more likely to overestimate what their audience comprehends.
Autistic individuals display many forms of repetitive or restricted behavior, which the Repetitive Behavior Scale-Revised (RBS-R) categorizes as follows.
No single repetitive behavior seems to be specific to autism, but only autism appears to have an elevated pattern of occurrence and severity of these behaviors.
Autistic individuals may have symptoms that are independent of the diagnosis, but that can affect the individual or the family.
A small fraction of individuals with ASD show unusual abilities, ranging from splinter skills such as the memorization of trivia to the extraordinarily rare talents of prodigious autistic savants.
Unusual responses to sensory stimuli are more common and prominent in autistic children, although there is no good evidence that sensory symptoms differentiate autism from other developmental disorders. The responses may be more common in children: a pair of studies found that autistic children had impaired tactile perception while autistic adults did not. The same two studies also found that autistic individuals had more problems with complex memory and reasoning tasks such as Twenty Questions; these problems were somewhat more marked among adults.
Several studies have reported associated motor problems that include poor muscle tone, poor motor planning, and toe walking; ASD is not associated with severe motor disturbances.
Atypical eating behavior occurs in about three-quarters of children with ASD, to the extent that it was formerly a diagnostic indicator. Selectivity is the most common problem, although eating rituals and food refusal also occur; this does not appear to result in malnutrition. Although some children with autism also have gastrointestinal (GI) symptoms, there is a lack of published rigorous data to support the theory that autistic children have more or different GI symptoms than usual; studies report conflicting results, and the relationship between GI problems and ASD is unclear.
Sleep problems are known to be more common in children with developmental disabilities, and there is some evidence that children with ASD are more likely to have even more sleep problems than those with other developmental disabilities; autistic children may experience problems including difficulty in falling asleep, frequent nocturnal awakenings, and early morning awakenings. Dominick et al. found that about two-thirds of children with ASD had a history of sleep problems.
Parents of children with ASD have higher levels of stress. Siblings of children with ASD report greater admiration of and less conflict with the affected sibling; siblings of individuals with ASD have greater risk of negative well-being and poorer sibling relationships as adults.
Genetic factors for autism are the most significant cause for autism spectrum disorders. Early studies of twins estimated heritability explains more than 90% of autism cases. However, most of the mutations that increase autism risk have not been identified. Typically, autism cannot be traced to a Mendelian (single-gene) mutation or to single chromosome abnormalities such as fragile X syndrome or 22q13 deletion syndrome. There may be significant interactions among mutations in several genes, or between the environment and mutated genes. Numerous candidate genes have been located; most encode proteins involved in neural development and function. The large number of autistic individuals with unaffected family members may result from copy number variations (CNVs)—spontaneous deletions or duplications in genetic material during meiosis. Hence, a substantial fraction of autism may be highly heritable but not inherited: that is, the mutation that causes the autism is not present in the parental genome.
All known teratogens (agents that cause birth defects) related to the risk of autism appear to act during the first eight weeks from conception, and though this does not exclude the possibility that autism can be initiated or affected later, it is strong evidence that autism arises very early in development. Although evidence for other environmental causes is anecdotal and has not been confirmed by reliable studies, extensive searches are underway. Environmental factors that have been claimed to contribute to or exacerbate autism, or may be important in future research, include certain foods, infectious disease, heavy metals, solvents, diesel exhaust, PCBs, phthalates and phenols used in plastic products, pesticides, brominated flame retardants, alcohol, smoking, illicit drugs, and vaccines. Although parents may first become aware of autistic symptoms in their child around the time of a routine vaccination, and parental concern about vaccines has led to a decreasing uptake of childhood immunizations and an increasing likelihood of measles outbreaks, there is overwhelming scientific evidence showing no causal association between the measles-mumps-rubella vaccine and autism, and there is no scientific evidence that the vaccine preservative thiomersal helps cause autism.
Despite extensive investigation, how autism occurs is not well understood. Its mechanism can be divided into two areas: the pathophysiology of brain structures and processes associated with autism, and the neuropsychological linkages between brain structures and behaviors. The behaviors appear to have multiple pathophysiologies.
Interactions between the immune system and the nervous system begin early during embryogenesis, and successful neurodevelopment depends on a balanced immune response. Several symptoms consistent with a poorly regulated immune response have been reported in autistic children. It is possible that aberrant immune activity during critical periods of neurodevelopment is part of the mechanism of some forms of ASD. As autoantibodies have not been associated with pathology, are found in diseases other than ASD, and are not always present in ASD, the relationship between immune disturbances and autism remains unclear and controversial.
Several neurotransmitter abnormalities have been detected in autism, notably increased blood levels of serotonin. Whether these lead to structural or behavioral abnormalities is unclear. Also, some inborn errors of metabolism are associated with autism but probably account for less than 5% of cases.
The mirror neuron system (MNS) theory of autism hypothesizes that distortion in the development of the MNS interferes with imitation and leads to autism's core features of social impairment and communication difficulties. The MNS operates when an animal performs an action or observes another animal of the same species perform the same action. The MNS may contribute to an individual's understanding of other people by enabling the modeling of their behavior via embodied simulation of their actions, intentions, and emotions. Several studies have tested this hypothesis by demonstrating structural abnormalities in MNS regions of individuals with ASD, delay in the activation in the core circuit for imitation in individuals with Asperger's, and a correlation between reduced MNS activity and severity of the syndrome in children with ASD. However, individuals with autism also have abnormal brain activation in many circuits outside the MNS and the MNS theory does not explain the normal performance of autistic children on imitation tasks that involve a goal or object.
A 2008 study of autistic adults found evidence for altered functional organization of the task-negative network, a large-scale brain network involved in social and emotional processing, with intact organization of the task-positive network, used in sustained attention and goal-directed thinking. A 2008 brain-imaging study found a specific pattern of signals in the cingulate cortex which differs in individuals with ASD.
The underconnectivity theory of autism hypothesizes that autism is marked by underfunctioning high-level neural connections and synchronization, along with an excess of low-level processes. Evidence for this theory has been found in functional neuroimaging studies on autistic individuals and by a brain wave study that suggested that adults with ASD have local overconnectivity in the cortex and weak functional connections between the frontal lobe and the rest of the cortex. Other evidence suggests the underconnectivity is mainly within each hemisphere of the cortex and that autism is a disorder of the association cortex.
Two major categories of cognitive theories have been proposed about the links between autistic brains and behavior.
The first category focuses on deficits in social cognition. Hyper-systemizing hypothesizes that autistic individuals can systematize—that is, they can develop internal rules of operation to handle internal events—but are less effective at empathizing by handling events generated by other agents. It extends the extreme male brain theory, which hypothesizes that autism is an extreme case of the male brain, defined psychometrically as individuals in whom systemizing is better than empathizing. This in turn is related to the earlier theory of mind, which hypothesizes that autistic behavior arises from an inability to ascribe mental states to oneself and others. The theory of mind is supported by autistic children's atypical responses to the Sally-Anne test for reasoning about others' motivations, and is mapped well from the mirror neuron system theory of autism.
The second category focuses on nonsocial or general processing. Executive dysfunction hypothesizes that autistic behavior results in part from deficits in flexibility, planning, and other forms of executive function. A strength of the theory is predicting stereotyped behavior and narrow interests; a weakness is that executive function deficits are not found in young autistic children. Weak central coherence theory hypothesizes that a limited ability to see the big picture underlies the central disturbance in autism. One strength of this theory is predicting special talents and peaks in performance in autistic people. A related theory—enhanced perceptual functioning—focuses more on the superiority of locally oriented and perceptual operations in autistic individuals. These theories map well from the underconnectivity theory of autism.
Neither category is satisfactory on its own; social cognition theories poorly address autism's rigid and repetitive behaviors, while the nonsocial theories have difficulty explaining social impairment and communication difficulties. A combined theory based on multiple deficits may prove to be more useful.
The American Academy of Pediatrics recommends that all children be screened for ASD at the 18- and 24-month well-child doctor visits, using autism-specific formal screening tests. In contrast, the UK National Screening Committee recommends against screening for ASD in the general population, because screening tools have not been fully validated and interventions lack sufficient evidence for effectiveness. Screening tools include the Modified Checklist for Autism in Toddlers (M-CHAT), the Early Screening of Autistic Traits Questionnaire, and the First Year Inventory; initial data on M-CHAT and its predecessor CHAT on children aged 18–30 months suggests that it is best used in a clinical setting and that it has low sensitivity (many false-negatives) but good specificity (few false-positives). Genetic screening for autism is generally still impractical.
Diagnosis is based on behavior, not cause or mechanism. Autism is defined in the DSM-IV-TR as exhibiting at least six symptoms total, including at least two symptoms of qualitative impairment in social interaction, at least one symptom of qualitative impairment in communication, and at least one symptom of restricted and repetitive behavior. Sample symptoms include lack of social or emotional reciprocity, stereotyped and repetitive use of language or idiosyncratic language, and persistent preoccupation with parts of objects. Onset must be prior to age three years, with delays or abnormal functioning in either social interaction, language as used in social communication, or symbolic or imaginative play. The disturbance must not be better accounted for by Rett syndrome or childhood disintegrative disorder. ICD-10 uses essentially the same definition.
Several diagnostic instruments are available. Two are commonly used in autism research: the Autism Diagnostic Interview-Revised (ADI-R) is a semistructured parent interview, and the Autism Diagnostic Observation Schedule (ADOS) uses observation and interaction with the child. The Childhood Autism Rating Scale (CARS) is used widely in clinical environments to assess severity of autism based on observation of children.
A pediatrician commonly performs a preliminary investigation by taking developmental history and physically examining the child. If warranted, diagnosis and evaluations are conducted with help from ASD specialists, observing and assessing cognitive, communication, family, and other factors using standardized tools, and taking into account any associated medical conditions. A differential diagnosis for ASD at this stage might also consider mental retardation, hearing impairment, and a specific language impairment such as Landau-Kleffner syndrome. ASD can sometimes be diagnosed by age 14 months, although diagnosis becomes increasingly stable over the first three years of life: for example, a one-year-old who meets diagnostic criteria for ASD is less likely than a three-year-old to continue to do so a few years later. In the UK the National Autism Plan for Children recommends at most 30 weeks from first concern to completed diagnosis and assessment, though few cases are handled that quickly in practice. A 2006 U.S. study found the average age of first evaluation by a qualified professional was 48 months and of formal ASD diagnosis was 61 months, reflecting an average 13-month delay, all far above recommendations.
Clinical genetics evaluations are often done once ASD is diagnosed, particularly when other symptoms already suggest a genetic cause. Although genetic technology allows clinical geneticists to link an estimated 40% of cases to genetic causes, consensus guidelines in the U.S. and UK are limited to high-resolution chromosome and fragile X testing. As new genetic tests are developed several ethical, legal, and social issues will emerge. Commercial availability of tests may precede adequate understanding of how to use test results, given the complexity of autism's genetics. Metabolic and neuroimaging tests are sometimes helpful, but are not routine.
Underdiagnosis and overdiagnosis are problems in marginal cases, and much of the recent increase in the number of reported ASD cases is likely due to changes in diagnostic practices. The increasing popularity of drug treatment options and the expansion of benefits has given providers incentives to diagnose ASD, resulting in some overdiagnosis of children with uncertain symptoms. Conversely, the cost of screening and diagnosis and the challenge of obtaining payment can inhibit or delay diagnosis. It is particularly hard to diagnose autism among the visually impaired, partly because some of its diagnostic criteria depend on vision, and partly because autistic symptoms overlap with those of common blindness syndromes.
The symptoms of autism and ASD begin early in childhood but are occasionally missed. Adults may seek retrospective diagnoses to help them or their friends and family understand themselves, to help their employers make adjustments, or in some locations to claim disability living allowances or other benefits.
The main goals of treatment are to lessen associated deficits and family distress, and to increase quality of life and functional independence. No single treatment is best and treatment is typically tailored to the child's needs. Intensive, sustained special education programs and behavior therapy early in life can help children acquire self-care, social, and job skills; claims that intervention by age two to three years is crucial are not substantiated. Available approaches include applied behavior analysis, developmental, and structured teaching. Educational interventions have some effectiveness in children; the limited research on the effectiveness of adult residential programs shows mixed results.
Medications are often used to treat problems associated with ASD. More than half of U.S. children diagnosed with ASD are prescribed psychoactive drugs or anticonvulsants, with the most common drug classes being antidepressants, stimulants, and antipsychotics. Aside from antipsychotics, there is scant reliable research about the effectiveness or safety of drug treatments for adolescents and adults with ASD. A person with ASD may respond atypically to medications, the medications can have adverse side effects, and no known medication relieves autism's core symptoms of social and communication impairments.
Many alternative therapies and interventions are available. Few are supported by scientific studies. Treatment approaches lack empirical support in quality-of-life contexts, and many programs focus on success measures that lack predictive validity and real-world relevance. Scientific evidence appears to matter less to service providers than program marketing, training availability, and parent requests. Many treatments are probably harmless. Some are not: for example, in 2005, botched chelation therapy killed a five-year-old autistic boy.
Treatment is expensive; indirect costs are more so. A U.S. study estimated an average cost of $3.2 million in 2003 U.S. dollars for someone born in 2000, with about 10% medical care, 30% extra education and other care, and 60% lost economic productivity. Publicly supported programs are often inadequate or inappropriate for a given child, and unreimbursed out-of-pocket medical or therapy expenses are associated with likelihood of family financial problems. After childhood, key treatment issues include residential care, job training and placement, sexuality, social skills, and estate planning.
There is no cure. Most children with autism lack social support, meaningful relationships, future employment opportunities or self-determination. Although core difficulties remain, symptoms often become less severe in later childhood. Few high-quality studies address long-term prognosis. Some adults show modest improvement in communication skills, but a few decline; no study has focused on autism after midlife. Acquiring language before age six, having IQ above 50, and having a marketable skill all predict better outcomes; independent living is unlikely with severe autism. A 2004 British study of 68 adults who were diagnosed before 1980 as autistic children with IQ above 50 found that 12% achieved a high level of independence as adults, 10% had some friends and were generally in work but required some support, 19% had some independence but were generally living at home and needed considerable support and supervision in daily living, 46% needed specialist residential provision from facilities specializing in ASD with a high level of support and very limited autonomy, and 12% needed high-level hospital care. A 2005 Swedish study of 78 adults that did not exclude low IQ found worse prognosis; for example, only 4% achieved independence. Changes in diagnostic practice and increased availability of effective early intervention make it unclear whether these findings can be generalized to recently diagnosed children.
Most recent reviews tend to estimate a prevalence of 1–2 per 1,000 for autism and close to 6 per 1,000 for ASD; because of inadequate data, these numbers may underestimate ASD's true prevalence. PDD-NOS is the vast majority of ASD, Asperger's is about 0.3 per 1,000 and the remaining ASD forms are much rarer. The number of reported cases of autism increased dramatically in the 1990s and early 2000s. This increase is largely attributable to changes in diagnostic practices, referral patterns, availability of services, age at diagnosis, and public awareness, though as-yet-unidentified contributing environmental risk factors cannot be ruled out. It is unknown whether autism's prevalence increased during the same period. An increase in prevalence would suggest directing more attention and funding toward changing environmental factors instead of continuing to focus on genetics.
The risk of autism is associated with several prenatal and perinatal risk factors. A 2007 review of risk factors found associated parental characteristics that included advanced maternal age, advanced paternal age, and maternal place of birth outside Europe or North America, and also found associated obstetric conditions that included low birth weight and gestation duration, and hypoxia during childbirth.
A few examples of autistic symptoms and treatments were described long before autism was named. The Table Talk of Martin Luther contains a story of a 12-year-old boy who may have been severely autistic. According to Luther's notetaker Mathesius, Luther thought the boy was a soulless mass of flesh possessed by the devil, and suggested that he be suffocated. Victor of Aveyron, a feral child caught in 1798, showed several signs of autism; the medical student Jean Itard treated him with a behavioral program designed to help him form social attachments and to induce speech via imitation.
The word autism first took its modern sense in 1938 when Hans Asperger of the Vienna University Hospital adopted Bleuler's terminology "autistic psychopaths" in a lecture in German about child psychology. Asperger was investigating a form of ASD now known as Asperger syndrome, though for various reasons it was not widely recognized as a separate diagnosis until 1981. Leo Kanner of the Johns Hopkins Hospital first used autism in its modern sense in English when he introduced the label early infantile autism in a 1943 report of 11 children with striking behavioral similarities. Almost all the characteristics described in Kanner's first paper on the subject, notably "autistic aloneness" and "insistence on sameness", are still regarded as typical of the autistic spectrum of disorders. It is not known whether Kanner derived the term independently of Asperger.
Kanner's reuse of autism led to decades of confused terminology like "infantile schizophrenia", and child psychiatry's focus on maternal deprivation during the mid-1900s led to misconceptions of autism as an infant's response to "refrigerator mothers". Starting in the late 1960s autism was established as a separate syndrome by demonstrating that it is lifelong, distinguishing it from mental retardation and schizophrenia and from other developmental disorders, and demonstrating the benefits of involving parents in active programs of therapy. As late as the mid-1970s there was little evidence of a genetic role in autism; now it is thought to be one of the most heritable of all psychiatric conditions. The rise of parent organizations and the destigmatization of childhood ASD have deeply affected how we view ASD, its boundaries, and its treatments. The Internet has helped autistic individuals bypass nonverbal cues and emotional sharing that they find so hard to deal with, and has given them a way to form online communities and work remotely. Sociological and cultural aspects of autism have developed: some in the community seek a cure, while others believe that autism is simply another way of being.

the ratio of diffusely reflected to incident electromagnetic radiation. It is a unitless measure indicative of a surface's or body's diffuse reflectivity. The word is derived from Latin albedo "whiteness", in turn from albus "white". The range of possible values is from 0 (dark) to 1 (bright).
The albedo is an important concept in climatology and astronomy. In climatology it is sometimes expressed as a percentage. Its value depends on the frequency of radiation considered: unqualified, it usually refers to some appropriate average across the spectrum of visible light. In general, the albedo depends on the direction and directional distribution of incoming radiation. Exceptions are Lambertian surfaces, which scatter radiation in all directions in a cosine function, so their albedo does not depend on the incoming distribution. In realistic cases, a bidirectional reflectance distribution function (BRDF) is required to characterize the scattering properties of a surface accurately, although albedos are a very useful first approximation.
Albedos of typical materials in visible light range from up to 90% for fresh snow, to about 4% for charcoal, one of the darkest substances. Deeply shadowed cavities can achieve an effective albedo approaching the zero of a blackbody. When seen from a distance, the ocean surface has a low albedo, as do most forests, while desert areas have some of the highest albedos among landforms. Most land areas are in an albedo range of.1 to.4. The average albedo of the Earth is about 30%. This is far higher than for the ocean primarily because of the contribution of clouds.
Human activities have changed the albedo (via forest clearance and farming, for example) of various areas around the globe. However, quantification of this effect is difficult on the global scale.
The classic example of albedo effect is the snow-temperature feedback. If a snow covered area warms and the snow melts, the albedo decreases, more sunlight is absorbed, and the temperature tends to increase. The converse is true: if snow forms, a cooling cycle happens. The intensity of the albedo effect depends on the size of the change in albedo and the amount of insolation; for this reason it can be potentially very large in the tropics.
The Earth's surface albedo is regularly estimated via Earth observation satellite sensors such as NASA's MODIS instruments onboard the Terra and Aqua satellites. As the total amount of reflected radiation cannot be directly measured by satellite, a mathematical model of the BRDF is used to translate a sample set of satellite reflectance measurements into estimates of directional-hemispherical reflectance and bi-hemispherical reflectance.
It has been shown that for many applications involving terrestrial albedo, the albedo at a particular solar zenith angle can reasonably be approximated by the proportionate sum of two terms: the directional-hemispherical reflectance at that solar zenith angle, and the bi-hemispherical reflectance, the proportion concerned being defined as the proportion of diffuse illumination.
Directional-hemispherical reflectance is sometimes referred to as black-sky albedo and bi-hemispherical reflectance as white sky albedo. These terms are important because they allow the albedo to be calculated for any given illumination conditions from a knowledge of the intrinsic properties of the surface.
The albedo of planets, satellites and asteroids can be used to infer much about their properties. The study of albedos, their dependence on wavelength, lighting angle ("phase angle"), and variation in time comprises a major part of the astronomical field of photometry. For small and far objects that cannot be resolved by telescopes, much of what we know comes from the study of their albedos. For example, the absolute albedo can indicate the surface ice content of outer solar system objects, the variation of albedo with phase angle gives information about regolith properties, while unusually high radar albedo is indicative of high metallic content in asteroids.
Enceladus, a moon of Saturn, has one of the highest known albedos of any body in the solar system, with 99% of EM radiation reflected. Another notable high albedo body is Eris, with an albedo of 86%. Many objects in the outer solar system and asteroid belt have low albedos down to about 5%. Such a dark surface is thought to be indicative of a primitive and heavily space weathered surface containing some organic compounds.
The overall albedo of the Moon is around 7%, but it is strongly directional and non-Lambertian, displaying also a strong opposition effect. While such reflectance properties are different from those of any terrestrial terrains, they are typical of the regolith surfaces of airless solar system bodies.
Two common albedos that are used in astronomy are the geometric albedo (measuring brightness when illumination comes from directly behind the observer) and the Bond albedo (measuring total proportion of electromagnetic energy reflected). Their values can differ significantly, which is a common source of confusion.
In detailed studies, the directional reflectance properties of astronomical bodies are often expressed in terms of the five Hapke parameters which semi-empirically describe the variation of albedo with phase angle, including a characterisation of the opposition effect of regolith surfaces.
where is astronomical albedo, is diameter in km.
Single scattering albedo - is used to define scattering of electromagnetic waves on small particles. It depends on properties of the material (refractive index), the size of the particle(s), and the wavelength of the incoming radiation.
According to the National Climatic Data Center's GHCN 2 data, which is composed of 30-year smoothed climatic means for thousands of weather stations across the world, the college weather station at Fairbanks, Alaska, is about 3 °C (5.4 °F) warmer than the airport at Fairbanks, partly because of air drainage patterns but also largely because of the lower albedo at the college resulting from a higher concentration of spruce trees and therefore less open snowy ground to reflect the heat back into space.
Although the albedo-temperature effect is most famous in colder regions of Earth, because more snow falls there, it is actually much stronger in tropical regions because in the tropics there is consistently more sunlight. When Brazilian ranchers cut down dark, tropical rainforest trees to replace them with even darker soil in order to grow crops, the average temperature of the area increases up to 3 °C (5.4 °F) year-round, although part of the effect is due to changed evaporation (latent heat flux).
Albedo works on a smaller scale, too. People who wear dark clothes in the summertime put themselves at a greater risk of heatstroke than those who wear lighter color clothes.
The albedo of a pine forest at 45°N in the winter in which the trees cover the land surface completely is only about 9%, among the lowest of any naturally occurring land environment. This is partly due to the color of the pines, and partly due to multiple scattering of sunlight within the trees which lowers the overall reflected light level. Due to light penetration, the ocean's albedo is even lower at about 3.5%, though this depends strongly on the angle of the incident radiation. Dense swampland averages between 9% and 14%. Deciduous trees average about 13%. A grassy field usually comes in at about 20%. A barren field will depend on the color of the soil, and can be as low as 5% or as high as 40%, with 15% being about the average for farmland. A desert or large beach usually averages around 25% but varies depending on the color of the sand.
Urban areas in particular have very unnatural values for albedo because of the many human-built structures which absorb light before the light can reach the surface. In the northern part of the world, cities are relatively dark, and Walker has shown that their average albedo is about 7%, with only a slight increase during the summer. In most tropical countries, cities average around 12%. This is similar to the values found in northern suburban transitional zones. Part of the reason for this is the different natural environment of cities in tropical regions, e.g. there are more very dark trees around; another reason is that portions of the tropics are very poor, and city buildings must be built with different materials. Warmer regions may also choose lighter colored building materials so the structures will remain cooler.
Because trees tend to have a low albedo, removing forests would tend to increase albedo and thereby could produce localized climate cooling. Cloud feedbacks further complicate the issue. In seasonally snow-covered zones, winter albedos of treeless areas are 10% to 50% higher than nearby forested areas because snow does not cover the trees as readily. Deciduous trees have an albedo value of about 0.15 to 0.18 while coniferous trees have a value of about 0.09 to 0.15. The difference between deciduous and coniferous is because coniferous trees are darker in general and have cone-shape seeds. The pattern of these seeds trap light energy more than deciduous trees.
Studies by the Hadley Centre have investigated the relative (generally warming) effect of albedo change and (cooling) effect of carbon sequestration on planting forests. They found that new forests in tropical and midlatitude areas tended to cool; new forests in high latitudes (e.g. Siberia) were neutral or perhaps warming.
Snow albedos can be as high as 90%; this, however, is for the ideal example: fresh deep snow over a featureless landscape. Over Antarctica they average a little more than 80%.
If a marginally snow-covered area warms, snow tends to melt, lowering the albedo, and hence leading to more snowmelt (the ice-albedo positive feedback). This is the basis for predictions of enhanced warming in the polar and seasonally snow covered regions as a result of global warming.
Water reflects light very differently from typical terrestrial materials. The reflectivity of a water surface is calculated using the Fresnel equations (see graph).
At the scale of the wavelength of light even wavy water is always smooth so the light is reflected in a specular manner (not diffusely). The glint of light off water is a commonplace effect of this. At small angles of incident light, waviness results in reduced reflectivity (from as high as 100%) because of the steepness of the reflectivity-vs.-incident-angle curve and a locally increased average incident angle.
Although the reflectivity of water is very low at high and medium angles of incident light, it increases tremendously at small angles of incident light such as occur on the illuminated side of the earth near the terminator (early morning, late afternoon and near the poles). However, as mentioned above, waviness causes an appreciable reduction. Since the light specularly reflected from water does not usually reach the viewer, water is usually considered to have a very low albedo in spite of its high reflectivity at low angles of incident light.
Note that White caps on waves look white (and have high albedo) because the water is foamed up (not smooth at the scale of the wavelength of light) so the Fresnel equations do not apply. Fresh ‘black’ ice exhibits Fresnel reflection.
Albedo and climate in some areas are already affected by artificial clouds, such as those created by the contrails of heavy commercial airliner traffic. A study following the burning of the Kuwaiti oil fields by Saddam Hussein showed that temperatures under the burning oil fires were as much as 10oC colder than temperatures several miles away under clear skies.
Aerosol (very fine particles/droplets in the atmosphere) has two effects, direct and indirect. The direct (albedo) effect is generally to cool the planet; the indirect effect (the particles act as CCNs and thereby change cloud properties) is less certain.
Another albedo-related effect on the climate is from black carbon particles. The size of this effect is difficult to quantify: the IPCC say that their "estimate of the global mean radiative forcing for BC aerosols from fossil fuels is.. +0.2 W m-2 (from +0.1 W m-2 in the SAR) with a range +0.1 to +0.4 W m..-2".


Abu Dhabi (, literally Father of gazelle) is the capital and second most populous city in the United Arab Emirates (UAE). It is also the seat of government for the emirate of Abu Dhabi. The city lies on a T-shaped island jutting into the Persian Gulf from the central western coast. Approximately 900,000 people lived in Abu Dhabi 2008, of whom 80% were expatriates. One of the world's largest producers of oil, Abu Dhabi has actively attempted to diversfy its economy in recent years through investments in financial services and tourism. Abu Dhabi is ruled by Khalifa bin Zayed Al Nahyan, who is also the President of the UAE.
Parts of Abu Dhabi were settled as far back as the 3rd millennium BC and its early history fits the nomadic herding and fishing pattern typical of the broader region. Modern Abu Dhabi traces its origins to the rise of an important tribal confederation, the Bani Yas in the late 18th century, who also assumed control of Dubai. In the 19th century the Dubai and Abu Dhabi branches parted ways.
Into the mid-20th century, the economy of Abu Dhabi continued to be sustained mainly by camel herding, production of dates and vegetables at the inland oases of Al Ain and Liwa Oasis, and fishing and pearl diving off the coast of Abu Dhabi city, which was occupied mainly during the summer months. Most dwellings in Abu Dhabi city were, at this time constructed of palm fronds (barasti), with the wealthier families occupying mud huts. The growth of the cultured pearl industry in the first half of the twentieth century created hardship for residents of Abu Dhabi as pearls represented the largest export and main source of cash earnings.
In 1939, Sheikh Shakhbut Bin-Sultan Al Nahyan granted petroleum concessions, and oil was first found in 1958. At first, oil money had a marginal impact. A few lowrise concrete buildings were erected, and the first paved road was completed in 1961, but Sheikh Shakbut, uncertain whether the new oil royalties would last, took a cautious approach, preferring to save the revenue rather than investing it in development. His brother, Zayed bin Sultan Al Nahyan, saw that oil wealth had the potential to transform Abu Dhabi. The ruling Al Nahyan family decided that Sheikh Zayed should replace his brother as ruler and carry out his vision of developing the country. On August 6, 1966, with the assistance of the British, Sheikh Zayed became the new ruler.
With the announcement by the UK in 1968 that it would withdraw from the Gulf area by 1971, Sheikh Zayed became the main driving force behind the formation of the United Arab Emirates.
After the Emirates gained independence in 1971, oil wealth continued to flow to the area and traditional mud-brick huts were rapidly replaced with banks, boutiques and modern highrises.
The emirate of Abu Dhabi is located in the oil-rich and strategic United Arab Emirates and is an active member of the Gulf Co-operation Council (GCC). It borders with the Kingdom of Saudi Arabia (south) and the Sultanate of Oman (east). The emirate borders the emirate of Dubai to its northeast. In the north is the Persian Gulf.
Abu Dhabi city is on an island located less than a quarter-kilometer from the mainland and is joined to the mainland by the Maqta and Musaffah Bridges. A third bridge, designed by Zaha Hadid, is currently under construction. Bridges connecting to Reem Island and Saadiyat Island are also under construction.
Most of Abu Dhabi is located on the island itself, but it has many suburbs on the mainland for example: The Khalifa Cities, Between Two Bridges, Mussafah Residential and more.
The majority of the inhabitants of Abu Dhabi are expatriate workers from India, Pakistan, Egypt, Bangladesh, Sri Lanka, Philippines, Britain, various countries from across the Arab world and elsewhere. Consequently, English, Tagalog, Tigrinya, Amharic, Bengali, and Urdu are widely spoken. Apart from Hindi, the many Indian expatriates also contribute other South Asian languages to the cultural milieu, including Malayalam, widely spoken in Kerala.
The native-born population are Arabic-speaking Gulf Arabs who are part of a clan-based society. The Al Nahyan family, part of the al-Falah branch of the Bani Yas clan, rules the emirate and has a central place in society.
Sheikh Khalifa bin Zayed Al Nahyan is the hereditary ruler of Abu Dhabi (UAE). He is the son of Sheikh Zayed Al Nahyan, the first president of the United Arab Emirates.
Abu Dhabi is the wealthiest emirate of the UAE in terms of Gross Domestic Product (GDP) and per capita income. The average net worth for Abu Dhabi's 420,000 citizens is AED 62 million (US$ 17 million), and more than $1 trillion is invested worldwide in this city alone. The Gross Domestic Product per capita also reached $63,000, which is far above the average income of the United Arab Emirates and which ranks third in the world after Luxembourg and Norway. Abu Dhabi is also planning many future projects sharing with the GCC and taking 29% of all the GCC future plannings. The United Arab Emirates is a fast-growing economy: in 2006 the per capita income grew by 9%, providing a GDP per capita of $49,700 and ranking third in the world at PPP. Abu Dhabi plays a large role in the world economy. Abu Dhabi's sovereign wealth fund, the Abu Dhabi Investment Authority (ADIA), currently estimated at US$ 875 billion, is the world's wealthiest soverign fund, in terms of total asset value.
Sunny/blue skies can be expected throughout the year. The months of April through September are generally hot and humid with maximum temperatures averaging above 40 °C (104°F). During this time, sandstorms also occur intermittently, in some cases reducing visibility down to a few meters.
The weather is cooler from November to March. This period also sees dense fog on some days. The oasis city of Al Ain, about 150 km away, bordering Oman, regularly records the highest summer temperatures in the country, however the dry desert air and cooler evenings make it a traditional retreat from the intense summer heat and year round humidity of the capital city.
Abu Dhabi International Airport (AUH) serves this city. The local time is GMT + 4 hours. Private vehicles and taxis are the primary means of transportation in the city. There is a 2 AED pick-up fee plus 0.50 AED per km. Public buses are available, but are not widely used. The fare starts at 2 AED and it is rare for the fare to go above 6 AED during intracity travel. There are bus routes to nearby towns such as Baniyas, Habashan and Al Ain, among others. A service to Dubai (about 160 km away) started in 2005.
The city was planned in the 1970s for an estimated maximum population of 600,000. In accordance with what was considered to be ideal urban planning at the time, the city has wide grid-pattern roads, and high-density tower blocks.
On the northerly end of the island, where the population density is highest, the main streets are lined with 20-story towers. Inside this rectangle of towers is a normal grid pattern of roads with lower density buildings (2 story villas or 6 story low-rise buildings).
Abu Dhabi city is a modern city with broad boulevards, tall office and apartment buildings, and busy shops. Principal thoroughfares are The Corniche, Airport Road, Sheikh Zayed Street, Hamdan Street and Khalifa Street.
Abu Dhabi city is known in the region for its greenery; the former desert strip today includes numerous parks and gardens.
Mail is generally delivered to post-office boxes only; however, there is door-to-door delivery for commercial organizations.
There are many parks (or public gardens) throughout the city. Entrance is usually free for children, however there is often an entry fee for adults. The city has a "Corniche," or seaside promenade, about 7 km in length, with gardens, playgrounds, and a BMX/Skateboard ring.
The design of the inner city roads and main roads are quite organised. All horizontal streets (starting from Corniche street, St. # 1) are odd and the verticals are evenly numbered. So Corniche is Street #1, Khalifa is Street # 3, Hamdan is Street # 5, and so on. While Salam Street is St # 8.
New developments on islands surrounding the city plan to increase the population of the city by up to 2,600,000.
Most recently, the government of Abu Dhabi has announced plans to fund a campus abroad for New York University, the first of its kind to be established abroad by a major US research university, which is set to receive students by 2010.
Abu Dhabi is trying to position itself as the "Cultural hub" of the Middle East, taking this mantle from such neighboring cities as Beirut and Cairo. It is home to a number of cultural institutions including the Cultural Foundation and the National Theater. The Cultural Foundation is home to the UAE Public Library and Cultural Center. Various cultural societies such as the Abu Dhabi Classical Music Society have a strong and visible following in the city. The recently launched Emirates Foundation makes grants in support of the arts, as well as to advance science and technology, education, environmental protection and social development. IPAF, the International Prize for Arabic Fiction, will be based in Abu Dhabi.
Abu Dhabi is home to several international and local private schools and universities.


The letter A is the first letter in the Latin alphabet. Its name in English is a (), plural A's, As, as, or "a's.
The letter A can be traced to a pictogram of an ox head in Egyptian hieroglyph or the Proto-semitic alphabet.
By about 1600 B.C. the Phoenician alphabet's letter had a linear form that served as the basis for some later forms. Its name must have corresponded closely to the Hebrew aleph.
When the Ancient Greeks adopted the alphabet, they had no use for the glottal stop that the letter had denoted in Phoenician and other Semitic languages, so they used the sign for the vowel /a/, and changed its name to alpha. In the earliest Greek inscriptions after the Greek Dark Ages, dating to the 8th century BC, the letter rests upon its side, but in the Greek alphabet of later times it generally resembles the modern capital letter, although many local varieties can be distinguished by the shortening of one leg, or by the angle at which the cross line is set.
The Etruscans brought the Greek alphabet to what is now Italy and left the letter unchanged. The Romans later adopted the Etruscan alphabet to write Latin, and the resulting letter was preserved in the modern Latin alphabet used to write many languages, including English.
The letter has two minuscule (lower-case) forms. The form used in most current handwriting, and in italic type, consists of a circle and vertical stroke (ɑ), called Latin alpha or "script a". Most printed material uses a form consisting of a small loop with an arc over it (a). Both derive from the majuscule (capital) form. In Greek handwriting, it was common to join the left leg and horizontal stroke into a single loop, as demonstrated by the Uncial version shown. Many fonts then made the right leg vertical. In some of these, the serif that began the right leg stroke developed into an arc, resulting in the printed form, while in others it was dropped, resulting in the modern handwritten form.
In English, the letter "A" by itself usually denotes the near-open front unrounded vowel (/æ/) as in pad, the open back unrounded vowel (/ɑː/) as in father, or, in concert with a later orthographic vowel, the diphthong /eɪ/ (though the pronunciation varies with the dialect) as in ace and major, due to effects of the great vowel shift.
In most other languages that use the Latin alphabet, the letter A denotes either an open back unrounded vowel (/ɑ/), or an open central unrounded vowel (/a/). In the International Phonetic Alphabet, variants of the letter A denote various vowels. In X-SAMPA, capital A denotes the open back unrounded vowel and lowercase a denotes the open front unrounded vowel.
A is the third-most common letter in English, and the second-most common in Spanish and French. On average, about 8.2% of letters in English tend to be As, while the number is 6.2% in Spanish and 4% in French.
A also is the English indefinite article, extended to an before a vowel. See a, an.
A- also is a prefix that serves to negate the morpheme to which it is attached, such as amoral, apolitical, etc. This derives from Greek.
In Unicode the capital A is codepoint U+0041 and the lowercase a is U+0061.
The ASCII code for capital A is 65 and for lowercase a is 97; or in binary 01000001 and 01100001, respectively.
The EBCDIC code for capital A is 193 and for lowercase a is 129.
The morse code for A is dit dah or a dot and a dash.
The numeric character references in HTML and XML are "&amp;#65;" and "&amp;#97;" for upper and lower case respectively.


The State of Alabama (), is located in the southern region of the United States of America. It is bordered by Tennessee to the north, Georgia to the east, Florida and the Gulf of Mexico to the south, and Mississippi to the west. Alabama ranks 30th in total land area and ranks second in the size of its inland waterways. The state ranks 23rd in population with almost 4.6 million residents in 2006.
From the American Civil War until World War II, Alabama, like many Southern States, suffered economic hardship, in part because of continued dependence on agriculture. More significantly, white rural, minority domination of the legislature until the 1960s meant that urban, contemporary interests were consistently underrepresented. In the years following the war, Alabama experienced significant recovery as the economy of the state transitioned from agriculture to diversified interests in heavy manufacturing, mineral extraction, education, and high technology. Today, the state is heavily invested in aerospace, education, health care, and banking, and various heavy industries including automobile manufacturing, mineral extraction, steel production and fabrication.
Alabama is unofficially nicknamed the Yellowhammer State, which is also the name of the state bird. Alabama is also known as the "Heart of Dixie". The state tree is the Longleaf Pine. The capital of Alabama is Montgomery, and the largest city is Birmingham.
Alabamu, and Allibamou. The use of state names derived from Native American languages is common with an estimated 27 states having names of Native American origin.
Although the origin of Alabama was evident, the meaning of the tribe's name was not always clear. An article without a byline appearing in the Jacksonville Republican on July 27, 1842 originated the idea that the meaning was "Here We Rest." This notion was popularized in the 1850s through the writings of Alexander Beaufort Meek. Experts in the Muskogean languages have been unable to find any evidence that would support this translation. It is now generally accepted that the word comes from the Choctaw words alba (meaning "plants" or "weeds") and amo (meaning "to cut", "to trim", or "to gather"). This results in translations such as "clearers of the thicket" or even "herb gatherers" which may refer to clearing of land for the purpose of planting crops or to collection of medicinal plants by medicine men.
Alabama is the 30th largest state in the United States with 52,423 square miles (135,775 km²) of total area: 3.19% of the area is water, making Alabama 23rd in the amount of surface water, also giving it the second largest inland waterway system in the United States.
About three-fifths of the land area is a gentle plain with a general descent towards the Mississippi River and the Gulf of Mexico. The North Alabama region is mostly mountainous, with the Tennessee River cutting a large valley creating numerous creeks, streams, rivers, mountains, and lakes.
Another natural wonder in Alabama is "Natural Bridge" rock, the longest natural bridge east of the Rockies, located just south of Haleyville, in Winston County.
Alabama generally ranges in elevation from sea level, down at Mobile Bay, to over 1,800 feet (550 m) in the Appalachian Mountains in the northeast. The highest point is Mount Cheaha (see map), at a height of nearly 2,405 ft (733 m).
States bordering Alabama include Tennessee to the north; Georgia to the east; Florida to the south; and Mississippi to the west. Alabama has coastline at the Gulf of Mexico, in the extreme southern edge of the state.
National Parks in Alabama include Horseshoe Bend National Military Park near Alexander City; Little River Canyon National Preserve near Fort Payne; Russell Cave National Monument in Bridgeport; Tuskegee Airmen National Historic Site in Tuskegee; and Tuskegee Institute National Historic Site near Tuskegee.
Alabama also contains the Natchez Trace Parkway, the Selma To Montgomery National Historic Trail, and the Trail Of Tears National Historic Trail.
Suburban Baldwin County, along the Gulf Coast, is the largest county in the state in both land area and water area.
A 5 mi-wide meteorite impact crater is located in Elmore County, just north of Montgomery. This is the Wetumpka crater, which is the site of "Alabama's greatest natural disaster". A 1000 ft-wide meteorite hit the area about 80 million years ago. The hills just east of downtown Wetumpka showcase the eroded remains of the impact crater that was blasted into the bedrock, with the area labeled the Wetumpka crater or astrobleme ("star-wound") because of the concentric rings of fractures and zones of shattered rock that can be found beneath the surface. In 2002, Christian Koeberl with the Institute of Geochemistry University of Vienna published evidence and established the site as an internationally recognized impact crater.
The climate of Alabama is described as temperate with an average annual temperature of 64 °F (18 °C). Temperatures tend to be warmer in the southern part of the state with its close proximity to the Gulf of Mexico, while the northern parts of the state, especially in the Appalachian Mountains in the northeast, tend to be slightly cooler. Generally, Alabama has very hot summers and mild winters with copious precipitation throughout the year. Alabama receives an average of 56 in of rainfall annually and enjoys a lengthy growing season of up to 300 days in the southern part of the state.
South Alabama reports more thunderstorms than any part of the U.S. The Gulf Coast, around Mobile Bay, averages between 70 and 80 days per year with thunder reported. This activity decreases somewhat further north in the state, but even the far north of the state reports thunder on about 60 days per year. Occasionally, thunderstorms are severe with frequent lightning and large hail - the central and northern parts of the state are most vulnerable to this type of storm. Alabama ranks seventh in the number of deaths from lightning and ninth in the number of deaths from lightning strikes per capita. Sometimes tornadoes occur - these are common throughout the state, although the peak season for tornadoes varies from the northern to southern parts of the state. Alabama shares the dubious distinction, with Kansas, of having reported more F5 tornadoes than any other state - according to statistics from the National Climatic Data Center for the period 1 January 1950 to 31 October 2006. An F5 tornado is the most powerful of its kind. Several long - tracked F5 tornadoes have contributed to Alabama reporting more tornado fatalities than any other state except for Texas and Mississippi. The Super Outbreak of March, 1974, badly affected Alabama. The northern part of the state - along the Tennessee Valley - is one of the areas in the US most vulnerable to violent tornadoes. The area of Alabama and Mississippi most affected by tornadoes is sometimes referred to as Dixie Alley, as distinct from the Tornado Alley of the Southern Plains. Alabama is one of the few places in the world that has a secondary tornado season (November and December) in addition to the Spring severe weather season.
Winters are generally mild in Alabama, as they are throughout most of the southeastern United States, with average January low temperatures around 40 °F in Mobile and around 32 °F in Birmingham. Snow is a rare event in much of Alabama. Areas of the state north of Montgomery may receive a dusting of snow a few times every winter, with an occasional moderately heavy snowfall every few years. In the southern Gulf coast, snowfall is less frequent, sometimes going several years without any snowfall.
Among the Native American people once living in the area of present day Alabama were Alabama (Alibamu), Cherokee, Chickasaw, Choctaw, Creek, Koasati, and Mobile. Trade with the Northeast via the Ohio River began during the Burial Mound Period (1000 BC-AD 700) and continued until European contact. Meso-American influence is evident in the agrarian Mississippian culture that followed.
The French founded the first European settlement in the state with the establishment of Mobile in 1702. Southern Alabama was French from 1702 to 1763, part of British West Florida from 1763 to 1780, and part of Spanish West Florida from 1780 to 1814. Northern and central Alabama was part of British Georgia from 1763 to 1783 and part of the American Mississippi territory thereafter. Its statehood was delayed by the lack of a coastline; rectified when Andrew Jackson captured Spanish Mobile in 1814. Alabama was the twenty-second state admitted to the Union, in 1819.
Alabama was the new frontier in the 1820s and 1830s. Settlers rapidly arrived to take advantage of fertile soils. Planters brought slaves with them, and traders brought in more from the Upper South as the cotton plantations expanded. The economy of the central "Black Belt" featured large cotton plantations whose owners built their wealth on the labor of enslaved African Americans. It was named for the dark, fertile soil. Elsewhere poor whites were subsistence farmers. According to the 1860 census, enslaved African Americans comprised 45% of the state's population of 964,201. There were only 2,690 free persons of color.
In 1861 Alabama seceded from the Union to join the Confederate States of America. While not many battles were fought in the state, Alabama contributed about 120,000 soldiers to the Civil War. All the slaves were freed by 1865. Following Reconstruction, Alabama was readmitted to the Union in 1868.
After the Civil War, the state was still chiefly rural and tied to cotton. Planters resisted working with free labor and sought to re-establish controls over African Americans. Whites used paramiliatry groups, Jim Crow laws and segregation to reduce freedoms of African Americans and restore their own dominance.
In its new constitution of 1901, the elite-dominated legislature effectively disfranchised African Americans through voting restrictions. While the planter class had engaged poor whites in supporting these efforts, the new restrictions resulted in disfranchising poor whites as well. By 1941 a total of more whites than blacks had been disfranchised: 600,000 whites to 520,000 blacks. This was due mostly to effects of the cumulative poll tax.
The damage to the African-American community was more pervasive, as nearly all its citizens lost the ability to vote. In 1900 fourteen Black Belt counties (which were primarily African American) had more than 79,000 voters on the rolls. By June 1,1903, the number of registered voters had dropped to 1,081. In 1900 Alabama had more than 181,000 African Americans eligible to vote. By 1903 only 2,980 had managed to "qualify" to register, although at least 74,000 black voters were literate. The shut out was longlasting.The disfranchisement was ended only by African Americans' leading the Civil Rights Movement and gaining Federal legislation in the mid-1960s to protect their voting and civil rights. Such legislation also protected the rights of poor whites.
The rural-dominated legislature continued to underfund schools and services for African Americans in the segregated state, but did not relieve them of paying taxes. Continued racial discrimination, agricultural depression, and the failure of the cotton crops due to boll weevil infestation led tens of thousands of African Americans to seek out opportunities in northern cities. They left Alabama in the early 20th century as part of the Great Migration to industrial jobs and better futures in northern industrial cities. The rate of population growth rate in Alabama (see table) dropped by nearly half from 1910-1920, reflecting the outmigration.
At the same time, many rural whites and blacks migrated to the city of Birmingham for work in new industrial jobs. It experienced such rapid growth that it was nicknamed "The Magic City." By the 1920s, Birmingham was the 19th largest city in the U.S and held more than 30% of the population of the state. Heavy industry and mining were the basis of the economy.
Despite massive population changes in the state from 1901 to 1961, the rural-dominated legislature refused to reapportion House and Senate seats based on population. They held on to old representation to maintain political and economic power in agricultural areas. In addition, the state legislature gerrymandered the few Birmingham legislative seats to ensure election by persons living outside of Birmingham.
Because of the long disfranchisement of African Americans, the state continued as one-party Democratic for decades. It produced a number of national leaders. Industrial development related to the demands of World War II brought prosperity. Cotton faded in importance as the state developed a manufacturing and service base. In the 1960s under Governor George Wallace, many whites in the state opposed integration efforts.
By the moral crusade of the Civil Rights Movement, African Americans achieved a restoration of voting and other civil rights through the passage of the national Civil Rights Act of 1964 and the Voting Rights Act of 1965. De jure segregation ended in the states as Jim Crow laws were invalidated or repealed.
Under the Voting Rights Act of 1965, cases were filed in Federal courts to force Alabama to properly redistrict by population both the state legislature House and Senate. In 1972, for the first time since 1901, the Alabama constitution's provision for periodic redistricting based on population was implemented. This benefited the many urban areas that had developed, and all in the population who had been underrepresented for more than 60 years.
After 1972, the state's white voters shifted much of their support to Republican candidates in presidential elections (as also occurred in neighboring southern states). Since 1990 the majority of whites in the state have also voted increasingly Republican in state elections.
As of 2005, Alabama has an estimated population of 4,557,808, which is an increase of 32,433, or 0.7%, from the prior year and an increase of 110,457, or 2.5%, since the year 2000. This includes a natural increase since the last census of 77,418 people (that is 319,544 births minus 242,126 deaths) and an increase due to net migration of 36,457 people into the state. Immigration from outside the United States resulted in a net increase of 25,936 people, and migration within the country produced a net increase of 10,521 people.
The state had 108,000 foreign-born (2.4% of the state population), of which an estimated 22.2% were illegal immigrants (24,000).
The center of population of Alabama is located in Chilton County, outside of the town of Jemison, an area known as Jemison Division.
The largest reported ancestry groups in Alabama: African American (26.0%), American (17.0%), English (7.8%), Irish (7.7%), German (5.7%), and Scots-Irish (2.0%). 'American' does not include those reported as Native American.
In a 2007 survey, nearly 70% of respondents could name all four of the Christian Gospels. Of those who indicated a religious preference, 59% said they possessed a "full understanding" of their faith and needed no further learning.
In a 2007 poll, 92% of Alabamians reported having at least some confidence in churches in the state.
According to the United States Bureau of Economic Analysis, the 2006 total gross state product was $160 billion, or $29,697 per capita for a ranking of 44th among states. Alabama's GDP increased 3.1% from 2005, placing Alabama number 23 in terms of state level GDP growth. The single largest increase came in the area of durable goods manufacturing. In 1999, per capita income for the state was $18,189.
Alabama's agricultural outputs include poultry and eggs, cattle, plant nursery items, peanuts, cotton, grains such as corn and sorghum, vegetables, milk, soybeans, and peaches. Although known as "The Cotton State", Alabama ranks between eight and ten in national cotton production, according to various reports, with Texas, Georgia and Mississippi comprising the top three.
Alabama's industrial outputs include iron and steel products (including cast-iron and steel pipe); paper, lumber, and wood products; mining (mostly coal); plastic products; cars and trucks; and apparel. Also, Alabama produces aerospace and electronic products, mostly in the Huntsville area, which is home of the NASA George C. Marshall Space Flight Center and the US Army Missile Command, headquartered at Redstone Arsenal.
Alabama is also home to the largest industrial growth corridor in the nation, including the surrounding states of Tennessee, Mississippi, Florida, and Georgia. Most of this growth is due to Alabama's rapidly expanding automotive manufacturing industry. In Alabama alone since 1993, it has generated more than 67,800 new jobs. Alabama currently ranks 2nd in the nation behind Detroit in automobile output. With recent expansions at sites in Alabama, by early 2009 the state will surpass Detroit and become the largest builder of automobiles in North America.
In May 2007, a site north of Mobile was selected by German steelmaker ThyssenKrupp for a $3.7 billion steel production plant, with the promise of 2,700 permanent jobs.
The city of Mobile, Alabama's only saltwater port, is a busy seaport on the Gulf of Mexico, and with inland waterway access to the Midwest via the Tennessee-Tombigbee Waterway.
Alabama levies a 2, 4, or 5% personal income tax, depending upon the amount earned and filing status. The state's general sales tax rate is 4%. The collection rate could be substantially higher, depending upon additional city and county sales taxes. The corporate income tax rate is currently 6.5%. The overall federal, state, and local tax burden in Alabama ranks the state as the second least tax-burdened state in the country.
As recently as 2003, Alabama had an annual budget deficit as high as $670 million. It is one of only a few handful of states to accomplish large surpluses, with a budget surplus of nearly $1.2 billion in 2007, and estimated at more than $2.1 billion for 2008. The declining economy may reduce that surplus.
Alabama has five major interstate roads that cross it: I-65 runs north-south roughly through the middle of the state; I-59/I-20 travels from the central west border to Birmingham, where I-59 continues to the north-east corner of the state and I-20 continues east towards Atlanta; I-85 goes from the border of Georgia and ends in Montgomery, providing a main thoroughfare to Atlanta; and I-10 traverses the southernmost portion of the state, running from west to east through Mobile. Another interstate road, I-22, is currently under construction. When completed around 2012 it will connect Birmingham with Memphis, Tennessee.
Major airports in Alabama include Birmingham International Airport (BHM), Dothan Regional Airport (DHN), Huntsville International Airport (HSV), Mobile Regional Airport (MOB), Montgomery Regional Airport (MGM), Muscle Shoals - Northwest Alabama Regional Airport (MSL), Tuscaloosa Regional Airport (TCL), and Pryor Field Regional Airport (DCU). For rail transport, Amtrak schedules the Crescent, a daily passenger train, running from New York to New Orleans with stops at Anniston, Birmingham, and Tuscaloosa.
The foundational document for Alabama's government is the Alabama Constitution, which was ratified in 1901. At almost 800 amendments and 310,000 words, it is the world's longest constitution and is roughly forty times the length of the U.S. Constitution. There is a significant movement to rewrite and modernize Alabama's constitution. This movement is based upon the fact that Alabama's constitution highly centralizes power in Montgomery and leaves practically no power in local hands. Any policy changes proposed around the state must be approved by the entire Alabama legislature and, frequently, by state referendum. One criticism of the current constitution claims that its complexity and length were intentional to codify segregation and racism.
The legislative branch is the Alabama Legislature, a bicameral assembly composed of the Alabama House of Representatives, with 105 members, and the Alabama Senate, with 35 members. The Legislature is responsible for writing, debating, passing, or defeating state legislation.
The executive branch is responsible for the execution and oversight of laws. It is headed by the Governor of Alabama. Other members of executive branch include the cabinet, the Attorney General of Alabama, the Alabama Secretary of State, the Alabama Commissioner of Agriculture and Industries, the Alabama State Treasurer, and the Alabama State Auditor.
The judicial branch is responsible for interpreting the Constitution and applying the law in state criminal and civil cases. The highest court is the Supreme Court of Alabama.
Alabama has 67 counties. Each county has its own elected legislative branch, usually called the County Commission, which usually also has executive authority in the county. Due to the restraints placed in the Alabama Constitution, all but seven counties (Jefferson, Lee, Mobile, Madison, Montgomery, Shelby, and Tuscaloosa) in the state have little to no home rule. Instead, most counties in the state must lobby the Local Legislation Committee of the state legislature to get simple local policies such as waste disposal to land use zoning.
Alabama is an alcoholic beverage control state; the government holds a monopoly on the sale of alcohol. However, counties can declare themselves "dry"; the state does not sell alcohol in those areas.
The current governor of the state is Bob Riley. The lieutenant governor is Jim Folsom Jr. The Democratic Party currently holds a large majority in both houses of the Legislature. Due to the Legislature's power to override a gubernatorial veto by a mere simple majority (most state Legislatures require a 2/3 majority to override a veto), the relationship between the executive and legislative branches can be easily strained when different parties control the branches.
During Reconstruction following the American Civil War, Alabama was occupied by federal troops of the Third Military District under General John Pope. In 1874, the political coalition known as the Redeemers took control of the state government from the Republicans, in part by suppressing the African American vote through intimidation and terrorism. White supremacy was re-established.
After 1890, a coalition of whites passed laws to segregate and disenfranchise black residents, a process completed in provisions of the 1901 constitution. Provisions which disfranchised African Americans also disfranchised poor whites, however. By 1941 more whites than blacks had been disfranchised: 600,000 to 520,000, although the impact was greater on the African-American community, as almost all of its citizens were disfranchised.
From 1901 to the 1960s, the state legislature failed to perform redistricting as population grew and shifted within the state. The result was a rural minority that dominated state politics until a series of court cases required redistricting in 1972.
With the disfranchisement of African Americans, the state became part of the "Solid South", a one-party system in which the Democratic Party became essentially the only political party in every Southern state. For nearly 100 years, local and state elections in Alabama were decided in the Democratic Party primary, with generally only token Republican challengers running in the General Election.
In the 1986 Democratic primary election, the then-incumbent Lieutenant Governor lost the Democratic nomination for Governor. The state Democratic party invalidated the election and placed the Lieutenant Governor's name on the ballot as the Democratic candidate instead of the candidate chosen in the primary. The voters of the state revolted at what they perceived as disenfranchisement of their right to vote and elected the Republican challenger Guy Hunt as Governor. This was the first Republican Governor elected in Alabama since Reconstruction. Since then, Republicans have been increasingly elected to state offices until in 2006 Democrats were barely holding a majority in the state legislature. Since 1986, only one Democrat, Don Siegelman, has managed to win the Governor's office. A corruption probe and eventual trial, the timing of which coincided with the 2006 state primary, relegated Siegelman to one term. Today, the state is mainly Republican.
Alabama state politics gained nationwide and international attention in the 1950s and 1960s during the American Civil Rights Movement, when majority whites bureaucratically, and at times, violently resisted protests for electoral and social reform. George Wallace, the state's governor, remains a notorious and controversial figure. Only with the passage of the Civil Rights Act of 1964 and Voting Rights Act of 1965 did African Americans regain suffrage and other civil rights.
In 2007, the Alabama Legislature passed, and the Governor signed, a resolution expressing "profound regret" over slavery and its lingering impact. In a symbolic ceremony, the bill was signed in the Alabama State Capitol, which served as the first Capital of the Confederate States of America.
From 1876 through 1956, Alabama supported only Democratic presidential candidates, by large margins. 1960 was a curious election. The Democrats won with John F. Kennedy on the ballot, but the Democratic electors from Alabama gave 6 of their 11 electoral votes as a protest to Harry Byrd. In 1964, Republican Barry Goldwater carried the state, in part because of his opposition to the 1964 Civil Rights Act, which restored the franchise for African Americans.
In the 1968 presidential election, Alabama supported native son and American Independent Party candidate George Wallace over both Richard Nixon and Hubert Humphrey. In 1976, Democratic candidate Jimmy Carter from Georgia carried the state, the region, and the nation, but Democratic control of the region slipped after that.
Since 1980, conservative Alabama voters have increasingly voted for Republican candidates at the Federal level, especially in Presidential elections. By contrast, Democratic candidates have been elected to many state-level offices and comprise a longstanding majority in the Alabama Legislature.
In 2004, George W. Bush won Alabama's nine electoral votes by a margin of 25 percentage points with 62.5% of the vote, mostly white voters. The eleven counties that voted Democratic were Black Belt counties, where African Americans are in the majority.
The state's two U.S. senators are Jefferson B. Sessions III and Richard C. Shelby, both Republicans.
Public primary and secondary education in Alabama is under the oversight of the Alabama State Board of Education as well as local oversight by 67 county school boards and 60 city boards of education. Together, 1,541 individual schools provide education for 743,364 elementary and secondary students.
Public school funding is appropriated through the Alabama Legislature through the Education Trust Fund. In FY 2006-2007, Alabama appropriated $3,775,163,578 for primary and secondary education. That represented an increase of $444,736,387 over the previous fiscal year.
In 2007, over 82 percent of schools made adequate yearly progress (AYP) toward student proficiency under the National No Child Left Behind law. In 2004, only 23 percent of schools met AYP.
Alabama's programs of higher education include 14 four-year public universities, numerous two-year community colleges, and 17 private, undergraduate and graduate universities. Public, post-secondary education in Alabama is overseen by the Alabama Commission on Higher Education. Colleges and universities in Alabama offer degree programs from 2-year associate degrees to 16 doctoral level programs.
Accreditation of academic programs is through the Southern Association of Schools and Colleges as well as a variety of subject focused national and international accreditation agencies.


In Greek mythology, Achilles (also Akhilleus or Achilleus; Ancient Greek: ) was a Greek hero of the Trojan War, the central character and greatest warrior of Homer's Iliad, which takes for its theme the Wrath of Achilles.
Achilles also has the attributes of being the most handsome of the heroes assembled against Troy, as well as the quickest. Central to his myth is his relationship with Patroclus, characterized in different sources as either deep friendship or passionate love.
Achilles's death came as divine retribution for his hubristic murder of Troilus. The Trojan boy had spurned his sexual advances and was killed by the enraged hero inside Apollo's temple. Later legends (beginning with a poem by Statius in the first century AD) state that Achilles was invulnerable on all of his body except for his heel. These legends state that Achilles was killed in battle by an arrow to the heel, and so an "Achilles' heel" or Achilles' tendon has come to mean a person's principal weakness.
Achilles was the son of the mortal Peleus, king of the Myrmidons, and the immortal sea nymph Thetis in Farsala, Thessaly. Zeus and Poseidon had been rivals for the hand of Thetis until Prometheus, the fire-bringer, warned Zeus of a prophecy that Thetis would bear a son greater than his father. For this reason, the two gods withdrew their pursuit, and had her wed to Peleus.
As with most mythology there is a tale which offers an alternative version of these events: in Argonautica (iv.760) Hera alludes to Thetis's chaste resistance to the advances of Zeus, that Thetis had been so loyal to Hera's marriage bond that she coolly rejected him.
According to the incomplete poem Achilleis written by Statius in the first century AD, and to no other sources, when Achilles was born Thetis tried to make him immortal by dipping him in the river Styx. However, she forgot to wet the heel she held him by, leaving him vulnerable at that spot. (See Achilles heel, Achilles' tendon.) It is not clear if this version of events was known earlier. In another version of this story, Thetis anointed the boy in ambrosia and put him on top of a fire to burn away the mortal parts of his body. She was interrupted by Peleus and abandoned both father and son in a rage.
Also in the fragmentary poems of the Epic Cycle in which we can find description of the hero's death, Kùpria (unknown author), Aithiopis by Arctinus of Miletus, Ilias Mikrà by Lesche of Mytilene, Iliou pèrsis by Arctinus of Miletus, there is no trace of any reference to his invulnerability or his famous (achilles) heel; in the later vase-paintings presenting Achilles' death, the arrow (or in many cases, arrows) hit his body.
Peleus entrusted Achilles to Chiron the Centaur, on Mt. Pelion, to be raised.
Achilles is the only mortal to experience consuming rage (menis). His anger is at some times wavering, at other times absolute. The humanization of Achilles by the events of the war is an important theme of the narrative.
When the Greeks left for the Trojan War, they accidentally stopped in Mysia, ruled by King Telephus. In the resulting battle, Achilles gave Telephus a wound that would not heal; Telephus consulted an oracle, who stated that "he that wounded shall heal".
According to other reports in Euripides' lost play about Telephus, he went to Aulis pretending to be a beggar and asked Achilles to heal his wound. Achilles refused, claiming to have no medical knowledge. Alternatively, Telephus held Orestes for ransom, the ransom being Achilles' aid in healing the wound. Odysseus reasoned that the spear had inflicted the wound; therefore, the spear must be able to heal it. Pieces of the spear were scraped off onto the wound and Telephus was healed. This is an example of sympathetic magic.
According to traditions related by Plutarch and the Byzantine scholar John Tzetzes, once the Greek ships arrived in Troy, Achilles fought and killed Cycnus of Colonae, a son of Poseidon. Cycnus was invulnerable, except for his head.
According to Dares Phrygius' Account of the Destruction of Troy, the Latin summary through which the story of Achilles was transmitted to medieval Europe, while Troilus, the youngest son of Priam and Hecuba (who some say was fathered by Apollo), was watering his horses at the Lion Fountain outside the walls of Troy, Achilles saw him and fell in love with his beauty (whose "loveliness of form" was described by Ibycus as being like "gold thrice refined"). The youth rejected his advances and took refuge inside the temple of Apollo. Achilles pursued him into the sanctuary and decapitated him on the god's own altar. At the time, Troilus was said to be a year short of his twentieth birthday, and the First Vatican Mythographer reports that if Troilus had lived to be twenty, Troy would have been invincible.
Homer's Iliad is the most famous narrative of Achilles' deeds in the Trojan War. The Homeric epic only covers a few weeks of the war, and does not narrate Achilles' death. It begins with Achilles' withdrawal from battle after he is dishonored by Agamemnon, the commander of the Achaean forces. Agamemnon had taken a woman named Chryseis as his slave. Her father Chryses, a priest of Apollo, begged Agamemnon to return her to him. Agamemnon refused and Apollo sent a plague amongst the Greeks. The prophet Calchas correctly determined the source of the troubles but would not speak unless Achilles vowed to protect him. Achilles did so and Calchas declared Chryseis must be returned to her father. Agamemnon consented, but then commanded that Achilles' battle prize Briseis be brought to replace Chryseis. Angry at the dishonor (and as he says later, because he loved Briseis) and at the urging of Thetis, Achilles refused to fight or lead his troops alongside the other Greek forces.
As the battle turned against the Greeks, Nestor declared that had Agamemnon not angered Achilles, the Trojans would not be winning and urged Agamemnon to appease Achilles. Agamemnon agreed and sent Odysseus and two other chieftains to Achilles with the offer of the return of Briseis and other gifts. Achilles refused and urged the Greeks to sail home as he was planning to do.
Eventually, however, hoping to retain glory despite his absence from the battle, Achilles prayed to his mother Thetis, asking her to plead with Zeus to allow the Trojans to push back the Greek forces.
The Trojans, led by Hector, subsequently pushed the Greek army back toward the beaches and assaulted the Greek ships. With the Greek forces on the verge of absolute destruction, Achilles consented to Patroclus leading the Myrmidons into battle, though Achilles would remain at his camp. Patroclus succeeded in pushing the Trojans back from the beaches, but was killed by Hector before he could lead a proper assault on the city of Troy.
After receiving the news of the death of Patroclus from Antilochus, the son of Nestor, Achilles grieved over his friend and held many funeral games in his honor. His mother Thetis came to comfort the distraught Achilles. She persuaded Hephaestus to make new armor for him, in place of the armor that Patroclus had been wearing which was taken by Hector. The new armor included the Shield of Achilles, described in great detail by the poet.
Enraged over the death of Patroclus, Achilles ended his refusal to fight and took the field killing many men in his rage but always seeking out Hector. Achilles even engaged in battle with the river god Scamander who became angry that Achilles was choking his waters with all the men he killed. The god tried to drown Achilles but was stopped by Hera and Hephaestus. Zeus himself took note of Achilles' rage and sent the gods to restrain him so that he would not go on to sack Troy itself, seeming to show that the unhindered rage of Achilles could defy fate itself as Troy was not meant to be destroyed yet. Finally Achilles found his prey. Achilles chased Hector around the wall of Troy three times before Athena, in the form of Hector's favorite and dearest brother, Deiphobus, persuaded Hector to fight face to face. Achilles got his vengeance, killing Hector with a blow to the neck. He then tied Hector's body to his chariot and dragged it around the battlefield for nine days.
With the assistance of the god Hermes, Hector's father, Priam, went to Achilles' tent and convinced Achilles to permit him to allow Hector his funeral rites. The final passage in the Iliad is Hector's funeral, after which the doom of Troy is just a matter of time.
Achilles, after his temporary truce with Priam, fought and killed the Amazonian warrior queen Penthesilea.
Following the death of Patroclus, Achilles's closest companion was Nestor's son Antilochus. When Memnon of Ethiopia killed Antilochus, Achilles was once again drawn onto the battlefield to seek revenge. The fight between Achilles and Memnon over Antilochus echoes that of Achilles and Hector over Patroclus, except that Memnon (unlike Hector) was also the son of a goddess.
Many Homeric scholars argued that episode inspired many details in the Iliad's description of the death of Patroclus and Achilles' reaction to it. The episode then formed the basis of the cyclic epic Aethiopis, which was composed after the Iliad, possibly in the 7th century BC. The Aethiopis is now lost, except for scattered fragments quoted by later authors.
Quintus of Smyrna also gives us an epic treatment of Memnon's mortal death and the immortality then bestowed upon him by Zeus as well as lyrical description of his countrymen's extreme grief.
As predicted by Hector with his dying breath, Achilles was thereafter killed by Paris — either by an arrow (to the heel according to Statius), or in an older version by a knife to the back while visiting Polyxena, a princess of Troy. In some versions, the god Apollo guided Paris' arrow.
Both versions conspicuously deny the killer any sort of valor owing to the common conception that Paris was a coward and not the man his brother Hector was, and Achilles remains undefeated on the battlefield. His bones are mingled with those of Patroclus, and funeral games are held. He was represented in the lost Trojan War epic of Arctinus of Miletus as living after his death in the island of Leuke at the mouth of the Danube (see below).
Paris was later killed by Philoctetes using the enormous bow of Heracles.
Achilles' armor was the object of a feud between Odysseus and Telamonian Ajax (Achilles' older cousin). They competed for it by giving speeches on why they were the bravest after Achilles and the most deserving to receive it. Odysseus won. Ajax went mad with grief and anguish and vowed to kill his comrades; he started killing sheep, thinking in his madness that they were Greek soldiers. He then committed suicide.
Achilles' relationship with Patroclus is a key aspect of his myth. Its exact nature has been a subject of dispute in both the classical period and modern times. In the Iliad, it is clear that the two heroes have a deep and extremely meaningful friendship, but the evidence of a romantic or sexual element is equivocal. Commentators from the classical period to today have tended to interpret the relationship through the lens of their own cultures. Thus, in 5th century BC Athens the relationship was commonly interpreted as pederastic.
There was an archaic heroic cult of Achilles on the White Island, Leuce, in the Black Sea off the modern coasts of Romania and Ukraine, with a temple and an oracle which survived into the Roman period.
In the lost epic Aithiopis, a continuation of the Iliad attributed to Arktinus of Miletos, Achilles’ mother Thetis returned to mourn him and removed his ashes from the pyre and took them to Leuce at the mouths of the Danube. There the Achaeans raised a tumulus for him and celebrated funeral games.
Pliny's Natural History (IV.27.1) mentions a tumulus that is no longer evident (Insula Akchillis tumulo eius viri clara), on the island consecrated to him, located at a distance of fifty Roman miles from Peuce by the Danube Delta, and the temple there. Pausanias has been told that the island is "covered with forests and full of animals, some wild, some tame. In this island there is also Achilles’ temple and his statue" (III.19.11). Ruins of a square temple 30 meters to a side, possibly that dedicated to Achilles, were discovered by Captain Kritzikly in 1823, but there has been no modern archeology done on the island.
Pomponius Mela tells that Achilles is buried in the island named Achillea, between Boristhene and Ister (De situ orbis, II, 7). And the Greek geographer Dionysius Periegetus of Bithynia, who lived at the time of Domitian, writes that the island was called Leuce "because the wild animals which live there are white. It is said that there, in Leuce island, reside the souls of Achilles and other heroes, and that they wander through the uninhabited valleys of this island; this is how Jove rewarded the men who had distinguished themselves through their virtues, because through virtue they had acquired everlasting honor" (Orbis descriptio, v. 541, quoted in Densuşianu 1913).
The heroic cult of Achilles on Leuce island was widespread in Antiquity, not only along the sealanes of the Pontic Sea but also in maritime cities whose economic interests were tightly connected to the riches of the Black Sea.
Leuce had also a reputation as a place of healing. Pausanias (III.19,13) reports that the Delphic Pythia sent a lord of Croton to be cured of a chest wound. Ammianus Marcellinus (XXII.8) attributes the healing to waters (aquae) on the island.
In the region of Gastouri (Γαστούρι) to the south of the city of Corfu Greece, Empress of Austria Elisabeth of Bavaria also known as Sissi built in 1890 a summer palace with Achilles as its central theme and it is a monument to platonic romanticism. The palace, naturally, was named after Achilles: Achilleion (Αχίλλειον). This elegant structure abounds with paintings and statues of Achilles both in the main hall and in the lavish gardens depicting the heroic and tragic scenes of the Trojan war.
Achilles' name can be analyzed as a combination of (akhos) "grief" and (Laos) "a people, tribe, nation, etc." In other words, Achilles is an embodiment of the grief of the people, grief being a theme raised numerous times in the Iliad (frequently by Achilles). Achilles' role as the hero of grief forms an ironic juxtaposition with the conventional view of Achilles as the hero of kleos (glory, usually glory in war).
Laos has been construed by Gregory Nagy, following Leonard Palmer, to mean a corps of soldiers. With this derivation, the name would have a double meaning in the poem: When the hero is functioning rightly, his men bring grief to the enemy, but when wrongly, his men get the grief of war. The poem is in part about the misdirection of anger on the part of leadership.
The name Achilleus was a common and attested name among the Greeks early after 7th century BC.It was also turned into the female form of Ἀχιλλεία,firstly attested in Attica,4th century BC, (IG II² 1617) and Achillia, a relief from Halicarnassus as the name of a female gladiator fighting, 'Amazonia'. Roman gladiatorial games often referenced classical mythology and this seems to reference Achilles' fight with Penthesilea, but give it an extra twist of Achilles being 'played' by a woman.
Some post-Homeric sources claim that in order to keep Achilles safe from the war, Thetis (or, in some versions, Peleus) hides the young man at the court of Lycomedes, king of Skyros. There, Achilles is disguised as a girl and lives among Lycomedes' daughters, perhaps under the name "Pyrrha" (the red-haired girl). With Lycomedes' daughter Deidamia, whom in the account of Statius he rapes, Achilles there fathers a son, Neoptolemus (also called Pyrrhus, after his father's possible alias). According to this story, Odysseus learns from the prophet Calchas that the Achaeans would be unable to capture Troy without Achilles' aid. Odysseus goes to Skyros in the guise of a peddler selling women's clothes and jewelry and places a shield and spear among his goods. When Achilles instantly takes up the spear, Odysseus sees through his disguise and convinces him to join the Greek campaign. In another version of the story, Odysseus arranges for a trumpet alarm to be sounded while he was with Lycomedes' women; while the women flee in panic, Achilles prepares to defend the court, thus giving his identity away.
In Homer's Odyssey, there is a passage in which Odysseus sails to the underworld and converses with the shades. One of these is Achilles, who when greeted as "blessed in life, blessed in death", responds that he would rather be a slave to the worst of masters than be king of all the dead. This has been interpreted as a rejection of his warrior life, but also as indignity to his martyrdom being slighted. Achilles was worshipped as a sea-god in many of the Greek colonies on the Black Sea, the location of the mythical "White Island" which he was said to inhabit after his death, together with many other heroes.
Post-Homeric literature explores a pederastic interpretation of the love between Achilles and Patroclus. By the fifth and fourth centuries, the deep — and arguably ambiguous — friendship portrayed in Homer blossomed into an unequivocal erotic love affair in the works of Aeschylus, Plato, and Aeschines, and seems to have inspired the enigmatic verses in Lycophron's third century Alexandra that claim Achilles slew Troilus in a matter of unrequited love.
The kings of the Epirus claimed to be descended from Achilles through his son. Alexander the Great, son of the Epiran princess Olympias, could therefore also claim this descent, and in many ways strove to be like his great ancestor; he is said to have visited his tomb while passing Troy.
Achilles fought and killed the Amazon Helene. Some also said he married Medea, and that after both their deaths they were united in the Elysian Fields of Hades — as Hera promised Thetis in Apollonius' Argonautica. In some versions of the myth, Achilles has a relationship with his captive Briseis.
The Greek tragedian Aeschylus wrote a trilogy of plays about Achilles, given the title Achilleis by modern scholars. The tragedies relate the deeds of Achilles during the Trojan War, including his defeat of Hector and eventual death when an arrow shot by Paris and guided by Apollo punctures his heel. Extant fragments of the Achilleis and other Aeschylean fragments have been assembled to produce a workable modern play. The first part of the Achilleis trilogy, The Myrmidons, focused on the relationship between Achilles and chorus, who represent the Achaean army and try to convince Achilles to give up his quarrel with Agamemnon; only a few lines survive today.
The tragedian Sophocles also wrote a play with Achilles as the main character, The Lovers of Achilles. Only a few fragments survive.
The philosopher Zeno of Elea centered one of his paradoxes on an imaginary footrace between "swift-footed" Achilles and a tortoise, in which he proved that Achilles could not catch up to a tortoise with a head start, and therefore that motion and change were impossible. As a student of the monist Parmenides and a member of the Eleatic school, Zeno believed time and motion to be illusions.
Achilles has frequently been mentioned in music.


Abraham Lincoln (February 12, 1809 – April 15, 1865) was the sixteenth President of the United States, serving from March 4, 1861 until his assassination. As an outspoken opponent of the expansion of slavery in the United States, Lincoln won the Republican Party nomination in 1860 and was elected president later that year. During his term, he helped preserve the United States by leading the defeat of the secessionist Confederate States of America in the American Civil War. He introduced measures that resulted in the abolition of slavery, issuing his Emancipation Proclamation in 1863 and promoting the passage of the Thirteenth Amendment to the Constitution in 1865.
Lincoln closely supervised the victorious war effort, especially the selection of top generals, including Ulysses S. Grant. Historians have concluded that he handled the factions of the Republican Party well, bringing leaders of each faction into his cabinet and forcing them to cooperate. Lincoln successfully defused a war scare with the United Kingdom in 1861. Under his leadership, the Union took control of the border slave states at the start of the war. Additionally, he managed his own reelection in the 1864 presidential election.
Opponents of the war (also known as "Copperheads") criticized him for refusing to compromise on the slavery issue. Conversely, the Radical Republicans, an abolitionist faction of the Republican Party, criticized him for moving too slowly in abolishing slavery. Even with these road blocks, Lincoln successfully rallied public opinion through his rhetoric and speeches; his Gettysburg Address is but one example of this. At the close of the war, Lincoln held a moderate view of Reconstruction, seeking to speedily reunite the nation through a policy of generous reconciliation. His assassination in 1865 was the first presidential assassination in U.S. history and made him a martyr for the ideal of national unity.
Abraham Lincoln was born on February 12, 1809, to Thomas Lincoln and Nancy Hanks, two uneducated farmers, in a one-room log cabin on the 348 acre Sinking Spring Farm, in southeast Hardin County, Kentucky (now part of LaRue County).
For some time, Thomas Lincoln, Abraham's father, was a respected and relatively affluent citizen of the Kentucky backcountry. He had purchased the Sinking Spring Farm in December of 1808 for $200 cash and assumption of a debt. The family belonged to a Hardshell Baptist church, although Abraham himself never joined their church, or any other church for that matter.
In 1816, the Lincoln family was forced to make a new start in Perry County (now in Spencer County), Indiana. He later noted that this move was "partly on account of slavery," and partly because of difficulties with land deeds in Kentucky: Unlike land in the Northwest Territory, Kentucky never had a proper U.S. survey, and farmers often had difficulties proving title to their property.
When Lincoln was nine, his mother, then thirty-four years old, died of milk sickness. Soon afterwards, his father remarried to Sarah Bush Johnston. Lincoln was affectionate toward his stepmother, whom he would call "Mother" for the rest of his life, but he was distant from his father.
In 1830, after more economic and land-title difficulties in Indiana, the family settled on public land in Macon County, Illinois. The following winter was desolate and especially brutal, and the family considered moving back to Indiana. The following year, when his father relocated the family to a new homestead in Coles County, Illinois, twenty-two-year-old Lincoln struck out on his own, canoeing down the Sangamon River to the village of New Salem in Sangamon County. Later that year, hired by New Salem businessman Denton Offutt and accompanied by friends, he took goods from New Salem to New Orleans via flatboat on the Sangamon, Illinois and Mississippi rivers.
Lincoln's formal education consisted of about 18 months of schooling, but he was largely self-educated and an avid reader. He was also a talented local wrestler and skilled with an axe. Lincoln avoided hunting and fishing because he did not like killing animals, even for food. At 6 foot 4 inches (1.93m), he was unusually tall, as well as strong.
Lincoln began his political career in 1832, at age 23, with an unsuccessful campaign for the Illinois General Assembly, as a member of the Whig Party. The centerpiece of his platform was the undertaking of navigational improvements on the Sangamon River. He believed that this would attract steamboat traffic, which would allow the sparsely populated, poorer areas along the river to flourish.
For several months, Lincoln ran a small store in New Salem.
In 1834, he won election to the state legislature, and, after coming across the Commentaries on the Laws of England, began to teach himself law. Admitted to the bar in 1837, he moved to Springfield, Illinois, that same year and began to practice law with John T. Stuart. With a reputation as a formidable adversary during cross-examinations and in his closing arguments, Lincoln became one of the most respected and successful lawyers in Illinois and grew steadily more prosperous.
He served four successive terms in the Illinois House of Representatives as a representative from Sangamon County, and became a leader of the Illinois Whig party. In 1837, he made his first protest against slavery in the Illinois House, stating that the institution was "founded on both injustice and bad policy." It was also in this same year that Lincoln met Joshua Fry Speed, who would become his most intimate friend.
Lincoln wrote a series of anonymous letters, published in 1842 in the Sangamon Journal, mocking State Auditor and prominent Democrat James Shields. Two years later, Lincoln entered law practice with William Herndon, a fellow Whig. In 1854, both men joined the fledgling Republican Party. Following Lincoln's death, Herndon began collecting stories about Lincoln and published them in "Herndon's Lincoln".
On November 4 1842 Lincoln married Mary Todd, daughter of a prominent slave-owning family from Kentucky. The couple had four sons. Robert Todd Lincoln was born in Springfield, Illinois on 1 August, 1843. Their only child to survive into adulthood, young Robert attended Phillips Exeter Academy and Harvard College.
The other Lincoln children were born in Springfield, Illinois, and died either during childhood or their teen years. Edward Baker Lincoln was born on 10 March, 1846, and died on 1 February, 1850, also in Springfield. William "Willie" Wallace Lincoln was born on 21 December, 1850, and died on 20 February, 1862 in Washington, D.C. during President Lincoln's first term. Thomas "Tad" Lincoln was born on 4 April, 1853, and died on 16 July, 1871 in Chicago.
A Whig and an admirer of party leader Henry Clay, Lincoln was elected to a term in the U.S. House of Representatives in 1846. As a freshman House member, he was not a particularly powerful or influential figure. However, he spoke out against the Mexican-American War, which he attributed to President Polk's desire for "military glory" and challenged the President's claims regarding the Texas boundary and offered Spot Resolutions, demanding to know on what "spot" on US soil that blood was first spilt.
Lincoln later damaged his political reputation with a speech in which he declared, "God of Heaven has forgotten to defend the weak and innocent, and permitted the strong band of murderers and demons from hell to kill men, women, and children, and lay waste and pillage the land of the just." Two weeks later, President Polk sent a peace treaty to Congress. While no one in Washington paid any attention to Lincoln, the Democrats orchestrated angry outbursts from across his district, where the war was popular and many had volunteered.
Warned by his law partner, William Herndon, that the damage was mounting and irreparable, Lincoln decided not to run for reelection. His statements were not easily forgotten, and would haunt him during the Civil War. These statements were also held against him when he applied for a position in the new Taylor administration. Instead, Taylor's people offered Lincoln various positions in the remote Oregon Territory, primarily the governorship. Acceptance of this offer would have ended his career in the rapidly growing state of Illinois, so Lincoln declined the position. Returning to Springfield, Lincoln gave up politics for several years and turned his energies to his law practice.
By the mid-1850s, Lincoln's caseload focused largely on the competing transportation interests of river barges and railroads. In one prominent 1851 case, he represented the Alton & Sangamon Railroad in a dispute with a shareholder, James A. Barret. Barret had refused to pay the balance on his pledge to the railroad on the grounds that it had changed its originally planned route. Lincoln argued that as a matter of law a corporation is not bound by its original charter when that charter can be amended in the public interest, that the newer route proposed by Alton & Sangamon was superior and less expensive, and that accordingly, the corporation had a right to sue Barret for his delinquent payment. He won this case, and the decision by the Illinois Supreme Court was eventually cited by several other courts throughout the United States.
The civil case which won Lincoln fame as a lawyer was the landmark Hurd v. Rock Island Bridge Company. America's expansion west, which Lincoln strongly supported, was seen as an economic threat to the river trade, which ran north-to-south, primarily on the Mississippi river. In 1856 a steamboat collided with a bridge, built by the Rock Island Railroad, between Rock Island, Illinois, and Davenport, Iowa, the first railroad bridge to span the Mississippi. The steamboat owner sued for damages, claiming the bridge was a hazard to navigation. Lincoln argued in court for the railroad and won, removing a costly impediment to western expansion by establishing the right of land routes to bridge waterways.
Possibly the most notable criminal trial of Lincoln's career as a lawyer came in 1858, when he defended William "Duff" Armstrong, who had been charged with murder. The case became famous for Lincoln's use of judicial notice — a rare tactic at that time — to show that an eyewitness had lied on the stand. After the witness testified to having seen the crime by moonlight, Lincoln produced a "Farmers' Almanac" to show that the moon on that date was at such a low angle that it could not have provided enough illumination to see anything clearly. Based almost entirely on this evidence, Armstrong was acquitted.
Lincoln was involved in more than 5,100 cases in Illinois alone during his 23-year legal career. Though many of these cases involved little more than filing a writ, others were more substantial and quite involved. Lincoln and his partners appeared before the Illinois State Supreme Court more than 400 times.
Lincoln returned to politics in response to the Kansas-Nebraska Act (1854), which expressly repealed the limits on slavery's extent as determined by the Missouri Compromise (1820). Illinois Democrat Stephen A. Douglas, the most powerful man in the Senate, proposed popular sovereignty as the solution to the slavery impasse, and incorporated it into the Kansas-Nebraska Act. Douglas argued that in a democracy the people should have the right to decide whether or not to allow slavery in their territory, rather than have such a decision imposed on them by Congress.
Drawing on remnants of the old Whig, Free Soil, Liberty and Democratic parties, he was instrumental in forming the new Republican Party. In a stirring campaign, the Republicans carried Illinois in 1854 and elected a senator. Lincoln was the obvious choice, but to keep the new party balanced he allowed the election to go to an ex-Democrat Lyman Trumbull.
In 1857-58, Douglas broke with President Buchanan, leading to a fight for control of the Democratic Party. Some eastern Republicans even favored the reelection of Douglas in 1858, since he had led the opposition to the Lecompton Constitution, which would have admitted Kansas as a slave state. Accepting the Republican nomination for Senate in 1858, Lincoln delivered his famous speech: "'A house divided against itself cannot stand.'(Mark 3:25) I believe this government cannot endure permanently half slave and half free. I do not expect the Union to be dissolved — I do not expect the house to fall — but I do expect it will cease to be divided. It will become all one thing, or all the other." The speech created an evocative image of the danger of disunion caused by the slavery debate, and rallied Republicans across the north.
The 1858 campaign featured the Lincoln-Douglas debates, a nationally famous contest on slavery. Lincoln warned that the "Slave Power" was threatening the values of republicanism, while Douglas emphasized the supremacy of democracy, as set forth in his Freeport Doctrine, which said that local settlers should be free to choose whether to allow slavery or not. Though the Republican legislative candidates won more popular votes, the Democrats won more seats, and the legislature reelected Douglas to the Senate. Nevertheless, Lincoln's eloquence transformed him into a national political star.
During the debates of 1858, the issue of race was often discussed. During a time period when few believed in racial egalitarianism, Stephen Douglas informed the crowds, "If you desire Negro citizenship… if you desire them to vote on an equality with yourselves… then support Mr. Lincoln and the Black Republican party, who are in favor of the citizenship of the negro." Lincoln countered that he was "not in favor of bringing about in any way the social and political equality of the white and black races." His opposition to slavery was opposition to the Slave Power, though this would change during the course of the Civil War.
On May 9-10, 1860, the Illinois Republican State Convention was held in Decatur. At this convention, Lincoln received his first endorsement to run for the presidency.
Entering the presidential nomination process as a distinct underdog, Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons. His expressed views on slavery were seen as more moderate than those of rivals William H. Seward and Salmon P. Chase. His "Western" origins also appealed to the newer states: other contenders, especially those with more governmental experience, had acquired enemies within the party and were weak in the critical western states, while Lincoln was perceived as a moderate who could win the West. Most Republicans agreed with Lincoln that the North was the aggrieved party as the Slave Power tightened its grasp on the national government. Yet despite his Southern connections (his in-laws owned slaves), Lincoln misunderstood the depth of the revolution underway in the South and the emergence of Southern nationalism. Throughout the 1850s he denied that there would ever be a civil war, and his supporters repeatedly rejected claims that his election would incite secession.
Throughout the election, Lincoln did not campaign or give speeches. This was handled by the state and county Republican organizations, who used the latest techniques to sustain party enthusiasm and thus obtain high turnout. There was little effort to convert non-Republicans, and there was virtually no campaigning in the South except for a few border cities such as St. Louis, Missouri, and Wheeling, Virginia; indeed, the party did not even run a slate in most of the South. In the North, there were thousands of Republican speakers, tons of campaign posters and leaflets, and thousands of newspaper editorials. These focused first on the party platform, and second on Lincoln's life story, making the most of his boyhood poverty, his pioneer background, his native genius, and his rise from obscurity. His nicknames, "Honest Abe" and "the Rail-Splitter," were exploited to the full. The goal was to emphasize the superior power of "free labor," whereby a common farm boy could work his way to the top by his own efforts.
On November 6, 1860, Lincoln was elected as the 16th President of the United States, beating Democrat Stephen A. Douglas, John C. Breckinridge of the Southern Democrats, and John Bell of the new Constitutional Union Party. He was the first Republican president, winning entirely on the strength of his support in the North: he was not even on the ballot in nine states in the South, and won only 2 of 996 counties in the other Southern states. Lincoln gained 1,865,908 votes (39.9% of the total), for 180 electoral votes; Douglas, 1,380,202 (29.5%) for 12 electoral votes; Breckenridge, 848,019 (18.1%) for 72 electoral votes; and Bell, 590,901 (12.5%) for 39 electoral votes. There were fusion tickets in some states, but even if his opponents had combined in every state, Lincoln had a majority vote in all but two of the states in which he won the electoral votes and would still have won the electoral college and the election.
As Lincoln's election became more likely, secessionists made it clear that their states would leave the Union. South Carolina took the lead, followed by six other cotton-growing states in the deep South. The upper South (Delaware, Maryland, Virginia, North Carolina, Tennessee, Kentucky, Missouri, and Arkansas) listened to and rejected the secessionist appeal. They decided to stay in the Union, though they warned Lincoln that they would not support an invasion through their territory. The seven Confederate states seceded before Lincoln took office, declaring themselves to be a new nation, the Confederate States of America. President Buchanan and President-elect Lincoln refused to recognize the Confederacy.
President-elect Lincoln evaded possible assassins in Baltimore, and on February 23, 1861, arrived in disguise in Washington, D.C. At his inauguration on March 4, 1861, the German American Turners formed Lincoln's bodyguard; and a sizable garrison of federal troops was also present, ready to protect the capital from Confederate invasion and local insurrection.
In his First Inaugural Address, Lincoln declared, "I hold that in contemplation of universal law and of the Constitution the Union of these States is perpetual. Perpetuity is implied, if not expressed, in the fundamental law of all national governments," arguing further that the purpose of the United States Constitution was "to form a more perfect union" than the Articles of Confederation which were explicitly perpetual, thus the Constitution too was perpetual. He asked rhetorically that even were the Constitution a simple contract, would it not require the agreement of all parties to rescind it?
By the time Lincoln took office, the Confederacy was an established fact, and no leaders of the insurrection proposed rejoining the Union on any terms. No compromise was found because a compromise was deemed virtually impossible. Buchanan might have allowed the southern states to secede, and some Republicans recommended that. However, conservative Democratic nationalists, such as Jeremiah S. Black, Joseph Holt, and Edwin M. Stanton had taken control of Buchanan's cabinet around January 1, 1861, and refused to accept secession. Lincoln and nearly every Republican leader adopted this position by March 1861: the Union could not be dismantled. However, as a strict follower of the constitution, Lincoln refused to take any action against the South unless the Unionists themselves were attacked first. This finally happened in April 1861.
Historian Allan Nevins argues that Lincoln made three miscalculations in believing that he could preserve the Union, hold government property, and still avoid war. He "temporarily underrated the gravity of the crisis," overestimated the strength of Unionist sentiment in the South and border states, and misunderstood the conditional support of Unionists in the border states.
In April 1861, after Union troops at Fort Sumter were fired upon and forced to surrender, Lincoln called on the governors of every state to send detachments totaling 75,000 troops to recapture forts, protect the capital, and "preserve the Union," which in his view still existed intact despite the actions of the seceding states. Virginia, which had repeatedly warned Lincoln that it would not allow an invasion of its territory or join an attack on another state, responded by seceding, along with North Carolina, Tennessee, and Arkansas.
The slave states of Missouri, Kentucky, Maryland, and Delaware did not secede, and Lincoln urgently negotiated with state leaders there, promising not to interfere with slavery. After the fighting started, he had rebel leaders arrested in all the border areas (especially in Maryland) and held in military prisons without trial. Over 18,000 were arrested, though none were executed. One, Clement Vallandigham, was exiled; but all of the remainder were released, usually after two or three months (see: Ex parte Merryman).
The Emancipation Proclamation, announced on September 22 and put into effect on January 1, 1863, freed slaves in territories not under Union control. As Union armies advanced south, more slaves were liberated until all of them in Confederate hands (over three million) were freed. Lincoln later said: "I never, in my life, felt more certain that I was doing right, than I do in signing this paper." The proclamation made the abolition of slavery in the rebel states an official war goal. Lincoln then threw his energies into passage of the Thirteenth Amendment to permanently abolish slavery throughout the nation.
In September 1862, thirteen northern governors met in Altoona, Pennsylvania, at the Loyal War Governors' Conference to discuss the Proclamation and Union war effort. In the end, the state executives fully supported the president's Proclamation and also suggested the removal of General George B. McClellan as commander of the Union's Army of the Potomac.
As a result of the bloodiest battle in the war which took place at Gettysburg, July 1-3, 1863, Lincoln's war effort suffered a great blow. As the Union Army decreased in numbers due to death, more soldiers were needed to replace the ranks. Lincoln's 1863 drafts were considered "odious" among many in the north, particularly immigrants. The New York Draft Riots of July, 1863 were the most notable manifestation of this discontent.
By November 1863, Lincoln was quite sensible of the fact that he desperately needed to do or say something that would revive the Union's spirits toward the war effort. Operating in an era without TV, radio, or internet, Lincoln would have to get his message out via the press. His presence at the dedication of the Gettysburg cemetery would certainly draw reporters from around the country, and by means of their reports, Lincoln could speak to the nation. Hence, his decision to go to Gettysburg and urge the Union to highly resolve that the dead there "shall not have died in vain" was Lincoln's way of saying that if the Copperhead peace democrats get their way, then the men who there gave the "last full measure of devotion" will have done so for no reason at all. In the Gettysburg Address, Lincoln was proposing this question: what would these men who died for this cause want us to do--quit now or finish the job? How the country answered this question would determine the 1864 election.
The political power of Lincoln's rhetoric was undeniable. Even a Copperhead with the misfortune of Mrs. Bixby would be moved by Lincoln's call to "be here dedicated to the unfinished work" that men like her sons had thus far so nobly advanced. Perhaps the most important political consequence of the power of the Gettysburg Address is that Lincoln indeed won the election in 1864, thus assuring that the war would continue until the victory had been achieved.
After Union victories at Gettysburg, Vicksburg and Chattanooga in 1863, victory seemed at hand, and Lincoln promoted Ulysses S. Grant General-in-Chief ( March 12, 1864). When the spring campaigns turned into bloody stalemates, Lincoln supported Grant's strategy of wearing down Lee's Confederate army at the cost of heavy Union casualties. With an election looming, he easily defeated efforts to deny his renomination. At the Convention, the Republican Party selected Andrew Johnson, a War Democrat from the Southern state of Tennessee, as his running mate in order to form a broader coalition. They ran on the new Union Party ticket uniting Republicans and War Democrats.
Lincoln did not show the pledge to his cabinet, but asked them to sign the sealed envelope.
While the Democratic platform followed the Peace wing of the party and called the war a "failure," their candidate, General George B. McClellan, supported the war and repudiated the platform.
Lincoln provided Grant with new replacements and mobilized his party to support Grant and win local support for the war effort. Sherman's capture of Atlanta in September ended defeatist jitters; the Democratic Party was deeply split, with some leaders and most soldiers openly for Lincoln; the Union party was united and energized, and Lincoln was easily reelected in a landslide. He won all but two states, capturing 212 of 233 electoral votes.
On March 4 1865, Lincoln delivered his second inaugural address, his favorite of all his speeches. At this time, a victory over the rebels was at hand, slavery was dead, and Lincoln was looking to the future.
The war was a source of constant frustration for the president, and occupied nearly all of his time. He had a contentious relationship with General McClellan, who became general-in-chief of all the Union armies in the wake of the embarrassing Union defeat at the First Battle of Bull Run and after the retirement of Winfield Scott in late 1861. Despite his inexperience in military affairs, Lincoln wanted to take an active part in determining war strategy. His priorities were twofold: to ensure that Washington, D.C. was well defended; and to conduct an aggressive war effort in the hope of ending the war quickly and appeasing the Northern public and press. McClellan, a youthful West Point graduate and railroad executive called back to active military service, took a more cautious approach. He took several months to plan and execute his Peninsula Campaign, with the objective of capturing Richmond by moving the Army of the Potomac by boat to the peninsula between the James and York Rivers. McClellan's delay irritated Lincoln, as did his insistence that no troops were needed to defend Washington, D.C. Lincoln insisted on holding some of McClellan's troops to defend the capital, a decision McClellan blamed for the ultimate failure of the Peninsula Campaign.
McClellan, a lifelong Democrat who was temperamentally conservative, was relieved as general-in-chief after releasing his "Harrison's Landing Letter", where he offered unsolicited political advice to Lincoln urging caution in the war effort. McClellan's letter incensed Radical Republicans, who successfully pressured Lincoln to appoint John Pope, a Republican, as head of the new Army of Virginia. Pope complied with Lincoln's strategic desire to move toward Richmond from the north, thus protecting the capital from attack. But Pope was soundly defeated at the Second Battle of Bull Run in the summer of 1862, forcing the Army of the Potomac to defend Washington for a second time. In response to his failure, Pope was sent to Minnesota to fight the Sioux.
Panicked by Lee's invasion of Maryland, Lincoln restored McClellan to command of all forces around Washington in time for the Battle of Antietam (September 1862). The ensuing Union victory enabled Lincoln to release his Emancipation Proclamation, but he relieved McClellan of his command shortly after the 1862 midterm elections and appointed Republican Ambrose Burnside to head the Army of the Potomac. Burnside had promised to follow through on Lincoln's strategic vision for a strong offensive against Lee and Richmond. After Burnside was stunningly defeated at Fredericksburg, Joseph Hooker was given the command, despite his idle talk about the necessity for a military dictator to win the war and a past history of criticizing his commanders. Hooker was routed by Lee at the Battle of Chancellorsville (May 1863), and relieved of command early in the subsequent Gettysburg Campaign replaced by George Meade.
After the Union victory at Gettysburg, Meade's failure to pursue Lee and months of inactivity for the Army of the Potomac persuaded Lincoln to bring in a western general, Ulysses S. Grant. Grant already had a solid string of victories in the Western Theater, including the battles of Vicksburg and Chattanooga. Responding to criticism of Grant, Lincoln was quoted as saying, "I cannot spare this man. He fights." Grant waged his bloody Overland Campaign in 1864 with a strategy of a war of attrition, characterized by high Union losses at battles such as the Wilderness and Cold Harbor, but by proportionately higher Confederate losses. His invasion campaign eventually bottled Lee up in the Siege of Petersburg, so that Grant could take Richmond, and bring the war to a close in the spring of 1865.
Lincoln authorized Grant to target civilians and infrastructure, hoping to destroy the South's morale and weaken its economic ability to continue fighting. This allowed Generals Sherman and Sheridan to destroy farms and towns in the Shenandoah Valley, Georgia, and South Carolina. The damage caused by Sherman's March to the Sea through Georgia totaled in excess of $100 million by Sherman's own estimate.
Lincoln had a star-crossed record as a military leader, possessing a keen understanding of strategic points (such as the Mississippi River and the fortress city of Vicksburg) and the importance of defeating the enemy's army, rather than simply capturing cities. He had, however, limited success in motivating his commanders to adopt his strategies until late 1863, when he found a man who shared his vision of the war in Ulysses S. Grant. Only then could he insist on using African American troops and relentlessly pursue a series of coordinated offensives in multiple theaters.
Throughout the war, Lincoln showed a keen curiosity with the military campaigns. He spent hours at the War Department telegraph office, reading dispatches from his generals. He visited battle sites frequently, and seemed fascinated by watching scenes of war. During Jubal Anderson Early's raid on Washington, D.C. in 1864, Lincoln had to be told to duck to avoid being shot while observing the battle.
Reconstruction began during the war as Lincoln and his associates pondered questions of how to reintegrate the Southern states and what to do with Confederate leaders and the freed slaves. Lincoln led the "moderates" regarding Reconstructionist policy, and was usually opposed by the Radical Republicans, under Thaddeus Stevens in the House and Charles Sumner and Benjamin Wade in the Senate (though he cooperated with these men on most other issues). Determined to find a course that would reunite the nation and not alienate the South, Lincoln urged that speedy elections under generous terms be held throughout the war in areas behind Union lines. His Amnesty Proclamation of December 8, 1863, offered pardons to those who had not held a Confederate civil office, had not mistreated Union prisoners, and would sign an oath of allegiance. Critical decisions had to be made as state after state was reconquered. Of special importance were Tennessee, where Lincoln appointed Andrew Johnson as governor, and Louisiana, where Lincoln attempted a plan that would restore statehood when 10 percent of the voters agreed to it. The Radicals thought this policy too lenient, and passed their own plan, the Wade-Davis Bill, in 1864. When Lincoln pocket-vetoed the bill, the Radicals retaliated by refusing to seat representatives elected from Louisiana, Arkansas, and Tennessee.
Lincoln's powerful rhetoric defined the issues of the war for the nation, the world, and posterity. His extraordinary command of the English language was evidenced in the Gettysburg Address, a speech dedicating the cemetery at Gettysburg that he delivered on November 19, 1863. The speech defied Lincoln's own prediction that "the world will little note, nor long remember what we say here." Lincoln's second inaugural address is also greatly admired and often quoted. In these speeches, Lincoln articulated better than anyone else the rationale behind the Union cause.
In recent years, historians have stressed Lincoln's use of and redefinition of republican values. As early as the 1850s, a time when most political rhetoric focused on the sanctity of the Constitution, Lincoln shifted emphasis to the Declaration of Independence as the foundation of American political values — what he called the "sheet anchor" of republicanism. The Declaration's emphasis on freedom and equality for all, rather than the Constitution's tolerance of slavers, shifted the debate. As Diggins concludes regarding the highly influential Cooper Union speech, "Lincoln presented Americans a theory of history that offers a profound contribution to the theory and destiny of republicanism itself." His position gained strength because he highlighted the moral basis of republicanism, rather than its legalisms. Nevertheless, in 1861 Lincoln justified the war in terms of legalisms (the Constitution was a contract, and for one party to get out of a contract all the other parties had to agree), and then in terms of the national duty to guarantee a "republican form of government" in every state. That duty was also the principle underlying federal intervention in Reconstruction.
During the Civil War, Lincoln appropriated powers no previous President had wielded: he used his war powers to proclaim a blockade, suspended the writ of habeas corpus, spent money without congressional authorization, and imprisoned 18,000 suspected Confederate sympathizers without trial. Nearly all of his actions, although vehemently denounced by the Copperheads, were subsequently upheld by Congress and the Courts.
Lincoln believed in the Whig theory of the presidency, which left Congress to write the laws while he signed them, vetoing only those bills that threatened his war powers. Thus, he signed the Homestead Act in 1862, making millions of acres of government-held land in the West available for purchase at very low cost. The Morrill Land-Grant Colleges Act, also signed in 1862, provided government grants for agricultural universities in each state. The Pacific Railway Acts of 1862 and 1864 granted federal support for the construction of the United States' First Transcontinental Railroad, which was completed in 1869. Other important legislation involved economic matters, including the first income tax and higher tariffs. Also included was the creation of the system of national banks by the National Banking Acts of 1863, 1864, and 1865, which allowed the creation of a strong national financial system. Congress created and Lincoln approved the Department of Agriculture in 1862, although that institution would not become a Cabinet-level department until 1889.
The Legal Tender Act of 1862 established the United States Note, the first paper currency in United States history. This was done to increase the money supply to pay for fighting the war.
During the war, Lincoln's Treasury Department effectively controlled all cotton trade in the occupied South — the most dramatic incursion of federal controls on the economy.
In 1862, Lincoln sent a senior general, John Pope, to put down the "Sioux Uprising" in Minnesota. Presented with 303 death warrants for convicted Santee Dakota who had massacred innocent farmers, Lincoln affirmed 39 of these for execution (one was later reprieved).
Originally, John Wilkes Booth, a well-known actor and a Confederate spy from Maryland, had formulated a plan to kidnap Lincoln in exchange for the release of Confederate prisoners. After attending an April 11 speech in which Lincoln promoted voting rights for blacks, an incensed Booth changed his plans and determined to assassinate the president. Learning that the President and First Lady, together with the Grants, would be attending Ford's Theatre, he laid his plans, assigning his co-conspirators to assassinate Vice President Andrew Johnson and Secretary of State William H. Seward.
Without his main bodyguard Ward Hill Lamon, to whom he related his famous dream regarding his own assassination, Lincoln left to attend the play Our American Cousin on April 14, 1865. As a lone bodyguard wandered, and Lincoln sat in his state box (Box 7) in the balcony, Booth crept up behind the President and waited for the funniest line of the play, hoping the laughter would muffle the noise of the gunshot. When the laughter began, Booth jumped into the box and aimed a single-shot, round-slug.44 caliber Henry Deringer at his head, firing at point-blank range. Major Henry Rathbone momentarily grappled with Booth but was cut by Booth's knife. Booth then leapt to the stage and shouted "Sic semper tyrannis!" (Latin: "Thus always to tyrants") and escaped, despite a broken leg suffered in the leap. A twelve-day manhunt ensued, in which Booth was chased by Federal agents (under the direction of Secretary of War Edwin M. Stanton). He was eventually cornered in a Virginia barn house and shot, dying of his wounds soon after.
An army surgeon, Doctor Charles Leale, initially assessed Lincoln's wound as mortal. The President was taken across the street from the theater to the Petersen House, where he lay in a coma for nine hours before he died. Several physicians attended Lincoln, including U.S. Army Surgeon General Joseph K. Barnes of the Army Medical Museum. Using a probe, Barnes located some fragments of Lincoln's skull and the ball lodged 6 inches (15 cm) inside his brain. Lincoln never regained consciousness and was officially pronounced dead at 7:22:10 a.m. April 15, 1865 at the age of 56. There is some disagreement among historians as to Stanton's words after Lincoln died. All agree that he began "Now he belongs to the.." with some stating he said "ages" while others believe he said "angels." After Lincoln's body was returned to the White House, his body was prepared for his lying in repose in the East Room. He was the first president to be assassinated or to lie in state.
The Army Medical Museum, now named the National Museum of Health and Medicine, has retained in its collection several artifacts relating to the assassination. Currently on display are the bullet that was fired from the Derringer pistol, the probe used by Barnes, pieces of Lincoln's skull and hair, and the surgeon's cuff stained with Lincoln's blood.
Lincoln's body was carried by train in a grand funeral procession through several states on its way back to Illinois. While much of the nation mourned him as the savior of the United States, Copperheads celebrated the death of a man they considered an unconstitutional tyrant. The Lincoln Tomb in Oak Ridge Cemetery in Springfield, is 177 feet (54 m) tall and, by 1874, was surmounted with several bronze statues of Lincoln. To prevent repeated attempts to steal Lincoln's body and hold it for ransom, Robert Todd Lincoln had Lincoln exhumed and reinterred in concrete several feet thick in 1901.
With over 120 photographs taken of him, Lincoln was the most photographed man in the United States up to the time he was assassinated.
Lincoln was known for appointing political rivals to high positions in his cabinet to keep in line all factions of his party — and to let them battle each other and not combine against Lincoln. Historians agree that except for Simon Cameron, it was a highly effective group.
In March 1860 in a speech in New Haven, Connecticut, Lincoln said, with respect to slavery, "Whenever this question shall be settled, it must be settled on some philosophical basis. No policy that does not rest upon some philosophical public opinion can be permanently maintained." The philosophical basis for Lincoln’s beliefs regarding slavery and other issues of the day require that Lincoln be examined "seriously as a man of ideas." Lincoln was a strong supporter of the American Whig version of liberal capitalism who, more than most politicians of the time, was able to express his ideas within the context of Nineteenth Century religious beliefs.
There were few people who strongly or directly influenced Lincoln’s moral and intellectual development and perspectives. There was no teacher, mentor, church leader, community leader, or peer that Lincoln would credit in later years as a strong influence on his intellectual development. Lacking a formal education, Lincoln’s personal philosophy was shaped by "an amazingly retentive memory and a passion for reading and learning." It was Lincoln’s reading, rather than his relationships, that were most influential in shaping his personal beliefs. Lincoln’s reading and study of the Bible was an integral part of his intellectual roots.
He found in the Declaration justification for Whig economic policy and opposition to territorial expansion and the nativist platform of the Know Nothings. In claiming that all men were created free, Lincoln and the Whigs argued that this freedom required economic advancement, expanded education, territory to grow, and the ability of the nation to absorb the growing immigrant population.
It was the Declaration of Independence, rather than the Bible, that Lincoln most relied on in order to oppose any further territorial expansion of slavery. He saw the Declaration as more than a political document. To him, as well as to many abolitionists and other antislavery leaders, it was, foremost, a moral document that had forever determined valuable criteria in shaping the future of the nation.
Lincoln's death made the President a martyr to many. Repeated polls of historians have ranked Lincoln as among the greatest presidents in U.S. history, often appearing in the first position. Among contemporary admirers, Lincoln is usually seen as personifying classical values of honesty and integrity, as well as respect for individual and minority rights, and human freedom in general.
Many American organizations of all purposes and agendas continue to cite his name and image, with interests ranging from the gay rights-supporting Log Cabin Republicans to the insurance corporation Lincoln National Corporation. The Lincoln automobile is also named after him. The ballistic missile submarine Abraham Lincoln (SSBN-602) and the aircraft carrier Abraham Lincoln (CVN-72) were named in his honor. Also, the Liberty ship SS Nancy Hanks was named for his mother. During the Spanish Civil War, the American faction of the International Brigades named themselves the Abraham Lincoln Brigade.
Lincoln has been memorialized in many city names, notably the capital of Nebraska. Lincoln, Illinois, is the only city to be named for Abraham Lincoln before he became President. Lincoln's name and image appear in numerous places. These include the Lincoln Memorial in Washington, D.C. the U.S. Lincoln $5 bill and the Lincoln cent, Lincoln's sculpture on the Mount Rushmore, and the Lincoln Home National Historic Site in Springfield, Illinois. In addition, New Salem, Illinois (a reconstruction of Lincoln's early adult hometown), Ford's Theatre, and Petersen House (where he died) are all preserved as museums. The Lincoln Shrine in Redlands, California, is located behind the A.K. Smiley Public Library. The state nickname for Illinois is Land of Lincoln.
Counties in 19 U.S. states (Arkansas, Colorado, Idaho, Kansas, Maine, Minnesota, Mississippi, Montana, Nebraska, Nevada, New Mexico, Oklahoma, Oregon, South Dakota, Tennessee, West Virginia, Washington, Wisconsin, and Wyoming) are named after Lincoln.
Abraham Lincoln's birthday, February 12, was formerly a national holiday, now commemorated as Presidents' Day. However, it is still observed in Illinois and many other states as a separate legal holiday, Lincoln's Birthday. A dozen states have legal holidays celebrating the third Monday in February as 'Presidents' Day' as a combination Washington-Lincoln Day.
To commemorate his upcoming 200th birthday in February 2009, Congress established the Abraham Lincoln Bicentennial Commission (ALBC) in 2000. Dedicated to renewing American appreciation of Lincoln’s legacy, the 15-member commission is made up of lawmakers and scholars and also features an adivsory board of over 130 various Lincoln historians and enthusiasts. Located at Library of Congress in Washington, D.C. the ALBC is the organizing force behind numerous tributes, programs and cultural events highlighting a two-year celebration scheduled to begin in February 2008 at Lincoln’s birthplace: Hodgenville, Kentucky.
Lincoln's birthplace and family home are national historic memorials: the Abraham Lincoln Birthplace National Historic Site in Hodgenville, and the Lincoln Home National Historic Site in Springfield, Illinois. The Abraham Lincoln Presidential Library and Museum opened in Springfield in 2005; it is a major tourist attraction, with state-of-the-art exhibits. The Abraham Lincoln National Cemetery is located in Elwood, Illinois.


Aristotle (Greek: Aristotélēs) (384 BC – 322 BC) was a Greek philosopher, a student of Plato and teacher of Alexander the Great. He wrote on many different subjects, including physics, metaphysics, poetry, theater, music, logic, rhetoric, politics, government, ethics, biology and zoology.
Aristotle (together with Socrates and Plato) is one of the most important philosophers in Western thought. He was one of the first to systematize Western philosophy and science. His thinking on physics and science had a profound impact on medieval thought, which lasted until the Renaissance, and the accuracy of some of his biological observations was only confirmed in the last century. His logical works contain the earliest formal study of logic known and were not superseded until the late nineteenth century. In the Middle Ages, Aristotelian metaphysics had a profound influence on philosophical and theological thinking in the Islamic and Jewish traditions, and on Christian thought, where its legacy is still felt in Christian theology, for example in Orthodox theology, and especially within the Catholic tradition shaped by scholasticism. All aspects of Aristotle's philosophy continue to be the object of active academic study today.
Though Aristotle wrote many elegant treatises and dialogues (Cicero described his literary style as "a river of gold"), it is thought that the majority of his writings are now lost. They were lost and rediscovered several times, and it is believed that only about one fifth of the original works has survived.
Aristotle was born in Stageira, Chalcidice, in 384 BC. His father was the personal physician to King Amyntas of Macedon. Aristotle was trained and educated as a member of the aristocracy. At about the age of eighteen, he went to Athens to continue his education at Plato's Academy. Aristotle remained at the academy for nearly twenty years, not leaving until after Plato's death in 347 BC. He then traveled with Xenocrates to the court of Hermias of Atarneus in Asia Minor. While in Asia, Aristotle traveled with Theophrastus to the island of Lesbos, where together they researched the botany and zoology of the island. Aristotle married Hermias' daughter (or niece) Pythias. She bore him a daughter, whom they named Pythias. Soon after Hermias' death, Aristotle was invited by Philip of Macedon to become tutor to Alexander the Great.
After spending several years tutoring the young Alexander, Aristotle returned to Athens. By 335 BC, he established his own school there, known as the Lyceum. Aristotle conducted courses at the school for the next twelve years. While in Athens, his wife Pythias died, and Aristotle became involved with Herpyllis of Stageira, who bore him a son whom he named after his father, Nicomachus. According to the Suda, he also had an eromenos, Palaephatus of Abydus.
It is during this period in Athens when Aristotle is believed to have composed many of his works. Aristotle wrote many dialogues, only fragments of which survived. The works that have survived are in treatise form and were not, for the most part, intended for widespread publication, as they are generally thought to be lecture aids for his students. His most important treatises include Physics, Metaphysics, Nicomachean Ethics, Politics, De Anima (On the Soul) and Poetics. These works, although connected in many fundamental ways, vary significantly in both style and substance.
Aristotle not only studied almost every subject possible at the time, but made significant contributions to most of them. In physical science, Aristotle studied anatomy, astronomy, economics, embryology, geography, geology, meteorology, physics and zoology. In philosophy, he wrote on aesthetics, ethics, government, metaphysics, politics, psychology, rhetoric and theology. He also studied education, foreign customs, literature and poetry. His combined works constitute a virtual encyclopedia of Greek knowledge. It has been suggested that Aristotle was probably the last person to know everything there was to be known in his own time.
Upon Alexander's death, anti-Macedonian sentiment in Athens once again flared. Eurymedon the hierophant denounced Aristotle for not holding the gods in honor. Aristotle fled the city to his mother's family estate in Chalcis, explaining, "I will not allow the Athenians to sin twice against philosophy." However, he died in Euboea of natural causes within the year (in 323 BC). Aristotle left a will and named chief executor his student Antipater, in which he asked to be buried next to his wife.
Aristotle's conception of logic was the dominant form of logic until 19th century advances in mathematical logic. Kant stated in the Critique of Pure Reason that Aristotle's theory of logic completely accounted for the core of deductive inference.
Aristotle "says that 'on the subject of reasoning' he 'had nothing else on an earlier date to speak of'". However, Plato reports that syntax was devised before him, by Prodikos of Keos, who was concerned by the correct use of words. Logic seems to have emerged from dialectics; the earlier philosophers made frequent use of concepts like reductio ad absurdum in their discussions, but never truly understood the logical implications. Even Plato had difficulties with logic; although he had a reasonable conception of a deduction system, he could never actually construct one and relied instead on his dialectic, which confused science with methodology. Plato believed that deduction would simply follow from premises, hence he focused on maintaining solid premises so that the conclusion would logically follow. Consequently, Plato realized that a method for obtaining conclusions would be most beneficial. He never succeeded in devising such a method, but his best attempt was published in his book Sophist, where he introduced his division method.
The order of the books (or the teachings from which they are composed) is not certain, but this list was derived from analysis of Aristotle's writings. It goes from the basics, the analysis of simple terms in the Categories, to the study of more complex forms, namely, syllogisms (in the Analytics) and dialectics (in the Topics and Sophistical Refutations). There is one volume of Aristotle's concerning logic not found in the Organon, namely the fourth book of Metaphysics.
Aristotle is also the creator of syllogisms with modalities (modal logic). The word modal refers to the word 'modes', explaining the fact that modal logic deals with the modes of truth. Aristotle introduced the qualification of 'necessary' and 'possible' premises.
Like his teacher Plato, Aristotle's philosophy aims at the universal. Aristotle, however, found the universal in particular things, which he called the essence of things, while Plato finds that the universal exists apart from particular things, and is related to them as their prototype or exemplar. For Aristotle, therefore, philosophic method implies the ascent from the study of particular phenomena to the knowledge of essences, while for Plato philosophic method means the descent from a knowledge of universal Forms (or ideas) to a contemplation of particular imitations of these. For Aristotle, "form" still refers to the unconditional basis of phenomena but is "instantiated" in a particular substance (see Universals and particulars, below). In a certain sense, Aristotle's method is both inductive and deductive, while Plato's is essentially deductive from a priori principles.
In Aristotle's terminology, "natural philosophy" is a branch of philosophy examining the phenomena of the natural world, and included fields that would be regarded today as physics, biology and other natural sciences. In modern times, the scope of philosophy has become limited to more generic or abstract inquiries, such as ethics and metaphysics, in which logic plays a major role. Today's philosophy tends to exclude empirical study of the natural world by means of the scientific method. In contrast, Aristotle's philosophical endeavors encompassed virtually all facets of intellectual inquiry.
In the larger sense of the word, Aristotle makes philosophy coextensive with reasoning, which he also would describe as "science". Note, however, that his use of the term science carries a different meaning than that covered by the term "scientific method". For Aristotle, "all science (dianoia) is either practical, poetical or theoretical" (Metaphysics 1025b25). By practical science, he means ethics and politics; by poetical science, he means the study of poetry and the other fine arts; by theoretical science, he means physics, mathematics and metaphysics.
If logic (or "analytics") is regarded as a study preliminary to philosophy, the divisions of Aristotelian philosophy would consist of: (1) Logic; (2) Theoretical Philosophy, including Metaphysics, Physics, Mathematics, (3) Practical Philosophy and (4) Poetical Philosophy.
In the period between his two stays in Athens, between his times at the Academy and the Lyceum, Aristotle conducted most of the scientific thinking and research for which he is renowned today. In fact, most of Aristotle's life was devoted to the study of the objects of natural science. Aristotle’s metaphysics contains observations on the nature of numbers but he made no original contributions to mathematics. He did, however, perform original research in the natural sciences, e.g. botany, zoology, physics, astronomy, chemistry, meteorology, and several other sciences.
Aristotle's writings on science are largely qualitative, as opposed to quantitative. Beginning in the sixteenth century, scientists began applying mathematics to the physical sciences, and Aristotle's work in this area was deemed hopelessly inadequate. His failings were largely due to the absence of concepts like mass, velocity, force and temperature. He had a conception of speed and temperature, but no quantitative understanding of them, which was partly due to the absence of basic experimental devices, like clocks and thermometers.
In places, Aristotle goes too far in deriving 'laws of the universe' from simple observation and over-stretched reason. Today's scientific method assumes that such thinking without sufficient facts is ineffective, and that discerning the validity of one's hypothesis requires far more rigorous experimentation than that which Aristotle used to support his laws.
Aristotle also had some scientific blind spots, the largest being his inability to see the application of mathematics to physics. Aristotle held that physics was about changing objects with a reality of their own, whereas mathematics was about unchanging objects without a reality of their own. In this philosophy, he could not imagine that there was a relationship between them. He also posited a flawed cosmology that we may discern in selections of the Metaphysics, which was widely accepted up until the 1500s. From the 3rd century to the 1500s, the dominant view held that the Earth was the center of the universe (geocentrism). This scientific concept, as proposed by Aristotle and Plato was later adopted as dogma by the Roman Catholic Church because it placed mankind at the center of the universe, and scientists who disagreed, such as Galileo, were considered heretics. This erroneous concept was eventually rejected.
Since he was perhaps the philosopher most respected by European thinkers during and after the Renaissance, these thinkers often took Aristotle's erroneous positions as given, which held back science in this epoch. However, Aristotle's scientific shortcomings should not mislead one into forgetting his great advances in the many scientific fields. For instance, he founded logic as a formal science and created foundations to biology that were not superseded (in the West) for two millennia. Moreover, he introduced the fundamental notion that nature is composed of things that change and that studying such changes can provide useful knowledge of underlying constants. This made the study of physics, and all other sciences, respectable. In actuality, however, this observation transcends physics into metaphysics.
Each of the four earthly elements has its natural place; the earth at the centre of the universe, then water, then air, then fire. When they are out of their natural place they have natural motion, requiring no external cause, which is towards that place; so bodies sink in water, air bubbles up, rain falls, flame rises in air. The heavenly element has perpetual circular motion.
Additionally, things can be causes of one another, causing each other reciprocally, as hard work causes fitness and vice versa, although not in the same way or function, the one is as the beginning of change, the other as the goal. (Thus Aristotle first suggested a reciprocal or circular causality as a relation of mutual dependence or influence of cause upon effect). Moreover, Aristotle indicated that the same thing can be the cause of contrary effects; its presence and absence may result in different outcomes.
Aristotle marked two modes of causation: proper (prior) causation and accidental (chance) causation. All causes, proper and incidental, can be spoken as potential or as actual, particular or generic. The same language refers to the effects of causes, so that generic effects assigned to generic causes, particular effects to particular causes, operating causes to actual effects. Essentially, causality does not suggest a temporal relation between the cause and the effect.
All further investigations of causality will consist of imposing the favorite hierarchies on the order causes, such as final > efficient > material > formal (Thomas Aquinas), or of restricting all causality to the material and efficient causes or to the efficient causality (deterministic or chance) or just to regular sequences and correlations of natural phenomena (the natural sciences describing how things happen instead of explaining the whys and wherefores).
Spontaneity and chance are causes of effects. Chance as an incidental cause lies in the realm of accidental things. It is "from what is spontaneous" (but note that what is spontaneous does not come from chance). For a better understanding of Aristotle's conception of "chance" it might be better to think of "coincidence": Something takes place by chance if a person sets out with the intent of having one thing take place, but with the result of another thing (not intended) taking place. For example: A person seeks donations. That person may find another person willing to donate a substantial sum. However, if the person seeking the donations met the person donating, not for the purpose of collecting donations, but for some other purpose, Aristotle would call the collecting of the donation by that particular donator a result of chance. It must be unusual that something happens by chance. In other words, if something happens all or most of the time, we cannot say that it is by chance.
There is also more specific kind of chance, which Aristotle names "luck", that can only apply to human beings, since it is in the sphere of moral actions. According to Aristotle, luck must involve choice (and thus deliberation), and only humans are capable of deliberation and choice. "What is not capable of action cannot do anything by chance".
Aristotle examines the concept of substance (ousia) in his Metaphysics, Book VII and he concludes that a particular substance is a combination of both matter and form. As he proceeds to the book VIII, he concludes that the matter of the substance is the substratum or the stuff of which it is composed, e.g. the matter of the house are the bricks, stones, timbers etc. or whatever constitutes the potential house. While the form of the substance, is the actual house, namely ‘covering for bodies and chattels’ or any other differentia (see also predicables). The formula that gives the components is the account of the matter, and the formula that gives the differentia is the account of the form.
3. alteration, which is change in quality.
The coming to be is a change where nothing persists of which the resultant is a property. In that particular change he introduces the concept of potentiality (dynamis) and actuality (entelecheia) in association with the matter and the form.
Referring to potentiality, this is what a thing is capable of doing, or being acted upon, if it is not prevented by something else. For example, the seed of a plant in the soil is potentially (dynamei) plant, and if is not prevented by something, it will become a plant. Potentially beings can either 'act' (poiein) or 'be acted upon' (paschein), which can be either innate or learned. For example, the eyes possess the potentiality of sight (innate - being acted upon), while the capability of playing the flute can be possessed by learning (exercise - acting).
In conclusion, the matter of the house is its potentiality and the form is its actuality. The formal cause (aitia) then of that change from potential to actual house, is the reason (logos) of the house builder and the final cause is the end, namely the house itself. Then Aristotle proceeds and concludes that the actuality is prior to potentiality in formula, in time and in substantiality.
With this definition of the particular substance (i.e. matter and form), Aristotle tries to solve the problem of the unity of the beings, e.g. what is that makes the man one? Since, according to Plato there are two Ideas: animal and biped, how then is man a unity? However, according to Aristotle, the potential being (matter) and the actual one (form) are one and the same thing.
Aristotle's predecessor, Plato, argued that all things have a universal form, which could be either a property, or a relation to other things. When we look at an apple, for example, we see an apple, and we also analyze a form of an apple. In this distinction, there is a particular apple and a universal form of an apple. Moreover, we can place an apple next to a book, so that we can speak of both the book and apple as being next to each other.
Plato argued that there are some universal forms that are not a part of particular things. For example, it is possible that there is no particular good in existence, but "good" is still a proper universal form. Bertrand Russell is a contemporary philosopher that agreed with Plato on the existence of "uninstantiated universals".
Aristotle disagreed with Plato on this point, arguing that all universals are "instantiated". Aristotle argued that there are no universals that are unattached to existing things. According to Aristotle, if a universal exists, either as a particular or a relation, then there must have been, must be currently, or must be in the future, something on which the universal can be predicated. Consequently, according to Aristotle, if it is not the case that some universal can be predicated to an object that exists at some period of time, then it does not exist.
One way for contemporary philosophers to justify this position is by asserting the eleatic principle.
In addition, Aristotle disagreed with Plato about the location of universals. As Plato spoke of the world of the forms, a location where all universal forms subsist, Aristotle maintained that universals exist within each thing on which each universal is predicated. So, according to Aristotle, the form of apple exists within each apple, rather than in the world of the forms.
Aristotle is the earliest natural historian whose work has survived in some detail. Aristotle did his research on natural history on the isle of Lesbos. The works that reflect this research, including History of Animals, Generation of Animals, and Parts of Animals, contain some remarkable observations and interpretations, along with sundry myths and mistakes. The most striking passages are about the sea-life visible from observation on Lesbos and available from the catches of fishermen. His observations on catfish, electric fish (Torpedo) and angler-fish are exceptional, as is his writing on cephalopods, molluscs, octopus, sepia (cuttlefish) and the paper nautilus (Argonauta argo). His description of the hectocotyl arm (see cephalopod) was about two thousand years ahead of its time, and widely disbelieved until its rediscovery in the nineteenth century. He separated the aquatic mammals from fish, and knew that sharks and rays were part of the group he called Selachē (selachians). He gave accurate descriptions of ruminants' four-chambered fore-stomachs, and of the unusual mammal-like embryological development of the hound shark Mustelus laevis.
However, for Charles Singer, "Nothing is more remarkable than [Aristotle's] efforts to [exhibit] the relationships of living things as a scala naturae" Aristotle's History of Animals classified organisms in relation to a hierarchical "Ladder of Life" (scala naturae), placing them according to complexity of structure and function so that higher organisms showed greater vitality and ability to move.
Aristotle believed that intellectual purposes, i.e. formal causes, guided all natural processes. Such a teleological view gave Aristotle cause to justify his observed data as an expression of formal design. Noting that "no animal has, at the same time, both tusks and horns," and "a single-hooved animal with two horns I have never seen," Aristotle suggested that Nature, giving no animal both horns and tusks, was staving off vanity, and giving creatures faculties only to such a degree as they are necessary. Noting that ruminants had a multiple stomachs and weak teeth, he supposed the first was to compensate for the latter, with Nature trying to preserve type of balance.
In a similar fashion, Aristotle believed that creatures were arranged in a graded scale of perfection rising from plants on up to man, the scala naturae or Great Chain of Being. His system had eleven grades, arranged according "to the degree to which they are infected with potentiality", expressed in their form at birth. The highest animals laid warm and wet creatures alive, the lowest bore theirs cold, dry, and in thick eggs.
Aristotle also held that the level of a creature's perfection was reflected in its form, but not foreordained by that form.
He placed great importance on the type(s) of soul an organism possessed, asserting that plants possess a vegetative soul, responsible for reproduction and growth, animals a vegetative and a sensitive soul, responsible for mobility and sensation, and humans a vegetative, a sensitive, and a rational soul, capable of thought and reflection.
Aristotle, in contrast to earlier philosophers, but in accordance with the Egyptians, placed the rational soul in the heart, rather than the brain. Notable is Aristotle's division of sensation and thought, which generally went against previous philosophers, with the exception of Alcmaeon.
His analysis of procreation is frequently criticized on the grounds that it presupposes an active, ensouling masculine element bringing life to an inert, passive, lumpen female element; it is on these grounds that Aristotle is considered by some feminist critics to have been a misogynist.
Aristotle's successor at the Lyceum, Theophrastus, wrote a series of books on botany—the History of Plants—which survived as the most important contribution of antiquity to botany, even into the Middle Ages. Many of Theophrastus' names survive into modern times, such as carpos for fruit, and pericarpion for seed vessel.
Rather than focus on formal causes, as Aristotle did, Theophrastus suggested a mechanistic scheme, drawing analogies between natural and artificial processes, and relying on Aristotle's concept of the efficient cause. Theophrastus also recognized the role of sex in the reproduction of some higher plants, though this last discovery was lost in later ages.
Following Theophrastus, the Lyceum failed to produce any original work. Though interest in Aristotle's ideas survived, they were generally taken unquestioningly. It is not until the age of Alexandria under the Ptolemies that advances in biology can be again found.
The first medical teacher at Alexandria Herophilus of Chalcedon, corrected Aristotle, placing intelligence in the brain, and connected the nervous system to motion and sensation. Herophilus also distinguished between veins and arteries, noting that the latter pulse while the former do not. Though a few ancient atomists such as Lucretius challenged the teleological viewpoint of Aristotelian ideas about life, teleology (and after the rise of Christianity, natural theology) would remain central to biological thought essentially until the 18th and 19th centuries. In the words of Ernst Mayr, "Nothing of any real consequence in biology after Lucretius and Galen until the Renaissance." (in Europe at least- advancement in the field continued in the Middle East and orient). Aristotle's ideas of natural history and medicine survived, but they were generally taken unquestioningly.
Aristotle considered ethics to be a practical science, i.e. one mastered by doing rather than merely reasoning. Further, Aristotle believed that ethical knowledge is not certain knowledge (like metaphysics and epistemology) but is general knowledge. He wrote several treatises on ethics, including most notably, Nichomachean Ethics, in which he outlines what is commonly called virtue ethics.
Aristotle taught that virtue has to do with the proper function of a thing. An eye is only a good eye in so much as it can see, because the proper function of an eye is sight. Aristotle reasoned that man must have a function uncommon to anything else, and that this function must be an activity of the soul. Aristotle identified the best activity of the soul as eudaimonia: a happiness or joy that pervades the good life. Aristotle taught that to achieve the good life, one must live a balanced life and avoid excess. This balance, he taught, varies among different persons and situations, and exists as a golden mean between two vices - one an excess and one a deficiency.
In addition to his works on ethics, which address the individual, Aristotle addressed the city in his work titled Politics. Aristotle's conception of the city is very organic, and he is considered one of the first to conceive of the city in this manner. Aristotle considered the city to be a natural community. Moreover, he considered the city to be prior to the family which in turn is prior to the individual, i.e. last in the order of becoming, but first in the order of being (1253a19-24). He is also famous for his statement that "man is by nature a political animal." Aristotle conceived of politics as being rather like an organism than like a machine, and as a collection of parts that cannot exist without the other.
Aristotle considered epic poetry, tragedy, comedy, dithyrambic poetry and music to be imitative, each varying in imitation by media, object, and manner. For example, music imitates with the media of rhythm and harmony, whereas dance imitates with rhythm alone, and poetry with language. The forms also differ in their object of imitation. Comedy, for instance, is a dramatic imitation of men worse than average; whereas tragedy imitates men slightly better than average. Lastly, the forms differ in their manner of imitiation - through narrative or character, through change or no change, and through drama or no drama. Aristotle believed that imitiation is natural to mankind and constitutes one of mankind's advantages over animals.
While it is believed that Aristotle's Poetics was comprised of two books - one on comedy and one on tragedy - only the portion that focuses on tragedy has survived. Aristotle taught that tragedy is composed of six elements: plot-structure, character, style, spectacle, and lyric poetry. The characters in a tragedy are merely a means of driving the story; and the plot, not the characters, is the chief focus of tragedy. Tragedy is the imitation of action arousing pity and fear, and is meant to effect the catharsis of those same emotions. Aristotle concludes Poetics with a discussion on which, if either, is superior: epic or tragic mimesis. He suggest that because tragedy possesses all the attributes of an epic, possibly possesses additional attributes such as spectacle and music, is more unified, and achieves the aim of its mimesis in shorter scope, it can be considered superior to epic.
Though Aristotle wrote many elegant treatises and dialogues (Cicero described his literary style as "a river of gold"), the vast majority of his writings are now lost, while the literary character of those that remain is disputed. Aristotle's works were lost and rediscovered several times, and it is believed that about one fifth of his original works have survived.
The story of the original manuscripts of his treatises is described by Strabo in his Geography and Plutarch in his Parallel Lives. The manuscripts were left from Aristotle to his successor Theophrastus, who in turn willed them to Neleus of Scepsis. Neleus supposedly took the writings from Athens to Scepsis, where his heirs let them languish in a cellar until the first century BC, when Apellicon of Teos discovered and purchased the manuscripts, bringing them back to Athens. According to the story, Apellicon tried to repair some of the damage that was done during the manuscripts' stay in the basement, introducing a number of errors into the text. When Lucius Cornelius Sulla occupied Athens in 86 BC, he carried off the library of Apellicon to Rome, where they were first published in 60 BC by the grammarian Tyrranion of Amisus and then by philosopher Andronicus of Rhodes.
Carnes Lord attributes the popular belief in this story to the fact that it provides "the most plausible explanation for the rapid eclipse of the Peripatetic school after the middle of the third century, and for the absence of widespread knowledge of the specialized treatises of Aristotle throughout the Hellenistic period, as well as for the sudden reappearance of a flourishing Aristotelianism during the first century B.C." Lord voices a number of reservations concerning this story, however. First, the condition of the texts is far too good for them to have suffered considerable damage followed by Apellicon's inexpert attempt at repair. Second, there is "incontrovertible evidence," Lord says, that the treatises were in circulation during the time in which Strabo and Plutarch suggest they were confined within the cellar in Scepsis. Third, the definitive edition of Aristotle's texts seems to have been made in Athens some fifty years before Andronicus supposedly compiled his. And fourth, ancient library catalogues predating Andronicus' intervention list an Aristotelean corpus quite similar to the one we currently possess. Lord sees a number of post-Aristotelean interpolations in the Politics, for example, but is generally confident that the work has come down to us relatively intact.
After the Roman period, Aristotle's works were by and large lost to the West for a second time. They were, however, preserved in the East by various Muslim scholars and philosophers, many of whom wrote extensive commentaries on his works. Aristotle lay at the foundation of the falsafa movement in Islamic philosophy, stimulating the thought of Al-Farabi, Ibn Sina, Ibn Rushd and others.
As the influence of the falsafa grew in the West, in part due to Gerard of Cremona's translations and the spread of Averroism, the demand for Aristotle's works grew. William of Moerbeke translated a number of them into Latin. When Thomas Aquinas wrote his theology, working from Moerbeke's translations, the demand for Aristotle's writings grew and the Greek manuscripts returned to the West, stimulating a revival of Aristotelianism in Europe, and ultimately revitalizing European thought through Muslim influence in Spain to fan the embers of the Renaissance.
It is the opinion of many that Aristotle's system of thought remains the most influential one ever put together by any single mind. According to historian Will Durant, no other philosopher has contributed so much to the enlightenment of the world. He single-handedly founded the sciences of Logic, Biology and Psychology. At the opposite pole, Bertrand Russell dismissed much of Aristotle's work as not particularly profound.
The German philosopher Friedrich Nietzsche has been said to have taken nearly all of his political philosophy from Aristotle. However implausible this is, it is certainly the case that Aristotle's rigid separation of action from production, and his justification of the subservience of slaves and others to the virtue - or arete - of a few justified the ideal of aristocracy. It is Martin Heidegger, not Nietzsche, who elaborated a new interpretation of Aristotle, intended to warrant his deconstruction of scholastic and philosophical tradition. More recently, Alasdair MacIntyre has attempted to reform what he calls the Aristotelian tradition in a way that is anti-elitist and capable of disputing the claims of both liberals and Nietzscheans.
The philosopher novelist, Ayn Rand, commented that in writing Atlas Shrugged the only philosopher to whom she could acknowledge a debt was Aristotle.
The secondary literature on Aristotle is vast. The following references are only a small selection.


An American in Paris is a symphonic composition by American composer George Gershwin, composed in 1928. Inspired by time Gershwin had spent in Paris, it is in the form of an extended tone poem evoking the sights and energy of the French capital in the 1920s. It is one of Gershwin's best-known compositions.
Gershwin composed the piece on commission from the New York Philharmonic. He also did the orchestration. (He did not orchestrate his musicals or the Rhapsody in Blue.) Gershwin scored An American in Paris for the standard instruments of the symphony orchestra plus celesta, saxophone, and automobile horns. Gershwin brought back some Parisian taxi horns for the New York premiere of the composition which took place on December 13, 1928 in Carnegie Hall with Walter Damrosch conducting the New York Philharmonic.
An American in Paris is scored for 3 flutes (3rd doubling on piccolo), 2 oboes, English horn, 2 clarinets in B flat, bass clarinet in B flat, 2 bassoons, 4 horns in F, 3 trumpets in B flat, 3 trombones, tuba, timpani, snare drum, bass drum, cymbals, low and high tom-toms, xylophone, glockenspiel, celesta, 4 taxi horns, alto saxophone, tenor saxophone, baritone saxophone, and strings.
An American in Paris has been frequently recorded over the years. The very first recording was made for RCA Victor in 1929 with Nathaniel Shilkret conducting the Victor Symphony Orchestra, drawn from members of the Philadelphia Orchestra. Gershwin was on hand to "supervise" the recording; however, Shilkret was reported to be in charge and eventually asked the composer to leave the recording studio. Then, a little later, Shilkret discovered there was no one to play the brief celesta solo during the slow section, so he hastily asked Gershwin if he might play the solo; Gershwin said he could and so he briefly participated in the actual recording. Later, Arthur Fiedler and the Boston Pops Orchestra recorded the work for RCA Victor, including one of the first stereo recordings of the music. In 1945, Arturo Toscanini and the NBC Symphony Orchestra recorded the music in Carnegie Hall, one of the few commercial recordings Toscanini made of music by an American composer.
In 1951, MGM released a musical comedy, An American in Paris, featuring Gene Kelly and Leslie Caron. Winner of numerous awards, including the 1951 Best Picture Oscar, the film was directed by Vincente Minnelli, featured many tunes of Gershwin, and concluded with an extensive, elaborate dance sequence built around Gershwin's symphonic poem (arranged for the film by Johnny Green).
A part of the symphonic composition is also featured in As Good as It Gets, released in 1997.

The Academy Awards, popularly known as the Oscars, are presented annually by the Academy of Motion Picture Arts and Sciences (AMPAS) to recognize excellence of professionals in the film industry, including directors, actors, and writers. The formal ceremony at which the awards are presented is among the most prominent and most watched film awards ceremonies in the world.
The 1st Academy Awards ceremony was held on Thursday, May 16, 1929, at the Hotel Roosevelt in Hollywood to honor outstanding film achievements of 1927 and 1928. It was hosted by actor Douglas Fairbanks and director William C. DeMille. The 80th Academy Awards ceremony was held on Sunday, February 24, 2008, at the Kodak Theatre in Los Angeles to honor outstanding film achievements of 2007. It was hosted by Comedy Central's The Daily Show host, Jon Stewart.
AMPAS, a professional honorary organization, maintains a voting membership of 5,829 as of 2007. Actors constitute the largest voting bloc, numbering 1,311 members (22 percent) of the Academy's composition. Votes for Oscars have been tabulated and certified by the auditing firm PricewaterhouseCoopers (and its predecessor Price Waterhouse) for the past 73 annual awards ceremonies.
The official name of the Oscar statuette is the Academy Award of Merit. The actual Oscar trophy can be sold with a cash value of 1 USD. Made of gold-plated britannium on a black metal base, it is 13.5 in (34 cm) tall, weighs 8.5 lb (3.85 kg) and depicts a knight rendered in Art Deco style holding a crusader's sword standing on a reel of film with five spokes. The five spokes each represent the original branches of the Academy: Actors, Writers, Directors, Producers, and Technicians. MGM’s art director Cedric Gibbons, one of the original Academy members, supervised the design of the award trophy by printing the design on scroll. In need of a model for his statue Gibbons was introduced by his then wife Dolores del Río to Emilio "El Indio" Fernández. Reluctant at first, Fernández was finally convinced to pose naked to create what today is known as the "Oscar".
Then sculptor George Stanley sculpted Gibbons's design in clay, and Alex Smith cast the statue in 92.5 percent tin and 7.5 percent copper and then gold-plated it. The only addition to the Oscar since it was created is a minor streamlining of the base. The original Oscar mold was cast in 1928 at the C.W. Shumway & Sons Foundry in Batavia, Illinois, which also contributed to casting the molds for the Vince Lombardi Trophy and Emmy Awards statuettes. Approximately 40 Oscars are made each year in Chicago, Illinois by the manufacturer, R.S. Owens. If they fail to meet strict quality control standards, the statuettes are cut in half and melted down.
The root of the name "Oscar" is contested. One biography of Bette Davis claims that she named the Oscar after her first husband, bandleader Harmon Oscar Nelson;one of the earliest mentions in print of the term Oscar dates back to Bette Davis's receipt of the award in 1936. Walt Disney is also quoted as thanking the Academy for his Oscar as early as 1932. Another claimed origin is that of the Academy’s Executive Secretary, Margaret Herrick, who first saw the award in 1931 and made reference to the statuette reminding her of her Uncle Oscar. Columnist Sidney Skolsky was present during Herrick’s naming and seized the name in his byline, "Employees have affectionately dubbed their famous statuette 'Oscar'" (Levy 2003). Both Oscar and Academy Award are registered trademarks of the Academy, fiercely protected through litigation and threats thereof.
As of the 80th Academy Awards ceremony held in 2008, a total of 2,696 Oscars have been awarded. A total of 293 different actors have won an acting Oscar (including Honorary Awards and Juvenile Awards).
Since 1950, the statuettes have been legally encumbered by the requirement that neither winners nor their heirs may sell the statuettes without first offering to sell them back to the Academy for $1. If a winner refuses to agree to this stipulation, then the Academy keeps the statuette. Academy Awards not protected by this agreement have been sold in public auctions and private deals for six-figure sums (Levy 2003).
This rule is highly controversial, since it implies that the winner does not own the award. The case of Michael Todd's grandson trying to sell Todd's Oscar statuette illustrates that there are many who do not agree with this idea. When Todd's grandson attempted to sell Todd's Oscar statuette to a movie prop collector, the Academy won the legal battle by getting a permanent injunction. Although some Oscar sales transactions have been successful, the buyers have subsequently returned the statuettes to the Academy, which keeps them in its treasury.
All AMPAS members must be invited to join. Invitation comes from the Board of Governors, on behalf of Academy Branch Executive Committees. Membership eligibility may be achieved by a competitive nomination or a member may submit a name based on other significant contribution to the field of motion pictures. Although winning an Academy Award usually results in an invitation to join, membership is not automatic.
New membership proposals are considered annually. The Academy does not publicly disclose its membership, although as recently as 2007 press releases have announced the names of those who have been invited to join. The 2007 release also stated that it has just under 6,000 voting members. While the membership had been growing until 2003, stricter policies have kept its size steady since then.
Today, according to Rules 2 and 3 of the official Academy Awards Rules, a film must open in the previous calendar year, from midnight at the start of January 1 to midnight at the end of December 31, in Los Angeles County, California, to qualify. Rule 2 states that a film must be "feature-length", defined as a minimum of 40 minutes, except for short subject awards and it must exist either on a 35 mm or 70 mm film print or on 24 fps or 48 fps progressive scan digital film print with native resolution not less than 1280x720.
The members of the various branches nominate those in their respective fields while all members may submit nominees for Best Picture. The winners are then determined by a second round of voting in which all members are then allowed to vote in most categories, including Best Picture.
As of the 79th Academy Awards, 847 members (past and present) of the Screen Actors Guild have been nominated for an Oscar (in all categories).
The major awards are presented at a live televised ceremony, most commonly in February or March following the relevant calendar year, and six weeks after the announcement of the nominees. This is an elaborate extravaganza, with the invited guests walking up the red carpet in the creations of the most prominent fashion designers of the day. Black tie dress is the most common outfit for men, although fashion may dictate not wearing a bowtie, and musical performers typically do not adhere to this. (The artists who recorded the nominees for Best Original Song quite often perform those songs live at the awards ceremony, and the fact that they are performing is often used to promote the television broadcast.) The Academy has for several years claimed that the award show has a billion viewers internationally, but this has so far not been confirmed by any independent sources. Neither has the Academy explained how it has reached this figure.
The Academy Awards is televised live across the United States (excluding Alaska and Hawaii) and gathers millions of viewers worldwide. The 2007 ceremony was watched by more than 40 million Americans. Other awards ceremonies (such as the Emmys, Golden Globes, and Grammys) are broadcast live in the East Coast but are on tape delay in the West Coast.
The Awards show was first televised on NBC in 1953. NBC continued to broadcast the event until 1960 when the ABC Network took over, televising the festivities through 1970, after which NBC resumed the broadcasts. ABC once again took over broadcast duties in 1976; it has contracted to do so through the year 2014.
After more than sixty years of being held in late March or early April, the ceremonies were moved up to late February or early March starting in 2004 to help disrupt and shorten the intense lobbying and ad campaigns associated with Oscar season in the film industry. Another reason was because of the growing TV ratings success of the NCAA Men's Division I Basketball Championship, which would cut into the Academy Awards audience. The earlier date is also to the advantage of ABC, as it currently usually occurs during the highly profitable and important February sweeps period. The Awards show holds the distinction of having won the most Emmys in history, with 38 wins and 167 nominations.
On March 30, 1981, the awards ceremony was postponed for one day after the shooting of President Ronald Reagan and others in Washington, D.C. On October 16, 2006, the awards event itself was designated a National Special Security Event by the United States Department of Homeland Security.
Movie studios are strictly prohibited from advertising films during the broadcast.
Since 2002, celebrities have been seen arriving at the Academy Awards in hybrid vehicles; during the telecast of the 79th Academy Awards in 2007, Leonardo DiCaprio and former vice president Al Gore announced that ecologically intelligent practices had been integrated into the planning and execution of the Oscar presentation and several related events.
Critics like Lisa De Moraes from the Washington Post and Tom O'Neill from the Los Angeles Times have pointed out that the ceremony telecast has an interesting history of unusual up-and-down ratings trend since Nielsen Ratings were measured for the ceremony since 1967 and audience size was recorded since 1974.
Historically, the "Oscarcast" pulled in a bigger haul when box-office hits were favored to win the Best Picture trophy. More than 57.25 million viewers tuned to the telecast in 1998, the year of Titanic, which generated close to $500 million at the box office pre-Oscars. The 76th Academy Awards ceremony in which The Lord of the Rings: The Return of the King (pre-telecast box office earnings of $368 million) received 11 Awards including Best Picture drew 43.56 million viewers. The most watched ceremony based on Nielsen ratings to date, however, was the 42nd Academy Awards (Best Picture, Midnight Cowboy) which drew a 43.4% household rating on April 7, 1970.
By contrast, ceremonies honoring films that have not performed well at the box office tend to show weaker ratings. The 78th Academy Awards which awarded low-budgeted, independent film Crash (with a pre-Oscar gross of $53.4 million) generated an audience of 38.94 million with a household rating of 22.91%. More recently, the 80th Academy Awards telecast was watched by 31.76 million viewers on average with a 18.66% household rating, the lowest rated and least watched ceremony to date. The Best Picture winner of that particular ceremony was another low-budget, independently financed film (No Country for Old Men), which generated $64.3 million prior to the ceremony.
Below is a chart of previous Academy Awards ceremonies and ratings since 1998.
The 1st Academy Awards were presented at a banquet dinner at the Hotel Roosevelt in Hollywood. Subsequent banquet ceremonies in the 1930s and early 40s were held in Los Angeles at either The Ambassador Hotel or the Biltmore Hotel.
Grauman's Chinese Theater in Hollywood then hosted the awards from 1944 to 1946, followed by the Shrine Auditorium in Los Angeles from 1947 to 1948. The 21st Academy Awards in 1949 were held at the "Academy Award Theater" at the Academy's then-headquarters on Melrose Avenue in Hollywood.
From 1950 to 1960, the awards were presented at Hollywood's Pantages Theater. The Oscars then moved to the Santa Monica Civic Auditorium in Santa Monica, California in 1961. By 1969, the Academy decided to move the ceremonies back to Los Angeles, this time at the Dorothy Chandler Pavilion in the Los Angeles Music Center. The Dorothy Chandler Pavilion hosted 19 consecutive Oscar ceremonies until 1988, when the Academy started to alternate between the Music Center and the Shrine Auditorium.
In 2002, Hollywood's Kodak Theater became the first permanent home of the awards. It is connected to the Hollywood & Highland Center, which contains 640,000 square feet (59,000 m²) of space including retail, restaurants, nightclubs, other establishments and a six-screen cinema. In fact, the Grand Staircase columns at the Kodak Theater showcase every movie that has won the Best Picture title since the first Academy Awards in 1929.
Critics have noted that many Best Picture Academy Award winners in the past have not stood the test of time. Several of these films, such as Around the World in 80 Days, Grand Hotel and Cecil B. DeMille's The Greatest Show on Earth are often considered to have aged poorly and to have little of the impact they had on their initial release. Several films that currently have wide critical approval were not named Best Picture, such as the highly acclaimed Citizen Kane, directed by Orson Welles and Raging Bull, directed by Martin Scorsese.
It has been suggested that actors are at a disadvantage in comedy roles, as relatively few acting awards have been given for performances in films considered primarily comedic. Jack Black, John C. Reilly, and Will Ferrell joked about this at the 79th Academy Awards ceremony.
Nonetheless, each of the acting categories boasts notable examples of Oscar-winning performances in comedic roles. These include Best Actors James Stewart in The Philadelphia Story and Jack Nicholson in As Good as It Gets; Best Actresses Judy Holliday in Born Yesterday and Gwyneth Paltrow in Shakespeare in Love ; Best Supporting Actors Jack Lemmon in Mister Roberts and Alan Arkin in Little Miss Sunshine; and Best Supporting Actresses Josephine Hull in Harvey and Mira Sorvino in Mighty Aphrodite.
Studios also lobby heavily for their films to be considered, leading to the complaint that nominations and awards may be largely a result of this lobbying rather than the quality of the material.
In the first year of the awards, the Best Director category was split into separate Drama and Comedy categories. At times, the Best Original Score category has been split into separate Drama and Comedy/Musical categories. Today, the Best Original Score category is one category. From the 1930s through the 1960s, the Cinematography, Art Direction, and Costume Design awards were split into separate categories for black and white and color films.
These awards are voted on by special committees, rather than by the Academy membership as a whole, but the individual selected to receive the special award may turn down the offer.


Actrius (Actresses) is a 1996 film directed by Ventura Pons. In the film, there are no male actors and the four leading actresses dubbed themselves in the Castilian version.
In order to prepare the role of an important old actress, a theatre student interviews three actresses who were her pupils: an international diva (Glòria Marc, played by Núria Espert), a television star (Assumpta Roca, played by Rosa Maria Sardà) and a dubbing director (Maria Caminal, played by Anna Lizaran).

Animalia is an illustrated children's book by Graeme Base. It was published in 1986.
Animalia is an alphabet book and contains twenty-six illustrations, one for each letter of the alphabet. Each illustration features an animal from the animal kingdom (A is for alligator, B is for butterfly, etc.) along with a short poem utilizing the letter of the page for many of the words. The illustrations contain dozens of small objects that the curious reader can try to identify. As an additional challenge, the author has hidden a picture of himself as a child in every picture. In 1987, Animalia won the title of Honour Book in the Children's Book Council of Australia Picture Book of the Year Awards. In 1996, a tenth anniversary edition was released.
Base also published a colouring book version for children to do their own colouring.
A television series was also created, based on the book.


Time coordinates on the TAI scales are conventionally specified using traditional means of specifying days, carried over from non-uniform time standards based on the rotation of the Earth. Specifically, both Julian Dates and the Gregorian calendar are used. TAI in this form was synchronised with Universal Time at the beginning of 1958, and the two have drifted apart ever since.
TAI as a frequency standard is a weighted average of the time kept by about 300 atomic clocks in over 50 national laboratories worldwide. The clocks are compared using satellites (see BIPM clock comparisons). Many of these are caesium atomic clocks, which are the standard by which the SI second is defined. Due to the averaging it is far more stable than any clock would be alone.
The participating institutions each broadcast in real time a frequency signal with time codes, which is their estimate of TAI. (Actually the time codes are usually published in the form of UTC.) The better laboratories' signals are mutually synchronised to within less than 10-7 s, but there are outliers up to 10-5 s out. These time scales are denoted in the form "TAI(NPL)" ("UTC(NPL)" for the UTC form), where "NPL" in this case identifies the National Physical Laboratory, UK. Some laboratories also publish their own atomic time scale, denoted in the form "TA(USNO)" ("USNO" identifies the United States Naval Observatory).
The clocks at different institutions are regularly compared against each other. The International Bureau of Weights and Measures (BIPM) combines these measurements to retrospectively calculate the weighted average that forms the most stable time scale possible. This combined time scale is published monthly in [ftp://ftp2.bipm.fr/pub/tai/publication/cirt/ Circular T], and is the canonical TAI. This time scale is expressed in the form of tables of differences UTC-UTC(x) and TAI-TA(x), for each participating institution x.
Errors in publication may be corrected by issuing a revision of the faulty Circular T or by errata in a subsequent Circular T. Aside from this, once published in Circular T the TAI scale is not revised. In hindsight it is possible to discover errors in TAI, and to make better estimates of the true proper time scale. Doing so does not create another version of TAI; it is instead considered to be creating a better realisation of Terrestrial Time (TT). See the article on TT for more information.
Atomic timekeeping services started experimentally in 1955, using the first caesium atomic clock at the National Physical Laboratory, UK (NPL). The first formalised atomic time scale was the A.1 scale defined by the United States Naval Observatory (USNO) in 1959. A.1 was defined by an epoch at the beginning of 1958: it was set to read Julian Date 2436204.5 (1958-01-01T00:00:00) at the UT2 instant JD 2436204.5 (1958-01-01T00:00:00) as calculated at USNO. This synchronisation was inevitably imperfect, depending as it did on the astronomical realisation of UT2. At the time, UT2 as published by various observatories differed by several centiseconds. A.1 was extrapolated backwards to 1956.
In 1961 the Bureau International de l'Heure (BIH) (later superseded by the BIPM and the IERS) constructed an atomic time scale named AM based on three atomic clocks. The clocks were compared by listening to radio time signals based on them. The BIH's time scale was synchronised with A.1's epoch, and extrapolated back to 1955 using time signals from the first caesium clock at NPL. This time scale was soon renamed from AM to A3.
Also in 1961, UTC began. UTC is a discontinuous time scale composed from segments that are linear transformations of atomic time, the discontinuities being arranged so that UTC approximates UT1. This was a compromise arrangement for a broadcast time scale: a linear transformation of the BIH's atomic time meant that the time scale was stable and internationally synchronised, while approximating UT1 means that tasks such as navigation which require a source of Universal Time continue to be well served by public time broadcasts.
In 1967 the SI second was redefined in terms of the frequency supplied by a caesium atomic clock.
More clocks were added to the A3 time scale from 1967, and it was renamed to TA. Finally in 1971 it was renamed TAI.
In the 1970s it became clear that the clocks participating in TAI were ticking at different rates due to gravitational time dilation, and the combined TAI scale therefore corresponded to an average of the altitudes of the various clocks. Starting from Julian Date 2443144.5 (1977-01-01T00:00:00), corrections were applied to the output of all participating clocks, so that TAI would correspond to proper time at mean sea level (the geoid). Because the clocks had been on average well above sea level, this meant that TAI slowed down, by about 10-12. The former uncorrected time scale continues to be published, under the name "EAL" ("Echelle Atomique Libre", meaning "Free Atomic Scale").
The instant that the gravitational correction started to be applied serves as the epoch for Barycentric Coordinate Time (TCB), Geocentric Coordinate Time (TCG), and Terrestrial Time (TT). All three of these time scales were defined to read JD 2443144.5003725 (1977-01-01T00:00:32.184) exactly at that instant. (The 32.184 s offset is to provide continuity with the older Ephemeris Time.) TAI is henceforth a realisation of TT, with the equation TT(TAI) = TAI + 32.184 s.
In the 1990s annual periodic variations in the rate of some clocks were traced to blackbody radiation that varies with the ambient temperature. It became clear that a correction for this was required. Accordingly, in 1997 the BIPM declared that the definition of the SI second referred to a caesium atom at rest and at absolute zero temperature. Temperature corrections were implemented in TAI from 1995 to 1998, speeding TAI up by about 10-14.3.


Altruism is selfless concern for the welfare of others. It is a traditional virtue in many cultures, and central to many religious traditions. In English, this idea was often described as the Golden rule of ethics. Some newer philosophies such as egoism have criticized the concept, with philosophers arguing that there is no moral obligation to help others. Some philosophies such as objectivism go one step further and argue that altruism is immoral as it is based on self-sacrifice. Altruism is the opposite of selfishness.
Altruism can be distinguished from a feeling of loyalty and duty. Altruism focuses on a motivation to help others or a want to do good without reward, while duty focuses on a moral obligation towards a specific individual (for example, God, a king), a specific organization (for example, a government), or an abstract concept (for example, patriotism etc). Some individuals may feel both altruism and duty, while others may not. Pure altruism is giving without regard to reward or the benefits of recognition.
The concept has a long history in philosophical and ethical thought, and has more recently become a topic for psychologists (especially evolutionary psychology researchers), sociologists, evolutionary biologists, and ethologists. While ideas about altruism from one field can have an impact on the other fields, the different methods and focuses of these fields lead to different perspectives on altruism. Researches on altruism were sparked in particular after the murder of Kitty Genovese in 1964, who was stabbed during half an hour, with passive witnesses withholding themselves from helping her.
The word "altruism" (derived from French autre "other", in its turn derived from Latin alter "other") was coined by Auguste Comte, the French founder of positivism, in order to describe the ethical doctrine he supported. He believed that individuals had a moral obligation to serve the interest of others or the "greater good" of humanity. Comte says, in his Catechisme Positiviste, that "[the] social point of view cannot tolerate the notion of rights, for such notion rests on individualism. We are born under a load of obligations of every kind, to our predecessors, to our successors, to our contemporaries. After our birth these obligations increase or accumulate, for it is some time before we can return any service.. This ["to live for others"], the definitive formula of human morality, gives a direct sanction exclusively to our instincts of benevolence, the common source of happiness and duty. [Man must serve] Humanity, who we are entirely."" As the name of the ethical doctrine is "altruism," doing what the ethical doctrine prescribes has also come to be referred to by the term "altruism" — serving others through placing their interests above one's own.
If one performs an act beneficial to others with a view to gaining some personal benefit, then it isn't an altruistically motivated act. There are several different perspectives on how "benefit" (or "interest") should be defined. A material gain (for example, money, a physical reward, etc.) is clearly a form of benefit, while others identify and include both material and immaterial gains (affection, respect, happiness, satisfaction etc.) as being philosophically identical benefits.
According to psychological egoism, while people can exhibit altruistic behavior, they cannot have altruistic motivations. Psychological egoists would say that while they might very well spend their lives benefitting others with no material benefit (or a material net loss) to themselves, their most basic motive for doing so is always to further their own interests. For example, it would be alleged that the foundational motive behind a person acting this way is to advance their own psychological well-being ("good feelings").
The French philosopher Pierre Rousselot (1878-1915) located the philosophical problem in terms of a pure "ecstatic" or totally selfless love versus an egotistic, more self-interested love, beginning his examination from Aristotle's text (Nicomachean Ethics, Book 9): "The friendly feelings that we bear for another have arisen from the friendly feelings that we bear for ourselves".
Critics of this theory conflating altruism with vanity and self-interest often reject it on the grounds that it's non-falsifiable; in other words, it is impossible to prove or disprove because immaterial gains such as a "good feelings" cannot be measured or proven to exist in all people performing altruistic acts. Psychological egoism has also been accused of using circular logic: "If a person willingly performs an act, that means he derives personal enjoyment from it; therefore, people only perform acts that give them personal enjoyment". This particular statement is circular because its conclusion is identical to its hypothesis (it assumes that people only perform acts that give them personal enjoyment, and concludes that people only perform acts that give them personal enjoyment).
In common parlance, altruism usually means helping another person without expecting material reward from that or other persons, although it may well entail the "internal" benefit of a "good feeling," sense of satisfaction, self-esteem, fulfillment of duty (whether imposed by a religion or ideology or simply one's conscience), or the like. In this way one need not speculate on the motives of the altruist in question.
Humans are not exclusively altruistic towards family members, previous co-operators or potential future allies, but can be altruistic towards people they don't know and will never meet. For example, some humans donate to international charities and volunteer their time to help society's less fortunate. It can however be argued that an individual would contribute to a charity to gain respect or stature within his/her own community.
It may strain plausibility to claim that these altruistic deeds are done in the hope of a return favor. Influenced by the consequentialist perspective of utilitarianism, the game theory analysis of this 'just in case' strategy, where the principle would be 'always help everyone in case you need to pull in a favor in return', is a decidedly non-optimal strategy, where the net expenditure of effort is far greater than the net profit when it occasionally pays off.
According to some, it is difficult to believe that these behaviors are solely explained as indirect selfish rationality, be it conscious or unconscious. Mathematical formulations of kin selection, along the lines of the prisoner's dilemma, are helpful as far as they go; but what a game-theoretic explanation glosses over is the fact that altruistic behavior can be attributed to that apparently mysterious phenomenon, the conscience. One recent suggestion, proposed by the philosopher Daniel Dennett, was initially developed when considering the problem of so-called 'free riders' in the tragedy of the commons, a larger-scale version of the prisoner's dilemma.
In game theory terms, a free rider is an agent who draws benefits from a cooperative society without contributing. In a one-to-one situation, free riding can easily be discouraged by a tit-for-tat strategy. But in a larger-scale society, where contributions and benefits are pooled and shared, they can be incredibly difficult to shake off.
Imagine an elementary society of cooperative organisms. Cooperative agents interact with each other, each contributing resources and each drawing on the common good. Now imagine a rogue free rider, an agent who draws a favor ("you scratch my back") and later refuses to return it. The problem is that free riding is always going to be beneficial to individuals at cost to society. How can well-behaved cooperative agents avoid being cheated? Over many generations, one obvious solution is for cooperators to evolve the ability to spot potential free riders in advance and refuse to enter into reciprocal arrangements with them. Then, the canonical free rider response is to evolve a more convincing disguise, fooling cooperators into cooperating after all. This can lead to an evolutionary arms races, with ever-more-sophisticated disguises and ever-more-sophisticated detectors.
In this evolutionary arms race, how best might one convince comrades that one really is a genuine cooperator, not a free rider in disguise? One answer is by actually making oneself a genuine cooperator, by erecting psychological barriers to breaking promises, and by advertising this fact to everyone else. In other words, a good solution is for organisms to evolve things that everyone knows will force them to be cooperators - and to make it obvious that they've evolved these things. According to this theory, evolution will thus produce organisms who are sincerely moral and who wear their hearts on their sleeves; in short, evolution will give rise to the phenomenon of conscience.
This theory, combined with ideas of kin selection and the one-to-one sharing of benefits, may explain how a blind process can produce a genuinely non-cynical form of altruism that gives rise to the human conscience.
Critics of such technical game theory analysis point out that it appears to forget that human beings are rational and emotional. To presume an analysis of human behavior without including human rationale or emotion is necessarily unrealistically narrow, and treats human beings as if they are mere machines, sometimes called Homo economicus. Another objection is that often people donate anonymously, so that it is impossible to determine if they really did the altruistic act (compare with Kant's affirmation that since motive determines the moral nature of an act, and that none can know for sure which motive was behind an act, therefore it is impossible to know if one single moral act ever existed).
Beginning with an understanding that rational human beings benefit from living in a benign universe, logically it follows that particular human beings may gain substantial emotional satisfaction from acts which they perceive to make the world a better place.
Altruists may be divided in two broad groups : Those who believe altruism is a matter of personal choice (and therefore selfishness can and should be tolerated - ethical egoism even supports egoism as a moral stance, denying altruism any value), and those who believe that altruism is a moral ideal which should be embraced, if possible, by all human beings.
Since Aristotle's classical distinction of regimes made in Politics, III, altruism is often held to be the kind of ethic that should guide the actions of politicians and other people in positions of power. Such people are usually expected to set their own interests aside and serve the populace. When they do not, they may be criticized as defaulting on what is believed to be an ethical obligation to place the interests of others above their own.
Ayn Rand, the founder of the objectivist philosophy argued that altruism operates on the principle of self-sacrifice and was hence intrinsically immoral. She defined sacrifice as the exchange of something of superior value for something of inferior value. Rand argued that the fundamental moral value to a living entity was life. Without that value there would be no living entities. As the universe follows consistent laws and living beings must take certain actions to survive, she argued, the moral code cannot be arbitrary but must follow a rational framework.
Sacrifice according to Rand was the worst kind of moral transgression as it fundamentally undermines the basic principle of a living entity: the optimization towards something better and not something worse. She argued that if altruism in its self-sacrificial form was truly embraced universally human kind would not remain in existence for long.
Norwegian Philosopher Arne Næss, a proponent of deep ecology, has suggested that the narrow concept of egoic self implies that all acts of "doing good" are acts of altruism, whereas, through a larger concept of the self-actualised "ecological self", in which it is the interconnectedness within progressively larger wholes, ultimately incorporating the whole of life (see Gaia hypothesis), means that our self interest ultimately requires the flourishing and well-being of the whole of life itself. This concept, similar in some respects to the land ethic of Aldo Leopold, sets the concept of Altruism within the widest possible boundary of moral concern.
In the science of ethology (the study of behavior), and more generally in the study of social evolution, altruism refers to behavior by an individual that increases the fitness of another individual while decreasing the fitness of the actor. Researchers on alleged altruist behaviours among animals have been ideologically opposed to the social darwinist concept of the "survival of the fittest", under the name of "survival of the nicest" — the latter being globally compatible, however, with darwinist' theory of evolution. Insistence on such cooperative behaviours between animals was first exposed by the Russian zoologist and anarchist Peter Kropotkin in his 1902 book, Mutual Aid: A Factor of Evolution.
The study of altruism was the initial impetus behind George R. Price's development of the Price equation which is a mathematical equation used to study genetic evolution. An interesting example of altruism is found in the cellular slime moulds, such as Dictyostelium mucoroides. These protists live as individual amoebae until starved, at which point they aggregate and form a multicellular fruiting body in which some cells sacrifice themselves to promote the survival of other cells in the fruiting body. Social behavior and altruism share many similarities to the interactions between the many parts (cells, genes) of an organism, but are distinguished by the ability of each individual to reproduce indefinitely without an absolute requirement for its neighbors.
Jorge Moll and Jordan Grafman, neuroscientists at the National Institutes of Health and LABS-D'Or Hospital Network (J.M.) provided the first evidence for the neural bases of altruistic giving in normal healthy volunteers, using functional magnetic resonance imaging. In their research, published in the Proceedings of the National Academy of Sciences USA in October, 2006, they showed that both pure monetary rewards and charitable donations activated the mesolimbic reward pathway, a primitive part of the brain that usually lights up in response to food and sex. However, when volunteers generously placed their interests of others before their own by making charitable donations, another brain circuit was selectively activated: the subgenual cortex/septal region. These structures are intimately related to social attachment and bonding in other species. Altruism, the experiment suggested, was not a superior moral faculty that suppresses basic selfish urges but rather was basic to the brain, hard-wired and pleasurable.
A new study by Samuel Bowles at the Santa Fe Institute in New Mexico, US, is seen by some as breathing new life into the model of group selection for Altruism, known as "Survival of the nicest". Bowles conducted a genetic analysis of contemporary foraging groups, including Australian aboriginals, native Siberian Inuit populations and indigenous tribal groups in Africa. It was found that hunter-gatherer bands of up to 30 individuals were considerably more closely related than was previously thought. Under these conditions, thought to be similar to those of the middle and upper Paleolithic, altruism towards other group-members would improve the overall fitness of the group.
If an individual defended the group but was killed, any genes that the individual shared with the overall group would still be passed on. Early customs such as food sharing or monogamy could have levelled out the "cost" of altruistic behaviour, in the same way that income taxes redistribute income in society. He assembled genetic, climactic, archaeological, ethnographic and experimental data to examine the cost-benefit relationship of human cooperation in ancient populations. In his model, members of a group bearing genes for altruistic behaviour pay a "tax" by limiting their reproductive opportunities to benefit from sharing food and information, thereby increasing the average fitness of the group as well as their inter-relatedness. Bands of altruistic humans would then act together to gain resources from other groups at this challenging time in history.
Altruist theories in evolutionary biology were contested by Amotz Zahavi, the inventor of the signal theory and its correlative, the handicap principle, based mainly on his observations of the Arabian Babbler, a bird commonly known for its surprising (alleged) altruistic behaviours.
Most, if not all, of the world's religions promote altruism as a very important moral value. Christianity, Buddhism, and Sikhism place particular emphasis on altruistic morality, as noted above, but Judaism, Islam, Hinduism and many other religions also promote altruistic behavior.
Altruism was central to the teachings of Jesus found in the Gospel especially in the Sermon on the Mount and the Sermon on the Plain. From biblical to medieval Christian traditions, tensions between self-affirmation and other-regard were sometimes discussed under the heading of "disinterested love," as in the Pauline phrase "love seeks not its own interests." In his book Indoctrination and Self-deception, Roderick Hindery tries to shed light on these tensions by contrasting them with impostors of authentic self-affirmation and altruism, by analysis of other-regard within creative individuation of the self, and by contrasting love for the few with love for the many. If love, which confirms others in their freedom, shuns propagandas and masks, assurance of its presence is ultimately confirmed not by mere declarations from others, but by each person's experience and practice from within. As in practical arts, the presence and meaning of love become validated and grasped not by words and reflections alone, but in the doing.
Though it might seem obvious that altruism is central to the teachings of Jesus, one important and influential strand of Christianity would qualify this. St Thomas Aquinas in the Summa Theologica, I:II Quaestion 26, Article 4 states that we should love ourselves more than our neighbour. His interpretation of the Pauline phrase is that we should seek the common good more than the private good but this is because the common good is a more desirable good for the individual. 'You should love your neighbour as yourself' from Leviticus 19 and Matthew 22 is interpreted by St Thomas as meaning that love for ourself is the exemplar of love for others. He does think though, that we should love God more than ourselves and our neighbour, taken as an entirety, more than our bodily life, since the ultimate purpose of love of our neighbour is to share in eternal beatitude, a more desirable thing than bodily well being. Comte was probably opposing this Thomistic doctrine, now part of mainstream Catholicism, in coining the word Altruism, as stated above.
Altruism is essential to the Sikh religion. In the late 1600's, Guru Gobind Singh Ji (the tenth guru in Sikhism), was in war with the Moghul rulers to protect the people of different faiths, when a fellow Sikh, Bhai Kanhaiya, attended the troops of the enemy. He gave water to the injured, which revived their strength. Some of them began to fight again and seemed to cause problems to the Sikh warriors. Sikh soldiers brought Bhai Kanhaiya before the Guru, and complained of his action that they considered counterproductive to their hard work in the battle filed.
"What were you doing, and why?" asked the Guru. "I was giving water to the wounded because I saw your face in them," replied Bhai Kanhaiya.
The Guru responded, "Then you should also give them ointment to heal their wounds. You were practicing what you were coached in the house of the Guru." In love of altruism, is there any room for hatred or duality?
It was under the tutelage of the Guru that Bhai Kanhaiya subsequently founded a volunteer corps for altruism. This volunteer corps till to date is engaged in doing good to others and trains new volunteering recruits for doing the same.
It is claimed by some Sikhs that Bhai Kanhaiya's successors who continued the tradition of serving others and who committed their lives to service of the sick and wounded lived longer than usual life spans. Bhai Kanhaiya’s successors were not related genetically in order to account for their exceptional longevity. Rather they were volunteers from the Sikh organizations who committed their lives to serve the sick; first they did it themselves and then they recruited others to do the same. All of them defied the recorded longevity norms of the time for a long span of over three centuries.
Longevity is determined by many factors, freedom from disease and stress are two such factors. The altruists were certainly observed to live calm and tranquil lives. For Sikhs, altruism was made an act of faith by their founders.


Ang Lee () (born October 23, 1954) is an Academy Award-winning film director from Taiwan.
In the 2007 book The Cinema of Ang Lee: The Other Side of the Screen, Whitney Crothers Dilley has analyzed in detail the striking diversity of Ang Lee's films, as well as Lee's recurring themes of alienation, marginalization, and repression. Many of Lee's films, particularly his early Chinese trilogy, have also focused on the interactions between modernity and tradition. Some of his films have also had a light-hearted comic tone which marks a break from the tragic historical realism which characterized Taiwanese filmmaking after the end of the martial law period in 1987. While The Wedding Banquet (1993) became a break-out hit for Lee as the most proportionately profitable film of 1993, it was Sense and Sensibility (1995) that brought Lee his first true international acclaim. Following that, both Crouching Tiger, Hidden Dragon (2000) (nominated for Academy Award for Best Director), and Brokeback Mountain (2005) (which won the Academy Award for Best Director), became cultural touchstones, sweeping awards ceremonies, and, in the case of Brokeback Mountain, sparking intense critical debates.
The director's cut of Crouching Tiger, Hidden Dragon premiered on the Ivy League campus of Dartmouth College in 2000. He received the Dartmouth Film Award in 2001, along with Meryl Streep. At Dartmouth, he also taught Kai Wong filmmaking.
Lee's film Brokeback Mountain (2005) won the Golden Lion (best film) award at the Venice International Film Festival and was named 2005's best film by the Los Angeles, New York, Boston, and London film critics. It also won best picture at the 2005 Broadcast Film Critics Association, Directors Guild of America, Writers Guild of America (Adapted Screenplay), Producers Guild of America and the Independent Spirit Awards as well as the Golden Globe Award for Best Motion Picture — Drama, with Lee winning the Golden Globe Award for Best Director. Brokeback also won Best Film and Best Director at the 2006 British Academy Awards (BAFTA). In January 2006, Brokeback scored a leading eight Academy Award nominations including Best Picture and Best Director, which Lee won. He is the first Asian and non-Caucasian director to do so.
Lee studied in the National Tainan First Senior High School where his father was a former principal. He was expected to pass the annual Joint College/University Entrance Examination, the only route to a university education in Taiwan. But after failing the Exam twice, to the disappointment of his father, he entered a three-year college, National Arts School (now reorganized and expanded as National Taiwan University of Arts) and graduated in 1975. His father had wanted him to become a professor, but he had become interested in art at college. This early frustration set his career on the path of performance art.
After finishing the mandatory military service, Lee went to the U.S. in 1979 to study at the University of Illinois at Urbana-Champaign, where he completed his bachelor's in theater in 1980. Thereupon, he enrolled at the Tisch School of the Arts of New York University, where he received his MFA. He was a classmate of Spike Lee and worked on the crew of his thesis film, "Joe's Bed-Stuy Barbershop: We Cut Heads. During graduate school, Lee finished a 16 mm short film, Shades of the Lake (1982), which won the Best Drama Award in Short Film in Taiwan. His own thesis work, a 43-minute drama, Fine Line" (1984), won NYU's Wasserman Award for Outstanding Direction and was later selected for the Public Broadcasting Service.
Lee's NYU thesis drew attention from the William Morris Agency, the famous talent and literary agency that later represented Lee. At first, though, WMA found Lee few opportunities, and Lee remained unemployed for six years. During this time, he was a full-time househusband, while his wife Jane Lin (), a molecular biologist, was the sole breadwinner for the family of four. This arrangement, an embarrassment in Chinese culture, put enormous pressure on the couple, but with Lin's support and understanding, Lee did not abandon his career in films but continued to generate new ideas from movies and performances. He also wrote several screenplays during this time.
In 1990, Lee submitted two screenplays, Pushing Hands and The Wedding Banquet, to a competition sponsored by Taiwan's Government Information Office, and they came in first and second respectively. The winning screenplays brought Lee to the attention of Li-Kong Hsu (), a recently promoted senior manager in a major studio who had strong interests in Lee's unique style and freshness. Hsu, a first-time producer, invited Lee to direct Pushing Hands, a full-length feature that debuted in 1991.
Pushing Hands (1992) was a success in Taiwan both among critics and at the box office. It received eight nominations in the Golden Horse Film Festival, Taiwan's premier film festival. Inspired by the success, Hsu collaborated with Lee in their second film, The Wedding Banquet (1993), which won the Golden Bear in the Berlin Film Festival and was nominated as the Best Foreign Language Film in both the Golden Globe and the Academy Awards. In all, this film collected eleven Taiwanese and international awards and made Lee a rising star.
Lee's first two movies were based on stories of Taiwanese Americans, and both were filmed in the US. In 1995, Hsu invited Lee to return to Taiwan to make Eat Drink Man Woman, a film that depicts traditional values, modern relationships, and family conflicts in Taipei. The film was once again a box office hit and was critically acclaimed. For a second consecutive year, Lee's film received the Best Foreign Language Film nomination in both the Golden Globe and Academy Awards, as well as in the British Academy Award. Eat Drink Man Woman won five awards in Taiwan and internationally, including the Best Director from Independent Spirit. Hollywood optioned the film rights and remade it into Tortilla Soup (2001, dir. María Ripoll). This is one of the rare occasions in which a Taiwanese film was remade outside the island.
Lee's three dramas opened the door to Hollywood for him. In 1995, Lee directed Columbia TriStar's British classical Sense and Sensibility. The switching from Taiwanese to British films did not stop Lee from claiming awards in the film festivals. Sense and Sensibility made Lee a second time director of the Golden Bear film in the Berlin Film Festival, and it was nominated in 7 Academy Awards and won the Best Adapted Screenplay by Emma Thompson. It also won the Golden Globe Award for Best Motion Picture - Drama. After these successes, Lee directed another two Hollywood movies: The Ice Storm (1997), a family-oriented satire set in 1970s suburban America, and Ride with the Devil, an American Civil War drama (1999).
Although the critics still highly favored these works, the box office was not impressive, which paused Lee's uninterrupted popularity from the general audience and art schools since his first full-length movie. However, in the late 1990s and 2000s, The Ice Storm has had high VHS and DVD sales and rentals and repeated screenings on Cable television, which has increased the film's popularity among audiences.
In 1999, Li-Kong Hsu, Lee's old partner and supporter, invited him to make a movie based on the traditional Chinese "wuxia" (martial arts and chivalry) genre. Excited about the opportunity to fulfill his childhood dream, Lee assembled a team from Taiwan, Hong Kong, and Mainland China for Crouching Tiger, Hidden Dragon (2000). The film was a surprising success worldwide. With Chinese dialogue and English subtitles, the film became the highest grossing foreign film in many countries, including the United States and the United Kingdom, and was nominated for Best Picture, Best Foreign Language Film, and Best Director at the Academy Awards. It ended up winning Best Foreign Language Film and three technical awards. The success of Crouching Tiger demonstrated that Lee's artistry had a general appeal; it also inspired such established directors as Zhang Yimou and Chen Kaige to explore wuxia films for Western audience.
In 2003, Lee returned to Hollywood to direct Hulk, his first big-budget movie. Even though the film was based on a comic book superhero and was filled with obligatory CGI special effects, Lee used the genre to tell the tortuous story between a father and his son. The movie was a disappointment amongst both critics and audiences. After the setback, Lee considered retiring early, but his father encouraged him to continue making movies.
In spite of the director's removal from the subject at hand, Brokeback Mountain showcased Lee's skills in probing depths of the human heart.
The 2005 movie about the forbidden love between two Wyoming sheepherders immediately caught public attention and initiated intense debates. The film was critically acclaimed at major international film festivals and won Lee numerous Best Director and Best Film awards worldwide. In addition, "Brokeback" became a cultural phenomenon and a box office hit. "Brokeback" was nominated for a leading eight Oscars and was the frontrunner for Best Picture heading into the March 5 ceremony, but lost out to Crash, a story about race relations in Los Angeles, in a controversial upset. There was speculation that the film's depiction of homosexuality might have been the reason for that upset. Lee said he was disappointed that his film did not win Best Picture, but was honored to win Best Director, becoming the First Asian to ever win the award.
After Brokeback Mountain, Lee returned to a Chinese topic. His next film is Lust, Caution, which is adapted from a short novel by a Chinese author Eileen Chang. The story was written in 1950 loosely based on an actual event that took place in 1939-1940 in Japanese occupied-Shanghai, China, during World War II. Similar to Brokeback Mountain, Ang Lee adapted and expanded a short, simple story into a featured film in a way that allows individual figures to develop sophisticated layers of reserved emotions, without being sidetracked by complicated plots or overstuffed materials.
Lust, Caution is being distributed by Focus Features and premiered at international film festivals in the summer and early fall of 2007. In the US, the movie received a NC-17 rating (no one 17 and under admitted) from the MPAA mainly due to several strongly explicit sex scenes. This was a challenge to the film's distribution because many theater chains in the United States refuse to show NC-17 films. The director and film studio have decided not to appeal the decision. In order to be permitted to show Lust, Caution in mainland China, however, Lee removed 9 minutes from the film to make the content suitable for minor audiences, according to government restrictions.
Ang Lee is also known for his longtime collaboration with writer/producer James Schamus, with whom he co-wrote and produced nearly all his films, including Pushing Hands, Eat Drink Man Woman, The Wedding Banquet, The Ice Storm, Ride with the Devil, Crouching Tiger Hidden Dragon, Tortilla Soup, Hulk, Brokeback Mountain, and Lust, Caution.
Lee, a naturalized US Citizen, is a dedicated fan of the Calgary Flames, lives in Larchmont, New York, with his wife, Jane Lin, a microbiologist, whom he married in 1983, and their younger son, Mason Lee (born 1990), a student at Mamaroneck High School. The couple also has another son, Haan Lee (born 1984).
Ang's Chinese language films show a fair amount of linguistic diversity, which is rarely found in most Chinese films with the exception of Wong Kar-Wai. In Pushing Hands, Mr. Old Chu had a fat Tai chi chuan student who spoke Cantonese. In The Wedding Banquet, Wai-tun Gao's would-be bride of convenience Wei-wei, spoke to her parents on the telephone in the Wu dialect (Shanghainese). And the Chinese restaurant's owner spoke Mandarin with a Tianjin accent. In Eat Drink Man Woman, most of the younger generation spoke Mandarin with a Taiwanese accent; a matriarch spoke Mandarin with a Hunan accent. There was also a scene in Eat Drink Man Woman where an old man spoke to Jia-Chien in Taiwanese, while she responded in Mandarin.
While Chow Yun-Fat and Michelle Yeoh were criticized by Mandarin speakers for what they considered Mandarin with poor accents in Crouching Tiger Hidden Dragon, Yeoh pointed out in an December 28, 2000 interview with Cinescape that, "My character lived outside of Beijing, and so I didn’t have to do the Beijing accent." When the interviewer Craig Reid remarked that, "[M]y mother-in-law has this strange Sichuan-Mandarin accent that's hard for me to understand," Yeoh responded, "[Y]es, provinces all have their very own strong accents. When we first started the movie, Cheng Pei Pei was going to have her accent, and Chang Zhen was going to have his accent, and this person would have that accent. And in the end nobody could understand what they were saying. Forget about us, even the crew from Beijing thought this was all weird." In Lust, Caution, languages range from Cantonese, Shanghainese, Mandarin, Suzhou dialect, to Hindi, Japanese and English.


Ayn Rand (, – March 6, 1982), born "'Alisa Zinov'yevna Rosenbaum' (), was a Russian-born American novelist and philosopher. She is widely known for her best-selling novels The Fountainhead and Atlas Shrugged", and for developing a philosophical system she called Objectivism.
She was an uncompromising advocate of rational individualism and laissez-faire capitalism, and vociferously opposed socialism, altruism, and other contemporary philosophical trends, as well as religion. Her influential and often controversial ideas have attracted both enthusiastic admirers and scathing denunciation.
Rand's writing (both fiction and non-fiction) emphasizes the philosophic concepts of objective reality in metaphysics, reason in epistemology, and rational egoism in ethics. In politics she was a proponent of laissez-faire capitalism and a staunch defender of individual rights, believing that the sole function of a proper government is protection of individual rights (including property rights).
She believed that individuals must choose their values and actions solely by reason, and that "Man—every man—is an end in himself, not the means to the ends of others." According to Rand, the individual "must exist for his own sake, neither sacrificing himself to others nor sacrificing others to himself. The pursuit of his own rational self-interest and of his own happiness is the highest moral purpose of his life." Because she held that faith is antithetical to reason, Rand opposed religion.
Rand decried the initiation of force and fraud, and held that government action should consist only in protecting citizens from criminal aggression (via the police) and foreign aggression (via the military) and in maintaining a system of courts to decide guilt or innocence for objectively defined crimes and to resolve disputes. Her politics are generally described as minarchist and libertarian, though she did not use the first term and disavowed any connection to the second.
Rand was born in Saint Petersburg, Russia, and was the eldest of three daughters (Alisa, Natasha, and Nora) of Zinovy Zacharovich Rosenbaum and Anna Borisovna Rosenbaum, agnostic and largely non-observant ethnic Jews. Her father was a chemist and a successful pharmaceutical entrepreneur who earned the privilege of living outside the Pale. From an early age, Alisa displayed an interest in literature and film.
Rand was twelve at the time of the Russian revolution of 1917, and her family life was disrupted by the rise of the Bolshevik party. Her father's pharmacy was confiscated by the Soviets, and the family fled to Crimea to recover financially. When Crimea fell to the Bolsheviks in 1921, Rand burned her diary, which contained vitriolic anti-Soviet writings. Rand then returned to St. Petersburg to attend the University of Petrograd, where she studied history and philosophy. Here she discovered the literary works of Edmond Rostand, Friedrich Schiller, and Fyodor Dostoevsky. She admired Rostand for his richly romantic imagination and Schiller for his grand, heroic scale. She admired Dostoevsky for his sense of drama and his intense moral judgments, but was deeply against his philosophy and his sense of life. She completed a three-year program in the department of Social Pedagogy that included history, philology and law, and received Certificate of Graduation (Diploma No. 1552) on 13 October 1924. She also encountered the philosophical ideas of Nietzsche, and loved his exaltation of the heroic and independent individual who embraced egoism and rejected altruism in Thus Spake Zarathustra, but later rejected other aspects of his philosophy when she discovered more of his writings.
Rand continued to write short stories and screenplays. She entered the State Institute for Cinema Arts in 1924 to study screenwriting; in late 1925, however, she was granted a visa to visit American relatives.
After a brief stay with her relatives in Chicago, she resolved never to return to the Soviet Union, and set out for Hollywood to become a screenwriter. Already using Rand as a Cyrillic contraction of her surname, she then adopted the name Ayn, of disputed origin.
Rand viewed herself equally as a novelist and a philosopher, as she said "(I am) both, and for the same reason." Rand's supporters note that she is part of a long tradition of authors who wrote philosophically rich fiction—including Dante, John Milton, Fyodor Dostoevsky and Albert Camus, and that philosophers such as Jean-Paul Sartre presented their philosophies in both fictional and non-fictional forms.
Her first literary success came with the sale of her screenplay Red Pawn" in 1932 to Universal Studios: "Von Sternberg later considered it for Dietrich, but Russian scenarios were out of favour and the project was dropped." Rand then wrote the play The Night of January 16th in 1934, which was produced on Broadway. The play was a courtroom drama in which a jury chosen from the audience decided the verdict, leading to one of two possible endings.
Frank O'Connor and Ayn Rand spent the summer of 1937 in Stony Creek, Connecticut, while Frank worked in summer stock theatre, and Ayn planned the novella Anthem, a dystopian vision of a futuristic society where collectivism has triumphed. Anthem did not find a publisher in the United States and was first published in England in 1938.
Rand's first major professional success came with her best-selling novel The Fountainhead (1943), which she wrote over a period of seven years.
The Broadway Hollywood department store on Hollywood and Vine in Hollywood has a moderne style annex just to the west of it built in the 1930's. The building of that addition was viewed by a young Ayn Rand and became the basis of her research on construction techniques and workers found within her novel. Architect Richard Neutra, who designed the international styled Laemmle Building (1932) across Hollywood Boulevard to the north, is said to be the man on which she modelled Howard Roark, her lead character.
The novel was rejected by twelve publishers. It was finally accepted by the Bobbs-Merrill Company publishing house, thanks mainly to a member of the editorial board, Archibald Ogden, who praised the book in the highest terms ("If this is not the book for you, then I am not the editor for you.") and finally prevailed. Eventually, The Fountainhead was a worldwide success, bringing Rand fame and financial security.
In 1949 it was made into a major motion picture by Warner Brothers with Gary Cooper and Patricia Neal; Rand wrote the screenplay. In the sixty years since it was published, Rand's novel has sold six million copies, and continues to sell about 100,000 copies per year.
Following the success of The Fountainhead, Rand wrote screenplays for two movies, Love Letters and You Came Along.
The theme of Atlas Shrugged is "The role of man's mind in society." Rand upheld the industrialist as one of the most admirable members of society and fiercely opposed the resentment popularly accorded to industrialists. This led her to envision a novel wherein the industrialists of America go on strike and retreat to a mountainous hideaway, where they build an independent free economy with gold currency. The American economy and its society in general, deprived of its most productive members, slowly start to collapse, while the government responds by increasing the already stifling controls on industry.
The novel, which includes elements of mystery and science fiction, deals with other diverse issues as wide-ranging as sex, music, medicine, politics, philosophy, industry, and human ability.
Rand's philosophical system, Objectivism, encompasses positions on metaphysics, epistemology, ethics, politics and aesthetics. While there have been "objectivist" theories in the past, Rand's Objectivism uses the term in a new way: it treats knowledge and values as neither subjective, nor intrinsic in existence (the traditional meaning of "objective") but rather as the factual identification, by Man's mind, of what exists.
Rand's greatest influence was Aristotle, especially Organon ("Logic"); she considered Aristotle the greatest philosopher. In particular, her philosophy reflects an Aristotelian epistemology and metaphysics—both Aristotle and Rand argued that "there exists an objective reality that is independent of mind and that is capable of being known." Although Rand was ultimately critical of Aristotle's ethics, others have noted her egoistic ethics "is of the eudemonistic type, close to Aristotle's own … a system of guidelines required by human beings to live their lives successfully, to flourish, to survive as 'man qua man.'" Younkins argued "that her philosophy diverges from Aristotle’s by considering essences as epistemological and contextual instead of as metaphysical. She envisions Aristotle as a philosophical intuitivist who declared the existence of essences within concretes.".
In her early life, Rand admired the work of Friedrich Nietzsche, and did share "Nietzsche's reverence for human potential and his loathing of Christianity and the philosophy of Immanuel Kant," but eventually became critical, seeing his philosophy as emphasizing emotion over reason and a subjective interpretation of reality rather than reality existing independently from the self. There is debate about the extent of the relationship between Rand's views and Nietzsche's, and over what seemed to be an evolution of Rand's view of Nietzsche. Allan Gotthelf, in On Ayn Rand, describes the first edition of We the Living as very sympathetic to Nietzschean ideas. Bjorn Faulkner and Karen Andre, characters from The Night of January 16th, exemplify certain aspects of Nietzsche's views. Ronald Merrill, author of The Ideas of Ayn Rand identified a passage in We the Living that Rand had omitted from the 1959 reprint: "In it, the heroine entertains (though finally rejects) sentiments explicitly attributed to Nietzsche about the justice of sacrificing the weak for the strong." Rand herself denied a close intellectual relationship with Nietzsche and characterized changes in later editions of We the Living as stylistic and grammatical.
The "phenomenal" world, said Kant, is not real: reality, as perceived by man's mind, is a distortion. The distorting mechanism is man's conceptual faculty: man's basic concepts (such as time, space, existence) are not derived from experience or reality, but come from an automatic system of filters in his consciousness (labeled "categories" and "forms of perception") which impose their own design on his perception of the external world and make him incapable of perceiving it in any manner other than the one in which he does perceive it. This proves, said Kant, that man's concepts are only a delusion, but a collective delusion which no one has the power to escape. Thus reason and science are "limited," said Kant; they are valid only so long as they deal with this world, with a permanent, pre-determined collective delusion (and thus the criterion of reason's validity was switched from the objective to the collective), but they are impotent to deal with the fundamental, metaphysical issues of existence, which belong to the "noumenal" world. The "noumenal" world is unknowable; it is the world of "real" reality, "superior" truth and "things in themselves" or "things as they are"—which means: things as they are not perceived by man.
Even apart from the fact that Kant's theory of the "categories" as the source of man's concepts was a preposterous invention, his argument amounted to a negation, not only of man's consciousness, but of any consciousness, of consciousness as such. His argument, in essence, ran as follows: man is limited to a consciousness of a specific nature, which perceives by specific means and no others, therefore, his consciousness is not valid; man is blind, because he has eyes—deaf, because he has ears—deluded, because he has a mind—and the things he perceives do not exist, because he perceives them.
On the contrary, Rand believed that man can have full, direct awareness of reality. In Rand's view, Kant's dichotomy severed rationality and reason from the real world.
In ethics, Rand criticized Kant for claiming that an action only has moral worth if it is done out of duty, a concept which, according to Rand, was an outgrowth of mysticism and had no basis in reality. She also strongly disagreed with Kant's notion that morality has nothing to do with happiness.
In Rand's words, "I have mentioned in many articles that Kant is the chief destroyer of the modern world… You will find that on every fundamental issue, Kant's philosophy is the exact opposite of Objectivism.
In 1950 Rand moved to 120 East 34th Street in New York City, and formed a group (jokingly designated "The Collective") which included future Federal Reserve chairman Alan Greenspan, a young psychology student named Nathan Blumenthal (later Nathaniel Branden) and his wife Barbara, and Leonard Peikoff, all of whom had been profoundly influenced by The Fountainhead. According to Branden, "I wrote Miss Rand a letter in 1949 … [and] I was invited to her home for a personal meeting in March, 1950, a month before I turned twenty." Rand launched the Objectivist movement with this group to promote her philosophy.
The group originally started out as informal gathering of friends who met with Rand on weekends at her apartment to discuss philosophy; later the Collective would proceed to play a larger, more formal role, helping edit Atlas Shrugged and promoting Rand's philosophy through the Nathaniel Branden Institute (NBI), established by him for that purpose. Many Collective members gave lectures at the NBI and in cities across the United States, while others wrote articles for its sister newsletter, The Objectivist.
Throughout the 1960s and 1970s, Rand developed and promoted her Objectivist philosophy through both her fiction and non-fiction works, and by giving talks at several east-coast universities, largely through the NBI: "The Objectivist Newsletter, later expanded and renamed simply The Objectivist, contained essays by Rand, Branden, and other associates … that analyzed current political events and applied the principles of Objectivism to everyday life." Rand later published some of these in book form.
After several years, Rand's close relationship with the much younger Branden turned into a romantic affair, with the consent of their spouses. It lasted until Branden (having separated from Barbara) entered into an affair with the young actress Patrecia Scott, whom he later married. The Brandens hid the affair from Rand, and when she found out, she abruptly ended her relationship with both Brandens and with the NBI, which closed. She published a letter in The Objectivist repudiating Branden for dishonesty and "irrational behavior", never disclosing their affair. Both Brandens remain personae non gratae to the mainline Objectivist movement, particularly the group that formed the Ayn Rand Institute.
Rand is considered one of the three founding mothers (along with Rose Wilder Lane and Isabel Paterson) of modern American libertarianism, although she rejected Libertarianism and the Libertarian movement.
She expressed qualified enthusiasm for the economic thought of Ludwig von Mises and Henry Hazlitt. The Ludwig von Mises Institute says that "it was largely as a result of Ayn's efforts that the work of von Mises began to reach its potential audience." Later Objectivists, such as Richard Salsman, have claimed that Rand's economic theories are implicitly more supportive of the doctrines of Jean-Baptiste Say, though Rand herself was likely not acquainted with his work.
Another source of controversy is Rand's view of homosexuality. According to remarks at the Ford Hall Forum at Northeastern University in 1971, Rand's personal view was that homosexuality is "immoral" and "disgusting." Specifically, she stated that "there is a psychological immorality at the root of homosexuality" because "it involves psychological flaws, corruptions, errors, or unfortunate premises." A number of noted current and former Objectivists have been highly critical of Rand for her views on homosexuality. Others, such as Kurt Keefner, have argued that "Rand’s views were in line with the views at the time of the general public and the psychiatric community," though he asserts that "she never provided the slightest argument for her position, … because she regarded the matter as self-evident, like the woman president issue" although in her article "About a Woman President" Rand said that that issue was not self-evident.
Rand defended the right of businesses to discriminate on the basis of sexual orientation, race, or any other criteria. Rand argued that no one's rights are violated by a private individual's or organization's refusal to deal with him, even if the reason is irrational.
After the hearings, when Rand was asked about her feelings on the effectiveness of their investigations, she described the process as "futile".
Rand supported, in principle, the right to give charity but opposed the notion that it was a moral duty, and she did not consider it a major virtue. She opposed all charity and social programs by the government. According to Cathy Young, her characterization of charity in her fiction was chiefly negative.
Rand was a visiting lecturer at several universities, beginning in 1960 when she talked at Yale University, Princeton University and Columbia University. In subsequent years, she went on to lecture at University of Wisconsin, Johns Hopkins University, Harvard University and MIT. She received an honorary doctorate from Lewis & Clark College in 1963.
For many years, she gave an annual lecture at the Ford Hall Forum, answering questions from the audience afterward.
In 1973, she was briefly reunited with her youngest sister, Nora, who still lived in the Soviet Union. Although Rand had written 1,200 letters to her family in the Soviet Union, and had attempted to bring them to the United States, she had ceased contacting them in 1937 after reading a notice in the post office that letters from Americans might imperil Russians at risk from Stalinist repression. Rand received a letter from Nora in 1973 and invited her and her husband to America; but her sister's views had changed, and to Rand's disappointment Nora voluntarily returned to the USSR.
Rand underwent surgery for lung cancer in 1974, and conflicts continued in the wake of the break with Branden and the subsequent collapse of the NBI. Many of her closest "Collective" friends parted company, and during the late 1970s her activities within the Objectivist movement declined, especially after the death of her husband on November 9, 1979. One of her final projects was work on a television adaptation of Atlas Shrugged. She had also planned to write another novel, To Lorne Dieterling, but did not get far in her notes.
Rand died of heart failure on March 6, 1982 at her 34th Street home in New York City, years after having successfully battled cancer, and was interred in the Kensico Cemetery, Valhalla, New York. David Kelley read Kipling's poem "If—" at her graveside.
Rand's funeral was attended by some of her prominent followers, including Alan Greenspan. A six-foot floral arrangement in the shape of a dollar sign was placed near her casket.
Rand's books continue to be widely sold and read, with more than 22 million copies sold (as of 2005), and 500,000 more being sold each year. Rand and Objectivism are less well known outside North America, although there are pockets of interest in Europe, Australia, and New Zealand. Her novels are reported to be popular in India and Turkey (where filmmaker Sinan Çetin publishes her works) and to be gaining an increasingly wider audience in Africa. She also enjoyed some popularity in Israel, through the early work of Moshe Kroy. Generally, Rand's work has had little effect on academic philosophy; her followers have been largely drawn from other professions. The Anthem Foundation for Objectivist Scholarship offers resources to study Objectivism at The University of Texas at Austin, Ashland University in Ohio, and the University of Pittsburgh. At the University of Pittsburgh, professors James Lennox and Allan Gotthelf head the research. Both scholars are renowned for their illuminations of Aristotle's writings. Duke University's professor Gary Hull is a member of the Ayn Rand Institute and has lectured courses incorporating Objectivist literature and discussion. Professor Allan Gotthelf also points to certain modern trends in academic philosophy which make philosophers more receptive to Objectivist ideas. Chief among them are the notions of essence and concept as epistemological developments in virtue theory ethics, and current projects in normative philosophies of science and logic. Following Rand's death, continued conflict within the Objectivist movement led to establishment of independent organizations claiming to be her intellectual heirs.
Another schism in the movement occurred in 1989, when Objectivist David Kelley wrote "A Question of Sanction," in which he defended his choice to speak to non-Objectivist libertarian groups: "It was a response to an article by Peter Schwartz in The Intellectual Activist, demanding that those who speak to libertarians be ostracized from the movement..[I] observed that Objectivism is not a closed system of belief; and that we might actually learn something by talking to people we disagree with." Kelley's description of the reasons behind the break is disputed by the Ayn Rand Institute. Peikoff, in an article for The Intellectual Activist called "Fact and Value" argued that Objectivism is, indeed, a closed system, and that truth and morality are directly related. Peikoff expelled Kelley from his organization, whereupon Kelley founded The Institute for Objectivist Studies, now known as The Atlas Society, which has its own web site that is focused on attracting readers of Ayn Rand's fiction, downplaying her role as a philosopher. The associated Objectivist Center division deals with more academic ventures. The Atlas Society/Objectivist Center also publishes The New Individualist (formerly Navigator), the first magazine in the U.S. to feature one of the Mohammad cartoons on the cover.
Rand's books continue to sell in large numbers; for example, Atlas Shrugged is consistently in the top few hundred best sellers at Amazon.com.
When asked in a 1991 survey by the Library of Congress and the Book-of-the-Month Club what the most influential book in the respondent's life was, Rand's Atlas Shrugged was the second most popular choice, after the Bible. Readers polled in 1998 and 1999 by Modern Library placed four of her books on the 100 Best Novels list (Atlas Shrugged, The Fountainhead, Anthem, and We the Living were in first, second, seventh, and eighth place, respectively) and one on the 100 Best Nonfiction list (The Virtue of Selfishness, in first place), with books about Rand and her philosophy in third and sixth place. A Freestar Media/Zogby poll conducted in 2007 found that around 8 percent of American adults have read Atlas Shrugged. However, the validity of such polls has been disputed.
Many individuals have acknowledged that Rand significantly influenced their lives, including: Harry Binswanger, Nathaniel Branden, Barbara Branden, Sinan Çetin, Roy A. Childs, James Clavell, Edward Cline, Chris Cox, Mark Cuban, Paul DePodesta, Steve Ditko, Terry Goodkind, Allan Gotthelf, Alan Greenspan, Hugh Hefner, Erika Holzer, John Hospers, Angelina Jolie, David Kelley, Billie Jean King, Anton LaVey, Rush Limbaugh, Frank Miller, Ron Paul, Michael Paxton, Neil Peart, Leonard Peikoff, Ronald Reagan, George Reisman, John Ridpath, Robert Ringer, Tracey Ross, Kay Nolte Smith, Tara Smith, John Stossel, Linda & Morris Tannehill, Margaret Thatcher, Clarence Thomas, Vince Vaughn, Jimmy Wales, and many others. Rand's philosophy of Objectivism continues to influence workers in the arts, business, and science. The "Randex" Web site updates a list of recent media references to Rand or her work.
BioShock, an award-winning video game released in the summer of 2007, is built around a story influenced by Ayn Rand's philosophy and Atlas Shrugged.
She appears on a 33 cent U.S. postage stamp, which debuted 22 April 1999 in New York City.
In a 1999 interview in the Chronicle of Higher Education, Rand scholar Chris Matthew Sciabarra said, "I know they laugh at Rand," while also noting a growing interest in her work in the academic community.
A 2006 conference at the University of Pittsburgh, "Concepts and Objectivity: Knowledge, Science, and Values," featured presentations by Objectivists Onkar Ghate, Allan Gotthelf, James Lennox, and Darryl Wright alongside influential non-Objectivist academics such as A.P. Martinich and Peter Railton.
One of the reasons for the prominence of Ayn Rand and Objectivism in the news and popular culture relative to other philosophical theories may be related to the dozens of student groups dedicated to promoting and studying the philosophy of Objectivism spread across the U.S. Australia, Canada, Israel, the Netherlands, New Zealand, and Norway. These clubs often present controversial speakers on topics such as abortion, religion, and foreign policy, often allying with controversial conservative (and sometimes liberal) organizations to organize their events. For example the NYU Objectivism Club hosted a joint panel on the Muhammad cartoons that received nationwide coverage for NYU's censorship of the cartoons. There are several dozen speakers sponsored by the Ayn Rand Institute and other organizations, who give nationwide tours each year speaking about Objectivism.
The Ayn Rand Institute has spent more than $5M on educational programs advancing Objectivism, including scholarships and clubs. These clubs often obtain educational materials and speakers from the ARI. The Objectivist Club Association and ObjectivismOnline provide free hosting and organizational resources for Ayn Rand clubs. There are also several conferences organized by various organizations, such as the Objectivist Conferences, which are attended by several hundred "new intellectuals" each summer for two weeks and feature dozens of philosophy courses and presentations of new publications and research.
A notable exception to the general lack of attention paid to Rand in academic philosophy is the essay "On the Randian Argument" by Harvard University philosopher Robert Nozick, which appears in his collection, Socratic Puzzles. Nozick is sympathetic to Rand's political conclusions, but does not think her arguments justify them. In particular, his essay criticizes her foundational argument in ethics—laid out most explicitly in her book The Virtue of Selfishness—which claims that one's own life is, for each individual, the ultimate value because it makes all other values possible. Nozick says that to make this argument sound one needs to explain why someone could not rationally prefer dying and thus having no values. Thus, he argues, her attempt to defend the morality of selfishness is essentially an instance of begging the question. Nozick also argues that Rand's solution to David Hume's famous is-ought problem is unsatisfactory.
The most famous review of Rand's novel Atlas Shrugged was written by the conservative author Whittaker Chambers and appeared in National Review in 1957. It was unrelentingly scathing. Chambers called the book "sophomoric"; and "remarkably silly," and said it "can be called a novel only by devaluing the term." He described the tone of the book as "shrillness without reprieve". Chambers accused Rand of supporting the same godless system as the Soviets, claiming "From almost any page of Atlas Shrugged, a voice can be heard, from painful necessity, commanding: 'To the gas chambers—go!'" The Intellectual Activist published a reply, arguing that Chambers had not actually read the book, as he misspelled the names of two major characters and used no quotations from the novel in his critique.
Another critic, Mimi Gladstein (author of The New Ayn Rand Companion), called Rand's characters flat and uninteresting, and her heroes implausibly wealthy, intelligent, physically attractive and free of doubt while arrayed against antagonists who are weak, pathetic, full of uncertainty, and lacking in imagination and talent.
Rand's aesthetic views differed substantially from those of the academic mainstream. She explained in a 1963 essay titled "The Goal of My Writing" that the goal of her fiction was to project her vision of an ideal man: not man as he is, but man as he might be and ought to be. Rand presented her theory of aesthetics more fully in her 1969 book, The Romantic Manifesto: A Philosophy of Literature.
Murray Rothbard (who helped define modern libertarianism and anarcho-capitalism), Jeff Walker, and Michael Shermer (founder of The Skeptics Society), have accused Objectivism of being a cult, claiming that it exhibited typical cult traits, including slavish adherence to unprovable doctrine and extreme adulation of the founder.
In response to one fan who offered her cult-like allegiance, Rand declared, "A blind follower is precisely what my philosophy condemns and what I reject. Objectivism is not a mystic cult".
Without Rand's knowledge or permission, We the Living was made into a pair of films, Noi vivi and Addio, Kira in 1942 by Scalara Films, Rome. They were nearly censored by the Italian government under Benito Mussolini, but they were permitted because the novel upon which they were based was anti-Soviet. The films were successful, and the public easily realized that they were as much against Fascism as Communism. These films were re-edited into a new version which was approved by Rand and re-released as We the Living in 1986.
The Fountainhead was a Hollywood film (1949, Warner Bros.) starring Gary Cooper, for which Rand wrote the screen-play. Rand initially insisted that Frank Lloyd Wright design the architectural models used in the film, but relented when his fee was too high.
A film adaptation of Atlas Shrugged is in pre-production as of late 2007, with production possibly starting in 2008, although that may be affected by the writer's strike. In September 2007, Lions Gate Films reported that it had hired Vadim Perelman to revise Randall Wallace's script and to direct the film, with screen star Angelina Jolie cast in the rôle of Dagny Taggart.
The Passion of Ayn Rand, an independent film about her life, was made in 1999, starring Helen Mirren, Eric Stoltz, and Peter Fonda. The film was based on the book by Barbara Branden, one of her former associates, and won several awards for Helen Mirren, including the Emmy and the Golden Globe.
In addition to the screenplay of The Fountainhead, Rand also collaborated on screenplays of You Came Along and Love Letters both filmed in 1945.


Alain Connes (born April 1, 1947) is a French mathematician, currently Professor at the College de France, IHES and Vanderbilt University.
Baum-Connes conjecture. He also introduced cyclic cohomology in the early 1980s as a first step in the study of noncommutative differential geometry.
Connes has applied his work in areas of mathematics and theoretical physics, including number theory, differential geometry and particle physics.
Connes was awarded the Fields Medal in 1982, the Crafoord Prize in 2001 and the gold medal of the CNRS in 2004. He is a member of the French Academy of Sciences and several foreign academies and societies, including the Danish Academy of Sciences, Norwegian Academy of Sciences, Russian Academy of Sciences, and US National Academy of Sciences.


Allan Dwan (April 3, 1885 – December 28, 1981) was a pioneering Canadian-born American motion picture director, producer and screenwriter.
Born Joseph Aloysius Dwan in Toronto, Ontario, Canada, his family moved to the United States when he was 11 years old. At university, he trained as an engineer and began working for a lighting company in Chicago. However, he had a strong interest in the fledgling motion picture industry and when Essanay Studios offered him the opportunity to become a scriptwriter, he took the job. At that time, some of the East Coast movie makers began to spend winters in California where the climate allowed them to continue productions requiring warm weather. Soon, a number of movie companies worked there year-round and, in 1911, Dwan began working part time in Hollywood. While still in New York, in 1917 he was the founding president of the East Coast chapter of the Motion Picture Directors Association.
After making a series of westerns and comedies, Dwan directed fellow Canadian Mary Pickford in several very successful movies as well as her husband, Douglas Fairbanks, notably in the acclaimed 1922 Robin Hood.
Following the introduction of the talkies, in 1937 he directed child-star Shirley Temple in Heidi and Rebecca of Sunnybrook Farm the following year.
Over his long and successful career spanning over 50 years, he directed over 400 motion pictures, many of them highly acclaimed, such as the 1949 box office smash, Sands of Iwo Jima. He directed his last movie in 1961.
He died in Los Angeles at the age of ninety-six, and is interred in the San Fernando Mission Cemetery, Mission Hills, California.
Allan Dwan has a star on the Hollywood Walk of Fame at 6263 Hollywood Boulevard in Hollywood.

Current GDP per capita grew 40% in the Sixties reaching a peak growth of 538% in the Seventies. But this proved unsustainable and growth collapsed to a paltry 9.7% in the turbulent Eighties.
Failure of timely reforms by successive governments caused the current GDP per capita to shrink by 28% in the Nineties.
This is a chart of trend of gross domestic product of Algeria at market prices estimated by the International Monetary Fund with figures in millions of Algerian Dinars.
For purchasing power parity comparisons, the US Dollar is exchanged at 70.01 Algerian Dinars only (updated May 24, 2007).
Burdened with a heavy foreign debt, Algiers concluded a one-year standby arrangement with the International Monetary Fund in April 1994 and the following year signed onto a three-year extended fund facility which ended 30 April, 1998. In March 2006, Russia agreed to erase $4.74 billion of Algeria's Soviet-era debt during a visit by President Vladimir Putin to the country, the first by a Russian leader in half a century. In return, president Abdelaziz Bouteflika agreed to buy $7.5 billion worth of combat planes, air-defence systems and other arms from Russia, according to the head of Russia's state arms exporter Rosoboronexport. Some progress on economic reform, Paris Club debt reschedulings in 1995 and 1996, and oil and gas sector expansion contributed to a recovery in growth since 1995, reducing inflation to approximately 1% and narrowing the budget deficit. Algeria's economy has grown at about 4% annually since 1999. The country's foreign debt has fallen from a high of $28 billion in 1999 to its current level of $5 billion. The spike in oil prices in 1999-2000 and the government's tight fiscal policy, as well as a large increase in the trade surplus and the near tripling of foreign exchange reserves has helped the country's finances. However, an ongoing drought, the after effects of the November 10, 2001 floods and an uncertain oil market make prospects for 2002-03 more problematic. The government pledges to continue its efforts to diversify the economy by attracting foreign and domestic investment outside the energy sector. However, it has thus far had little success in reducing high unemployment, officially estimated at 30% and improving living standards.
President Bouteflika has announced sweeping economic reforms, which, if implemented, will significantly restructure the economy. Still, the economy remains heavily dependent on volatile oil and gas revenues. The government has continued efforts to diversify the economy by attracting foreign and domestic investment outside the energy sector, but has had little success in reducing high unemployment and improving living standards. Other priority areas include banking reform, improving the investment environment, and reducing government bureaucracy.
The government has announced plans to sell off state enterprises: sales of a national cement factory and steel plant have been completed and other industries are up for offer. In 2001, Algeria signed an Association Agreement with the European Union; it has started accession negotiations for entry into the World Trade Organization.
Since Roman times Algeria has been noted for the fertility of its soil. About 14 % of the inhabitants are engaged in agricultural pursuits. More than 7,500,000 acres (30,000 km²) are devoted to the cultivation of cereal grains. The Tell is the grain-growing land. During the time of French rule its productivity was increased substantially by the sinking of artesian wells in districts which only required water to make them fertile. Of the crops raised, wheat, barley and oats are the principal cereals. A great variety of vegetables and of fruits, especially citrus products, is exported.
A considerable amount of cotton was grown at the time of the United States' Civil War, but the industry declined afterwards. In the early years of the 20th century efforts to extend the cultivation of the plant were renewed. A small amount of cotton is also grown in the southern oases. Large quantities of crin vegetal (vegetable horse-hair) an excellent fibre, are made from the leaves of the dwarf palm. The olive (both for its fruit and Petroleum) and tobacco are cultivated with great success.
Algeria also exports figs, dates, esparto grass, and cork. It is the largest oat market in Africa.
The growing of vines was undertaken early by the colonists, but it was not until vineyards in France were attacked by phylloxera that the export of wine from Algeria became significant. In 1883, despite precautionary measures, Algerian vineyards were also attacked but in the meantime the quality of their wines had been proved. In 1850 less than 2000 acres (8 km²) were devoted to the grape, but in 1878 this had increased to over 42,000 acres (170 km²), which yielded 7,436,000 gallons (28,000 m³) of wine. Despite bad seasons and ravages of insects, cultivation extended, and in 1895 the vineyards covered 300,000 acres (1,200 km²), the produce being 88,000,000 gallons (333,000 m³). The area of cultivation in 1905 exceeded 400,000 acres (1,600 km²), and in that year the amount of wine produced was 157,000,000 gallons (594,000 m³). By that time the limits of profitable production had been reached in many parts of the country. Practically the only foreign market for Algerian wine is France, which in 1905 imported about 110,000,000 gallons (416,000 m³).
The Algerian body responsible for wine cultivation is called the National Office of Marketing of Wine Products (ONCV).
Fishing is a flourishing but minor industry. Fish caught are principally sardines, bonito, smelt and sprats. Fresh fish are exported to France, dried and preserved fish to Spain and Italy. Coral fisheries are found along the coast from Bona to Tunis.
Under French administration, the commerce of Algeria developed greatly: the total imports and exports at the time of the French occupation (1830) did not exceed £ 175,000. In 1850 the figures had reached £5,000,000; in 1868, £12,000,000; in 1880, £17,000,000; and in 1890, £20,000,000. From this point progress was slower and the figures varied considerably year by year. In 1905 the total value of the foreign trade was £24,500,000. About five-sixths of the trade is with or via France, into which country several Algerian goods have been admitted duty-free since 1851, and all since 1867. French goods, except sugar, have been admitted into Algeria without payment of duty since 1835. After the increase, in 1892, of the French minimum tariff, which applied to Algeria also, foreign trade greatly diminished.
By far Algeria's most significant exports, financially, are petroleum and natural gas. The reserves are mostly in the Eastern Sahara; the Algerian government curbed the exports in the 1980s to slow depletion; exports increased again somewhat in the 1990s. Other significant exports are sheep, oxen, and horses; animal products, such as wool and skins; wine, cereals (rye, barley, oats), vegetables, fruits (chiefly figs and grapes for the table) and seeds, esparto grass, oils and vegetable extracts (chiefly olive oil), iron ore, zinc, natural phosphates, timber, cork, crin vegetal and tobacco. The import of wool exceeds the export. Sugar, coffee, machinery, metal work of all kinds, clothing and pottery are largely imported. Of these by far the greater part comes from France. The British imports consist chiefly of coal, cotton fabrics and machinery.
Algeria trades most extensively with France and Italy, in terms of both imports and exports, but also trades with the United States and Spain.


Algeria (, "Al Jaza'ir, Berber:, Dzayer [ldzæjər]), officially the 'People's Democratic Republic of Algeria', is the second largest country on the African continent and the 11th largest country in the world in terms of total area. It is bordered by Tunisia in the northeast, Libya in the east, Niger in the southeast, Mali and Mauritania in the southwest, a few kilometers of the Western Sahara in the west, Morocco in the northwest, and the Mediterranean Sea in the north.
Algeria is a member of the United Nations, African Union, Arab League, and OPEC. It also contributed towards the creation of the Arab Maghreb Union. Constitutionally, Algeria is defined as an Islamic, Arab, and Amazigh (Berber) country.
Al-jazā’ir" is itself a truncated form of the city's older name jazā’ir banī mazghannā, "the islands of (the tribe) Bani Mazghanna", used by early medieval geographers such as al-Idrisi and Yaqut al-Hamawi.
Algeria has been inhabited by Berbers (or Imazighen) since at least 10,000 BC. After 1000 BC, the Carthaginians began establishing settlements along the coast. The Berbers seized the opportunity offered by the Punic Wars to become independent of Carthage, and Berber kingdoms began to emerge, most notably Numidia. In 200 BC, however, they were once again taken over, this time by the Roman Republic. When the Western Roman Empire collapsed, Berbers became independent again in many areas, while the Vandals took control over other parts, where they remained until expelled by the generals of the Byzantine Emperor, Justinian I. The Byzantine Empire then retained a precarious grip on the east of the country until the coming of the Arabs in the eighth century.
Having converted the Kutama of Kabylie to its cause, the Shia Fatimids overthrew the Rustamids, and conquered Egypt. They left Algeria and Tunisia to their Zirid vassals; when the latter rebelled and adopted Sunnism, the Shia Fatimids sent in the Banu Hilal, a populous Arab tribe, to weaken them. This initiated the Arabization of the region. The Almoravids and Almohads, Berber dynasties from the west founded by religious reformers, brought a period of relative peace and development; however, with the Almohads' collapse, Algeria became a battleground for their three successor states, the Algerian Zayyanids, Tunisian Hafsids, and Moroccan Marinids. In the fifteenth and sixteenth centuries, the Spanish Empire started attacking and subsuming a few Algerian coastal settlements.
Algeria was brought into the Ottoman Empire by Khair ad-Din and his brother Aruj in 1517, and they established Algeria's modern boundaries in the north and made its coast a base for the Ottoman corsairs; their privateering peaked in Algiers in the 1600s. Piracy on American vessels in the Mediterranean resulted in the First (1801–1805) and Second Barbary War (1815) with the United States. Those piracy acts forced people captured on the boats into slavery; alternatively when the pirates attacked coastal villages in southern and western Europe the inhabitants were forced into slavery.
Raids by Barbary pirates on Western Europe did not cease until 1816, when a Royal Navy raid, assisted by six Dutch vessels, destroyed the port of Algiers and its fleet of Barbary ships.
Spanish occupation of Algerian ports at this time was a source of concern for the local inhabitants.
On the pretext of a slight to their consul, the French invaded Algiers in 1830. In contrast to Morocco and Tunisia, the conquest of Algeria by the French was long and particularly violent and resulted in the disappearance of about a third of the Algerian population. France was responsible for the extermination of 1.5 million Algerians. According to Olivier Le Cour Grandmaison, the French pursued a policy of extermination against the Algerians.
The French conquest of Algeria was slow due to intense resistance from such as Emir Abdelkader, Ahmed Bey and Fatma N'Soumer. Indeed the conquest was not technically complete until the early 1900s when the last Tuareg were conquered.
Meanwhile, however, the French made Algeria an integral part of France, a status that would end only with the collapse of the Fourth Republic in 1958. Tens of thousands of settlers from France, Spain, Italy, and Malta moved in to farm the Algerian coastal plain and occupy significant parts of Algeria's cities. These settlers benefited from the French government's confiscation of communally held land, and the application of modern agriculture techniques that increased the amount of arable land. Algeria's social fabric suffered during the occupation: literacy plummeted, while land confiscation uprooted much of the population.
Starting from the end of the nineteenth century, people of European descent in Algeria (or natives like Spanish people in Oran), as well as the native Algerian Jews (typically Sephardic in origin), became full French citizens. After Algeria's 1962 independence, they were called Pieds-Noirs. In contrast, the vast majority of Muslim Algerians (even veterans of the French army) received neither French citizenship nor the right to vote.
In 1954, the National Liberation Front (FLN) launched the Algerian War of Independence which was a guerrilla campaign. By the end of the war, newly elected President Charles de Gaulle, understanding that the age of empire was ending, held a plebiscite, offering Algerians three options. This resulted in an overwhelming vote for complete independence from the French Colonial Empire. Over one million people, 10% of the population, then fled the country for France in just a few months in mid-1962. These included most of the 1,025,000 Pieds-Noirs, as well as 81,000 Harkis (pro-French Algerians serving in the French Army).
As feared, there were widespread reprisals against those who remained in Algeria. It is estimated that somewhere between 50,000 and 150,000 Harkis and their dependents were killed by the FLN or by lynch mobs in Algeria, sometimes in circumstances of extreme cruelty.
Algeria's first president was the FLN leader Ahmed Ben Bella. He was overthrown by his former ally and defence minister, Houari Boumédienne in 1965. Under Ben Bella the government had already become increasingly socialist and authoritarian, and this trend continued throughout Boumédienne's government. However, Boumédienne relied much more heavily on the army, and reduced the sole legal party to a merely symbolic role. Agriculture was collectivised, and a massive industrialization drive launched. Oil extraction facilities were nationalized. This was especially beneficial to the leadership after the 1973 oil crisis. However, the Algerian economy became increasingly dependent on oil which led to hardship when the price collapsed during the 1980s oil glut.
In foreign policy, Algeria was a member and leader of the Non-Aligned Movement. A dispute with Morocco over the Western Sahara nearly led to war. While Algeria shares much of its history and cultural heritage with neighbouring Morocco, the two countries have had somewhat hostile relations with each other ever since Algeria's independence. This is for two reasons: Morocco's disputed claim to portions of western Algeria (which led to the Sand War in 1963), and Algeria's support for the Polisario Front, an armed group of Sahrawi refugees seeking independence for the Moroccan-ruled Western Sahara, which it hosts within its borders in the city of Tindouf.
Within Algeria, dissent was rarely tolerated, and the state's control over the media and the outlawing of political parties other than the FLN was cemented in the repressive constitution of 1976.
Boumédienne died in 1978, but the rule of his successor, Chadli Bendjedid, was little more open. The state took on a strongly bureaucratic character and corruption was widespread.
The modernization drive brought considerable demographic changes to Algeria. Village traditions underwent significant change as urbanization increased. New industries emerged, agricultural employment was substantially reduced. Education was extended nationwide, raising the literacy rate from less than 10% to over 60%. There was a dramatic increase in the fertility rate to 7-8 children per mother.
Therefore by 1980, there was a very youthful population and a housing crisis. The new generation struggled to relate to the cultural obsession with the war years and two conflicting protest movements developed: left-wingers, including Berber identity movements; and Islamic 'intégristes'. Both groups protested against one-party rule but also clashed with each other in universities and on the streets during the 1980s. Mass protests from both camps in Autumn 1988 forced Bendjedid to concede the end of one-party rule. Elections were planned to happen in 1991.
In December 1991, the Islamic Salvation Front won the first round of the country's first multi-party elections. The military then intervened and cancelled the second round, forced then-president Bendjedid to resign, and banned all political parties based on religion (including the Islamic Salvation Front). The ensuing conflict engulfed Algeria in the violent Algerian Civil War.
More than 160,000 people were killed between 17 January 1992 and June 2002. Most of the deaths were between militants and government troops, but a great number of civilians were also killed. The question of who was responsible for these deaths was controversial at the time amongst academic observers; many were claimed by the Armed Islamic Group. Though many of these massacres were carried out by Islamic extremists, the Algerian regime itself has used the army and foreign mercenaries to conduct horrific massacres of men, women and children and then blame it upon all Islamic groups within the country in a campaign to discredit them and Islam amongst the wider population.
Elections resumed in 1995, and after 1998, the war waned. On 27 April 1999, after a series of short-term leaders representing the military, Abdelaziz Bouteflika, the current president, was elected.
By 2002, the main guerrilla groups had either been destroyed or surrendered, taking advantage of an amnesty program, though sporadic fighting continued in some areas (See Islamic insurgency in Algeria (2002–present)).
The issue of Berber language and identity increased in significance, particularly after the extensive Kabyle protests of 2001 and the near-total boycott of local elections in Kabylie. The government responded with concessions including naming of Tamazight (Berber) as a national language and teaching it in schools.
Much of Algeria is now recovering and developing into an emerging economy. The high prices of oil and gas are being used by the new government to improve the country's infrastructure and especially improve industry and agricultural land. Recently, overseas investment in Algeria has increased.
Most of the coastal area is hilly, sometimes even mountainous, and there are a few natural harbours. The area just south of the coast, known as the Tell Atlas, is fertile. Further south is the Atlas mountain range and the Sahara desert. The Ahaggar Mountains (Arabic: جبال هقار‎), also known as the Hoggar, are a highland region in central Sahara, southern Algeria. They are located about 1,500 km (932 miles) south of the capital, Algiers and just west of Tamanghasset.
Algiers, Oran, Constantine, and Annaba are Algeria's main cities.
Northern Algeria is in the temperate zone and has a mild, Mediterranean climate. It lies within approximately the same latitudes as Southern California and has somewhat similar climatic conditions. Its broken topography, however, provides sharp local contrasts in both prevailing temperatures and incidence of rainfall. Year-to-year variations in climatic conditions are also common.
In the Tell Atlas, temperatures in summer average between 21 and 24 °C and in winter drop to 10 to 12 °C. Winters are not particularly cold, but the humidity level is high. In eastern Algeria, the average temperatures are somewhat lower, and on the steppes of the High Atlas plateaux, winter temperatures hover only a few degrees above freezing. A prominent feature of the climate in this region is the sirocco, a dusty, choking south wind blowing off the desert, sometimes at gale force. This wind also occasionally reaches into the coastal Tell.
In Algeria, only a relatively small corner of the torrid Sahara lies across the Tropic of Cancer in the torrid zone. In this region even in winter, midday desert temperatures can be very hot. After sunset, however, the clear, dry air permits rapid loss of heat, and the nights are cool to chilly. Enormous daily ranges in temperature are recorded.
Rainfall is fairly abundant along the coastal part of the Tell Atlas, ranging from 400 to 670 mm annually, the amount of precipitation increasing from west to east. Precipitation is heaviest in the northern part of eastern Algeria, where it reaches as much as 1000 mm in some years. Farther inland, the rainfall is less plentiful. Prevailing winds that are easterly and north-easterly in summer change to westerly and northerly in winter and carry with them a general increase in precipitation from September through December, a decrease in the late winter and spring months, and a near absence of rainfall during the summer months. Algeria also has ergs, or sand dunes between mountains, which in the summer time when winds are heavy and gusty, temperatures can get up to 110 °F.
The head of state is the President of the Republic, who is elected to a five-year term, renewable once. Algeria has universal suffrage at age 18. The President is the head of the Council of Ministers and of the High Security Council. He appoints the Prime Minister who is also the head of government. The Prime Minister appoints the Council of Ministers.
The Algerian parliament is bicameral, consisting of a lower chamber, the "National People's Assembly (APN), with 380 members; and an upper chamber, the Council Of Nation, with 144 members. The APN is elected every five years.
Tensions between Algeria and Morocco in relation with the Western Sahara conflict, have put great obstacles in the way of tightening the Maghreb Arab Union, nominally established in 1989 but with little practical weight, with its coastal neighbors.
Algeria is currently divided into 48 provinces (wilayas), 553 districts (daïras) and 1,541 municipalities (communes, baladiyahs). Each province, district, and municipality is named after its seat, which is mostly also the largest city.
According to the Algerian constitution, a province is a territorial collectivity enjoying some economic freedom". The People's Provincial Assembly is the political entity governing a province, which has also a "president", who is elected by the members of the that assembly. They are in turn elected on universal suffrage every five years. The "Wali" (Prefect or governor) directs each province. This person is chosen by the Algerian President to handle the PPA's decisions.
The fossil fuels energy sector is the backbone of Algeria's economy, accounting for roughly 60% of budget revenues, 30% of GDP, and over 95% of export earnings. The country ranks fourteenth in petroleum reserves, containing 11.8 billion barrels of proven oil reserves with estimates suggesting that the actual amount is even more. The U.S. Energy Information Administration reported that in 2005, Algeria had 160 trillion cubic feet (Tcf) of proven natural gas reserves, the eighth largest in the world.
Algeria’s financial and economic indicators improved during the mid-1990s, in part because of policy reforms supported by the International Monetary Fund (IMF) and debt rescheduling from the Paris Club. Algeria’s finances in 2000 and 2001 benefited from an increase in oil prices and the government’s tight fiscal policy, leading to a large increase in the trade surplus, record highs in foreign exchange reserves, and reduction in foreign debt. The government's continued efforts to diversify the economy by attracting foreign and domestic investment outside the energy sector have had little success in reducing high unemployment and improving living standards, however. In 2001, the government signed an Association Treaty with the European Union that will eventually lower tariffs and increase trade. In March 2006, Russia agreed to erase $4.74 billion of Algeria's Soviet-era debt during a visit by President Vladimir Putin to the country, the first by a Russian leader in half a century. In return, president Bouteflika agreed to buy $7.5 billion worth of combat planes, air-defense systems and other arms from Russia, according to the head of Russia's state arms exporter Rosoboronexport.
Algeria also decided in 2006 to pay off its full $8bn (£4.3bn) debt to the Paris Club group of rich creditor nations before schedule. This will reduce the Algerian foreign debt to less than $5bn in the end of 2006. The Paris Club said the move reflected Algeria's economic recovery in recent years.
Since Roman times Algeria has been noted for the fertility of its soil. 9.4% of Algerians are employed in the agricultural sector.
A considerable amount of cotton was grown at the time of the United States' Civil War, but the industry declined afterwards. In the early years of the twentieth century efforts to extend the cultivation of the plant were renewed. A small amount of cotton is also grown in the southern oases. Large quantities of a vegetable that resembles horsehair, an excellent fiber, are made from the leaves of the dwarf palm. The olive (both for its fruit and oil) and tobacco are cultivated with great success.
More than 7,500,000 acres (30,000 km²) are devoted to the cultivation of cereal grains. The Tell is the grain-growing land. During the time of French rule its productivity was increased substantially by the sinking of artesian wells in districts which only required water to make them fertile. Of the crops raised, wheat, barley and oats are the principal cereals. A great variety of vegetables and fruits, especially citrus products, are exported. Algeria also exports figs, dates, esparto grass, and cork. It is the largest oat market in Africa.
Algeria is known for Bertolli's olive oil spread, although the spread has an Italian background.
The current population of Algeria is 33,333,216 (July 2007 est.).
About 70% of Algerians live in the northern, coastal area; the minority who inhabit the Sahara are mainly concentrated in oases, although some 1.5 million remain nomadic or partly nomadic. Almost 30% of Algerians are under 15. Algeria has the fourth lowest fertility rate in the Greater Middle East after Cyprus, Tunisia, and Turkey.
97% of the population is classified ethnically as Berber/Arab and religiously as Sunni Muslim 97%, the few non-Sunni Muslims are mainly Ibadis 1.3% from the M'Zab valley. (See also Islam in Algeria.) A mostly foreign Roman Catholic community of about 45,000 exists, along with about 350,000 Protestant Christians, and some 500 Jewish. The Jewish community of Algeria, which once constituted 2% of the total population, has substantially decreased due to emigration, mostly to France and Israel.
Europeans account for less than 1% of the population, inhabitating almost exclusively the largest metropolitan areas. However, during the colonial period there was a large (15.2% in 1962) European population, consisting primarily of French people, in addition to Spaniards in the west of the country, Italians and Maltese in the east, and other Europeans in smaller numbers known as pieds-noirs, concentrated on the coast and forming a majority in cities like Bône, Oran, Sidi Bel Abbès, and Algiers. Almost all of this population left during or immediately after the country's independence from France.
Housing and medicine continue to be pressing problems in Algeria. Failing infrastructure and the continued influx of people from rural to urban areas has overtaxed both systems. According to the UNDP, Algeria has one of the world's highest per housing unit occupancy rates for housing, and government officials have publicly stated that the country has an immediate shortfall of 1.5 million housing units.
Women make up 70 percent of Algeria’s lawyers and 60 percent of its judges. Women dominate medicine. Increasingly, women contribute more to household income than men. Sixty percent of university students are women, university researchers say.
Most Algerians are Berber or Arab, by language or identity, but almost all Algerians are Berber in origin. Today, the Arab-Berber issue is often a case of self-identification or identification through language and culture, rather than a racial or ethnic distinction. The Berber people are divided into several ethnic groups, Kabyle in the mountainous north-central area, Chaoui in the eastern Atlas Mountains, Mozabites in the M'zab valley, and Tuareg in the far south. Small pockets of Black African populations also are in Algeria.
Education is officially compulsory for children between the ages of 6 and 15. In the year 1997, there was an outstanding amount of teachers and students in primary schools.
Modern Algerian literature, split between Arabic and French, has been strongly influenced by the country's recent history. Famous novelists of the twentieth century include Mohammed Dib, Albert Camus, and Kateb Yacine, while Assia Djebar is widely translated. Among the important novelists of the 1980s were Rachid Mimouni, later vice-president of Amnesty International, and Tahar Djaout, murdered by an Islamist group in 1993 for his secularist views.
In philosophy and the humanities, Jacques Derrida, the father of deconstruction, was born in El Biar in Algiers; Malek Bennabi and Frantz Fanon are noted for their thoughts on decolonization; Augustine of Hippo was born in Tagaste (modern-day Souk Ahras); and Ibn Khaldun, though born in Tunis, wrote the Muqaddima while staying in Algeria.
Algerian culture has been strongly influenced by Islam, the main religion. The works of the Sanusi family in pre-colonial times, and of Emir Abdelkader and Sheikh Ben Badis in colonial times, are widely noted. The Latin author Apuleius was born in Madaurus (Mdaourouch), in what later became Algeria.
The Algerian musical genre best known abroad is raï, a pop-flavored, opinionated take on folk music, featuring international stars such as Khaled and Cheb Mami. However, in Algeria itself the older, highly verbal chaabi style remains more popular, with such stars as El Hadj El Anka, Dahmane El Harrachi and El Hachemi Guerouabi, while the tuneful melodies of Kabyle music, exemplified by Idir, Ait Menguellet, or Lounès Matoub, have a wide audience. For more classical tastes, Andalusi music, brought from Al-Andalus by Morisco refugees, is preserved in many older coastal towns.
In painting, Mohammed Khadda and M'Hamed Issiakhem have been notable in recent years.
Most Algerians speak Algerian Arabic.
Arabic is spoken natively in dialectal form ("Darja") by some 83.2% of the population. However in the media and official occasions the spoken language is Standard Arabic.
The Berbers (or Imazighen), who form approximately 45% of the population, largely speak one of the various dialects of Tamazight as opposed to Arabic. But a majority can use the both, Berber and Algerian Arabic. Arabic remains Algeria's only official language, although Tamazight has recently been recognized as a national language alongside it.
Ethnologue counts eighteen living languages within Algeria, splitting both Arabic and Tamazight into several different languages, as well as including the Korandje language, which is unrelated to Arabic or Tamazight.
The language issue is politically sensitive, particularly for the Berber minority, which has been disadvantaged by state-sanctioned Arabization. Language politics and Arabization have partly been a reaction to the fact that 130 years of French colonization had left both the state bureaucracy and much of the educated upper class completely Francophone, as well as being motivated by the Arab nationalism promoted by successive Algerian governments.
French is still the most widely studied foreign language, but very rarely spoken as a native language. Since independence, the government has pursued a policy of linguistic Arabization of education and bureaucracy, with some success, although many university courses continue to be taught in French. Recently, schools have started to incorporate French into the curriculum as early as children start to learn Arabic, as many Algerians are fluent in French. French is also used in media and commerce.
It is the direct successor of the Armée de Libération Nationale (ALN), which fought French colonial occupation during the Algerian War of Independence (1954-62).
The People's National Army consists of 127,500 members, with some 100,000 reservists. The army is under the control of the president, who also is minister of National Defense (current president is Abdelaziz Bouteflika). Defense expenditures accounted for some $2.67 billion or 3.5% of GDP. One and a half years of national military service is compulsory for males.
Algeria is a leading military power in North Africa and has its force oriented toward its western (Morocco) and eastern (Libya) borders. Its primary military supplier has been the former Soviet Union, which has sold various types of sophisticated equipment under military trade agreements, and the People's Republic of China. Algeria has attempted, in recent years, to diversify its sources of military material. Military forces are supplemented by a 45,000-member gendarmerie or rural police force under the control of the president and 30,000-member Sûreté nationale or Metropolitan police force under the Ministry of the Interior.
Recently, the Algerian Air Force signed a deal with Russia to purchase 49 MiG-29SMT and 6 MiG-29UBT at an estimated $1.5 Billion. They also agreed to return old airplanes purchased from the Former USSR. Russia is also building 2 636-type diesel submarines for Algeria.
There are several UNESCO World Heritage Sites in Algeria including Al Qal'a of Beni Hammad, the first capital of the Hammadid empire; Tipasa, a Phoenician and later Roman town; and Djémila and Timgad, both Roman ruins; M'Zab Valley, a limestone valley containing a large urbanized oasis; also the Casbah of Algiers is an important citadel. The only natural World Heritage Sitesis the Tassili n'Ajjer, a mountain range.

Called "the literary leader of the age", despite the fact that he is incapable of writing anything that people actually want to read. What people want to read, he says, is irrelevant. He complains that it is disgraceful that artists are treated as peddlers, and that there should be a law limiting the sales of books to ten thousand copies. He is a member of the Looters. Balph Eubank appears in section 161.
A railroad contractor whom Dagny Taggart hires to replace the track on the Rio Norte Line with Rearden Metal. Nealy is incompetent, but Dagny can find no one better in all the country. Nealy believes that anything can get done with enough muscle power. He sees no role for intelligence in human achievement, and this is manifest in his inability to organize the project and to make decisions. He relies on Dagny and Ellis Wyatt to run things, and resents them for doing it, because it appears to him like they are just bossing people around. Ben Nealy appears in section 171.
Editorial writer for the magazine The Future. He typically bashes business and businessmen, but he never says anything specific in his articles, relying on innuendo, sneers, and denunciation. He wrote a hatchet job on Hank Rearden called The Octopus. He is also vocal in support of the Equalization of Opportunity Bill. Later on he has a radio interview program, in which Dagany Taggart is forced to appear by the threat of revelation of her relationships with Rearden - but she turns the tables by herself revealing the relationship, taking pride in it and denouncing the regime. In the aftermath, Scudder is made the scapegoat and loses his job. Bertram Scudder appears in section 161.
A wealthy socialite who is having a meaningless sexual affair with James Taggart that coincides with the overall meaninglessness of her life. She regrets having to wake up every morning because she has to face another empty day. She is deliberately crude in a way that casts ridicule on her high social position. Betty Pope appears in sections 142 and 161.
An unnamed employee working on the Taggart Comet train. Dagny Taggart" hears Brakeman whistling the theme of a concerto. When she asks him what piece it is from, he says it is Halley's Fifth Concerto. When Dagny points out that Richard Halley only wrote four concertos, Brakeman claims he made a mistake and that he does not recall where he heard the piece.
Later, after Dagny instructs the train crew how to proceed, he asks a co-worker who she is, and learns she is the one who runs Taggart Transcontinental.
It is later discovered that the unknown brakeman is one of the strikers, when Dagny meets him in the valley. Brakeman appears in sections 112 and 113.
Dime store shopgirl who marries James Taggart after a chance encounter in her store the night the John Galt Line was deemed his greatest success. She marries him thinking he is the heroic person behind Taggart Transcontinental. She is horrible to Dagny until the night before she commits suicide, when she confesses to Dagny that when she married Jim, she thought he had all of the Taggart family's positive traits - she thought she was marrying someone like Dagny. Like Eddie Willers, Cherryl is one representation of a "good" person who lacks the extraordinary capacities of the primary heroes of the novel.
The president of political organization Friends of Global Progress (which is supported by Philip Rearden), and one of "Lillian Rearden's" friends. He believes that ideas are just air, that this is no time for talk, but for action. He is not bothered by the fact that action unguided by ideas is random and pointless. Global Progress is a sponsor of the Equalization of Opportunity Bill. Claude Slagenhop appears in section 161.
A thuggish personage who's assigned by Wesley Mouch to keep watch over the workings of Taggart Transcontinental, and later assumes control over the company after Dagny Taggart leaves. He carries a pistol and a lucky rabbit's foot, he dresses in a military uniform. The "spiritual heir" of Dr. Robert Stadler, Meigs comes to a fitting end at the hands of Project X. His role is to act as the frankly brutal face of the regime, which frightens and disgusts more hypocritical people. Though of a different profession, he is similar to the architect Gus Webb in The Fountainhead, who similarly behaves in a crude and brutal manner and frightens more hypocritical architects. Both characters become prominent in the later part of their respective books, with Webb becoming Ellsworth Toohey's favorite in place of Keating when Toohey feels less of need to keep a mask, while Meigs comes to prominence when the regime finds it impossible to continue with more subtle and seemingly civilised methods.
Dagny Taggart is the protagonist of the novel, and, in general, it is Dagny's perception of the battle between John Galt and the Looters that is the readers'. She holds the title of 'Vice-President in Charge of Operations' of Taggart Transcontinental, under her brother, James Taggart. However, due to James' incompetence, it is Dagny that is actually responsible for all the workings of the railroad.
Taggart has romantic relationships with the three men of ability: Francisco d'Anconia, Hank Rearden, and John Galt. Ultimately, she ends up with Galt, on account of the superiority of his talents and qualities. Nonetheless, she remains on good terms with the other two, despite ending her sexual relationships with them.
Dagny personifies the typical struggle within many capitalists: when to stop trying to change the social policies that impinge on capitalist goals. Hers is the most unusual perspective in the book, as she has one foot in both camps. She tries to "fix" the social policies of the government while still maintaining her belief in free enterprise. The ultimate lesson taught through Dagny is that reason cannot triumph over the unreasonable until the unreasonable perish.
She is a typical Randian heroine, similar to Dominique Francon (The Fountainhead) or Kira Argounova (We the Living).
Dagny appears in sections 112, 113, 114, 132, 133, 141, 145, 146, 147, 148, 151, 152, and 161.
The middle-aged president of the Phoenix-Durango railroad. Running a railroad is just about the only thing he knows. When the Anti-dog-eat-dog Rule is used to drive his business out of Colorado, he loses the will to fight, and resigns himself to a quiet life of books and fishing. He claims that somebody had to be sacrificed, it turned out to be him, and he has no right to complain, bowing to the will of the majority. When pressed he says he does not really believe this is right, but he cannot understand why it is wrong and what the alternative might be. He is trapped by a moral code that makes him a willing victim, and rather than challenge that morality, he simply gives up. Still, it is never clearly explained why he was never made part of Galt's "strike" (his private act of dropping out and living in retirement is quite in tune with it) and why he was never invited to the hidden valley where he would have fit right in. Dan Conway appears in sections 145 and 146, and is mentioned in section 148.
A contractor who finished the San Sebastian Line and who is hired to lay the new Rearden Metal track for the Rio Norte Line. Before he gets a chance to do so, he mysteriously disappears. Dick McNamara is mentioned in sections 133 and 141.
Special Assistant to the Vice-President in Charge of Operation at Taggart Transcontinental. He grew up with Dagny Taggart. His father and grandfather worked for the Taggarts, and he followed in their footsteps. He is completely loyal to Dagny and to Taggart Transcontinental. He is also secretly in love with Dagny. Willers is generally assumed to represent the common man: someone who does not possess the promethian creative ability of The Strikers, but nevertheless matches them in moral courage and is capable of appreciating and making use of their creations. He sticks out with the railway to the bitter end, even when the old world is obviously collapsing and Dagny has shifted her attention and loyalty to saving the captive Galt. In the end, he stays with a broken-down train in the middle of the desert, like a captain going down with his ship. It is unclear whether or not the strikers or anyone else will return to save him. Eddie Willers appears in sections 111, 114, 117, 132, 133, 141, 151, and 152.
The head of Wyatt Oil. He has almost single-handedly revived the economy of Colorado by discovering oil there. He is quick-tempered, more bound to violent outbursts than other characters. When first introduced, he is aggressive towards Dagny, whom he does not yet know and whom he blames for what are in fact her brother's policies which directly threaten his business. Of all the disappearances of industrialists in the novel, Wyatt's is surely the most dramatic: when the government passes laws and decrees which make it impossible for him to continue, he does not just go quietly away but sets all his oil wells on fire, leaving a jeering note: "I am leaving it as I found it. Take over. It's yours." Without his expertise, the State Science Institute is unable to bring those wells back into production. Later, when Dagny meets him in the hidden valley where his energies are not encountering futile daily obstructions, there is little of that violence to be seen. Though involved in a different profession, the character seems very similar to the sculptor Steven Mallory in The Fountainhead, Howard Roark's friend who in a similar kind of violent outburst tried to assassinate Ellsworth Toohey. Ellis Wyatt is mentioned or appears in sections 111, 114, 132, 146, 147, 148, and 152.
One of the central characters in Atlas Shrugged. Owner by inheritance of the world's largest copper mining empire, the man behind the San Sebastián Mines, and a childhood friend and first love of Dagny Taggart.
Francisco began working on the sly as a teenager in order to learn all he could about business. While still a student at Patrick Henry University, a classmate of John Galt and Ragnar Danneskjöld and student of both Hugh Akston and Robert Stadler, he began working at a copper foundry, and investing in the stock market. By the time he was twenty he had made enough to purchase the foundry. He began working for d'Anconia Copper as assistant superintendent of a mine in Montana, but was quickly promoted to head of the New York office. He took over d'Anconia Copper at age 23, after the death of his father.
When he was 26, Francisco secretly joined the Strikers and began to slowly destroy the d'Anconia empire so the Looters could not get it. He adopted the persona of a worthless playboy, by which he is known to the world, as an effective cover.
His full name is Francisco Domingo Carlos Andres Sebastián d'Anconia.
Francisco d'Anconia appears or is mentioned in sections 132, 141, 144, 151, and 152 - this last section includes a detailed history of his life.
Fred Kinnan is a labour leader and member of the looter cabal. Unlike the others, however, Kinnan is straightforward and honest about his purpose. At the meeting to decide on whether to enact Directive 10-289 (giving government sweeping powers over industry) Kinnan is the only one to openly state the true motivations of himself and his fellow conspirators.
At the end of Galt's 3 hour speech, he expresses admiration for the man, as he says what he means. Despite this, Kinnan admits that he is one of the people Galt is out to destroy.
One of the central characters in Atlas Shrugged. He is the founder of Rearden Steel and the inventor of Rearden Metal, a form of metal stronger than steel. Scientists in the real world have yet to duplicate this feat.
He lives in Philadelphia with his wife Lillian, his brother Philip, and his elderly mother Gertrude (whose name almost never appears in the book), all of whom he supports. Gwen Ives is his secretary.
The character of Hank Rearden has two important roles to play in the novel. First, he is aware that there is something wrong with the world but is unsure of what it is. Rearden is guided toward an understanding of the solution through his friendship with "Francisco d'Anconia", who does know the secret, and by this mechanism the reader is also prepared to understand the secret when it is revealed explicitly in Galt's Speech.
Second, Rearden is used to illustrate Rand's theory of sex. Lillian Rearden cannot appreciate Hank Rearden's virtues, and she is portrayed as being disgusted by sex. Dagny Taggart clearly does appreciate Rearden's virtues, and this appreciation evolves into a sexual desire. Rearden is torn by a contradiction because he accepts the premises of the traditional view of sex as a lower instinct, while responding sexually to Dagny, who represents his highest values. Rearden struggles to resolve this internal conflict and in doing so illustrates Rand's sexual theory. Rearden appears in sections 121, 132, 147, and 161, and is mentioned in sections 114 and 131.
Identified as "One of the last great advocates of reason." He was a renowned philosopher and the head of the Department of Philosophy at Patrick Henry University, where he taught "Francisco d'Anconia, John Galt, and Ragnar Danneskjöld. He was, along with Robert Stadler", a father figure to these three. Akston's name is so hallowed that a young lady, on hearing that Francisco had studied under him, is shocked. She thought he must have been one of those great names from an earlier century. He now works as a cook in a roadside diner, and proves extremely skillful at that (Like many of Rand's characters, who feel no reluctance to work at "menial" jobs and do them well). When Dagny tracks him down, and before she discovers his true identity, he rejects her enthusiastic offer to manage the dining car services for Taggart Transcontinental. Hugh Akston is mentioned in section 161.
The President of Taggart Transcontinental, a leader of the Looters, and the book's most important antagonist. Taggart is an expert influence peddler who is incapable of making decisions on his own. He relies on his sister Dagny Taggart to actually run the railroad, but nonetheless opposes her in almost every endeavor. In a sense, he is the antithesis of Dagny.
As the novel progresses, the moral philosophy of the Looters is revealed: it is a code of nihilism. The goal of this code is to not exist, to become a zero. Taggart struggles to remain unaware that this is his goal. He maintains his pretence that he wants to live, and becomes horrified whenever his mind starts to grasp the truth about himself. This contradiction leads to the recurring absurdity of his life: the desire to destroy those on whom his life depends, and the horror that he will succeed at this. In the final chapters of the novel, he suffers a complete mental breakdown upon realizing that he can no longer deceive himself in this respect.
In the introduction to the 35th anniversary edition, (1991), Leonard Peikoff introduced excerpts from Rand's journals concerning the book. Among other things, it is disclosed that as originally conceived James Taggart was religious, regularly going to a priest to confess his sins and ask for absolution. There is no hint of this in the final version as published. Presumably, however, this "asking for absoultion" was connected with the above-mentioned hiding of Taggart's real goal from himself.
This also implies that the Taggart Family was originally conceived as being of Roman Catholic background, of which also there is little trace left in the published version. It fits well with the Taggarts' long-standing friendship with the Latin American D'Anconia Family. However, "Nathaniel", the name of the Taggart Dynasty's 19th Century founder, is an Old Testament name of the kind more common among Protestants than among Catholics.
James Taggart appears in sections 111, 114, 131, 132, 143, 144, 152 and 161, and is mentioned in sections 146 and 148.
The enigmatic John Galt is the male hero of Atlas Shrugged, and typifies the Randian hero. By trade, he is an engineer, and has developed a revolutionary new motor powered by ambient static electricity that has the potential to change the world. However, in disgust at the collectivization forced upon him at his workplace at the Twentieth Century Motor Company, he goes on strike, depriving the world of his invaluable invention.
To increase the impact, he persuades each individual of talent whom he considers to share his own ethical creed, to join him on strike, in a secret and secluded hiding place called Galt's Gulch. Amongst them are Francisco d'Anconia and Ragnar Danneskjöld, with whom he had studied at Patrick Henry University. At first, Dagny Taggart considered Galt to be a destructive force, and grants him the epithet 'the Destroyer'. However, when she is convinced of the futility of her own struggle, and the nobility of Galt's, she falls in love with him.
John Galt's name is enshrined in the question "Who is John Galt?" The phrase is used popularly as an expression of helplessness and despair at the sorry state of the world. The answer is expressed in a range of legends: none of which is entirely true, but all of which reflect an aspect of his achievements and labours.
The wildly unsupportive wife of Hank Rearden. They have been married eight years as the novel begins.
Lillian is a frigid Moocher who seeks to destroy her husband. She compares being Rearden's wife with owning the world's most powerful horse. Since she cannot comfortably ride a horse that goes too fast, she must bridle it down to her level, even if that means it will never reach its full potential and its power will be greviously wasted.
Lillian also serves to illustrate Rand's Theory of sex. Lillian believes sex is a base animal instinct and that sexual indulgence is a sign of moral weakness. She is incapable of feeling this kind of desire, which she believes testifies to her moral superiority. However, according to the theory of sex, Lillian's lack of sexual capacity results from her inability to experience value in herself; she is therefore unable to respond sexually when she experiences value in others.
Lillian tolerates sex with her husband only because she is 'realistic' enough to know he is just a brute who requires satisfaction of his brute instincts. In section 161 she indicates that she abhors "Francisco d'Anconia", because she believes he is a sexual adventurer. Lillian Rearden appears in sections 121 and 161.
A group of antagonistic characters sometimes referred to as "James Taggart and his friends". They are similar to the Moochers. The Looters consist of men and women who use force to obtain value from those who produce it. They seek to destroy the producers despite the fact that they are dependent upon them. The Looters include: Mr. Thompson, Balph Eubank, Floyd Ferris, James Taggart, Orren Boyle, Paul Larkin, Robert Stadler, Simon Pritchett, Wesley Mouch, Eugene Lawson, Cuffy Meigs and the Mexican government of the time.
A wealthy banker who mysteriously disappeared in protest after he was given a court order to loan money to an incompetent applicant. When the order came down, he liquidated his entire business, made sure that all the account holders received every penny due them, and joined Galt's strike. His birth name was Michael, but he had it legally changed after a news article called him "Midas" in a derogatory fashion. Midas Mulligan is responsible for the creation and distribution of the money that is exclusively used in Atlantis, and is the original owner of the land where Atlantis is located.
A group of characters, similar to the Looters, who use guilt as a weapon against those who produce value. They seek to destroy the producers despite the fact that they are dependent upon them. The Moochers include Lillian Rearden, Philip Rearden, and Hank Rearden's mother.
A hack composer who writes trite scores for movies and modern symphonies that no one listens to. He believes melody is a primitive vulgarity. He is one of "Lillian Rearden's friends and a member of the cultural elite. Mort Liddy appears in section 161.
The president of the Amalgamated Switch and Signal Company, Inc. of Connecticut. He is a businessman who sees nothing wrong with the moral code that is destroying society and would never dream of saying he is in business for any reason other than the good of society. He is unable to grapple with abstract issues, and is frightened of anything controversial. Dagny Taggart hires Mr. Mowen to produce switches made of Rearden Metal. He is reluctant to build anything with this unproven technology, and has to be ridden and cajoled before he is willing to accept the contract. When pressured by public opinion, he discontinues production of the switches, forcing Dagny to find an alternative source. Mr. Mowen appears in section 171.
A menial worker for Taggart Transcontinental who often dines with Eddie Willers" in the employee's cafeteria. Eddie finds him very easy to talk to, and Mystery Worker not-so-subtly leads him on so that Eddie reveals important information about Dagny Taggart and Taggart Transcontinental; Ayn Rand chooses to record only Eddie's side of each conversation. Eddie tells him which suppliers and contractors Dagny is most dependent on, and with remarkable consistency, those are the next men to disappear mysteriously. Later in the novel the reader discovers the true identity of the Mystery Worker to be John Galt. Mystery Worker appears in section 133.
He works in the Taggart Terminal. Twenty years ago he owned a cigarette factory but it went under, and he's been working at his newsstand ever since. He is a collector of cigarettes, and knows every brand ever made. He occasionally chats with Dagny Taggart when she comes by. On one occasion, in section 132, after Dagny asks him about his collection, he bemoans the fact that there are no new brands and the old brands are all disappearing. He examines a cigarette given to Dagny by Hugh Akston, but it is a new brand that he has never seen before. It carries the sign of the dollar.
The head of Associated Steel and a friend of James Taggart. He is one of the Looters. He is an investor in the San Sebastian Mines. Orren Boyle appears or is mentioned in sections 111, 114, 131, 132, 144, and 152.
Assistant to the Manager of the Taggart Terminal in New York. He catches "Dagny Taggart's eye as one of the few competent men on staff. After seeing the sorry state of the Ohio Division she decides to make him its new Superintendent. However, as soon as she returns to New York, Kellogg informs her that he is quitting his job. He admits that he loves his work, but that is not enough to keep him. He will not say why he is leaving or what he will do. Later, he is noticed working as transient labor by the unsuccessful/unmotivated businessman Mr. Mowen. Owen Kellog eventually reaches, and settles in Atlantis. Owen Kellogg appears in sections 112 and 114.
An unsuccessful, middle-aged businessman, a friend of the Rearden family, and a member of the Looters. In section 121 Larkin visits Philadelphia to warn Hank Rearden of possible trouble from Washington. In section 131 he meets with the other Looters to work out a plan to bring Rearden down. James Taggart knows he is friends with Hank Rearden and challenges his loyalty, and Larkin assures Taggart that he will go along with them. Paul Larkin appears in sections 121, 132, and 2A1.
The younger brother of Hank Rearden, and a Moocher". He lives in his brother's home in Philadelphia and is completely dependent on him. He believes that the source of his sustenance is evil and would love to see him destroyed. He has never had a career and spends his time perfunctorily working for various social groups.
He becomes resentful of his brother's charity. He then requests that he be granted a job from his brother because he should not have to be burdened by the feeling of inadequacy of not earning his own livelihood. When confronted by his brother on how this job should be a mutually beneficial arrangement, Philip shrugs the argument off as irrelevant and that the job should be entitled to him solely based on his need for money and the fact of familial ties. Philip Rearden appears in sections 121 and 161.
One of the original Strikers. He is now world famous as a pirate. Ragnar was from Norway, the son of a bishop and the scion of one of Norway's most ancient, noble families. He attended Patrick Henry University and became friends with John Galt and "Francisco d'Anconia, while studying under Hugh Akston and Robert Stadler". When he became a pirate, he was disowned and excommunicated. There is a price on his head in Norway, Portugal, Turkey.
Ragnar seizes relief ships that are being sent from the United States to Europe. As the novel progresses, Ragnar begins, for the first time, to become active in American waters, and is even spotted in Delaware Bay. Reportedly, his ship is better than any available in the fleets of the world's navies.
People assume that as a pirate he simply takes the seized goods to himself. However, while many other protagonists take pride in making a personal profit from the proceeds of their creativity, Danneskjöld's motivation is to restore to other creative people the money which was in his view unjustly taken away from them - specifically, their income tax payments.
industrialists, to the amounts of the income tax taken from them - which are handed to them (in gold) upon their joining the Strikers.
Kept in the background for much of the book, Danneskjöld makes a personal appearance when he risks his life to meet Hank Rearden in the night and hand him a bar of gold as an "advance payment", to encourage Rearden to persevere in his increasingly difficult situation.
As a robber with ideological principles, Danneskjöld superficially resembles Robin Hood; however, he considers Robin Hood as an arch-enemy which he had sworn to pursue and destroy - or rather, not Robin Hood the person, who is long dead, but the principle that it is permissible to rob the rich and give to the poor, a principle which in Danneskjöld's (and Rand's) view is highly pernicious.
In the conversation with Rearden, Danneskjöld claims to limit himself to attacks on government property and never touch private property. This constradicts previous chapters where there is mention of Danneskjöld sinking ships belonging of "D'anconia Copper and destroying Orren Boyle's plant on the coast of Maine, where Boyle attempted to produce Rearden Metal". However, the first does not truly constitute robbery, since it was done with the consent of and in collusion with the owner, Danneskjöld's old friend "Francisco D'anconia", and was aimed at helping Francisco's efforts to destroy his own company. And the second was in reaction to Boyle having violated, with government sanction, Rearden's intellectual property (the term did not yet exist at the time of writing).
Danneskjöld is married to the former actress Kay Ludlow - a relationship kept hidden from the outside world, which only knows of Ludlow as a former famous film star who retired and dropped out of sight. It is mentioned that some of the Strikers have strong reservations about his way of "conducting the common struggle".
Members of Danneskjöld's crew, other than himself, are never named nor appear in the book. Evidently, they are not given access of the hidden valley where their captain sometimes goes, nor - on the basis of need to know - are they given its location, which they might give away if captured.
Such a prolonged and successful piratical career would require a secret haven, probably on the Atlantic Coast of the US. In the end of the book, Danneskjöld's crew are mentioned as preparing to form a new community, while his ship would be converted into "a modest ocean liner". Danneskjöld himself refreshes his knowledge of Aristotle and prepares to become a full-time philosopher, and it is hinted that posterity might remember him mainly as Hugh Akston's disciple rather than as a pirate.
According to Ayn Rand (verbal report), his name is a tribute to Victor Hugo. In Hugo's first novel, Hans of Iceland, the hero becomes the first of the Counts of Danneskjöld. His name may be a pun on 'Dane's Gold', although "skjold" means shield, not gold. The first name "Ragnar" recalls Ragnar Lodbrok, one of the most famous of the viking leaders (to whose many piratical exploits no motive other than seeking loot was ever attributed). Ragnar Danneskjöld appears in section 161.
However, there are some inaccuracies. 'Ö' is not a Norwegian letter, but a Swedish one; its Norwegian equivalent is 'ø'. "Skjöld" and "skjøld" still exists in Scandinavian surnames and is an old fashioned spelling of the word for "shield", that is now "skjold" (Norwegian) and "sköld" (Swedish). Also, there is actually no noble class in Norway, as the Black Death of the Middle Ages forced any survivors to revert to subsistence farming.
Named Gertrude, she is a Moocher who lives with her son Hank Rearden at his home in Philadelphia. She is involved in church-based charity work, and berates Rearden whenever she can. She insults him by saying he was always selfish, even as a child. She dotes on her weak son Philip Rearden. Rearden's mother appears in section 121.
Dagny Taggart's favorite composer, who mysteriously disappeared after the evening of his greatest triumph. In section 141 we learn that Richard Halley spent years as a struggling and unappreciated composer. At age 24 his opera Phaethon was performed for the first time, to an audience who booed and heckled it. (It was based on the Greek myth in which Phaethon steals his father's chariot, and dies in an audacious attempt to drive the sun across the sky. Halley changed the story, though, into one of triumph, in which Phaethon succeeds.) For years Halley wrote in obscurity. After nineteen years, Phaethon was performed again, but this time it was received to the greatest ovation the opera house had ever heard. It appears his critics felt he had paid his dues long enough that he was at last worthy of their approval. The following day, Halley retired, sold the rights to his music, and disappeared. Richard Halley is mentioned in sections 112, 114, 133, and 141, and appears in section 152.
A former professor at Patrick Henry University, mentor to Francisco d'Anconia, John Galt and Ragnar Danneskjöld. He has since become a sell-out, one who had great promise but squandered it for social approval, to the detriment of the free. He works at the State Science Institute where all his inventions are perverted for use by the military, including the instrument of his demise: Project X. The character might be modeled on Robert Oppenheimer and his part in the creation of nuclear weapons.
The prestigious head of the Department of Philosophy at Patrick Henry University and is considered the leading philosopher of the age. He is also a Looter. He is certainly representative of the philosophy of the age - he is a crude reductionist who believes man is nothing but a collection of chemicals; he believes there are no standards, that definitions are fluid, reason is a superstition, that it is futile to seek meaning in life, and that the duty of a philosopher is to show that nothing can be understood. He explains all this in his book The Metaphysical Contradictions of the Universe, and at cocktail parties. Dr. Pritchett appears in section 161.
People of the mind who go on strike because they do not appreciate being exploited by the Looters and demonized by a society who depends on them for its very existence. The leader of the Strikers is John Galt. Other Strikers include: Hugh Akston, Francisco d'Anconia, Ragnar Danneskjöld, Richard Halley, and the Brakeman. Characters who join the Strikers in the course of the book include: Dagny Taggart, Ellis Wyatt, Hank Rearden, Dick McNamara, and Owen Kellogg.
The "Head of the State," which essentially means that he's the President of the United States, though he's never specifically referred to as such. In the world of Atlas Shrugged all Presidents and Prime Ministers are referred to simply as "Head of the State" and "Mr. ____." This is because countries have been standardized as "People's States" which seem to share a common form of government. Thompson's title can thus be seen as reflecting the fact that the US is in the process of evolving into one of these "People's States." One of the Looters, he's not particularly intelligent and has a very undistinguished look. He knows politics, however, and is a master of public relations and back-room deals. Rand's notes indicate that she modelled him on President Harry S. Truman.
A member of the Looters and, at the beginning of the storyline, the incompetent lobbyist whom Hank Rearden reluctantly employs in Washington. Initially Wesley Mouch is the least powerful and least significant of the Looters - the other members of this group feel they can look down upon him with impunity. Eventually he becomes the most powerful Looter, and the country's economic dictator, thereby illustrating Rand's belief that a government-run economy places too much power in the hands of incompetent bureaucrats who would never have positions of similar influence in a private sector business. His name, of course, is a pun on the word "mooch," his modus operandi. Wesley Mouch appears in section 131 and is mentioned in section 161.
A young bureaucrat sent by the government to watch over Rearden’s mills. Though he starts out as a cynical follower of the looters’ code, his experience at the mills transforms him, and he comes to respect and admire the producers. He is shot attempting to inform Hank Rearden about a government plot, but does succeed in warning Rearden just before he dies.
In the introduction to the 35th anniversary edition, (1991), Leonard Peikoff introduced excerpts from Rand's journals concerning the book, which she originally intended to call "The Strike". Among many other things, the journals reveal some characters which were originally planned to appear in the book and were deleted from the final version.
Interestingly, Rand successfully did something similar in her very first book, "We the Living". There, one of the main characters is a Communist, Andrei Taganov, who definitely can be described, in a paraphrase of the above, as "a positive character honestly devoted to the good but practicing consistently the ideology of Marxism". In other words, a very idealistic and dedicated Communist, who is totally devoted to the Party and is willing to lay down his life for Communism, yet is a sympathetic (and convincing) major character in a book which is as anti-Communist as can be. (Andrei is, moreover, the lover of the book's heroine Kira, which Rand explicitly described as representing herself in character though not in specific biographical details).
Peikoff also mentions that as originally conceived the book was going to have a character named Stacy Rearden, a sister of Hank Rearden. Not arhum much is told of what her role was supposed to be and why she was eventually dropped. Apparently, she was going to be another parasite like Rearden's brother, mother and wife; presumably, Rand came to the conclusion that three such characters around Rearden sufficiently fulfilled her literary and philosophical purposes.


Atlas Shrugged is a novel by Ayn Rand, first published in 1957 in the United States. It was Rand's last work of fiction before concentrating her writings exclusively on philosophy, politics and cultural criticism. At over one thousand pages in length, she considered it her magnum opus. Also, at approximately 645,000 words, Atlas Shrugged is one of the longest novels ever written in any European language. The book explores a number of philosophical themes that Rand would subsequently develop into the philosophy of Objectivism. According to a 1991 United States survey by the Library of Congress and the Book of the Month Club, Atlas Shrugged was the book that made most difference in readers lives after the Bible.
The theme of Atlas Shrugged is the role of the mind in man's existence and, consequently, presentation of the morality of rational self-interest.
The main conflicts of the book surrounds the decision of the "individuals of the mind" to go on strike, refusing to contribute their inventions, art, business leadership, scientific research, or new ideas of any kind to the rest of the world. Society, they believe, hampers them by interfering with their work and underpays them by confiscating the profits and dignity they have rightfully earned. The peaceful cohesiveness of the world disintegrates, lacking those individuals whose productive work comes from mental effort. The strikers believe that they are crucial to a society that exploits them, denying them freedom or acknowledging their right to self-interest, and the gradual collapse of civilization triggered by their strike.
The novel's title is an allusion to the Greek Titan Atlas who was described as literally holding the world on his shoulders, discussing what might happen if those holding up civilization suddenly decided to stop doing so. In the novel, the mythological analogy comes during a conversation between two protagonists, Francisco d'Anconia and Hank Rearden, near the end of part two, chapter three, where Francisco (convincing Rearden that he is under-appreciated) tells Rearden that if he could suggest to Atlas that he do one thing, it would be to shrug.
In the world of Atlas Shrugged, society stagnates when independent productive achievers began to be socially demonized and even punished for their accomplishments, even though society had been far more healthy and prosperous by allowing, encouraging and rewarding self-reliance and individual achievement. Independence and personal happiness flourished to the extent that people were free, and achievement was rewarded to the extent that individual ownership of private property was strictly respected. The hero, John Galt, lives a life of laissez-faire capitalism as the only way to live consistent with his beliefs.
In addition to the plot's more obvious statements about the significance of industrialists and mental work to society, this explicit conflict is used by Rand to draw wider philosophical conclusions, both implicit in the plot and via the character's own statements. Positions are expressed on a variety of topics, including sex, politics, friendship, charity, childhood, and many others. Part of this is the theme that its broad array of ideas are in fact interrelated by their basic philosophy, and the significance of ideas to society and to one's life.
Atlas Shrugged portrays fascism, socialism and communism – any form of state intervention in society – as systemically and fatally flawed. However, Rand claimed that it is not a fundamentally political book, but that the politics portrayed in the novel are a result of her attempt to display her image of the ideal person and the individual mind's position and value in society.
Rand argues that independence and individual achievement enable society to survive and thrive, and should be embraced. But this requires a "rational" moral code. She argues that, over time, coerced self-sacrifice causes any society to self-destruct.
She is similarly dismissive of faith beyond empirical reason, in a god or higher being, or anything else as an authority over one's own mind. The book positions itself against religion specifically, often directly within the characters' dialogue.
Galt's Gulch was inspired by Ouray, Colorado. It was here that Rand found inspiration to complete the novel, though she greatly expanded the small valley to include her many ideas for the story.
Exactly when Atlas Shrugged is meant to take place is kept deliberately vague. In section 152, the population of New York City is given as 7 million. The historical New York City reached 7 million people in the 1930s, which might place the novel sometime after that. There are many early 20th century technologies available, but the political situation is clearly different from actual history. One interpretation is that the novel takes place many years in the future, implying that since the world lapsed into its socialistic morass, a global stagnation has occurred in technological growth, population growth, and indeed growth of any kind; the wars, economic depressions, and other events of the 20th century would be a distant memory to all but scholars and academicians. This would be in line with Rand's ideas and commentary on other novels depicting utopian and dystopian societies. Furthermore, this is also in line with an excerpt from a 1964 interview with Playboy magazine in which Rand states "What we have today is not a capitalist society, but a mixed economy – that is, a mixture of freedom and controls, which, by the presently dominant trend, is moving toward dictatorship. The action in Atlas Shrugged takes place at a time when society has reached the stage of dictatorship. When and if this happens, that will be the time to go on strike, but not until then," thus implying that her novel takes place at some point in the future. The concept of societal stagnation in the wake of collectivist systems is central to the plot of another of Rand's works, Anthem.
In Atlas Shrugged, all countries outside the US have become, or become during the novel, "People's States". There are many examples of early 20th century technology in Atlas Shrugged, but no post-war advances such as nuclear weapons, helicopters, or computers. Jet planes are mentioned briefly as being a relatively new technology. Television is a novelty that has yet to assume any cultural significance, while radio broadcasts are prominent (in fact, television only makes its first appearance later on in the book, reflecting the fact that television appeared in the fifties, i.e. during the ten years it took to write the book). Although Rand does not use many of the technological innovations available while she was writing in the book, she introduces some advanced, fictional inventions (e.g. sonic-based weapons of mass destruction, torture devices, as well as power plants and a highly advanced strong steel alloy).
Most of the action in Atlas Shrugged occurs in the United States. However, there are important events around the world, such as in the People's States of Mexico, Chile, and Argentina, and piracy at sea.
The leaders and innovators of industry in the world seem to be disappearing, and the apparent decline of civilization is making it more and more difficult for her to sustain her life-long aspirations of running the trans-continental railroad, which has been in her family for several generations. She deals with other characters who often personify archetypes of what Rand considers the various schools of philosophy for living and working in the world (though they are in most cases often unconscious of it).
Hank Rearden, a self-made businessman of great integrity whose career is hindered by his feelings of obligation toward his wife.
Francisco d'Anconia, Dagny's childhood friend, first love, and king of the copper industry, appears to have become a worthless playboy who is purposely destroying his business.
James Taggart (Dagny's brother), president of the railroad, who seems peripherally aware of the troubles facing the company and the country in general, but who almost always makes the most short term and ultimately self-destructive choice.
As the novel progresses, the myths about the real John Galt, as well as Francisco d'Anconia's actions, increasingly become a reflection of the state of the culture and seem to make more and more sense. Hank and Dagny begin to experience the futility of their attempts to survive in a society that hates them and those like them for their greatness.
Dagny and Hank find the remnants of a motor that turns atmospheric static electricity into kinetic energy, an astounding feat; they also find evidence that the minds (the "Atlases") of the world are disappearing because of one particular "destroyer" taking them away. Dagny and Hank deal with the irrationalities and apparent contradictions of their atmosphere, and search for the creator of the motor as well as "the destroyer" who is draining the world of its prime movers, in an effort to secure their ability to live rational lives.
The question "Who is John Galt?" is also answered towards the closing of the novel — John Galt is a man disgusted that non-productive members of society use laws and guilt to leech from the value created by productive members of society, and furthermore even exalt the qualities of the leeches over the workers and inventors. He made a pledge that he would never live his life for the sake of another man, nor ask another man to live for him, and founded an enclave, separate from the rest of the country, where he and other productive members of society have fled.
John Galt's speech is the core of Atlas Shrugged. In it, Galt explains the philosophy of Objectivism. The speech encompasses metaphysical, epistemological, ethical, and political ideas.
The speech is very long, spanning 56 pages in one paperback edition (the only interruption occurs after the first paragraph), and appears in the chapter "This is John Galt Speaking" in the third section of the book. Later in the book, the speech is referred to as being approximately three hours long.
Rand's heroes must continually fight against the "looters" and "moochers" of the society surrounding them.
The looters are those who confiscate others' earnings "at the point of a gun" (figuratively speaking) —often because they are government officials, and thus their demands are backed by the threat of force. Some looters are following the policies of the government, such as the officials who confiscate one state's seed grain to feed the starving citizens of another state; others are exploiting those policies, such as the railroad regulator who illegally sells the railroad's supplies on the side. The common factor is that both use force to take property from the people who produced or earned it, and both are ultimately destructive.
The moochers are those who demand others' earnings because they claim to be needy and unable to earn themselves. Even as they beg for their help, however, they curse the people who make that help possible, because they hate the talented for having the talent they don't possess. Although the moochers seem benign at first glance, they are portrayed as more destructive than the looters—they destroy the productive through guilt and often motivate the legal looting performed by governments.
Looting and mooching are seen at all levels of the world Atlas Shrugged portrays, from the looting officials Dagny Taggart must work around and the mooching brother Hank Rearden struggles with, to the looting of whole industries by companies like Associated Steel and the mooching demands for foreign aid by the starving countries of Europe.
The entire story of Atlas Shrugged can be seen as an answer to the question, what would happen if this sanction were revoked? When Atlas shrugs, relieving himself of the burden of carrying the world, he is revoking his sanction.
The concept may be original in the thinking of Ayn Rand and is foundational to her moral theory. She holds that evil is a parasite on the good and can only exist if the good tolerates it. To quote from Galt's Speech: "Evil is impotent and has no power but that which we let it extort from us," and, "I saw that evil was impotent..and the only weapon of its triumph was the willingness of the good to serve it." Morality requires that we do not sanction our own victimhood, Rand claims. In adhering to this concept, Rand assigns virtue to the trait of rational selfishness. However, Rand contends that moral selfishness does not mean a license to do whatever one pleases, guided by whims. It means the exacting discipline of defining and pursuing one's rational self-interest. A code of rational self-interest rejects every form of human sacrifice, whether of oneself to others or of others to oneself.
Throughout Atlas Shrugged, numerous characters admit that there is something wrong with the world but they cannot put their finger on what it is. The concept they cannot grasp is the sanction of the victim. The first person to grasp the concept is John Galt, who vows to stop the motor of the world by getting the creators of the world to withhold their sanction.
We first glimpse the concept in section 121 when Hank Rearden feels he is duty-bound to support his family, despite their hostility towards him.
Atlas Shrugged endorses the belief that a society's best hope rests on its adopting a system of pure laissez-faire. John Galt says,"The political system we will build is contained in a single moral premise: no man may obtain any values from others by resorting to physical force," and claims, "no rights can exist without the right to translate one’s rights into reality—to think, to work and to keep the results—which means: the right of property." The characters are assessed negatively or positively based their productive effort, respect for rights, intellectual honesty, and moral integrity, and this does not necessarily reflect their class backgrounds. Different social classes are represented among both the heroes and the villains of Atlas Shrugged. Among the heroes, John Galt and Hank Rearden are from working class backgrounds, while Dagny Taggart and Francisco d'Anconia are from wealthy families. Among the villains, Fred Kinnan is from a working class background, while James Taggart and Betty Pope are from wealthy families.
In rejecting the traditional altruistic moral code, Rand also rejects the sexual code that, in her view, is the logical implication of altruism.
Rand introduces a theory of sex in Atlas Shrugged that is based in her broader ethical and psychological theories. Far from being a debasing animal instinct, sex to Rand is the highest celebration of human values, a physical response to intellectual and spiritual values that gives concrete expression to what could otherwise only be experienced in the abstract. This theory of sex is almost identical to that espoused in the platonic dialogue Symposium.
In Atlas Shrugged, characters are sexually attracted to those who embody or seem to embody their values, be they higher or lower values by Rand's standards. Characters who lack clear purpose find sex devoid of meaning. This is illustrated in the contrasting relationships of Hank Rearden with Lillian Rearden and Dagny Taggart, by the relationships of James Taggart with Cherryl Brooks and later with Lillian Rearden, and finally in the relationship between Dagny and John Galt.
The companies in Atlas Shrugged are generally divided into two groups: those that are operated by hard working characters who join in John Galt's Movement and those owned by looters and moochers. The first group are usually given the name of the owner, while companies operated by antagonist characters are given names like Associated Steel.
For example, Hank Rearden's companies are all named after him; Wyatt Oil after Ellis Wyatt; and Taggart Transcontinental and d'Anconia Copper are named after their founders (and, being family-held, their present owners). Nielsen Motors, Hammond Cars and Ayers Music Publishing are also presented as competent. Those who use their own names to name their companies become Strikers, with the minor exception of Mr. Ayers of the Ayers Music Publishing Company.
On the other hand, Orren Boyle named his government-dependent, influence-peddling company Associated Steel. Another company in the novel is the Amalgamated Switch and Signal Company, Inc. The exceptions here are the Phoenix Durango Railroad, which was run by a competent entrepreneur who becomes a Striker in his own way without joining the actual Strikers in Galt's Gulch, and the Twentieth Century Motor Company, originally run by Jed Starnes. The mismanagement of the Twentieth Century in the hands of Starnes' heirs first seeds the thoughts of a strike in John Galt's mind.
James Jerome Hill (1838– 1916) was known as the Empire Builder and built the Great Northern Railway that is in many ways similar to Taggart Transcontinental.
It is commonly noted that in actuality there had never been a US railway company as the one described in the book, maintaining tracks of its own all the way from the Atlantic to the Pacific. Rather, in the United States, the term transcontinental railroad usually refers to a line over the Rocky Mountains between the Midwest and Pacific Ocean, and such companies tend to have the area of the Mississippi River as a transfer point with other companies active in the East.
Taggart Transcontinental in the later part of the book is driven to act in this manner and rely on other companies for the western part of its traffic; that is, however, an emergency measure which is part of the gradual collapse of the company (and the entire world) and Dagny is far from pleased with the need to resort to it.
By 1957, the date of the book's publication, railways in the USA were facing a decline that had begun in the 1920s. Passengers were increasingly switching to road transport. Air transport was also growing quickly. (For details, see Amtrak; Passenger rail service before Amtrak.) Railroads are still the most efficient type of transportation through land.
Because the book centers on industrial capitalism, Ayn Rand mentions many technologies throughout the book. In addition to normal technologies, she introduces several fictional inventions, including refractor rays (Gulch mirage), Rearden Metal, a sonic death ray ("Project X"), motors powered by static electricity, and a sophisticated electrical torture device.
Rearden metal is a fictitious metal alloy invented by Hank Rearden. It is lighter than traditional steel but stronger, and is to steel what steel was to iron. It is described as greenish-blue. Among its ingredients are iron and copper, two metals seldom found together in real-world alloys.
Project X, a.k.a. Project Xylophone, is an invention of the scientists at the State Science Institute, requiring tons of Rearden metal. It is a sonic weapon, capable of destroying everything in a 300-mile radius. The scientists claim that the project will be used to preserve peace and squash rebellion. The mechanism is destroyed towards the end of the book, and emits a sonic pulse that destroys everything within a hundred mile radius, including Cuffy Meigs and Dr. Stadler, as well as half of the Taggart Bridge, which spanned the Mississippi River, and was, effectively, the lifeline of New York City.
John Galt invented a new type of electrical apparatus described in the book as a motor. This motor is revolutionary because it uses static electricity from the atmosphere as its main source of energy, requiring only a small amount of conventional fuel to run the conversion mechanism. The motor is described as super-efficient, and capable of revolutionizing the industry of the world. This approximates a perpetual motion machine of the second kind, a machine which spontaneously converts thermal energy into mechanical work (versus conventional heat engines, which convert thermal energy into mechanical work by transferring thermal energy from one reservoir to another). The theory is that the power is drawn from the environment (possibly approximating the Casimir effect, though that was extremely obscure and scientifically controversial at the time Atlas Shrugged was written).
The book gives the source as static electricity from the air, and suggests that a new physics was necessary to tap it. Additionally, the motor could be seen as a metaphor for a person who, like Rearden and Dagny, has the ability to convert dispersed energy and resources into useful materials.
Dagny discovers a discarded prototype of the motor, and it is superficially described in section Part 1, Chapter 9. In Part 3, Chapter 1, Dagny learns that Galt is using a working version of the motor to generate electricity for Galt's Gulch.
A torture device invented by Dr. Floyd Ferris is introduced towards the end where John Galt is tortured. It consists of having the victim tied to a mattress with electrodes attached to the wrists, the ankles and the hips. Electricity is passed in various combinations (wrist-to-wrist, ankle-to-hip) to inflict pain on the victim. The electricity amount being passed through the victim is calculated to cause maximum pain without inflicting any permanent physical damage to the victim (in some ways akin to a large, immobile taser). It is located in the Science Institute.
Rand also mentioned technologies that were unavailable at the time, but which have since been invented. Examples are voice activated door locks (Gulch power station), palm-activated door locks (Galt's NY lab), and shale-oil drilling.
Atlas Shrugged was generally disliked by critics, despite being a popular success. According to a 1991 United States survey by the Library of Congress and the Book of the Month Club, Atlas Shrugged was the book that made most difference in readers lives after the Bible.
It was reviewed shortly after its publication in 1957 by many major newspapers and magazines. The initial reviews were largely negative, criticizing both the book's literary qualities and its political vision.
In the conservative magazine the National Review, Whittaker Chambers wrote a critical review of the Atlas Shrugged, in which he argues against, among other things, the novel's implicit endorsement of atheism whereby "Randian man, like Marxian man is made the center of a godless world." The Intellectual Activist's Robert Tracinski published a reply, arguing that Chamber did not actually read the novel, as he misspells the names of major characters, and never uses quotations from the novel itself.
Former Ayn Rand associate Nathaniel Branden argues that Atlas Shrugged "encourages emotional repression and self-disowning" and that it, along with Rand's other major Objectivist novel, The Fountainhead, contains contradictory messages. Though he notes that the book shows that Rand understood the human need for social interaction, Branden claims that "rarely you find the heroes and heroine talking to each other on a simple, human level without launching into philosophical sermons," which he believes is used to increase the reader's self-alienation. He further questions the psychological impact of the novel, stating that John Galt's claim that contempt and moral condemnation are appropriate responses to wrongdoing clashes with the recommendations of psychologists, who say that this kind of behavior only causes the wrongdoing to repeat itself.
The libertarian Cato Institute held a joint conference with The Atlas Society, an Objectivist organization, to celebrate the fortieth anniversary of the publication of Atlas Shrugged.
Conservative Associate Justice of the Supreme Court Clarence Thomas cites Atlas Shrugged as among his favorite novels, as does neolibertarian Larry Elder.
In an article titled "Celebrity Rand Fans" in the Objectivist magazine The New Individualist, Robert James Bidinotto traces the novel's growing influence among major Hollywood stars, sports champions, and public figures.
Literary critic Harold Bloom included her in a critical anthology he edited, American Women Fiction Writers, 1900-1960, Vol. Three, (Chelsea House, 1998). The C-SPAN television series American Writers listed Rand as one of twenty-two surveyed figures of American literature, though primarily mentioning The Fountainhead rather than Atlas Shrugged.
Film rights to the novel Atlas Shrugged were purchased by the Baldwin Entertainment Group in 2003. Lions Gate Entertainment has picked up worldwide distribution rights and screenwriter Randall Wallace has created a 127-page screenplay from the novel. Angelina Jolie has been confirmed to play the role of Dagny Taggart and Brad Pitt is rumored to be cast as John Galt. Both are fans of Rand's works.
According to IMDb, as of September 5 2007, the Atlas Shrugged project is "Back in development." Lionsgate has hired director Vadim Perelman to direct the film.

Anthropology (from Greek: ἄνθρωπος, anthropos, "human being"; and λόγος, logos, "speech" lit. to talk about human beings) is the study of humanity. Anthropology has origins in the natural sciences, the humanities, and the social sciences. The term was first used by François Péron when discussing his encounters with Tasmanian Aborigines. Ethnography is both one of its primary methods and the text that is written as a result of the practice of anthropology and its elements.
Since the work of Franz Boas and Bronisław Malinowski in the late 19th and early 20th centuries, social anthropology has been distinguished from other social science disciplines by its emphasis on in-depth examination of context, cross-cultural comparisons (socio-cultural anthropology is by nature a comparative discipline), and the importance it places on long-term, experiential immersion in the area of research, often known as participant-observation. Cultural anthropology in particular has emphasized cultural relativity and the use of findings to frame cultural critiques. This has been particularly prominent in the United States, from Boas's arguments against 19th-century racial ideology, through Margaret Mead's advocacy for gender equality and sexual liberation, to current criticisms of post-colonial oppression and promotion of multiculturalism.
The anthropologist Eric Wolf once described anthropology as "the most scientific of the humanities, and the most humanistic of the sciences." Contemporary anthropologists claim a number of earlier thinkers as their forebears, and the discipline has several sources; Claude Lévi-Strauss, for example, claimed Montaigne and Rousseau as important influences.
Several ancient and medieval writers and scholars may be considered forerunners of anthropology, insofar as they conducted or wrote detailed studies of the customs of different peoples, including the Greek writer Herodotus, often called the "father of history" and the Roman historian Tacitus, who wrote many of our only surviving contemporary accounts of several ancient Celtic and Germanic peoples. A candidate for one of the first scholars to carry out comparative ethnographic-type studies in person was the medieval Persian scholar Abū Rayhān al-Bīrūnī in the 11th century, who wrote about the peoples, customs, and religions of the Indian subcontinent, and wrote detailed comparative studies on the religions and cultures in the Middle East, Mediterranean and South Asia. None of these scholars' activities, however, led to the establishment of a sustained tradition of comparative study of customs, beliefs, and the ways that human behavior and experience are shaped by participation in a particular group of people with a shared history.
Most scholars consider modern anthropology as an outgrowth of the Age of Enlightenment, a period when Europeans attempted systematically to study human behavior, the known varieties of which had been increasing since the 15th century as a result of the first European colonization wave. The traditions of jurisprudence, history, philology, and sociology then evolved into something more closely resembling the modern views of these disciplines and informed the development of the social sciences, of which anthropology was a part. Developments in systematic study of ancient civilizations through the disciplines of Classics and Egyptology informed both archaeology and eventually social anthropology, as did the study of East and South Asian languages and cultures. At the same time, the Romantic reaction to the Enlightenment produced thinkers, such as Johann Gottfried Herder and later Wilhelm Dilthey, whose work formed the basis for the "culture concept," which is central to the discipline.
Institutionally, anthropology emerged from the development of natural history (expounded by authors such as Buffon) that occurred during the European colonization of the 17th, 18th, 19th and 20th centuries. Programs of ethnographic study originated in this era as the study of the "human primitives" overseen by colonial administrations. There was a tendency in late 18th century Enlightenment thought to understand human society as natural phenomena that behaved in accordance with certain principles and that could be observed empirically. In some ways, studying the language, culture, physiology, and artifacts of European colonies was not unlike studying the flora and fauna of those places.
Early anthropology was divided between proponents of unilinealism, who argued that all societies passed through a single evolutionary process, from the most primitive to the most advanced, and various forms of non-lineal theorists, who tended to subscribe to ideas such as diffusionism. Most 19th-century social theorists, including anthropologists, viewed non-European societies as windows onto the pre-industrial human past. As academic disciplines began to differentiate over the course of the 19th century, anthropology grew increasingly distinct from the biological approach of natural history, on the one hand, and from purely historical or literary fields such as Classics, on the other. A common criticism has been that many social science scholars (such as economists, sociologists, and psychologists) in Western countries focus disproportionately on Western subjects, while anthropology focuses disproportionately on the "Other"; this has changed over the last part of the 20th century as anthropologists increasingly also study Western subjects, particularly variation across class, region, or ethnicity within Western societies, and other social scientists increasingly take a global view of their fields.
In the twentieth century, academic disciplines have often been institutionally divided into three broad domains. The natural and biological sciences seek to derive general laws through reproducible and verifiable experiments. The humanities generally study local traditions, through their history, literature, music, and arts, with an emphasis on understanding particular individuals, events, or eras. The social sciences have generally attempted to develop scientific methods to understand social phenomena in a generalizable way, though usually with methods distinct from those of the natural sciences. In particular, social sciences often develop statistical descriptions rather than the general laws derived in physics or chemistry, or they may explain individual cases through more general principles, as in many fields of psychology. Anthropology (like some fields of history) does not easily fit into one of these categories, and different branches of anthropology draw on one or more of these domains.
Anthropology as it emerged among the colonial powers (mentioned above) has generally taken a different path than that in the countries of southern and central Europe (Italy, Greece, and the successors to the Austro-Hungarian and Ottoman empires). In the former, the encounter with multiple, distinct cultures, often very different in organization and language from those of Europe, has led to a continuing emphasis on cross-cultural comparison and a receptiveness to certain kinds of cultural relativism. In the successor states of continental Europe, on the other hand, anthropologists often joined with folklorists and linguists in the nationalist/nation-building enterprise. Ethnologists in these countries tended to focus on differentiating among local ethnolinguistic groups, documenting local folk culture, and representing the prehistory of the nation through museums and other forms of public education. In this scheme, Russia occupied a middle position. On the one hand, it had a large Asian region of highly distinct, pre-industrial, often non-literate peoples, similar to the situation in the Americas; on the other hand, Russia also participated to some degree in the nationalist discourses of Central and Eastern Europe. After the Revolution of 1917, anthropology in the USSR and later the Soviet Bloc countries were highly shaped by the need to conform to Marxist theories of social evolution.
E. B. Tylor ( 2 October 1832 – 2 January 1917) and James George Frazer ( 1 January 1854 – 7 May 1941) are generally considered the antecedents to modern sociocultural anthropology in Britain. Though Tylor undertook a field trip to Mexico, both he and Frazer derived most of the material for their comparative studies through extensive readings of Classical materials (literature and history of Greece and Rome), the work of the early European folklorists, and reports from missionaries, travelers, and contemporaneous ethnologists. Tylor advocated strongly for unilinealism and a form of "uniformity of mankind". Tylor in particular laid the groundwork for theories of cultural diffusionism, stating that there are three ways that different groups can have similar cultural forms or technologies: "independent invention, inheritance from ancestors in a distant region, transmission from one race [sic] to another." Tylor formulated one of the early and influential anthropological conceptions of culture as "that complex whole which includes knowledge, belief, art, morals, law, custom, and any other capabilities and habits acquired by man as a member of society." However, as Stocking notes, Tylor mainly concerned himself with describing and mapping the distribution of particular elements of culture, rather than with the larger function, and generally seemed to assume a Victorian idea of progress rather than the idea of non-directional, multilineal cultural development proposed by later anthropologists. Tylor also theorized about the origins of religious feelings in human beings, proposing a theory of animism as the earliest stage, and noting that "religion" has many components, of which he believed the most important to be belief in supernatural beings (as opposed to moral systems, cosmology, etc.). James George Frazer, a Scottish scholar with a broad knowledge of Classics, also concerned himself with religion, myth, and magic. His comparative studies, most influentially in the numerous editions of The Golden Bough, analyzed similarities in religious belief and symbolism worldwide.
Neither Tylor nor Frazer, however, were particularly interested in fieldwork, nor were they interested in examining how the cultural elements and institutions fit together. Towards the turn of the century, a number of anthropologists became dissatisfied with this categorization of cultural elements; historical reconstructions also came to seem increasingly speculative. Under the influence of several younger scholars, a new approach came to predominate among British anthropologists, concerned with analyzing how societies held together in the present (synchronic analysis, rather than diachronic or historical analysis), and emphasizing long-term (one to several years) immersion fieldwork. Cambridge University financed a multidisciplinary expedition to the Torres Strait Islands in 1898, organized by Alfred Court Haddon and including a physician-anthropologist, W. H. R. Rivers, as well as a linguist, a botanist, other specialists. The findings of the expedition set new standards for ethnographic description.
A decade and a half later, Polish-born anthropology student Bronisław Malinowski (1884-1942) was beginning what he expected to be a brief period of fieldwork in the old model, collecting lists of cultural items, when the outbreak of the First World War stranded him in New Guinea. As a subject of the Austro-Hungarian Empire resident on a British colonial possession, he was effectively confined to New Guinea for several years. He made use of the time by undertaking far more intensive fieldwork than had been done by British anthropologists, and his classic ethnography, Argonauts of the Western Pacific, (1922) advocated an approach to fieldwork that became standard in the field: getting "the native's point of view" through participant observation. Theoretically, he advocated a functionalist interpretation, which examined how social institutions functioned to meet individual needs.
Malinowski and Radcliffe-Brown's influence stemmed from the fact that they, like Boas, actively trained students and aggressively built up institutions that furthered their programmatic ambitions. This was particularly the case with Radcliffe-Brown, who spread his agenda for "Social Anthropology" by teaching at universities across the British Commonwealth. From the late 1930s until the postwar period appeared a string of monographs and edited volumes that cemented the paradigm of British Social Anthropology (BSA). Famous ethnographies include The Nuer, by Edward Evan Evans-Pritchard, and The Dynamics of Clanship Among the Tallensi, by Meyer Fortes; well-known edited volumes include African Systems of Kinship and Marriage and African Political Systems.
Max Gluckman, together with many of his colleagues at the Rhodes-Livingstone Institute and students at Manchester University, collectively known as the Manchester School, took BSA in new directions through their introduction of explicitly Marxist-informed theory, their emphasis on conflicts and conflict resolution, and their attention to the ways in which individuals negotiate and make use of the social structural possibilities.
Later in the 1960s and 1970s, Edmund Leach and his students Mary Douglas and Nur Yalman, among others, introduced French structuralism in the style of Lévi-Strauss; while British anthropology has continued to emphasize social organization and economics over purely symbolic or literary topics, differences among British, French, and American sociocultural anthropologies have diminished with increasing dialogue and borrowing of both theory and methods. Today, social anthropology in Britain engages internationally with many other social theories and has branched in many directions.
In countries of the British Commonwealth, social anthropology has often been institutionally separate from physical anthropology and primatology, which may be connected with departments of biology or zoology; and from archaeology, which may be connected with departments of Classics, Egyptology, and the like. In other countries (and in some, particularly smaller, British and North American universities), anthropologists have also found themselves institutionally linked with scholars of folklore, museum studies, human geography, sociology, social relations, ethnic studies, cultural studies, and social work.
From its beginnings in the early 19th century through the early 20th century, anthropology in the United States was influenced by the presence of Native American societies. As in other colonial powers (including Britain, France, Spain, Portugal, and the countries of Latin America) this encounter with colonial subjects manifested in several ways. Curiosity, admiration, desire to "reform" or "civilize" native practices, or simple puzzlement at how societies could function with such different social and political systems, all motivated early ethnographers. Practical concerns of Christian missionaries and colonial administrators, seeking to communicate with native peoples or ascertain how to incorporate them, helped gain funding and institutional attention. Statements of ethnologists (as well as many amateurs, missionaries, and colonial administrators, who were not clearly distinguished from more committed scholars in this era prior to the professionalization of anthropology) often played into political debates around the definitions of humanity and citizenship. These conflicts between what may be seen as the pursuit of pure knowledge or the facilitation of intercultural understanding on the one hand, and the potentially exploitative, oppressive, or coercive uses to which that knowledge might be put, on the other, concerned many early anthropologists and has become a major source of controversy and self-examination within the discipline since at least the mid-20th century. The claim that anthropology accompliced to the "project of colonialism" is a misconception that has grown out of several critical perspectives from the 1960s and 70s.
Cultural anthropology in the United States was influenced greatly by the ready availability of Native American societies as ethnographic subjects. The field was pioneered by staff of the Bureau of Indian Affairs and the Smithsonian Institution's Bureau of American Ethnology, men such as John Wesley Powell and Frank Hamilton Cushing. Lewis Henry Morgan (1818-1881), a lawyer from Rochester, New York, became an advocate for and ethnological scholar of the Iroquois. His comparative analyses of religion, government, material culture, and especially kinship patterns proved to be influential contributions to the field of anthropology. Like other scholars of his day (such as Edward Tylor), Morgan argued that human societies could be classified into categories of cultural evolution on a scale of progression that ranged from savagery, to barbarism, to civilization. Generally, Morgan used technology (such as bowmaking or pottery) as an indicator of position on this scale.
Franz Boas established academic anthropology in the United States in opposition to this sort of evolutionary perspective. Boasian anthropology was politically active and suspicious of research dictated by the U.S. government and wealthy patrons. It was rigorously empirical and skeptical of overgeneralizations and attempts to establish universal laws. Boas studied immigrant children to demonstrate that biological race was not immutable, and that human conduct and behavior resulted from nurture, rather than nature.
Influenced by the German tradition, Boas argued that the world was full of distinct cultures, rather than societies whose evolution could be measured by how much or how little "civilization" they had. He believed that each culture has to be studied in its particularity, and argued that cross-cultural generalizations, like those made in the natural sciences, were not possible. In doing so, he fought discrimination against immigrants, African Americans, and Native North Americans. Many American anthropologists adopted his agenda for social reform, and theories of race continue to be popular targets for anthropologists today. The so-called "Four Field Approach" has its origins in Boasian Anthropology, dividing the discipline in the four crucial and interrelated fields of sociocultural, biological, linguistic, and prehistoric anthropology.
Boas used his positions at Columbia University and the American Museum of Natural History to train and develop multiple generations of students. His first generation of students included Alfred Kroeber, Robert Lowie, Edward Sapir and Ruth Benedict, who each produced richly detailed studies of indigenous North American cultures. They provided a wealth of details used to attack the theory of a single evolutionary process. Kroeber and Sapir's focus on Native American languages helped establish linguistics as a truly general science and free it from its historical focus on Indo-European languages.
The publication of Alfred Kroeber's textbook, Anthropology, marked a turning point in American anthropology. After three decades of amassing material, Boasians felt a growing urge to generalize. This was most obvious in the 'Culture and Personality' studies carried out by younger Boasians such as Margaret Mead and Ruth Benedict. Influenced by psychoanalytic psychologists such as Sigmund Freud and Carl Jung, these authors sought to understand the way that individual personalities were shaped by the wider cultural and social forces in which they grew up. Though such works as Coming of Age in Samoa and The Chrysanthemum and the Sword remain popular with the American public, Mead and Benedict never had the impact on the discipline of anthropology that some expected. Boas had planned for Ruth Benedict to succeed him as chair of Columbia's anthropology department, but she was sidelined by Ralph Linton, and Mead was limited to her offices at the AMNH.
Canadian anthropology began, as in other parts of the Colonial world, as ethnological data in the records of travellers and missionaries. In Canada, Jesuit missionaries such as Fathers LeClercq, Le Jeune and Sagard, in the 1600s, provide the oldest ethnographic records of native tribes in what was then the Domain of Canada.
True anthropology began with a Government department: the Geological Survey of Canada, and George Mercer Dawson (director in 1895). Dawson's support for anthropology created impetus for the profession in Canada. This was expanded upon by Prime Minister Wilfrid Laurier, who established a Division of Anthropology within the Geological Survey in 1910. Anthropologists were recruited from England and the USA, setting the foundation for the unique Canadian style of anthropology. Early scholars include the brilliant linguist and Boasian, Edward Sapir, also Oxford graduates Marius Barbeau and Diamond Jenness. Born in rural Québec, Barbeau became a Rhodes scholar and eventually a classmate of Jenness. The two studied under Tylor and Marett at Oxford. In Canada, Barbeau and Jenness worked at the National Museum (as it became known later). In 1944, Canada's first home-grown anthropologist established the archive which has become a key source of ethnographic and folklore material.
Following George Mercer Dawson (of McGill, Montreal) and Franz Boas, Sapir and Barbeau conducted ethnographic research and collected material culture from the peoples of the Northwest Coast, especially Haida. Jenness is best known for his research in the Arctic among the Copper Inuit. However, in actuality, they all worked in a variety of areas in Canada, recording traditions and songs, studying languages, and collecting artifacts for the museum. They essentially had sole responsibility for the development of the profession in Canada from 1910 until 1925 when Sapir left. The development was slow relative to expansion (due to the colonizing needs) of Britain and the USA.
The first academic position in anthropology at a Canadian university was awarded to Thomas McIlwraith at the University of Toronto in 1925. The next universities to hire anthropologists, UBC and McGill, did so only in 1947. The first PhD in anthropology was granted in 1956, with only a few more being granted until the late 1960s. The 1970s brought a boom in university development and in professional anthropology, and by 1980 about 400 people with doctorates in anthropology were employed in Canada, and many more with a master's degree. Harry Hawthorne built the department at UBC and set a standard for the use of anthropological research as a guide to public policy in his classic report to the federal government, coauthored by M.-A. Tremblay, "A Survey of the Contemporary Indians of Canada" (1966, 1967).
Canadian Anthropology is characterized by a combination of Americanist Boasian-influenced interest in Native American tribes and peoples, British Anthropological concerns with social function and process, and Francophone concerns with small, rural and ethnically isolated community studies. Issues of disparity, continuity and change, political-economy, environment and cultural ecology, and personality, culture and symbolism predominated the discourse from World War I to the Vietnam War era.
Anthropology in France has a less clear genealogy than the British and American traditions, in part because many French writers influential in anthropology have been trained or held faculty positions in sociology, philosophy, or other fields rather than in anthropology. Most commentators consider Marcel Mauss (1872-1950), nephew of the influential sociologist Émile Durkheim to be the founder of the French anthropological tradition. Mauss belonged to Durkheim's Année Sociologique group; and while Durkheim and others examined the state of modern societies, Mauss and his collaborators (such as Henri Hubert and Robert Hertz) drew on ethnography and philology to analyze societies which were not as 'differentiated' as European nation states. Two works by Mauss in particular proved to have enduring relevance: Essay on the Gift a seminal analysis of exchange and reciprocity, and his Huxley lecture on the notion of the person, the first comparative study of notions of person and selfhood cross-culturally.
Throughout the interwar years, French interest in anthropology often dovetailed with wider cultural movements such as surrealism and primitivism which drew on ethnography for inspiration. Marcel Griaule and Michel Leiris are examples of people who combined anthropology with the French avant-garde. During this time most of what is known as ethnologie was restricted to museums, such as the Musée de l'Homme founded by Paul Rivet, and anthropology had a close relationship with studies of folklore.
Above all, however, it was Claude Lévi-Strauss who helped institutionalize anthropology in France. In addition to the enormous influence his structuralism exerted across multiple disciplines, Lévi-Strauss established ties with American and British anthropologists. At the same time he established centers and laboratories within France to provide an institutional context within anthropology while training influential students such as Maurice Godelier and Françoise Héritier who would prove influential in the world of French anthropology. Much of the distinct character of France's anthropology today is a result of the fact that most anthropology is carried out in nationally funded research laboratories (CNRS) rather than academic departments in universities.
Other influential writers in the 1970s include Pierre Clastres, who explains in his books on the Guayaki tribe in Paraguay that "primitive societies" actively oppose the institution of the state. Therefore, these stateless societies are not less evolved than societies with states, but took the active choice of conjuring the institution of authority as a separate function from society. The leader is only a spokesperson for the group when it has to deal with other groups ("international relations") but has no inside authority, and may be violently removed if he attempts to abuse this position.
The most important French social theorist since Foucault and Lévi-Strauss is Pierre Bourdieu, who trained formally in philosophy and sociology and eventually held the Chair of Sociology at the Collège de France. Like Mauss and others before him, however, he worked on topics both in sociology and anthropology. His fieldwork among the Kabyles of Algeria places him solidly in anthropology, while his analysis of the function and reproduction of fashion and cultural capital in European societies places him as solidly in sociology.
Anthropology in Greece and Portugal is much influenced by British anthropology. In Greece, there was since the 19th century a science of the folklore called laographia (laography), in the form of "a science of the interior", although theoretically weak; but the connotation of the field deeply changed after World War II, when a wave of Anglo-American anthropologists introduced a science "of the outside". In Italy, the development of ethnology and related studies did not received as much attention as other branches of learning.
Germany and Norway are the countries that showed the most division and conflict between scholars focusing on domestic socio-cultural issues and scholars focusing on "other" societies.
Before WWII British 'social anthropology' and American 'cultural anthropology' were still distinct traditions. After the war, enough British and American anthropologists borrowed ideas and methodlogical approaches from each other that some began to speak of them collectively as 'sociocultural' anthropology.
In the 1950s and mid-1960s anthropology tended increasingly to model itself after the natural sciences. Some anthropologists, such as Lloyd Fallers and Clifford Geertz, focused on processes of modernization by which newly independent states could develop. Others, such as Julian Steward and Leslie White, focused on how societies evolve and fit their ecological niche—an approach popularized by Marvin Harris. Economic anthropology as influenced by Karl Polanyi and practiced by Marshall Sahlins and George Dalton challenged standard neoclassical economics to take account of cultural and social factors, and also employed Marxian analysis into anthropological study. In England, British Social Anthropology's paradigm began to fragment as Max Gluckman and Peter Worsley experimented with Marxism and authors such as Rodney Needham and Edmund Leach incorporated Lévi-Strauss's structuralism into their work.
Structuralism also influenced a number of developments in 1960s and 1970s, including cognitive anthropology and componential analysis. Authors such as David Schneider, Clifford Geertz, and Marshall Sahlins developed a more fleshed-out concept of culture as a web of meaning or signification, which proved very popular within and beyond the discipline. In keeping with the times, much of anthropology became politicized through the Algerian War of Independence and opposition to the Vietnam War; Marxism became a more and more popular theoretical approach in the discipline. By the 1970s the authors of volumes such as Reinventing Anthropology worried about anthropology's relevance.
Since the 1980s issues of power, such as those examined in Eric Wolf's Europe and the People Without History, have been central to the discipline. In the 80s books like Anthropology and the Colonial Encounter pondered anthropology's ties to colonial inequality, while the immense popularity of theorists such as Antonio Gramsci and Michel Foucault moved issues of power and hegemony into the spotlight. Gender and sexuality became popular topics, as did the relationship between history and anthropology, influenced by Marshall Sahlins (again), who drew on Lévi-Strauss and Fernand Braudel to examine the relationship between social structure and individual agency. Also influential in these issues were Nietzsche, Heidegger, the critical theory of the Frankfurt School, Derrida and Lacan.
In the late 1980s and 1990s authors such as George Marcus and James Clifford pondered ethnographic authority, particularly how and why anthropological knowledge was possible and authoritative. They were reflecting trends in research and discourse initiated by Feminists in the academy, although they excused themselves from commenting specifically on those pioneering critics. Nevertheless, key aspects of feminist theorsing and methods became de rigueur as part of the 'post-modern moment' in anthropology: Ethnographies became more reflexive, explicitly addressing the author's methodology, cultural, gender and racial positioning, and their influence on his or her ethnographic analysis. This was part of a more general trend of postmodernism that was popular contemporaneously. Currently anthropologists pay attention to a wide variety of issues pertaining to the contemporary world, including globalization, medicine and biotechnology, indigenous rights, virtual communities, and the anthropology of industrialized societies.
A number of subfields or modes of anthropology cut across these divisions. For example, medical anthropology is often considered a subfield of socio-cultural anthropology; however, many anthropologists who study medical topics also look at biological variation in populations or the interaction of culture and biology. They may also use linguistic analysis to understand communication around health and illness, or archaeological techniques to understand health and illness in historical or prehistorical populations. Similarly, forensic anthropologists may use both techniques from both physical anthropology and archaeology, and may also practice as medical anthropologists. Environmental or ecological anthropology, a growing subfield concerned with the relationships between humans and their environment, is another example that brings cultural and biological—and at times, archaeological—approaches together, as it can deal with a broad range of topics from environmentalist movements to wildlife or habitat conservation to traditional ecological knowledge and practices. Biocultural anthropology is a broad term used to describe syntheses of cultural and biological perspectives. Applied anthropology is perhaps better considered an emphasis than a subfield in the same sense as the standard four; applied anthropologists may work for government agencies, nongovernmental agencies, or private industry, using techniques from any of the subfields to address matters such as policy implementation, impact assessments, education, marketing research, or product development.
More recently, anthropology programs at several prominent U.S. universities have begun dividing the field into two: one emphasizing the humanities, critical theory, and interpretive or semiotic approaches; the other emphasizing evolutionary theory, quantitive methods, and explicit theory testing (over idiographic description), though there have also been institutional pressures to rejoin at least one high-profile split department. At some universitities, biological anthropology and archaeology programs have also moved from departments of anthropology to departments of biology or other related fields. This has occasioned much discussion within the American Anthropological Association, and it remains to be seen whether some form of the four-field organization will persist in North American universities.
As might be inferred from the above list of subfields, anthropology is a methodologically diverse discipline, incorporating both qualitative methods and quantitative methods. Ethnographies—intensive case studies based on field research—have historically had a central place in the literature of sociocultural and linguistic anthropology, but are increasingly supplemented by mixed-methods approaches. Currently, technological advancements are spurring methodological innovation across anthropology's subfields. Radiocarbon dating, population genetics, GPS, and digital video- and audio-recording are just a few of the many technologies spurring new developments in anthropological research.
During the first four decades of the 20th century, American cultural anthropology developed under the powerful influence of Franz Boas and his students and their struggle against racial determinism and the ethnocentrism of 19th-century cultural evolutionism. With the additional impact of the Great Depression and World War II, American anthropology developed a pronounced, obvious left-wing liberal tone by the 1950s. However, the discipline's deep involvement with nonwestern cultures put it in a vulnerable position during the campus upheavals of the late 1960s and in the subsequent "culture wars." The "politics of anthropology" has become a pervasive concern since then. Whatever the realities, the notion of anthropology as somehow complicit in morally unacceptable projects has become a significant topic both within the discipline and in "cultural studies" and "post-colonialism," etc.
However, anthropology is once again being used in warfare as part of the US Army's strategy in Afghanistan. The Christian Science Monitor reports that "Counterinsurgency efforts focus on better grasping and meeting local needs" in Afghanistan, under the rubric of Human Terrain Team (HTT).
More recently, there have been concerns expressed about bioprospecting, along with struggles for self-representation for native peoples and the repatriation of indigenous remains and material culture, with anthropologists often in the lead on these issues.
Other political controversies come from the emphasis in American anthropology on cultural relativism and its long-standing dismissal of the concept of race. The development of sociobiology in the late 1960s was opposed by cultural anthropologists such as Marshall Sahlins, who argued that these positions were reductive (for more details see the section on the relations with the natural sciences and the Humanities). While authors such John Randal Baker continued to develop the biological concept of race into the 1970s, the rise of genetics has proven to be central to developments on this front. As genetics continues to advance as a science, scholars such as Luca Cavalli-Sforza have continued to transform and advance notions of race through the use of recent developments in genetics, such as tracing past migrations of peoples through their mitochondrial and Y-chromosomal DNA, and ancestry-informative markers.
Some authors argue that anthropology originated and developed as the study of "other cultures", both in terms of time (past societies) and space (non-European/non-Western societies). For example, the classic of urban anthropology, Ulf Hannerz in the introduction to his seminal Exploring the City: Inquiries Toward an Urban Anthropology mentions that the "Third World" had habitually received most of attention; anthropologists who traditionally specialized in "other cultures" looked for them far away and started to look "across the tracks" only in late 1960s. Now there exist many works focusing on peoples and topics very close to the author's "home". It is also argued that other fields of study, like History and Sociology, on the contrary focus disproportionately on the West.
In France, the study of existing contemporary society has been traditionally left to sociologists, but this is increasingly changing, starting in the 1970s from scholars like Isac Chiva and journals like Terrain ("fieldwork"), and developing with the center founded by Marc Augé (Le Centre d'anthropologie des mondes contemporains, the Anthropological Research Center of Contemporary Societies). The same approach of focusing on "modern world" topics by Terrain, was also present in the British Manchester School of the 1950s.
It has been reported that there has been an "institutional and academic apartheid" between the two sorts of anthropology, the one focusing on the "Other" and the one focusing on the "Self" contemporary society; an apartheid ranging from a "no contact" status to even open conflict. The countries where this was greater were Germany and Norway, but it was also significant in the 1980s France.


Archaeology, archeology, or archæology (from Greek: αρχαιολογία - archaiologia, from αρχαίος - archaios, "primal, ancient, old" and λόγος - logos, "study") is the science that studies human cultures through the recovery, documentation, analysis and interpretation of material remains and environmental data, including architecture, artifacts, features, biofacts, and landscapes. Because archaeology's aim is to understand mankind, it is a humanistic endeavor.
The goals of archaeology vary, and there is debate as to what its aims and responsibilities are. Some goals include the documentation and explanation of the origins and development of human cultures, understanding culture history, chronicling cultural evolution, and studying human behavior and ecology, for both prehistoric and historic societies. Archaeologists are also concerned with the study of methods used in the discipline, and the theoretical and philosophical underpinnings underlying the questions archaeologists ask of the past. The tasks of surveying areas in order to find new sites, excavating sites in order to recover cultural remains, classification, analysis, and preservation are all important phases of the archaeological process. These are all important sources of information. Given the broad scope of the discipline there is a great deal of cross-disciplinary research in archaeology. It draws upon anthropology, history, art history, classics, ethnology, geography, geology, physics, information sciences, chemistry, statistics, paleoecology, paleontology, paleozoology, paleoethnobotany, paleobotany.
In parts of Europe and the Old World, the discipline has its roots in antiquarianism and the study of Latin and Ancient Greek, and so has a natural affinity with the field of history.
Archaeology in ancient China developed from antiquarian pursuits as well, specifically from the scholar-official's desires to revive the use of ancient relics in state ritual. This pursuit of his Chinese peers was criticized by Shen Kuo (1031–1095), who asserted that archaeology should be the pursuit of studying functionality, discovering the methods of manufacture from ancient times, and should be studied with an interdisciplinary approach. Yet there were others who took the discipline as seriously as Shen; the official, historian, poet, and essayist Ouyang Xiu (1007–1072) compiled an analytical catalogue of ancient rubbings on stone and bronze which pioneered ideas in early epigraphy and archaeology.
In North America archaeology is one of the four sub-fields, or branches of anthropology. The other three branches are cultural anthropology, the study of living cultures and societies; linguistics, the study of language, including the origins of language and language groups; and physical anthropology, includes the study of human evolution and physical and genetic characteristics.
Often archaeology provides the only means to learn of the existence and behaviors of people of the past. Across the millennia many thousands of cultures and societies and billions of people have come and gone of which there is little or no written record or existing records are misrepresentative or incomplete. Writing as it is known today did not exist in human civilization until the 4th millennium BC, in a relatively small number of technologically advanced civilizations. In contrast Homo sapiens has existed for at least 200,000 years, and other species of Homo for millions of years (see Human evolution). These civilizations are, not coincidentally, the best-known; they are open to the inquiry of historians for centuries, while the study of pre-historic cultures has arisen only recently. Even within a literate civilization many events and important human practices are not officially recorded. Any knowledge of the early years of human civilization – the development of agriculture, cult practices of folk religion, the rise of the first cities – must come from archaeology.
Even where written records do exist, they are often incomplete and invariably biased to some extent. In many societies, literacy was restricted to the elite classes, such as the clergy or the bureaucracy of court or temple. The literacy even of aristocrats has sometimes been restricted to deeds and contracts. The interests and world-view of elites are often quite different from the lives and interests of the populace. Writings that were produced by people more representative of the general population were unlikely to find their way into libraries and be preserved there for posterity. Thus, written records tend to reflect the biases, assumptions, cultural values and possibly deceptions of a limited range of individuals, usually only a fraction of the larger population. Hence, written records cannot be trusted as a sole source. The material record is closer to a fair representation of society, though it is subject to its own inaccuracies, such as sampling bias and differential preservation.
In addition to their scientific importance, archaeological remains sometimes have political or cultural significance to descendants of the people who produced them, monetary value to collectors, or simply strong aesthetic appeal. Many people identify archaeology with the recovery of such aesthetic, religious, political, or economic treasures rather than with the reconstruction of past societies.
This view is often espoused in works of popular fiction, such as Raiders of the Lost Ark, The Mummy, and "King Solomon's Mines". When such unrealistic subjects are treated more seriously, accusations of pseudoscience are invariably levelled at their proponents (see Pseudoarchaeology, below). However, these endeavours, real and fictional, are not representative of modern archaeology.
The history of archaeology has been one of increasing professionalisation, and the use of an increasing range of techniques, to obtain as much data on the site being examined as possible.
Excavations of ancient monuments and the collection of antiquities have been taking place for thousands of years, but these were mostly for the extraction of valuable or aesthetically pleasing artifacts.
It was only in the 19th century that the systematic study of the past through its physical remains began to be carried out. A notable early development was the founding in Rome in 1829, by Eduard Gerhard and others, of the Institute for Archaeological Correspondence (Instituto di corrispondenza archeologica or Institut für archäologische Korrespondenz). Archaeological methods were developed by both interested amateurs and professionals, including Augustus Pitt Rivers and William Flinders Petrie.
This process was continued in the 20th century by such people as Mortimer Wheeler, whose highly disciplined approach to excavation greatly improved the quality of evidence that could be obtained.
During the 20th century, the development of urban archaeology and then rescue archaeology have been important factors, as has the development of archaeological science, which has greatly increased the amount of data that it is possible to obtain.
Another branch, archaeoastronomy, is not as well known as archaeology, but deals with the study of ancient or traditional astronomies in cultural context.
There is no single theory of archaeology, and even definitions are disputed. Until the mid-20th century, there was a general consensus that archaeology was closely related to both history and anthropology.
The first major phase in the history of archaeological theory in the United States developed during the late 19th and early 20th centuries. It is commonly referred to as cultural, or culture, history. It is best known for its emphasis on historical particularism.
In the 1920's in the American Southwest cultural historical archaeology was intimately tied with the direct historical approach. This approach continues to be pursued in the American Southwest, the American Northwest Coast, Mesoamerica, the Andes, Oceania, Siberia, and other world areas where there appears to be continuity between living, indigenous populations and archaeological remains of past groups. In pursuing the direct historical approach, ethnohistorical and early historical records play an important role in articulating the connections between modern people and the archaeological past. Literary sources can be used in other contexts as well, for example, in the case of Hadrian's Wall.
In the 1960s, a number of primarily American archaeologists, such as Lewis Binford and Kent Flannery, rebelled against the paradigms of cultural history. They proposed a "New Archaeology", which would be more "scientific" and "anthropological", with hypothesis testing and the scientific method very important parts of what became known as processual archaeology.
In the 1980s, a new postmodern movement arose led by the British archaeologists Michael Shanks, Christopher Tilley, Daniel Miller, and Ian Hodder. It questioned processualism's appeals to scientific positivism and impartiality, and emphasised the importance of a more self-critical theoretical reflexivity. This approach is termed post-processual archaeology. However, this approach has been criticized by processualists as lacking scientific rigor. The validity of both processualism and post-processualism is still under debate.
Historical Processualism is an emerging paradigm that seeks to incorporate a focus on process and post-processual archaeology's emphasis of reflexivity and history.
Archaeological theory now borrows from a wide range of influences, including neo-Darwinian evolutionary thought, phenomenology, postmodernism, agency theory, cognitive science, Functionalism, gender-based and Feminist archaeology, and Systems theory.
A modern archaeological project often begins with a survey. Regional survey is the attempt to systematically locate previously unknown sites in a region. Site survey is the attempt to systematically locate features of interest, such as houses and middens, within a site. Each of these two goals may be accomplished with largely the same methods.
Survey was not widely practiced in the early days of archaeology. Cultural historians and prior researchers were usually content with discovering the locations of monumental sites from the local populace, and excavating only the plainly visible features there. Gordon Willey pioneered the technique of regional settlement pattern survey in 1949 in the Viru Valley of coastal Peru, and survey of all levels became prominent with the rise of processual archaeology some years later.
Survey work has many benefits if performed as a preliminary exercise to, or even in place of, excavation. It requires relatively little time and expense, because it does not require processing large volumes of soil to search out artifacts. (Nevertheless, surveying a large region or site can be expensive, so archaeologists often employ sampling methods.) As with other forms of non-destructive archaeology, survey avoids ethical issues (of particular concern to descendant peoples) associated with destroying a site through excavation. It is the only way to gather some forms of information, such as settlement patterns and settlement structure. Survey data are commonly assembled into maps, which may show surface features and/or artifact distribution.
The simplest survey technique is surface survey. It involves combing an area, usually on foot but sometimes with the use of mechanized transport, to search for features or artifacts visible on the surface. Surface survey cannot detect sites or features that are completely buried under earth, or overgrown with vegetation. Surface survey may also include mini-excavation techniques such as augers, corers, and shovel test pits.
Aerial survey is conducted using cameras attached to airplanes, balloons, or even kites. A bird's-eye view is useful for quick mapping of large or complex sites. Aerial photographs are used to document the status of the archaeological dig. Aerial imaging can also detect many things not visible from the surface. Plants growing above a buried man made structure, such as a stone wall, will develop more slowly, while those above other types of features (such as middens) may develop more rapidly. Photographs of ripening grain, which changes colour rapidly at maturation, have revealed buried structures with great precision. Aerial photographs taken at different times of day will help show the outlines of structures by changes in shadows. Aerial survey also employs infrared, ground-penetrating radar wavelengths, and thermography.
Archaeological geophysics can be the most effective way to see beneath the ground. Magnetometers detect minute deviations in the Earth's magnetic field caused by iron artifacts, kilns, some types of stone structures, and even ditches and middens. Devices that measure the electrical resistivity of the soil are also widely used. Archaeological Features whose electrical resistivity contrasts with that of surrounding soils can be detected and mapped. Some archaeological features (such as those composed of stone or brick) have higher resistivity than typical soils, while others (such as organic deposits or unfired clay) tend to have lower resistivity.
Although some archaeologists consider the use of metal detectors to be tantamount to treasure hunting, others deem them an effective tool in archaeological surveying. Examples of formal archaeological use of metal detectors include musketball distribution analysis on English Civil War battlefields, metal distribution analysis prior to excavation of a nineteenth century ship wreck, and service cable location during evaluation. Metal detectorists have also contributed to the archaeological record where they have made detailed records of their results and refrained from raising artifacts from their archaeological context. In the UK, metal detectorists have been solicited for involvement in the Portable Antiquities Scheme.
Regional survey in underwater archaeology uses geophysical or remote sensing devices such as marine magnetometer, side-scan sonar, or sub-bottom sonar.
Archaeological excavation existed even when the field was still the domain of amateurs, and it remains the source of the majority of data recovered in most field projects. It can reveal several types of information usually not accessible to survey, such as stratigraphy, three-dimensional structure, and verifiably primary context.
Modern excavation techniques require that the precise locations of objects and features, known as their provenance or provenience, be recorded. This always involves determining their horizontal locations, and sometimes vertical position as well (also see Primary Laws of Archaeology). Similarly, their association, or relationship with nearby objects and features, needs to be recorded for later analysis. This allows the archaeologist to deduce what artifacts and features were likely used together and which may be from different phases of activity. For example, excavation of a site reveals its stratigraphy; if a site was occupied by a succession of distinct cultures, artifacts from more recent cultures will lie above those from more ancient cultures.
Excavation is the most expensive phase of archaeological research. Also, as a destructive process, it carries ethical concerns. As a result, very few sites are excavated in their entirety. Sampling is even more important in excavation than in survey. It is common for large mechanical equipment, such as backhoes (JCBs), to be used in excavation, especially to remove the topsoil (overburden), though this method is increasingly used with great caution. Following this rather dramatic step, the exposed area is usually hand-cleaned with trowels or hoes to ensure that all features are apparent.
The next task is to form a site plan and then use it to help decide the method of excavation. Features dug into the natural subsoil are normally excavated in portions in order to produce a visible archaeological section for recording. A feature, for example a pit or a ditch, consists of two parts: the cut and the fill. The cut describes the edge of the feature, where the feature meets the natural soil. It is the feature's boundary. The fill is, understandably, what the feature is filled with, and will often appear quite distinct from the natural soil. The cut and fill are given consecutive numbers for recording purposes. Scaled plans and sections of individual features are all drawn on site, black and white and colour photographs of them are taken, and recording sheets are filled in describing the context of each. All this information serves as a permanent record of the now-destroyed archaeology and is used in describing and interpreting the site.
Once artifacts and structures have been excavated, or collected from surface surveys, it is necessary to properly study them, to gain as much data as possible. This process is known as post-excavation analysis, and is normally the most time-consuming part of the archaeological investigation. It is not uncommon for the final excavation reports on major sites to take years to be published.
At its most basic, the artifacts found are cleaned, catalogued and compared to published collections, in order to classify them typologically and to identify other sites with similar artifact assemblages. However, a much more comprehensive range of analytical techniques are available through archaeological science, meaning that artifacts can be dated and their compositions examined. The bones, plants and pollen collected from a site can all be analyzed (using the techniques of zooarchaeology, paleoethnobotany, and palynology), while any texts can usually be deciphered.
These techniques frequently provide information that would not otherwise be known and therefore contribute greatly to the understanding of a site.
As with most academic disciplines, there are a very large number of archaeological sub-disciplines characterised by a specific method or type of material (e.g. lithic analysis, music, archaeobotany), geographical or chronological focus (e.g. Near Eastern archaeology, Medieval archaeology), other thematic concern (e.g. maritime archaeology, landscape archaeology, battlefield archaeology), or a specific archaeological culture or civilisation (e.g. Egyptology).
Historical archaeology is the study of cultures with some form of writing.
In England, archaeologists have uncovered the long-lost layouts of medieval villages abandoned after the crises of the 14th century and the equally lost layouts of 17th century parterre gardens swept away by a change in fashion. In downtown New York City archaeologists have exhumed the 18th century remains of the African burial ground.
Ethnoarchaeology is the archaeological study of living people. The approach gained notoriety during the emphasis on middle range theory that was a feature of the processual movement of the 1960's.
Early ethnoarchaeological research focused on hunting and gathering or foraging societies. Ethnoarchaeology continues to be a vibrant component of post-processual and other current archaeological approaches.
Experimental archaeology represents the application of the experimental method to develop more highly controlled observations of processes that create and impact the archaeological record. In the context of the context of the logical positivism of processualism with its goals of improving the scientific rigor of archaeological epistemologies the experimental method gained importance. Experimental techniques remain a crucial component to improving the inferential frameworks for interpreting the archaeological record.
Archaeometry is a field of study that aims to systematize archaeological measurement. It emphasizes the application of analytical techniques from physics, chemistry, and engineering. It is a lively field of research that frequently focuses on the definition of the chemical composition of archaeological remains for source analysis.
Cultural resources management (CRM) also called heritage management in Britain, is a branch of archaeology that accounts for most research done in the United States and much of that in western Europe as well. In the United States, CRM archaeology has been a growing concern since the passage of the National Historic Preservation Act of 1966 and most of the archaeology done in that country today proceeds from either direct or related requirements of that measure. In the United States, the vast majority of taxpayers, scholars, and politicians believe that CRM has helped to preserve much of that nation's history and prehistory that would have otherwise been lost in the expansion of cities, dams, and highways. Along with other statutes, this mandates that no construction project on public land or involving public funds may damage an unstudied archaeological site.
The application of CRM in the United Kingdom is not limited to government-funded projects. Since 1990 PPG 16 has required planners to consider archaeology as a material consideration in determining applications for new development. As a result, numerous archaeological organisations undertake mitigation work in advance of (or during) construction work in archaeologically sensitive areas, at the developer's expense.
In England, ultimate responsibility of care for the historic environment rests with the Department for Culture, Media and Sport in association with English Heritage. In Scotland, Wales and Northern Ireland, the same responsibilities lie with Historic Scotland, Cadw and the Environment and Heritage Service (Northern Ireland) respectively.
Among the goals of CRM are the identification, preservation, and maintenance of cultural sites on public and private lands, and the removal of culturally valuable materials from areas where they would otherwise be destroyed by human activity, such as proposed construction. This study involves at least a cursory examination to determine whether or not any significant archaeological sites are present in the area affected by the proposed construction. If these do exist, time and money must be allotted for their excavation. If initial survey and/or test excavation indicates the presence of an extraordinarily valuable site, the construction may be prohibited entirely. CRM is a thriving entity, especially in the United States and Europe where archaeologists from private companies and all levels of government engage in the practice of their discipline.
Cultural resources management has, however, been criticized. CRM is conducted by private companies that bid for projects by submitting proposals outlining the work to be done and an expected budget. It is not unheard-of for the agency responsible for the construction to simply choose the proposal that asks for the least funding. CRM archaeologists face considerable time pressure, often being forced to complete their work in a fraction of the time that might be allotted for a purely scholarly endeavour. Compounding the time pressure is the vetting process of site reports which are required (in the US) to be submitted by CRM firms to the appropriate State Historic Preservation Office (SHPO). From the SHPO's perspective there is to be no difference between a report submitted by a CRM firm operating under a deadline, and a multi-year academic project. The end result is that for a Cultural Resource Management archaeologist to be successful, they must be able to produce academic quality documents at a corporate world pace.
The annual ratio of open academic archaeology positions (inclusive of Post-Doc, temporary, and non tenure track appointments) to the annual number of archaeology MA/MSc and PhD students is grossly disproportionate. This dearth of academic positions causes a predictable excess of well educated individuals who join the ranks of the following year's crop of non-academically employed archaeologists. Cultural Resource Management, once considered an intellectual backwater for individuals with "strong backs and weak minds" has reaped the benefit of this massive pool of well educated professionals. This results in CRM offices increasingly staffed by advance degreed individuals with a track record of producing scholarly articles but who have the notches on their trowels to show they have been in the trenches as a shovelbum.
Early archaeology was largely an attempt to uncover spectacular artifacts and features, or to explore vast and mysterious abandoned cities. Such pursuits continue to fascinate the public. Books, films, and video games, such as "King Solomon's Mines, The Mummy, Raiders of the Lost Ark, and Tomb Raider" all testify to the public's interest in the discovery aspect of archaeology.
Much thorough and productive research has indeed been conducted in dramatic locales such as Copán and the Valley of the Kings, but the bulk of activities and finds of modern archaeology are not so sensational. Archaeological adventure stories tend to ignore the painstaking work involved in carrying out modern survey, excavation, and data processing. Some archaeologists refer to such portrayals as "pseudoarchaeology".
Archaeology has been portrayed in the mainstream media in sensational ways. This has its advantages and disadvantages. Many practitioners point to the childhood excitement of Indiana Jones films and Tomb Raider games as the inspiration for them to enter the field. Archaeologists are also very much reliant on public support, the question of exactly who they are doing their work for is often discussed. Without a strong public interest in the subject, often sparked by significant finds and celebrity archaeologists, it would be a great deal harder for archaeologists to gain the political and financial support they require.
Motivated by a desire to halt looting, curb pseudoarchaeology, and to secure greater public funding and appreciation for their work, archaeologists are mounting public-outreach campaigns. They seek to stop looting by combatting people who illegally take artifacts from protected sites, and by alerting people who live near archaeological sites of the threat of looting. Common methods of public outreach include press releases, and the encouragement of school field trips to sites under excavation by professional archaeologists.
One audience for archaeologists' work is the public. They increasingly realize that their work can benefit non-academic and non-archaeological audiences, and that they have a responsibility educate and inform the public about archaeology. Local heritage awareness is aimed at increasing civic and individual pride through projects such as community excavation projects, and better public presentations of archaeological sites and knowledge.
In the UK, popular archaeology programs such as Time Team and Meet the Ancestors have resulted in a huge upsurge in public interest. Where possible, archaeologists now make more provisions for public involvement and outreach in larger projects than they once did, and many local archaeological organizations operate within the Community archaeology framework to expand public involvement in smaller-scale, more local projects. Archaeological excavation, however, is best undertaken by well-trained staff that can work quickly and accurately. Often this requires observing the necessary health and safety and indemnity insurance issues involved in working on a modern building site with tight deadlines. Certain charities and local government bodies sometimes offer places on research projects either as part of academic work or as a defined community project. There is also a flourishing industry selling places on commercial training excavations and archaeological holiday tours.
Archaeologists prize local knowledge and often liaise with local historical and archaeological societies, which is one reason why Community archaeology projects are starting to become more common. Often archaeologists are assisted by the public in the locating of archaeological sites, which professional archaeologists have neither the funding, nor the time to do. Anyone looking to participate in archaeological opportunities should contact one of these local societies or organizations.
Pseudoarchaeology is an umbrella term for all activities that claim to be archaeological but in fact violate commonly accepted archaeological practices. It includes much fictional archaeological work (discussed above), as well as some actual activity. Many non-fiction authors have ignored the scientific methods of processual archaeology, or the specific critiques of it contained in post-processualism.
An example of this type is the writing of Erich von Däniken. His Chariots of the Gods (1968), together with many subsequent lesser-known works, expounds a theory of ancient contacts between human civilisation on Earth and more technologically advanced extraterrestrial civilisations. This theory, known as palaeocontact theory, or Ancient astronaut theory, is not exclusively Däniken's nor did the idea originate with him. Works of this nature are usually marked by the renunciation of well-established theories on the basis of limited evidence, and the interpretation of evidence with a preconceived theory in mind.
Xenoarchaeology is the hypothetical future examination of the archaeology of extraterrestrials. It is theoretical and based in science fiction work, and is not a recognised sub-discipline of archaeology.
Cryptoarchaeology claims to be a valid form of archaeology, in that it may follow commonly accepted best practices and the scientific method of processual archaeology, though it focuses on anomalous discoveries and other such remains that do not adhere to orthodox theory and thought.
Looting of archaeological sites by people in search of hoards of buried treasure is an ancient problem. For instance, many of the tombs of the Egyptian pharaohs were looted in antiquity.
Archaeology stimulates interest in ancient objects, but it can also attract unwelcome attention by looters to these places. The commercial demand for artifacts encourages looting and the illicit antiquities trade, which smuggles items abroad to private collectors. Looters damage or destroy archaeological sites, deny archaeologists valuable information that would be recovered from excavation, and ultimately rob people of the opportunity to know their past.
Popular consciousness often associates looting with poor Third World countries, but this is a false assumption. A lack of financial resources and political will are chronic worldwide problems inhibiting more effective protection of archaeological sites.
In the United States, examples such as the case of Kennewick Man have illustrated the tensions between Native Americans and archaeologists which can be summarized as a conflict between a need to remain respectful towards burials sacred sites and the academic benefit from studying them. For years, American archaeologists dug on Indian burial grounds and other places considered sacred, removing artifacts and human remains to storage facilities for further study. In some cases human remains were not even thoroughly studied but instead archived rather than reburied. Furthermore, Western archaeologists' views of the past often differ from those of tribal peoples. The West views time as linear; for many natives, it is cyclic. From a Western perspective, the past is long-gone; from a native perspective, disturbing the past can have dire consequences in the present.
As a consequence of this, American Indians attempted to prevent archaeological excavation of sites inhabited by their ancestors, while American archaeologists believed that the advancement of scientific knowledge was a valid reason to continue their studies. This contradictory situation was addressed by the Native American Graves Protection and Repatriation Act (NAGPRA, 1990), which sought to reach a compromise by limiting the right of research institutions to possess human remains. Due in part to the spirit of postprocessualism, some archaeologists have begun to actively enlist the assistance of indigenous peoples likely to be descended from those under study.
Archaeologists have also been obliged to re-examine what constitutes an archaeological site in view of what native peoples believe to constitute sacred space. To many native peoples, natural features such as lakes, mountains or even individual trees have cultural significance. Australian archaeologists especially have explored this issue and attempted to survey these sites in order to give them some protection from being developed. Such work requires close links and trust between archaeologists and the people they are trying to help and at the same time study.
While this cooperation presents a new set of challenges and hurdles to fieldwork, it has benefits for all parties involved. Tribal elders cooperating with archaeologists can prevent the excavation of areas of sites that they consider sacred, while the archaeologists gain the elders' aid in interpreting their finds. There have also been active efforts to recruit aboriginal peoples directly into the archaeological profession.
A new trend in the heated controversy between First Nations groups and scientists is the repatriation of native artifacts to the original descendants. An example of this occurred June 21, 2005, when community members and elders from a number of the 10 Algonquian nations in the Ottawa area convened on the Kitigan Zibi reservation in Kanawagi, Quebec, to inter ancestral human remains and burial goods — some dating back 6,000 years.
The ceremony marked the end of a journey spanning thousands of years and many miles. The remains and artifacts, including beads, tools and weapons, were originally excavated from various sites in the Ottawa Valley, including Morrison and the Allumette Islands. They had been part of the Canadian Museum of Civilization’s research collection for decades, some since the late 1800s. Elders from various Algonquin communities conferred on an appropriate reburial, eventually deciding on traditional redcedar and birchbark boxes lined with redcedar chips, muskrat and beaver pelts.
Now, an inconspicuous rock mound marks the reburial site where close to 90 boxes of various sizes are buried. Although negotiations were at times tense between the Kitigan Zibi community and museum, they were able to reach agreement.
Kennewick Man is another repatriation candidate that has been the source of heated debate.


With the exception of theoretical agronomy, research in agronomy, more than in any other field, is strongly related to local areas. It can be considered a science of ecoregions, because it is closely linked to soil properties and climate, which are never exactly the same from one place to another. Many people think an agricultural production system relying on local weather, soil characteristics, and specific crops has to be studied locally. Others feel a need to know and understand production systems in as many areas as possible, and the human dimension of interaction with nature.
Agricultural science is seen by some to have began with Mendel's genetic work, but in modern terms might be better dated from the chemical fertilizer outputs of plant physiological understanding in eighteenth century Germany. Today it is very different from what it was even in 1950. Intensification of agriculture since the 1960s in developed and developing countries, often referred to as the Green Revolution, was closely tied to progress made in selecting and improving crops and animals for high productivity, as well as to developing additional inputs such as artificial fertilizers and phytosanitary products.
As the oldest and largest human intervention in nature, the environmental impact of agriculture in general and more recently intensive agriculture, industrial development, and population growth have raised many questions among agricultural scientists and have led to the development and emergence of new fields. These include technological fields that assume the solution to technological problems lies in better technology, such as integrated pest management, waste treatment technologies, landscape architecture, genomics, and agricultural philosophy fields that include references to food production as something essentially different from non-essential economic 'goods'. In fact, the interaction between these two approaches provide a fertile field for deeper understanding in agricultural science.
New technologies, such as biotechnology and computer science (for data processing and storage), and technological advances have made it possible to develop new research fields, including genetic engineering, agrophysics, improved statistical analysis, and precision farming. Balancing these, as above, are the natural and human sciences of agricultural science that seek to understand the human-nature interactions of traditional agriculture, including interaction of religion and agriculture, and the non-material components of agricultural production systems.
Agriculture sciences seek to feed the world's population while preventing biosafety problems that may affect human health and the environment. This requires promoting good management of natural resources and respect for the environment, and increasingly concern for the psychological wellbeing of all concerned in the food production and consumption system.
Economic, environmental, and social aspects of agriculture sciences are subjects of ongoing debate. Recent crises (such as Avian Flu, mad cow disease and issues such as the use of genetically modified organisms) illustrate the complexity and importance of this debate.


In the history of science, alchemy from Arabic (الكيمياء )(al-kimiya) refers to both an early form of the investigation of nature and an early philosophical and spiritual discipline, both combining elements of chemistry, metallurgy, physics, medicine, astrology, semiotics, mysticism, spiritualism, and art all as parts of one greater force. Alchemy has been practiced in Mesopotamia, Ancient Egypt, Persia, India, Japan, Korea and China, in Classical Greece and Rome, in the Muslim civilization, and then in Europe up to the 19th century—in a complex network of schools and philosophical systems spanning at least 2500 years.
Alchemy was known as the spagyric art after Greek words meaning to separate and to join together. Compare this with the primary dictum of Alchemy in Latin: SOLVE ET COAGULA — Separate, and Join Together.
The best-known goals of the alchemists were the transmutation of common metals into gold (called chrysopoeia) or silver (less well known is plant alchemy, or "spagyric"); the creation of a "panacea or the elixir of life," a remedy that supposedly would cure all diseases and prolong life indefinitely; and the discovery of a universal solvent. Although these were not the only uses for the science, they were the ones most documented and well known. Starting with the Middle Ages, European alchemists invested much effort on the search for the "philosopher's stone", a legendary substance that was believed to be an essential ingredient for either or both of those goals. The Philosophers Stone was believed to mystically amplify the user's knowledge of alchemy so much that anything was attainable. Alchemists enjoyed prestige and support through the centuries, though not for their pursuit of those goals, nor the mystic and philosophical speculation that dominates their literature. Rather it was for their mundane contributions to the "chemical" industries of the day—the invention of gunpowder, ore testing and refining, metalworking, production of ink, dyes, paints, cosmetics, leather tanning, ceramics, glass manufacture, preparation of extracts, liquors, and so on (it seems that the preparation of aqua vitae, the "water of life", was a fairly popular "experiment" among European alchemists).
Starting with the Middle Ages, some alchemists increasingly came to view these metaphysical aspects as the true foundation of alchemy; and organic and inorganic chemical substances, physical states, and molecular material processes as mere metaphors for spiritual entities, spiritual states and ultimately, spiritual transformations. In this sense, the literal meanings of 'Alchemical Formulas' were a blind, hiding their true spiritual philosophy, which being at odds with the Medieval Christian Church was a necessity that could have otherwise lead them to the "stake and rack" of the Inquisition under charges of heresy. Thus, both the transmutation of common metals into gold and the universal panacea symbolized evolution from an imperfect, diseased, corruptible and ephemeral state towards a perfect, healthy, incorruptible and everlasting state; and the philosopher's stone then represented some mystic key that would make this evolution possible. Applied to the alchemist himself, the twin goal symbolized his evolution from ignorance to enlightenment, and the stone represented some hidden spiritual truth or power that would lead to that goal. In texts that are written according to this view, the cryptic alchemical symbols, diagrams, and textual imagery of late alchemical works typically contain multiple layers of meanings, allegories, and references to other equally cryptic works; and must be laboriously "decoded" in order to discover their true meaning.
Q. When the Philosophers speak of gold and silver, from which they extract their matter, are we to suppose that they refer to the vulgar gold and silver?
A. By no means; vulgar silver and gold are dead, while those of the Philosophers are full of life.
Alchemical symbolism has been occasionally used by psychologists and philosophers. Carl Jung reexamined alchemical symbolism and theory and began to show the inner meaning of alchemical work as a spiritual path. Alchemical philosophy, symbols and methods have enjoyed something of a renaissance in post-modern contexts, such as the New Age movement.
Jung saw alchemy as a Western proto-psychology dedicated to the achievement of individuation. In his interpretation, alchemy was the vessel by which Gnosticism survived its various purges into the Renaissance. In this sense, Jung viewed alchemy as comparable to a Yoga of the West. The act of Alchemy seemed to improve the mind and spirit of the Alchemist. His interpretaion of Chinese alchemical texts in terms of his analytical psychology also served as the same function.
Within the Magnum Opus, was the creation of the Sanctum Moleculae, that is the 'Sacred Masses' that were derived from the Sacrum Particulae, that is the 'Sacred Particles', needed to complete the process of achieving the Magnum Opus.
Islamic alchemy was a forerunner of modern scientific chemistry. Alchemists used many of the same laboratory tools that we use today. These tools were not usually sturdy or in good condition, especially during the medieval period of Europe. Many transmutation attempts failed when alchemists unwittingly made unstable chemicals. This was made worse by the unsafe conditions.
Up to the 16th Century, alchemy was considered serious science in Europe; for instance, Isaac Newton devoted considerably more of his time and writing to the study of alchemy (see Isaac Newton's occult studies) than he did to either optics or physics, for which he is famous. Other eminent alchemists of the Western world are Roger Bacon, Saint Thomas Aquinas, Tycho Brahe, Thomas Browne, and Parmigianino. The decline of alchemy began in the 18th century with the birth of modern chemistry, which provided a more precise and reliable framework for matter transmutations and medicine, within a new grand design of the universe based on rational materialism.
In the first half of the nineteenth century, one established chemist, Baron Carl Reichenbach, worked on concepts similar to the old alchemy, such as the Odic force, but his research did not enter the mainstream of scientific discussion.
Matter transmutation, the old goal of alchemy, enjoyed a moment in the sun in the 20th century when physicists were able to convert platinum atoms into gold atoms via a nuclear reaction. However, the new gold atoms, being unstable isotopes, lasted for under five seconds before they broke apart. More recently, reports of table-top element transmutation—by means of electrolysis or sonic cavitation—were the pivot of the cold fusion controversy of 1989. None of those claims have yet been reliably duplicated.
Traditional medicines involve transmutation by alchemy, using pharmacological or combination pharmacological and spiritual techniques. In Chinese medicine the alchemical traditions of pao zhi will transform the nature of the temperature, taste, body part accessed or toxicity. In Ayurveda the samskaras are used to transform heavy metals and toxic herbs in a way that removes their toxicity. In the spagyric processing of herbal medicine similar effects are found. These processes are actively used to the present day.
In 1919, Ernest Rutherford used artificial disintegration to convert nitrogen into oxygen.
The history of alchemy has become a vigorous academic field. As the obscure hermetic language of the alchemists is gradually being "deciphered", historians are becoming more aware of the intellectual connections between that discipline and other facets of Western cultural history, such as the sociology and psychology of the intellectual communities, kabbalism, spiritualism, Rosicrucianism, and other mystic movements, cryptography, witchcraft, and the evolution of science and philosophy.
Alchemy encompasses several philosophical traditions spanning some four millennia and three continents. These traditions' general penchant for cryptic and symbolic language makes it hard to trace their mutual influences and "genetic" relationships.
Famous alchemists include Wei Boyang in Chinese alchemy; Calid, Geber and Rhazes in Arabic alchemy; Nagarjuna in Indian alchemy; and Albertus Magnus and pseudo-Geber in European alchemy; as well as the anonymous author of the Mutus Liber, published in France in the late 17th century, and which was a 'wordless book' that claimed to be a guide to making the philosopher's stone, using a series of 15 symbols and illustrations.
Alchemy, generally, derives (your mother)from the old French alkemie; and the Arabic al-kimia: "the art of transformation." Some scholars believe the Arabs borrowed the word "kimia" from the Greeks. Others, such as Mahdihassan, argue that its origins are Chinese.
Thus, an alchemist was called a 'chemist' in popular speech, and later the suffix "-ry" was added to this to describe the art of the chemist as "chemistry".


Automatic dependent surveillance-broadcast (ADS-B) is an aviation system composed of both Mode-S Extended Squitter (1090 ES) transponders, and Universal Access Transceivers (UAT). These datalink equipped aircraft, and airport surface vehicles periodically broadcast their state vector (horizontal and vertical position, horizontal and vertical velocity) and other aviation related information. ADS-B supports improved use of airspace, reduced ceiling/visibility restrictions, improved surface surveillance, and enhanced safety such as conflict management.
Under ADS-B, a vehicle periodically broadcasts its own state vector and other information without knowing what other vehicles or entities might be receiving it, and without expectation of an acknowledgement or reply. ADS-B is automatic in the sense that no pilot or controller action is required for the information to be issued. It is dependent surveillance in the sense that the surveillance-type information so obtained depends on the suitable navigation and broadcast capability in the source vehicle.
The source of the state vector and other transmitted information as well as user applications are not considered to be part of the ADS-B system.
ADS-B is inherently different from ADS-A, in that ADS-A is based on a negotiated one-to-one peer relationship between an aircraft providing ADS information and a ground facility requiring receipt of ADS messages. For example, ADS-A reports are employed in the Future Air Navigation System (FANS) using the Aircraft Communication Addressing and Reporting System (ACARS) as the communication protocol. During flight over areas without radar coverage (e.g. oceanic, polar), reports are periodically sent by an aircraft to the controlling air traffic region.
The ADS-B link can be used to provide other broadcast services, such as FIS-B and TIS-B. Another potential aircraft-based broadcast capability is to transmit aircraft measurements of meteorological data.
TIS-B supplements ADS-B air-to-air services to provide complete situational awareness in the cockpit of all traffic known to the ATC system. TIS-B is an important service for an ADS-B link in airspace where not all aircraft are transmitting ADS-B information. The ground ADS-B station transmits surveillance target information on the ADS-B data link for unequipped aircraft or aircraft transmitting only on another ADS-B link.
The multilink gateway service is a companion to TIS-B for achieving interoperability in low altitude terminal airspace. Because aircraft that primarily operate in high altitude airspace are equipped with 1090ES, and aircraft operating primarily in low altitude airspace are equipped with UAT, these aircraft cannot share air-to-air ADS-B data. In terminal areas, where both types of ADS-B link are in use, ADS-B ground stations use ground-to-air broadcasts to relay ADS-B reports received on one link to aircraft using the other link.
FIS-B provides weather text, weather graphics, NOTAMs, ATIS, and similar information. FIS-B is inherently different from ADS-B in that it requires sources of data external to the aircraft or broadcasting unit, and has different performance requirements such as periodicity of broadcast.
In the US, FIS-B services will be provided over the UAT link in areas that have a ground surveillance infrastructure.
In addition, FLARM is a simple but highly effective low-cost and low-range implementation of an ADS-B concept which has spread rapidly in general Aviation, especially gliders and helicopters. As a consequence of the low-range and non-certification, there is no ATC downlink.
In 2002, the FAA has announced a dual link decision using 1090 MHz ES and UAT as mediums for the ADS-B system in the United States. The 1090 MHz extended squitter ADS-B link for air carrier and private/commercial operators of high performance aircraft, and Universal Access Transceiver (UAT) ADS-B link for the typical general aviation user.
Europe has not officially chosen a physical layer for ADS-B. A number of technologies are in use. However, the influential Eurocontrol CASCADE program uses 1090ES exclusively.
With 1090ES, the existing Mode S transponder (TSO C-112 or a stand alone 1090 MHz transmitter) supports a message type known as the extended squitter (ES) message. It is a periodic message that provides position, velocity, heading, time, and, in the future, intent. The basic ES does not offer intent since current flight management systems do not provide such data – called trajectory change points. To enable an aircraft to send an extended squitter message, the transponder is modified (TSO C-166A) and aircraft position and other status information is routed to the transponder. ATC ground stations and TCAS-equipped aircraft already have the necessary 1090 MHz (Mode S) receivers to receive these signals, and would only require enhancements to accept and process the additional Extended Squitter information. 1090ES does not support FIS-B service.
The UAT system is specifically designed for ADS-B operation. UAT has lower cost and greater uplink capacity than 1090ES. Although 978 MHz resides in the TACAN assigned portion of the aeronautical spectrum, in the US 978 is used for transmission of airborne ADS-B reports and for broadcast of ground-based aeronautical information. UAT users have access to ground-based aeronautical data and can receive reports from proximate traffic (FIS-B and TIS-B). TIS-B provides reports for proximate aircraft through a multilink gateway service that provides ADS-B reports for 1090ES equipped aircraft and non-ADS-B equipped Radar traffic.
The VDL Mode 4 system could utilize one or more of the existing aeronautical VHF frequencies as the radio frequency physical layer for ADS-B transmissions. VDL Mode 4 uses a protocol (STDMA) that allows it to be self-organizing, meaning no master ground station is required. This medium is best used for short message transmissions from a large number of users. VDL Mode 4 systems are under consideration in Northern Europe.
The ADS-B data link supports a number of airborne and ground applications. Each application has its own operational concepts, algorithms, procedures, standards, and user training.
A Cockpit Display of Traffic Information (CDTI) is a generic display that provides the flight crew with surveillance information about other aircraft, including their position. Traffic information for a CDTI may be obtained from one or multiple sources, including ADS-B, TCAS, and TIS-B. Direct air-to-air transmission of ADS-B messages supports display of proximate aircraft on a CDTI.
In addition to traffic based on ADS-B reports, a CDTI function might also display current weather conditions, terrain, airspace structure, obstructions, detailed airport maps, and other information relevant to the particular phase of flight.
Eventually, the ACAS function may be provided based solely on ADS-B, without requiring active interrogations of other aircraft transponders.
The U.S. FAA ADS-B implementation is broken into three segments each with a corresponding time line. Ground segment implementation and deployment is expected to begin in 2009 and be completed by 2013 throughout the National Airspace System. Airborne equipage is user driven and is expected to be completed both voluntarily based on perceived benefits and through regulatory actions (Rulemaking) by the FAA. The cost to equip with ADS-B Out capability is relatively small and would benefit the airspace with surveillance in areas not currently served by radar. The FAA intends to provide similar service within the NAS to what radar is currently providing (5NM en route and 3NM terminal radar standards) as a first step to implementation. However, ADS-B In capability is viewed as the most likely way to improve NAS throughput and enhance capacity.
ADS-B deployment and voluntary equipage, along with rule making activities. Pockets of development will exploit equipment deployment in the areas that will provide proof of concept for integration to ATC automation systems deployed in the NAS.
ADS-B In equipage will be based on user perceived benefit, but is expected to be providing increased situational awareness and efficiency benefits within this segment. Those aircraft who choose to equip in advance of any mandate will see benefits associated with preferential routes and specific applications. Limited radar decommissioning will begin in the time frame with an ultimate goal of a 50% reduction in the Secondary Surveillance Radar infrastructure.
A concern for any ADS-B protocol is the capacity for carrying ADS-B messages from aircraft, as well as allowing the radio channel to continue to support any legacy services. For 1090ES, each ADS-B message is composed of a pair of data packets. The greater the number of packets transmitted from one aircraft, the lesser the number of aircraft that can participate in the system, due to the fixed and limited channel data bandwidth.
System capacity is defined by establishing a criterion for what the worst environment is likely to be, then making that a minimum requirement for system capacity. For 1090ES, both TCAS and ATCRBS are existing users of the channel. 1090ES ADS-B must not reduce capacity of these existing systems.
The FAA national program office and other International aviation regulators are addressing concerns about ADS-B non-secure nature of ADS-B transmissions. ADS-B messages can be used to know the location of an aircraft, and there is no means to guarantee that this information is not used inappropriately. Additionally, there are some concerns about the integrity of ADS-B transmissions. ADS-B messages can be produced, with simple low cost measures, which spoof the locations of multiple phantom aircraft to disrupt safe air travel. There is no foolproof means to guarantee integrity, but there are means to monitor for this type of activity.
There are some concerns about ADS-B dependence. The system does not function independently, to the extent that the "D" in "ADS-B" stands for "Dependent". An independent means of verifying surveillance is considered by some to have more value than a dependent means.
There are some General Aviation concerns that ADS-B removes anonymity of the VFR aircraft operations. The ICAO 24-bit transponder code specifically assigned to each aircraft will allow monitoring of that aircraft when within the service volumes of the ADS-B system. Unlike the current Mode A/C transponders, there is no code "1200", which offers casual anonymity. ADS-B identifies the aircraft uniquely among all in the world.
Currently there are no laws preventing anyone from listening to and decoding ADS-B transmissions. Like Cellular Phone however, laws can easily implemented to make reception a crime. The ongoing debate amongst hobbyists is to display real-time activity on personal screens and then delay five minutes on networked displays. Others feel that, like GPS data, it should be freely available.
Two receivers are currently popular, but they are first generation and quite expensive. The first on the market was Kinetic Avionics with their SBS-1 and SBS-2 products. The second was the AirNav RadarBox. The Kinetic products are designed to be closed and proprietary systems. In the last few years they have become even more secretive, and no longer communicate with the end-users. On the other hand, there is good customer support from their dealers. Just the opposite, AirNav is quite open in their design and communicates with the end-users.
Both of these devices were designed to be portable and do not work as well in the base configuration, as the user must supply expensive low-loss coax between the antenna and receiver (due to microwave losses). Some have corrected this design by cutting the SBS-1 circuit board in half, and moving the receiver to the antenna. The digital half then remains next to the computer. With this modification video grade coax can then be used (50 ohms).
Both products have specialized single-use receivers in them. Unlike most radios there is no Intermediate Frequency (IF). The ADS-B data flows from the antenna through an LNA pre-amp. It is bandwidth filtered, and then the pulses are extracted using a logarithmic amplifier chip. This chip can operate directly at the ADS-B frequency of 1090 MHz. These analog pulses are then applied to a high speed analog to digital (A/D) converter (40 MHz for Kinetic) and then on to the FPGA (Field-Programmable Gate Array), where the Mode-S frames are detected. The detected Mode-S packets are then sent to the Personal Computer via a USB interface. Both the SBS and RadarBox negotiate a secret key to get the data flowing initially.
Because these are consumer grade devices, the receivers are easily overloaded by nearby aircraft. The closer you get to the airport, the shorter the range volume it will detect. In normal use away from airports, the user will see line-of-sight to the horizon. The microwave signals will not go through mountains or buildings, so altitude and an uncluttered horizon are key to maximum detection. Aircraft may fade-out when banking away from the receiver location. Even with these limitations many users can see 100 miles easily with the antenna on their window sill, but usually not in all directions.


Austria () (Österreich), officially the Republic of Austria () (Republik Österreich), is a landlocked country in Central Europe.
It borders both Germany and the Czech Republic to the north, Slovakia and Hungary to the east, Slovenia and Italy to the south, and Switzerland and Liechtenstein to the west. The capital is the city of Vienna on the Danube River.
Austria is a parliamentary representative democracy comprising nine federal states and is one of six European countries that have declared permanent neutrality and one of the few countries that includes the concept of everlasting neutrality in its constitution. Austria has been a member of the United Nations since 1955 and joined the European Union in 1995.
The German name Österreich can be translated into English as the "eastern realm", which is derived from Old German Ostarrîchi. The name was Latinized as "Austria", although it has no etymological connection with the name of Australia (which derives from Latin Australis meaning The South). Reich can also mean "empire," and this connotation is the one that is understood in the context of the Austrian/Austro-Hungarian Empire, Holy Roman Empire, although not in the context of the modern Republic of Österreich. The term probably originates in a vernacular translation of the Medieval Latin name for the region: Marchia orientalis, which translates as "eastern marches" or "eastern borderland", as it was situated at the eastern edge of the Holy Roman Empire, that was also mirrored in the name Ostmark, for a short period applied after the Anschluss to Germany.
However, Friedrich Heer, one the most important Austrian historians in the 20th century, stated in his book Der Kampf um die österreichische Identität (The Austrian Identity), that the Germanic form ostarrîchi was not a translation of the Latin word, but both resulted from a much older term originating in the Celtic languages of ancient Austria: More than 2,500 years ago, the major part of the actual country was called Norig by the Celtic population (Hallstatt culture); No- or Nor- meant East or Eastern, whereas Rig is the realted to the modern German Reich; realm (among other things). Accordingly, Norig would essentially mean ostarrîchi and Österreich, thus Austria. The Celtic name was eventually Latinized to noricum, when the Romans conquered and Romanized the country that later became Austria. The name of Noricum was then used to designate the Roman province.
The current official designation is the Republic of Austria (Republik Österreich). It was originally known after the fall of the Austro-Hungarian Empire from 1918 as the Republic of German Austria (Republik Deutschösterreich), but the state was forced to change its name to "Republic of Austria" in 1919 by the Treaty of Saint-Germain. The name was changed again during the Austro-fascist regime (1934–1938), into Federal State of Austria (Bundesstaat Österreich), but restored after regaining independence and the birth of the Second Austrian Republic (1955–present).
During the period of monarchy, Austria was known as the Austrian Empire (Kaisertum Österreich) ; however no official designation existed since the empire was strongly multiethnic. After the Austro-Hungarian Compromise of 1867, the empire became known as Austria-Hungary reflecting the dual monarchy character.
Settled in prehistoric times, the central European land that is now Austria was occupied in pre-Roman times by various Celtic tribes. The Celtic kingdom of Noricum was claimed by the Roman Empire and made a province. After the fall of the Roman Empire, of which most of Austria was part (all parts south of the Danube), the area was invaded by Bavarians, Slavs and Avars. Charlemagne conquered the area in 788 and encouraged colonization and Christianity. As part of Eastern Francia, the core areas that now encompass Austria were bequeathed to the house of Babenberg. The area was known as the marchia Orientalis and was given to Leopold of Babenberg in 976.
The first record showing the name Austria is from 996 where it is written as Ostarrîchi, referring to the territory of the Babenberg March. The term Ostmark is not historically ascertained and appears to be a translation of marchia orientalis that came up only much later.
The following centuries were characterized by the settlement of the country. In 1156 the Privilegium Minus elevated Austria to the status of a duchy. In 1192, the Babenbergs also acquired the Duchy of Styria.
With the death of Frederick II in 1246, the line of the Babenbergers went extinct. Otakar II of Bohemia effectively controlled the duchies of Austria, Styria and Carinthia after that. His reign came to an end with his defeat at Dürnkrut at the hand of Rudolf I of Germany in 1278. Thereafter, until World War I, Austria's history was largely that of its ruling dynasty, the Habsburgs.
In the fourteenth and fifteenth centuries, the Habsburgs began to accumulate other provinces in the vicinity of the Duchy of Austria. In 1438, Duke Albert V of Austria was chosen as the successor to his father-in-law, Emperor Sigismund. Although Albert himself only reigned for a year, from then on, every emperor of the Holy Roman Empire was a Habsburg, with only one exception.
The Habsburgs began also to accumulate lands far from the Hereditary Lands. In 1477, Archduke Maximilian, only son of Emperor Frederick III, married the heiress Maria of Burgundy, thus acquiring most of the Low Countries for the family. His son Philip the Fair married the heiress of Castile and Aragon, and thus acquired Spain and its Italian, African, and New World appendages for the Habsburgs.
In 1526, following the Battle of Mohács, Austrian rulers expanded their territories, bringing Bohemia and the part of Hungary not occupied by the Ottomans under their rule. Ottoman expansion into Hungary led to frequent conflicts between the two powers, particularly evident in the so-called Long War of 1593 to 1606.
The long reign of Leopold I (1657–1705) saw the culmination of the Austrian conflict with the Turks. Following the successful defense of Vienna in 1683, a series of campaigns resulted in the return of all of Hungary to Austrian control by the Treaty of Carlowitz in 1699.
The later part of the reign of Emperor Charles VI (1711–1740) saw Austria relinquish many of these fairly impressive gains, largely due to Charles's apprehensions at the imminent extinction of the House of Habsburg. Charles was willing to offer concrete advantages in territory and authority in exchange for other powers' worthless recognitions of the Pragmatic Sanction that made his daughter Maria Theresa his heir. With the rise of Prussia the Austrian–Prussian dualism began in Germany.
Austria became engaged in the war with Revolutionary France, which lasted until 1797 and at the beginning proved unsuccessful for Austria. Defeats by Napoleon meant the end of the old Holy Roman Empire in 1806. Just two years before the abolition of the Holy Roman Empire in 1806, in 1804 the Empire of Austria was founded, which was transformed in 1867 into the dual-monarchy Austria-Hungary. However, in 1814 Austria was part of the Allied forces invading France and conquering it. Following the Napoleonic wars Austria emerged from the Congress of Vienna in 1815 as one of three of the continent's dominant powers (together with Russia and Prussia). In 1815 the German Confederation, (German) Deutscher Bund was founded under the presidency of Austria. Austria and Prussia were the leading powers of the German Confederation. Its central institution was the Bundesversammlung in Frankfurt. Because of unsolved social, political and national conflicts some of the German inhabitants took part in the 1848 revolution to create a unified Germany. The Frankfurt Parliament in the St. Paul's Church elected the arch duke Johann of Habsburg as a Reichsverweser, an administrator of the German Empire. For a new German empire would have been possible three options: a Greater Germany Großdeutschland with the German-speaking territories of the Habsburg Empire, a Greater Austrian solution, Großösterreich, the German Confederation with the whole Habsburgian territories, and a smaller German solution, Kleindeutsche the German Confederation without Austria at all. As Austria was not willing to relinquish its German-speaking territories to what would become the German Empire of 1848 the parliament offered the crown to the Prussian King Friedrich Wilhelm IV. Austria grew out of Germany, Prussia grew in. In 1864 Austria and Prussia fought together against Denmark, to free the independent duchies of Schleswig and Holstein. Austria and Prussia could not agree on a solution to the administration of Schleswig and Holstein, which led to the Austro-Prussian War of 1866. Austria, together with most of the other German states, was defeated by Prussia in the Battle of Königgrätz in Bohemia. Austria had to leave the Germanic Confederation and subsequently no longer took part in German politics. After 1871, it was one of two Empires: the German Empire to the north and Austria-Hungary to the south.
The Austro-Hungarian Compromise of 1867, the Ausgleich, provided for a dual sovereignty, the empire of Austria and the kingdom of Hungary, under Franz Joseph I, who ruled until his death on 21 November 1916. The German-Hungarian rule of this diverse empire, which included various Slav groups such as Poles, Ukrainians, Czechs, Slovaks, Slovenes, Serbs and Croats, as well as large Italian and Romanian communities. As a result, ruling Austria-Hungary became increasingly difficult in an age of emerging nationalist movements. Yet the central government tried its best to be accommodating in some respects; minorities were entitled to schools in their own language, for example.
The assassination of Archduke Franz Ferdinand in Sarajevo in 1914 by Gavrilo Princip (a member of the Serbian nationalist group the Black Hand) was the immediate cause for the outbreak of World War I, leading to the downfall and the end of the Austro-Hungarian Empire. War left the country in political chaos and economic ruin, the Central Powers (being Austria-Hungary, Bulgaria, Germany and Turkey) having been defeated in 1918. The Empire was broken up - Austria, with most of the German-speaking parts became a republic (see Treaty of Saint-Germain) and the remaining subordinate territories became independent states. However, over 3 million German Austrians found themselves living outside of the Allied inspired borders of the Austrian Republic in the nations of Czechoslovakia, Yugoslavia, Hungary and Italy. A particular large German minority was found in the newly-established Czechoslovakia with the entire historic German populations of Bohemia, Moravia and Austrian Silesia cut off from their motherland of Austria. Austria was also deprived of half of Tyrol, which was awarded to Italy as a prize for entering the war on the Allied side. Austria has sustained this loss to the present day and this had been a major source of friction with Italy until the 1980's. Today the situation in South Tyrol is resolved, serving as a model for inter-ethnic and transnational cooperation in Europe.
Between 1918 and 1919, Austria was officially known as the Republic of German Austria (Republik Deutschösterreich). Many territories it claimed under its control included regions that were later assigned to neighboring nations. Not only did the Entente powers forbid German Austria to unite with Germany, they also forbade the name; it was therefore changed to the Republic of Austria. The monarchy was dissolved in 1919 and a parliamentary democracy was set up under the constitution of 10 November 1920.
In the autumn of 1922, Austria was granted an international loan supervised by the League of Nations. The purpose of the loan was to avert bankruptcy, stabilize the currency, and improve its general economic condition. With the granting of the loan, Austria passed from an independent state to the control exercised by the League of Nations. At the time, the real ruler of Austria became the League, through its commissioner in Vienna. The commissioner was a Dutchman not formally part of the Austrian government. Austria had fallen under an international receivership, which had not been seen openly since Lord Croner became the financial adviser to the bankrupt Khedivial Government of Egypt a little less than half a century earlier.
The First Austrian Republic, lasted until 1933 when Chancellor Engelbert Dollfuss dissolved parliament and established an autocratic regime tending towards Italian fascism, (Austrofascism) in order, partly, to check the power of Nazis who were still advocating union with Germany.
The two big parties at this time —the Social Democrats and the Conservatives— had paramilitary armies, which fought each other. The "Heimwehr" (later integrated into the "Vaterländische Front"), the paramilitary arm of the Conservative party supported Dollfuss' s Fascist regime; the "Republikanischer Schutzbund", was the military arm of the Social Democrats which was outlawed in 1933 but still existed underground - civil war was to break out.
After the Austrian Civil War in February 1934, several members of the Schutzbund were executed, the Social Democratic party was outlawed and many of its members were imprisoned or emigrated. In May of that year the Fascists introduced a new constitution ("Maiverfassung") which cemented Dollfuss's power but on 25 July he was assassinated in a Nazi coup attempt.
His successor Kurt Schuschnigg, struggled to keep Austria independent (even a restoration of the Habsburgs was contemplated), but on 12 March 1938 German troops occupied the country and established a plebiscite confirming union with Germany. Hitler, himself a native of Austria who had lost Austrian citizenship in 1925, proclaimed its Anschluss with Germany, incorporating it to the Third Reich. Austria thus ceased to exist as an independent state; the Nazis called it Ostmark until 1942 when it was again renamed Alpen-Donau-Reichsgaue.
Just before the collapse of the Third Reich, the defeat of Germany and the end of the war in 1945, Karl Renner astutely set up a Provisional Government in Vienna in April of that year with the tacit approval of the Soviet forces, and declared Austria's secession from the Third Reich.
Much like Germany, Austria, too, was divided into a British, a French, a Soviet and an American Zone and governed by the Allied Commission for Austria. Largely owing to Karl Renner's action on April 27th in setting up a Provisional Government, however, there was a subtle difference in the treatment of Austria by the Allies. The Austrian Government was recognized and tolerated by the Four Powers. Austria, in general, was treated like it had been originally invaded by Germany and liberated by the Allies.
Although the Eastern part of Austria, including the greater Vienna area, lay in the Soviet Zone, the capital itself was equally divided into four occupational zones. Outside of Vienna, however, travel across zone borders, in particular leaving or entering the Soviet zone, was difficult and time-consuming if possible at all. During the time of the Berlin Air Lift, Soviet military pressure was increased further, but could be successfully overcome by skillful military, political and diplomatic influence on the part of the other Allies.
On 15 May 1955 Austria regained full independence by concluding the Austrian State Treaty with the Four Occupying Powers. On 26 October 1955 Austria was declared "permanently neutral" by act of Parliament, which it remains to this day.
The political system of the Second Republic came to be characterized by the system of Proporz, meaning that most posts of some political importance were split evenly between members of the Social Democrats (Labour Party) and the People's Party (Conservatives).
Interest group representations with mandatory membership (e.g. for workers, businesspeople, farmers etc.) grew to considerable importance and were usually consulted in the legislative process, so that hardly any legislation was passed that did not reflect widespread consensus. The Proporz and consensus systems largely held even during the years between 1966 and 1983, when there were non-coalition governments, but this era has now passed.
Austria today has five major political parties: The SPÖ (Labour Party), the ÖVP (Conservatives), the "Greens" (Environmental, social-liberal) and FPÖ/BZÖ (both right-wing, nationalist). SPÖ and ÖVP share about 75% of the parliamentary mandates, while the remaining 25% are divided between the other three parties.
Austria became a member of the European Union in 1995 and retained its constitutional neutrality, like some other EU members, such as Sweden. The major parties SPÖ and ÖVP have contrary opinions about the future status of Austria's military neutrality: While the SPÖ supports a neutral role in the EU (together with other neutral EU members like Sweden), the ÖVP argues for stronger integration into the EU's security policy; even a future NATO is not ruled out by some ÖVP politicians. Since the "permanent neutrality" forms part of the Austrian constitution, a two-thirds majority in the Austrian parliament would be needed for such a change in policy.
The Parliament of Austria is located in Vienna, the nation's largest city and capital. Austria became a federal, parliamentarian, democratic republic through the Federal Constitution of 1920. It was reintroduced in 1945 to the nine states of the Federal Republic. The head of state is the Federal President, who is directly elected by popular vote. The chairman of the Federal Government is the Federal Chancellor, who is appointed by the president. The government can be removed from office by either a presidential decree or by vote of no confidence in the lower chamber of parliament, the Nationalrat.
The Parliament of Austria consists of two chambers. The composition of the Nationalrat is determined every five years by a general election in which every citizen over 16 years (since 2007) is allowed to vote to fill its 183 seats. A recent extension of that term from four to five years will become effective after the next election. While there is a general threshold of 4 percent for all parties at federal elections (Nationalratswahlen), there remains the possibility to gain a direct seat, or Direktmandat, in one of the 43 regional election districts. The Nationalrat is the dominant chamber in the formation of legislation in Austria. However, the upper house of parliament, the Bundesrat has a limited right of veto (the Nationalrat can — in almost all cases — ultimately pass the respective bill by voting a second time. This is referred to as 'Beharrungsbeschluss, lit. "vote of persistence"). A convention, called the Österreich -Konvent was convened in June 30, 2003 to decide upon suggestions to reform the constitution, but has failed to produce a proposal that would receive the two thirds of votes in the Nationalrat necessary for constitutional amendments and/or reform. However, some important parts of the final report were generally agreed upon and are still expected to be implemented.
In September 2002, the coalition between the People's Party and the Freedom Party dissolved after a shake-up in the Freedom Party. In November 2002, the People's Party made large gains in general elections again. After a lot of coalition talks with other parties, the People's Party again formed a government with the Freedom Party in February 2003 with Wolfgang Schüssel as Chancellor.
After general elections held in October 2006, the Social Democrats emerged as the largest party, whereas the People's Party lost about 8% in votes. Political realities prohibited any of the two major parties from forming a coalition with smaller parties. In January 2007 the People's Party and Social Democrats formed a Grand Coalition with the social democrat Alfred Gusenbauer as Chancellor.
The 1955 Austrian State Treaty ended the occupation of Austria following World War II and recognized Austria as an independent and sovereign state. In October 1955, the Federal Assembly passed a constitutional law in which "Austria declares of her own free will her perpetual neutrality." The second section of this law stated that "in all future times Austria will not join any military alliances and will not permit the establishment of any foreign military bases on her territory." Since then, Austria has shaped its foreign policy on the basis of neutrality.
Austria began to reassess its definition of neutrality following the fall of the Soviet Union, granting overflight rights for the UN-sanctioned action against Iraq in 1991, and, since 1995, contemplating participation in the EU's evolving security structure. Also in 1995, it joined the Partnership for Peace and subsequently participated in peacekeeping missions in Bosnia.
Austria attaches great importance to participation in the Organisation for Economic Co-operation and Development and other international economic organizations, and it has played an active role in the Organization for Security and Cooperation in Europe (OSCE).
In 1972, the country began construction of a nuclear-powered electricity-generation station at Zwentendorf on the River Danube, following a unanimous vote in parliament. However, in 1978, a referendum voted approximately 50.5% against nuclear power, 49.5% for, and parliament subsequently unanimously passed a law forbidding the use of nuclear power to generate electricity.
Austria currently produces more than half of its electricity by hydropower. Together with other renewable energy sources such as wind, solar and biomass powerplants, the electricity supply from renewable energy amounts to nearly 80% of total use in Austria. The rest is produced by gas and oil powerplants.
The manpower of the Austrian Armed Forces ("Bundesheer") mainly relies on conscription. All males who have reached the age of eighteen and are found fit get recruited for a six months long military service, which can be postponed under some circumstances. Conscientious objection is legally possible and obliges to serve an institutionalized nine months civilian service instead.
Only since 1998, women can volunteer to become professional soldiers.
The main sectors of the Bundesheer are Joint Forces (Streitkräfteführungskommando, SKFüKdo) which consist of Land Forces (Landstreitkräfte), Air Forces (Luftstreitkräfte), International Missions (Internationale Einsätze), and Special Forces (Spezialeinsatzkräfte) ; next to Mission Support (Kommando Einsatzunterstützung; KdoEU) and Command Support (Kommando Führungsunterstützung; KdoFüU). In 2004, Austria expends about 0.9% of its GDP for defense. The Army currently has about 45,000 soldiers, of which about half are conscripts. As head of state, Austrian President (currently Heinz Fischer) is nominally the Commander-in-Chief of the Bundesheer. In practical reality, however, command of the Austrian Armed Forces is almost exclusively exercised by the Minister of Defense, currently Norbert Darabos.
With the end of the Cold War, and more importantly the removal of the former heavily guarded "Iron Curtain" separating Austria and Hungary, the Austrian military have been assisting Austrian border guards in trying to prevent border crossings by illegal immigrants. This assistance will come to an end when Hungary joins the EU Schengen area in 2008, for all intents and purposes abolishing "internal" border controls between treaty states. Some politicians have called for a prolongation of this mission, but the legality of this is heavily disputed. In accordance with the Austrian constitution, armed forces may only be deployed in a limited number of cases, mainly to defend the country and aid in cases of national emergencies, such as in the wake of natural disasters etc. They may generally not be used as auxiliary police forces.
Despite, or perhaps because of, its self-declared status of permanent neutrality, Austria has a long and proud tradition of engaging in UN-led peacekeeping and other humanitarian missions. The Austrian Forces Disaster Relief Unit (AFDRU), in particular, an all-volunteer unit with close ties to civilian specialists (rescue dog handlers, etc) enjoys a reputation as a quick (standard deployment time is 10 hours) and efficient SAR unit. Currently, larger contingents of Austrian forces are deployed in Bosnia, Kosovo and, since 1974, on the Golan Heights.
As a federal republic, Austria is divided into nine states (). These states are then divided into districts (Bezirke) and cities (Statutarstädte). Districts are subdivided into municipalities (Gemeinden). Cities have the competencies otherwise granted to both districts and municipalities. The states are not mere administrative divisions but have some distinct legislative authority separate from the federal government.
Austria is a largely mountainous country due to its location in the Alps. The Central Eastern Alps, Northern Limestone Alps and Southern Limestone Alps are all partly in Austria. Of the total area of Austria (84 000 km² or 32,000 sq. mi), only about a quarter can be considered low lying, and only 32% of the country is below 500 meters (1,640 ft). The high mountainous Alps in the west of Austria flatten somewhat into low lands and plains in the east of the country.
Austria can be divided into five areas. The biggest area are the Austrian Alps, which constitute 62% of Austria's total area. The Austrian foothills at the base of the Alps and the Carpathians account for around 12% of its area. The foothills in the east and areas surrounding the periphery of the Pannoni low country amount to about 12% of the total landmass. The second greater mountain area (much lower than the Alps) is situated in the north. Known as the Austrian granite plateau, it is located in the central area of the Bohemian Mass, and accounts for 10% of Austria. The Austrian portion of the Vienna basin comprises the remaining 4%.
The greater part of Austria lies in the cool/temperate climate zone in which humid westerly winds predominate. With over half of the country dominated by the Alps the alpine climate is the predominant one. In the East, in the Pannonian Plain and along the Danube valley, the climate shows continental features with less rain than the alpine areas. Although Austria is cold in the winter, in the summer temperatures can be relatively warm reaching 20-35 degrees Celsius.
Austria is one of the 10 richest countries in the world in terms of GDP per capita, has a well-developed social market economy, and a very high standard of living. Until the 1980s, many of Austria's largest industry firms were nationalised; in recent years, however, privatisation has reduced state holdings to a level comparable to other European economies. Labour movements are particularly strong in Austria and have large influence on labour politics. Next to a highly-developed industry, international tourism is the most important part of the national economy.
Germany has historically been the main trading partner of Austria, making it vulnerable to rapid changes in the German economy. But since Austria became a member state of the European Union it has gained closer ties to other European Union economies, reducing its economic dependence on Germany. In addition, membership in the EU has drawn an influx of foreign investors attracted by Austria's access to the single European market and proximity to EU aspiring economies. Growth in GDP accelerated in recent years and reached 3.3% in 2006.
Responsibility for educational oversight in Austria lies partly at the Austrian states (Bundesländer), and partly with the federal government. Optional kindergarten education is provided for all children between the ages of three and six years. School attendance is compulsory for nine years, i.e. usually to the age of fifteen. The Programme for International Student Assessment, coordinated by the OECD, currently ranks Austria's education as the 18th best in the world, being significantly higher than the OECD average.
Primary education lasts for four years. Alongside Germany, secondary education includes two main types of schools based on a pupil's ability as determined by grades from the primary school: the Gymnasium for the more gifted children which normally leads to the Matura which is a requirement for access to universities and the Hauptschule which prepares pupils for vocational education but also for further education (HTL = institution of higher technical education; HAK = commercial academy; HBLA = institution of higher education for economic business; etc.), where you also get the Matura.
The Austrian university system had been open to any student who passed the Matura examination until recently. A 2006 bill allowed the introduction of entrance exams for studies such as Medicine. Currently all EU students are charged a fee of about €370 per semester for all university studies. A recent OECD report criticized the Austrian education system for the low number of students attending universities and the overall low number of academics compared to other OECD countries.
Austria's population estimate in October 2006 was 8,292,322. The population of the capital, Vienna, exceeds 1.6 million (2.2 million with suburbs), representing about a quarter of the country's population and is known for its vast cultural offerings and high standard of living.
In contrast to the capital, other cities do not exceed 1 million inhabitants: the second largest city Graz is home to 250,099 inhabitants, followed by Linz (188,968), Salzburg (150,000), and Innsbruck (117,346). All other cities have fewer than 100,000 inhabitants.
German-speaking Austrians, by far the country's largest group, form roughly 90% of Austria's population. The Austrian federal states of Carinthia and Styria are home to a significant indigenous Slovenian speaking minority with around 14,000 members (Austrian census; unofficial numbers of Slovene groups speak of up to 50,000). In the east-most Bundesland, Burgenland (formerly part of the Hungarian half of Austria-Hungary) about 20,000 of Austrian citizens speak Hungarian and 30,000 speak Croatian. The remaining number of Austria's people are of non-Austrian descent, many from surrounding countries, especially from the former East Bloc nations. So-called guest workers (Gastarbeiter) and their descendants, as well as refugees from Yugoslav wars and other conflicts, also form an important minority group in Austria. Since 1994 the Roma-Sinti (gypsies) are an officially recognized ethnic minority in Austria.
According to census information published by Statistik Austria for the year 2001 () there were a total of 710,926 foreign nationals living in Austria. Of these, 124,392 speak German as their mother tongue (presumably immigrants from Germany, Switzerland, Liechtenstein, the Windische Slovenians and also the South Tyrolian part of northern Italy.) The next largest populations of linguistic and ethnic groups are 240,863 foreign nationals from the former Yugoslavia (Serbian being the largest number of these at 135,376, followed by Croatian at 105,487); 123,417 Turkish nationals; 25,155 whose native tongue is English; 24,446 Albanian; 17,899 Polish; 14,699 Hungarian; 12,216 Romanian; 7,982 Arabs; 6,902 Slovenian (not including the Windisch minority); 6,891 Slovakian; 6,707 Czech; 5,916 Persian; 5,677 Italian; 5,466 Russian; 5,213 French; 4,938 Chinese; 4,264 Spanish; 3,503 Bulgarian. The populations of the rest fall off sharply below 3,000.
The mother tongue of the population by prevalence, is German (88.6%) followed by Turkish (2.3%), Serbian (2.2%), Croatian (1.6%), Hungarian (0.5%) and Bosnian (0.4%).
The official language, German, is spoken by almost all residents of the country. Austria's mountainous terrain led to the development of many distinct German dialects. All of the dialects in the country, however, belong to Austro-Bavarian groups of German dialects, with the exception of the dialect spoken in its western-most Bundesland, Vorarlberg, which belongs to the group of Alemannic dialects. There is also a distinct grammatical standard for Austrian German with a few differences to the German spoken in Germany.
As of 2006, some of the Austrian states introduced standardised tests for new citizens, to assure their language ability, cultural knowledge and accordingly their ability to integrate into the Austrian society.
An estimated 13,000 to 40,000 Slovenians in the Austrian state of Carinthia (the Carinthian Slovenes) as well as Croatians (around 30,000) and Hungarians in Burgenland were recognized as a minority and have enjoyed special rights following the Austrian State Treaty (Staatsvertrag) of 1955. The Slovenians in the Austrian state of Styria (estimated at a number between 1,600 and 5,000) are not recognized as a minority and do not enjoy special rights, although the State Treaty of July 27 1955 states otherwise.
The right for bilingual topographic signs for the regions where Slovene- and Croat-Austrians live alongside the Germanic population (as required by the 1955 State Treaty) is still to be fully implemented. Many Carinthians are afraid of Slovenian territorial claims, pointing to the fact that Yugoslav troops entered the state after each of the two World Wars and considering that some official Slovenian atlases show parts of Carinthia as Slovenian cultural territory. The current governor, Jörg Haider, has made this fact a matter of public argument in autumn 2005 by refusing to increase the number of bilingual topographic signs in Carinthia. A poll by the Kärntner Humaninstitut conducted in January 2006 states that 65% of Carinthians are not in favour of an increase of bilingual topographic signs, since the original requirements set by the State Treaty of 1955 have already been fulfilled according to their point of view. Another interesting phenomenon is the so called "Windischen-Theorie" stating that the Slovenians can be split in two groups: actual Slovenians and Windische (a traditional German name for Slavs), based on differences in language between Austrian Slovenians, who were taught Slovenian standard language in school and those Slovenians who spoke their local Slovenian dialect but went to German schools. The term Windische was applied to the latter group as a means of distinction. This theory was never generally accepted and fell out of use some decades ago.
At the end of the twentieth century, about 74% of Austria's population were registered as Roman Catholic, while about 5% considered themselves Protestants. Both these numbers have been in decline for decades, especially Roman Catholicism, which has suffered an increasing number of seceders from the church. Austrian Catholics are obliged to pay a mandatory tax (calculated by income —about 1%) to the Austrian Roman Catholic Church, which might (have) act(ed) as an incentive to leave the church.
About 12% of the population declare that they have no religion. Of the remaining people, about 180,000 are members of Eastern Orthodox Churches and about 8,100 are Jewish. It has to be noted that the Austrian Jewish Community of 1938 – Vienna alone counted more than 200,000 - was reduced to solely 4,000 to 5,000 after the Second World War. The influx of Eastern Europeans, especially from the former Yugoslav nations, Albania and particularly from Turkey largely contributed to a substantial Muslim minority in Austria — around 340,000 are registered as members of various Muslim communities. Buddhism, which was legally recognized as a religion in Austria in 1983 has a following of 20,000 (10,402 at the 2001 census).
While northern and central Germany was the origin of the Reformation, Austria (and Bavaria) was the heart of the Counter-Reformation in the sixteenth and seventeenth centuries, when the absolute monarchy of Habsburg imposed a strict regime to maintain Catholicism's power and influence among Austrians. The Habsburgs viewed themselves as the vanguard of Roman Catholicism and all other confessions and religions were oppressed. In 1781, Emperor Joseph II issued a Patent of Tolerance that allowed other Christian confessions a limited freedom of worship. Religious freedom was declared a constitutional right in the Austro-Hungarian Ausgleich in 1867 thus paying tribute to the fact that the monarchy was home of numerous religions beside Roman Catholicism such as Greek, Serbian, Romanian, Russian, and Bulgarian Orthodox Christians (Austria neighboured the Ottoman empire for centuries), and both Calvinist and Lutheran Protestants.
Austria continued to remain largely influenced by Catholicism. After 1918, First Republic Catholic leaders such as Theodor Innitzer and Ignaz Seipel took leading positions within or close to Austria's government and increased their influence during the time of the Austrofascism —Catholicism was treated much like a state religion by Engelbert Dollfuss and Kurt Schuschnigg. Although Catholic leaders welcomed the Germans in 1938 during the Anschluss of Austria into Germany, Austrian Catholicism stopped its support of Nazism later on and many former religious public figures became involved with the resistance during the Third Reich. After 1945, a stricter secularism was imposed in Austria, and religious influence on politics declined.
Austria's past as a European power and its cultural environment have generated a broad contribution to various forms of art, most notably among them music. Austria has been the birthplace of many famous composers such as Wolfgang Amadeus Mozart, Joseph Haydn, Franz Schubert, Anton Bruckner, Johann Strauss, Sr. Johann Strauss, Jr. and Gustav Mahler as well as members of the Second Viennese School such as Arnold Schoenberg, Anton Webern and Alban Berg.
Vienna has long been especially an important center of musical innovation. Eighteenth and nineteenth century composers were drawn to the city due to the patronage of the Habsburgs, and made Vienna the European capital of classical music. During the Baroque period, Slavic and Hungarian folk forms influenced Austrian music. Vienna's status began its rise as a cultural center in the early 1500s, and was focused around instruments including the lute. Ludwig van Beethoven spent the better part of his life in Vienna.
Austria's current national anthem was chosen after World War II to replace the traditional Austrian anthem by Joseph Haydn. The composition, which was initially attributed to Mozart, was most likely not composed by Mozart himself.
Austria has also produced one notable jazz musician, keyboardist Josef Zawinul who helped pioneer electronic influences in jazz as well as being a notable composer in his own right. Falco was an internationally acclaimed pop and rock musician.
Among Austrian artists and architects one can find painters Gustav Klimt, Oskar Kokoschka, Egon Schiele or Friedensreich Hundertwasser, photographer Inge Morath or architect Otto Wagner.
Austria was the cradle of numerous scientists with international reputations. Among them are Ludwig Boltzmann, Ernst Mach, Victor Franz Hess and Christian Doppler, prominent scientists in the nineteenth century. In the twentieth century, contributions by Lise Meitner, Erwin Schrödinger and Wolfgang Pauli to nuclear research and quantum mechanics were key to these areas' development during the 1920s and 1930s. A present-day quantum physicist is Anton Zeilinger, noted as the first scientist to demonstrate quantum teleportation.
In addition to physicists, Austria was the birthplace of two of the greatest philosophers of the twentieth century, Ludwig Wittgenstein and Karl Popper. In addition to them biologists Gregor Mendel and Konrad Lorenz as well as mathematician Kurt Gödel and engineers such as Ferdinand Porsche and Siegfried Marcus were Austrians.
A focus of Austrian science has always been medicine and psychology, starting in medieval times with Paracelsus. Eminent physicians like Theodore Billroth, Clemens von Pirquet, and Anton von Eiselsberg have built upon the achievements of the 19th century Vienna School of Medicine. Austria was home to psychologists Sigmund Freud, Alfred Adler, Paul Watzlawick and Hans Asperger and psychiatrist Viktor Frankl.
The Austrian School of Economics, which is prominent as one of the main competitive directions for economic theory, is related to Austrian economists Joseph Schumpeter, Eugen von Böhm-Bawerk, Ludwig von Mises, and Friedrich Hayek.
Other noteworthy Austrian-born émigrés include the management thinker Peter Drucker and the 38th Governor of California, Arnold Schwarzenegger.
Complementing its status as a land of artists and scientists, Austria has always been a country of poets, writers, and novelists. It was the home of novelists Arthur Schnitzler, Stefan Zweig, Thomas Bernhard, Franz Kafka, and Robert Musil, of poets Georg Trakl, Franz Werfel, Franz Grillparzer, Rainer Maria Rilke, and Adalbert Stifter, and of writer Karl Kraus.
Famous contemporary playwrights and novelists are Nobel prize winner Elfriede Jelinek and writer Peter Handke.
Austria's cuisine is derived from the cuisine of the Austro-Hungarian Empire. In addition to native regional traditions, it has been influenced above all by Hungarian, Czech, Jewish, Italian and Bavarian cuisines, from which both dishes and methods of food preparation have often been borrowed. The Austrian Cuisine is therefore one of the most multi and transcultural cuisines in Europe.
Typical Austrian dishes include Wiener Schnitzel, Schweinsbraten, Kaiserschmarren, Knödel, Sachertorte and Tafelspitz. There are also Kasnockn, a macaroni dish with fresh Pinzgauer cheese and parsley, and Eierschwammerl (chanterelle) dishes. The Eierschwammerl are the native yellow, tan mushrooms. These mushrooms are delicious, especially when in a thick Austrian soup, or on regular meals.
The candy PEZ was invented in Austria. Austria is also famous for its Apfelstrudel.
The most popular sport in Austria is alpine skiing and Austria shows constant dominance in the Nations-Cup. Similar sports such as snowboarding or ski-jumping are also widely popular.
The most popular team sport in Austria is football. However, Austria rarely has international success in this discipline, though the 2008 UEFA European Football Championship is jointly being held with Switzerland. Besides football, Austria also has professional national leagues for most major team sports including ice hockey and basketball.

American Samoa ( or Sāmoa Amelika) is an unincorporated territory of the United States located in the South Pacific Ocean, southeast of the sovereign state of Samoa. The main (largest and most populous) island is Tutuila, with the Manua Islands, Rose Atoll, and Swains Island also included in the territory. American Samoa is part of the Samoan Islands chain, located west of the Cook Islands, north of Tonga, and some 300 miles (500 km) south of Tokelau. To the west are the islands of the Wallis and Futuna group. The 2000 census showed a total population of 57,291. The total land area is 200.22 km² (77.305 sq mi).
It is generally believed that the Samoan Islands were originally inhabited as early as 1000 BC. Samoa was not reached by European explorers until the eighteenth century.
The pre-Western history of Eastern Samoa (now American Samoa) is inextricably bound with the history of Western Samoa (now independent Samoa). The Manu'a Islands of American Samoa has one of the oldest histories of Polynesia, in connection with the Tui Manua title, connected with the histories of the archipelagos of Fiji, Tonga, the Cook Islands, Tokelau and elsewhere in the Pacific, all of which had once been under Manu'a's occupation. During the Tongan 300 years of rule over Samoa(AD900-AD1200), Manu'a was the only island group that remained independent. The islands of Tutuila and Aunu'u were politically connected to 'Upolu island in what is now independent Samoa. It can be said that all the Samoa islands are politically connected today through the faamatai chiefly system and through family connections that are as strong as ever. This system of the faamatai and the customs of faasamoa originated with two of the most famous early chiefs of Samoa, who were both women and related, Nafanua and Salamasina.
Early Western contact included a battle in the eighteenth century between French explorers and islanders in Tutuila, for which the Samoans were blamed in the West, giving them a reputation for ferocity. Early nineteenth century Rarotongan missionaries to the Samoa islands were followed by a group of Western missionaries led by John Williams of the Congregationalist London Missionary Society in the 1830s, officially bringing Christianity to Samoa. Less than a hundred years later, the Samoan Congregationalist Church became the first independent indigenous church of the South Pacific.
In March of 1889, a German naval force invaded a village in Samoa, and by doing so destroyed some American property. Three American warships then entered the Samoan harbor and were prepared to fire on the three German warships found there. Before guns were fired, a typhoon sank both the American and German ships. A compulsory armistice was called because of the lack of warships.
International rivalries in the latter half of the nineteenth century were settled by the 1899 Treaty of Berlin in which Germany and the U.S. divided the Samoan archipelago. The U.S. formally occupied its portion—a smaller group of eastern islands with the noted harbor of Pago Pago—the following year. The western islands are now the independent state of Samoa.
After the U.S. took possession of Samoa, the U.S. Navy built a coaling station on Pago Pago Bay for its Pacific Squadron and appointed a local Secretary. The navy secured a Deed of Cession of Tutuila in 1900 and a Deed of Cession of Manuʻa in 1904. The last sovereign of Manuʻa, the Tui Manuʻa Elisala, was forced to sign a Deed of Cession of Manuʻa following a series of US Naval trials, known as the "Trial of the Ipu", in Pago Pago, Taʻu, and aboard a Pacific Squadron gunboat.
After World War I, during the time of the Mau movement in Western Samoa (then a New Zealand protectorate), there was a corresponding American Samoa Mau movement, led by Samuel Sailele Ripley, who was from Leone village and was a WWI war veteran. After meetings in America, he was prevented from disembarking from the ship that brought him home to American Samoa and was not allowed to return. The American Samoa Mau movement having been suppressed by the US Navy, in 1930 the US Congress sent a committee to investigate the status of American Samoa, led by Americans who had had a part in the overthrow of the Hawaiian Kingdom.
In 1938, famous aviator Ed Musick and his crew died on the Pan American World Airways S-42 Samoan Clipper over Pago Pago, on a survey flight to Auckland, New Zealand. Sometime after take-off the aircraft experienced trouble and Musick turned it back toward Pago Pago. As the crew began dumping fuel in preparation for an emergency landing a spark in the fuel pump caused an explosion that tore the aircraft apart in mid-air.
During World War II, U.S. Marines in Samoa outnumbered the local population, having a huge cultural influence. Young Samoan men from the age of 14 and above were combat trained by US military personnel. Samoans served in various capacities during WWII, including as combatants, medical personnel, code personnel, ship repair, and others.
In time, the Navy-appointed governor was replaced by a locally elected one. Although technically considered "unorganized" in that the U.S. Congress has not passed an Organic Act for the territory, American Samoa is self-governing under a constitution that became effective on July 1, 1967. The U.S. Territory of American Samoa is on the United Nations list of Non-Self-Governing Territories, a listing which is disputed by territorial government officials.
Politics of American Samoa takes place in a framework of a presidential representative democratic dependency, whereby the Governor is the head of government, and of a pluriform multi-party system. American Samoa is an unincorporated and unorganized territory of the United States, administered by the Office of Insular Affairs, U.S. Department of the Interior. Its constitution was ratified 1966 and came into effect 1967. Executive power is exercised by the government. Legislative power is vested in the two chambers of the legislature. The American political parties (Republican and Democratic) exist in American Samoa, but few politicians are aligned with the parties. The judiciary is independent of the executive and the legislature.
There is also the traditional village politics of the Samoa Islands, the "fa'amatai" and the "fa'asamoa", which continues in American Samoa and in independent Samoa, and which interacts across these current boundaries. The Fa'asamoa is the language and customs, and the Fa'amatai the protocols of the "fono" (council) and the chiefly system. The Fa'amatai and the Fono take place at all levels of the Samoan body politic, from the family, to the village, to the region, to national matters. The "matai" (chiefs) are elected by consensus within the fono of the extended family and village(s) concerned. The matai and the fono (which is itself made of matai) decide on distribution of family exchanges and tenancy of communal lands. The majority of lands in American Samoa and independent Samoa are communal. A matai can represent a small family group or a great extended family that reaches across islands, and to both American Samoa and independent Samoa.
Samoans are entitled to elect one non-voting delegate to the United States House of Representatives. Their delegate since 1989 has been Democrat Eni Fa'aua'a Hunkin Faleomavaega, Jr. They also receive delegates to the Democratic and Republican National Conventions.
American Samoa is administratively divided into three districts and two "unorganized" atolls. The districts and unorganized atolls are subdivided into 74 villages. Pago Pago is the capital of American Samoa. It is one of the largest villages and is located on the eastern side of Tutuila island in Ma'oputasi County district #9. Some have mistakenly cited Fagatogo as the capital due to the fact that is listed in the Constitution of American Samoa as the official seat of government.
American Samoa is located within the geographical region of Oceania. With a total land area of 199 km² (76.83 square miles), it is slightly larger than the District of Columbia. Consisting of five, rugged volcanic islands and two coral atolls, it is frequently hit by typhoons between December and March, due to its positioning in the South Pacific Ocean. In addition, Rose Atoll, located in American Samoa, is the southernmost point in the territory of the United States.
In 1997 a protest was issued against Samoa, formerly named Western Samoa, for changing its official name to the shorter form. The official view in American Samoa is that such a form detracts from the Samoan identity of American Samoa, and public officials and documents from American Samoa still refer to Samoa as Western Samoa.
Swains Island is claimed by supporters of independence for Tokelau as part of that country. Swains Islanders and Tokelauans enjoy linguistic and cultural affinities. Tokelauans refer to Swains as Olohega. In 2006 and 2007, unsuccessful, United Nations-sponsored referenda on independence for Tokelau, currently administered by New Zealand, revived a dormant source of tension. The American and New Zealand governments are not concerned to pursue any change of territorial status over the Swains Island issue. However, the existence of a clause in a draft independence treaty espoused by United Nations-driven Tokelauan nationalists is a matter which will be a potential source of diplomatic tension. In one direction or another, the way out of this impasse may depend on the extent that the United States government shows a willingness or otherwise to support the United Nations' decolonization efforts at the expense of the current territorial integrity of American Samoa.
Employment on the island falls into three relatively equally-sized categories of approximately 5,000 workers each: the public sector, the two tuna canneries, and the rest of the private sector. There are only a few federal employees in American Samoa and no active military personnel except members of the U.S. Coast Guard. (there is an Army Reserve unit, however); the overwhelming majority of public sector employees work for the American Samoa Government. The two tuna canneries (StarKist and Samoa Packing) export several hundred million dollars worth of canned tuna to the United States. In early 2007 the Samoan economy was highlighted in the U.S. Congress as it was not mentioned in the minimum wage bill, at the request of the Samoan delegate to the United States House of Representatives, Eni Faleomavaega.
The Fair Labor Standards Act has, since inception, contained special provisions for American Samoa, citing its limited economy. Since the American set based on the recommendations of a Special Industry Committee meeting bi-annually. Originally, the Act contained provisions for other territories, which were phased out as those territories developed more diverse economies.
American Samoa is small enough to have just one ZIP code, 96799. The island contains 23 primary schools and six secondary schools, all of which are operated by the American Samoa Department of Education. American Samoa Community College, founded in 1970, provides post-secondary education on the islands.
The culture in American Samoa is almost the same as in Western Samoa (Upolu). The U.S. military and agricultural occupation distinguishes the civilization of American Samoa from the sovereign Samoa.
About 30 ethnic Samoans, many from American Samoa, currently play in the National Football League. A 2002 article from ESPN estimated that a Samoan male (either an American Samoan, or a Samoan living in the 50 United States) is 40 times more likely to play in the NFL than a non-Samoan American.
A number have also ventured into professional wrestling (see especially Anoa'i family).
American Samoa's national soccer team is considered one of the newest teams in the world. It also has the distinction of suffering the worst loss in international soccer history: they lost to Australia 31 - 0 in a FIFA World Cup qualifying match on April 11 2001.



Historically, astronomy was more concerned with the classification and description of phenomena in the sky, while astrophysics attempted to explain these phenomena and the differences between them using physical laws. Today, that distinction has mostly disappeared. Professional astronomers are highly educated individuals who typically have a PhD in physics or astronomy and are employed by research institutions or universities. They spend the majority of their time working on research, although they quite often have other duties such as teaching, building instruments, or aiding in the operation of an observatory. The letter of professional astronomers in the United States is actually quite small. The American Astronomical Society, which is the major organization of professional astronomers in North America, has approximately 6500 members. This number includes scientists from other fields, such as physics, geology, and engineering, whose research interests are closely related to astronomy. The International Astronomical Union comprises almost 10,000 members from 87 different countries who are involved in astronomical research at the PhD level and beyond.
While the number of professional astronomers world-wide is not much larger than the population of a small town, there is a huge community of amateur astronomers. Most cities have amateur astronomy clubs that meet on a regular basis and often host star parties in their communities. The Astronomical Society of the Pacific is the largest general astronomical society in the world, comprising both professional and amateur astronomers as well as educators from 70 different nations. Like any hobby, most people who think of themselves as amateur astronomers may devote a few hours a month to stargazing and reading the latest developments in research. However, amateurs span the range from so-called "armchair astronomers" to the very ambitious, who own science-grade telescopes and instruments with which they are able to make their own discoveries and assist professional astronomers in research.
Contrary to the classical image of an old astronomer peering through a telescope through the dark hours of the night, it is very rare for a modern professional astronomer to use an eyepiece on a larger telescope. It is far more common to use a charge-coupled device camera to record a long, deep exposure, allowing a more sensitive image to be created because the light is added over time. Before CCDs, photographic plates were a common method of observation. Modern astronomers spend relatively little time at telescopes - most spend a few weeks per year observing, and the rest of their time reducing the data (changing it from raw data to processed images) and analyzing it. Many astronomers work entirely from astronomical survey or space observatory data. Others work with radio telescopes like the Very Large Array, which is entirely automated, although it is maintained by telescope operators.
Astronomers are generally funded by research grants from national governments (e.g. the National Science Foundation and NASA in the US) and their home institutions, for those who work at universities. Astronomers who serve as faculty spend much of their time teaching undergraduate and graduate classes. Most universities also have outreach programs including public telescope time and sometimes planetariums as a public service and to encourage interest in the field.

Amoeboids are unicellular lifeforms that mainly consist of contractile vacuoles, a nucleus, and cytoplasm as their basic structure. They move and feed by means of temporary cytoplasmic projections, called pseudopods (false feet). They have appeared in a number of different groups. Some cells in multicellular animals may be amoeboid, for instance human white blood cells, which consume pathogens. Many protists also exist as individual amoeboid cells, or take such a form at some point in their life-cycle. The most famous such organism is Amoeba proteus; the name amoeba is variously used to describe its close relatives, other organisms similar to it, or the amoeboids in general.
Amoeboids may be divided into several morphological categories based on the form and structure of the pseudopods. Those where the pseudopods are supported by regular arrays of microtubules are called actinopods, and forms where they are not are called rhizopods, further divided into lobose, filose, and reticulose amoebae. There is also a strange group of giant marine amoeboids, the xenophyophores, that do not fall into any of these categories.
Traditionally the amoeboid protozoa are grouped together as the subphylum Sarcodina, variously ranked from class to phylum, with each of the above categories as a formal subtaxon. However, since they are all based on form rather than phylogeny, newer systems generally separate some out or abandon them entirely. Most amoeboids are now included in two major supergroups - the Amoebozoa, including most lobose amoebae and slime moulds, and the Rhizaria, including the Cercozoa, Foraminifera, radiolarian classes and certain heliozoa. However, amoeboids have appeared separately in many other groups, including various different lines of algae not listed above.
Sarcodina is a subphylum of the phylum Sarcomastigophora, of unicellular life forms that move by cytoplasmic flow. Some species use cytoplasmic extensions called pseudopodia for locomotion or feeding. The subphylum includes such protozoa as the common amoeba and the Foraminifera and Radiolaria. Most members of the subphylum reproduce asexually through fission, although some reproduce sexually. Sarcodina is sometimes subdivided into two classes - Rhizopoda and Actinopoda.


American Standard Code for Information Interchange (ASCII), ASK-ee, is a character encoding based on the English alphabet. ASCII codes represent text in computers, communications equipment, and other devices that work with text. Most modern character encodings — which support many more characters than did the original — have a historical basis in ASCII.
Work on ASCII began in 1960. The first edition of the standard was published in 1963, a major revision in 1967, and the most recent update in 1986. It currently defines codes for 128 characters: 33 are non-printing, mostly obsolete control characters that affect how text is processed, and 94 are printable characters (excluding the space).
I have also approved recommendations of the Secretary of Commerce regarding standards for recording the Standard Code for Information Interchange on magnetic tapes and paper tapes when they are used in computer operations.
All computers and related equipment configurations brought into the Federal Government inventory on and after July 1, 1969, must have the capability to use the Standard Code for Information Interchange and the formats prescribed by the magnetic tape and paper tape standards when these media are used.
Like other character encodings, ASCII specifies a correspondence between digital bit patterns and character symbols (i.e. graphemes and control characters). This allows digital devices to communicate with each other and to process, store, and communicate character-oriented information such as written language. The ASCII character encoding — or a compatible extension (see below) — is used on nearly all common computers, especially personal computers and workstations. The preferred MIME name for this encoding is "US-ASCII".
Except for a few of the ASCII control characters that prescribe some elementary line-oriented formatting, ASCII does not define any mechanism for describing the structure or appearance of text within a document. Other schemes, such as markup languages, address page and document layout and formatting.
ASCII is, strictly, a seven-bit code, meaning it uses patterns of seven binary digits (a range of 0 to 127 decimal) to represent each character. When ASCII was introduced, many computers used eight-bit bytes (groups of bits), also called octets, as the native data type. In seven-bit ASCII encoding, the eighth bit was commonly used as a parity bit for error checking on communication lines or for other device-specific functions. Machines that did not use parity checking typically set the eighth bit to 0.
The American National Standards Institute (then called the American Standards Association or ASA, and later the United States of America Standards Institute or USASI) developed ASCII based on earlier teleprinter encoding systems. Circa 1956, Ivan Idelson, at Ferranti in the UK, had proposed the Cluff-Foster-Idelson coding of characters on 7 track paper tape to a British Standards committee. This was one of the influences on ASCII. ASCII itself first entered commercial use in 1963 as a seven-bit teleprinter code for American Telephone & Telegraph's TWX (Teletype Wide-area eXchange) network. TWX originally used the earlier five-bit Baudot code, which was also used by the competing Telex teleprinter system. The Bell System had planned to upgrade to a six-bit code derived from the Fieldata project, which contained many punctuation and control characters that the Baudot code did not, but was persuaded instead to join the American Standards Association (part of ANSI) subcommittee that had started to develop ASCII. Compared with earlier telegraph codes, the proposed Bell code and ASCII both underwent re-ordering for more convenient sorting (especially alphabetization) of lists, and added features for devices other than teleprinters. Bob Bemer introduced features such as the escape sequence. His British colleague Hugh McGregor Ross helped to popularize this work — according to Bemer, "so much so that the code that was to become ASCII was first called the Bemer-Ross Code in Europe".
ASCII was published as ASA X3.4-1963 and then subsequently updated as USASI X3.4-1967, USASI X3.4-1968, ANSI X3.4-1977, and finally, ANSI X3.4-1986.
Other international standards bodies have ratified character encodings such as ISO/IEC 646 that are identical or nearly identical to ASCII, with extensions for characters outside the English alphabet and symbols used outside the United States, such as the symbol for the United Kingdom's pound sterling (£). Almost every country needed an adapted version of ASCII since ASCII only suited the needs of the USA and a few other countries. For example, Canada had its own version that supported French. Although these encodings are sometimes referred to as ASCII, true ASCII is strictly defined only by ANSI standard.
ASCII has been incorporated into the Unicode character set as the first 128 symbols, so the ASCII characters have the same numeric codes in both sets. This allows UTF-8 to be backward compatible with ASCII, a significant advantage.
ASCII reserves the first 32 codes (numbers 0–31 decimal) for control characters: codes originally intended not to carry printable information, but rather to control devices (such as printers) that make use of ASCII, or to provide meta-information about data streams such as those stored on magnetic tape. For example, character 10 represents the "line feed" function (which causes a printer to advance its paper), and character 8 represents "backspace".
The original ASCII standard used only short descriptive phrases for each control character. The ambiguity this left was sometimes intentional (where a character would be used slightly differently on a terminal link than on a data stream) and sometimes more accidental (such as what "delete" means).
Probably the most influential single device on the interpretation of these characters was the ASR-33 Teletype series, which was a printing terminal with an available paper tape reader/punch option. Paper tape was a very popular medium for long-term program storage up through the 1980s, lower cost and in some ways less fragile than magnetic tape. In particular, the Teletype 33 machine assignments for codes 17 (Control-Q, DC1, also known as XON), 19 (Control-S, DC3, also known as XOFF), and 127 (DELete) became de-facto standards. Because the keytop for the O key also showed a left-arrow symbol (from ASCII-1963, which had this character instead of underscore), a noncompliant use of code 15 (Control-O, Shift In) interpreted as "delete previous character" was also adopted by many early timesharing systems but eventually faded out.
The use of Control-S (XOFF, an abbreviation for "transmit off") as a handshaking signal warning a sender to stop transmission because of impending overflow, and Control-Q (XON, "transmit on") to resume sending, persists to this day in many systems as a manual output control technique. On some systems Control-S retains its meaning but Control-Q is replaced by a second Control-S to resume output.
Code 127 is officially named "delete" but the Teletype label was "rubout". Since the original standard gave no detailed interpretation for most control codes, interpretations of this code varied. The original Teletype meaning, and the intent of the standard, was to make it an ignored character, the same as NUL (all zeroes). This was specifically useful for paper tape, because punching the all-ones bit pattern on top of an existing mark would obliterate it. Tapes designed to be "hand edited" could even be produced with spaces of extra NULs (blank tape) so that a block of characters could be "rubbed out" and then replacements put into the empty space.
As video terminals began to replace printing ones, the value of the "rubout" character was lost. DEC systems, for example, interpreted "Delete" to mean "remove the character before the cursor," and this interpretation also became common in Unix systems. Most other systems used "Backspace" for that meaning and used "Delete" as it was used on paper tape, to mean "remove the character after the cursor". That latter interpretation is the most common today.
Many more of the control codes have taken on meanings quite different from their original ones. The "escape" character (code 27), for example, was originally intended to allow sending other control characters as literals instead of invoking their meaning. This is the same meaning of "escape" encountered in URL encodings, C language strings, and other systems where certain characters have a reserved meaning. Over time this meaning has been coopted and has eventually drifted. In modern use, an ESC sent to the terminal usually indicates the start of a command sequence, usually in the form of an ANSI escape code. An ESC sent from the terminal is most often used as an "out of band" character used to terminate an operation, as in the TECO and vi text editors.
The inherent ambiguity of many control characters, combined with their historical usage, has also created problems when transferring "plain text" files between systems. The clearest example of this is the newline problem on various operating systems. On printing terminals there is no question that you terminate a line of text with both "Carriage Return" and "Linefeed". The first returns the printing carriage to the beginning of the line and the second advances to the next line without moving the carriage. However, requiring two characters to mark the end of a line introduced unnecessary complexity and questions as to how to interpret each character when encountered alone. To simplify matters, plain text files on Unix systems use line feeds alone to separate lines. Similarly, older Macintosh systems, among others, use only carriage returns in plain text files. Various DEC operating systems used both characters to mark the end of a line, perhaps for compatibility with teletypes, and this de facto standard was copied in the CP/M operating system and then in MS-DOS and eventually Microsoft Windows. Transmission of text over the Internet, for protocols as E-mail and the World Wide Web, uses both characters. The DEC operating systems, along with CP/M, tracked file length only in units of disk blocks and used Control-Z (SUB) to mark the end of the actual text in the file (also done for CP/M compatibility in some cases in MS-DOS, though MS-DOS has always recorded exact file-lengths). Control-C (ETX, End of TeXt) might have made more sense, but was already in wide use as a program abort signal. UNIX's use of Control-D (EOT, End of Transmission) appears on its face similar, but is used only from the terminal and never stored in a file.
While the codes mentioned above have retained some semblance of their original meanings, many of the codes originally intended for stream delimiters or for link control on a terminal have lost all meaning except their relation to a letter. Control-A is almost never used to mean "start of header" except on an ANSI magnetic tape. When connecting a terminal to a system, or asking the system to recognize that a logged-out terminal wants to log in, modern systems are much more likely to want a carriage return or an ESCape than Control-E (ENQuire, meaning "is there anybody out there?").
The abbreviation ASCIIZ or ASCIZ refers to a null-terminated ASCII string (also known as a C string).
RFC 2822 refers to NO-WS-CTL, non-whitespace control characters. These are control characters that do not include carriage return, line feed, and white space characters (see here), i.e.: decimal 1–8, 11–12, 14–31, and 127.
Code 32, the "space" character, denotes the space between words, as produced by the space-bar of a keyboard. Codes 33 to 126, known as the printable characters, represent letters, digits, punctuation marks, and a few miscellaneous symbols.
Of these, only the aliases "US-ASCII" and "ASCII" have achieved widespread use. One often finds them in the optional "charset" parameter in the Content-Type header of some MIME messages, in the equivalent "meta" element of some HTML documents, and in the encoding declaration part of the prolog of some XML documents.
As computer technology spread throughout the world, different standards bodies and corporations developed many variations of ASCII in order to facilitate the expression of non-English languages that used Roman-based alphabets. One could class some of these variations as "ASCII extensions", although some misuse that term to cover all variants, including those that do not preserve ASCII's character-map in the 7-bit range.
The PETSCII Code used by Commodore International for their 8-bit systems is probably unique among post-1970 codes in being based on ASCII-1963 instead of the far more common ASCII-1967.
ISO/IEC 646 (1972), the first attempt to remedy ASCII's English language bias, created compatibility problems, since it remained a 7-bit character-set. It made no additional codes available, so it reassigned some in language-specific variants. Escape codes were defined to indicate which national variant applied to a piece of text, but these were rarely used, so it was often impossible to know what variant to work with and therefore which character a code represented, and text-processing systems could generally cope with only one variant anyway.
Eventually, improved technology brought out-of-band means to represent the information formerly encoded in the eighth bit of each byte, freeing this bit to add another 128 additional character-codes for new assignments.
For example, IBM developed 8-bit code pages, such as code page 437, which replaced the control-characters with graphic symbols such as smiley faces, and mapped additional graphic characters to the upper 128 positions. Operating systems such as DOS supported these code-pages, and manufacturers of IBM PCs supported them in hardware. Digital Equipment Corporation developed the Multinational Character Set (DEC-MCS) for use in the popular VT220 terminal.
Eight-bit standards such as ISO/IEC 8859 (derived from the DEC-MCS) and Mac OS Roman developed as true extensions of ASCII, leaving the original character-mapping intact, but adding additional character definitions after the first 128 (i.e. 7-bit) characters. This enabled representation of characters used in a broader range of languages. But these standards continued to suffer from incompatibilities and limitations. Still, ISO-8859-1 (Latin 1), its variant Windows-1252 (often mislabeled as ISO-8859-1), and the original 7-bit ASCII remain the most common character encodings in use today.
Unicode and the ISO/IEC 10646 Universal Character Set (UCS) have a much wider array of characters, and their various encoding forms have begun to supplant ISO/IEC 8859 and ASCII rapidly in many environments. While ASCII is limited to 128 characters, Unicode and the UCS support more characters by separating the concepts of unique identification (using natural numbers called code points) and encoding (to 8-, 16- or 32-bit binary formats, called UTF-8, UTF-16 and UTF-32).
To permit backward compatibility, the 128 ASCII and 256 ISO-8859-1 (Latin 1) characters are assigned Unicode/UCS code points that are the same as their codes in the earlier standards. Therefore, ASCII can be considered a 7-bit encoding scheme for a very small subset of Unicode/UCS, and, conversely, the UTF-8 encoding forms are binary-compatible with ASCII for code points below 128, meaning every properly encoded ASCII file is also a valid UTF-8 file. The other encoding forms resemble ASCII in how they represent the first 128 characters of Unicode, but use 16 or 32 bits per character, so they require conversion for compatibility.
The slang expression ASCIIbetical is sometimes used for this order.
In programming, alphanumeric sorting means to sort by numeric value, without regard of any character set. An alphanumerically sorted array of bytes will appear ASCIIbetically when viewed in an ASCII-compatible character set.
A refined version of this order converts uppercase letters to lowercase before comparing ASCII values.



Animation is a storytelling medium that it consists in the rapid display of a sequence of images of 2-D artwork or model positions in order to create an illusion of movement.
It is an optical illusion of motion due to the phenomenon of persistence of vision, and can be created and demonstrated in a number of ways. The most common method of presenting animation is as a motion picture or video program, although several other forms of presenting animation also exist.
Animation can sometimes refer to a way of activating fx a community, i.e. 'animating' the users. This means actions which encourages users to interact with a given service and is connected to moderation.
Early examples of attempts to capture the phenomenon of motion into a still drawing can be found in paleolithic cave paintings, where animals are depicted with multiple legs in superimposed positions, clearly attempting to convey the perception of motion.
The phenakistoscope, zoetrope and praxinoscope, as well as the common flip book, were early popular animation devices invented during the 1800s. These devices produced movement from sequential drawings using technological means, but animation did not really develop much further until the advent of motion picture film.
There is no single person who can be considered the "creator" of the art of film animation, as there were several people doing several projects which could be considered various types of animation all around the same time.
French filmmaker Georges Méliès was a creator of special effect films, such as A Trip to the Moon. He used many techniques – one of which was to stop the camera rolling, change something in the scene, and then continue rolling the film. This is a very similar idea to that of what later became stop-motion animation. Méliès accidentally happened upon the technique when his camera broke down while shooting a bus driving by. When the camera was fixed, a horse happened to be passing by just as Méliès continued to film. The result was that the bus appeared to change into a horse.
J. Stuart Blackton was possibly the first American filmmaker to use the techniques of stop-motion and hand-drawn animation. Introduced to filmmaking by Edison, he pioneered these concepts at the turn of the 20th century, with his first copyrighted work dated 1900. Several of his films, among them The Enchanted Drawing (1900) and Humorous Phases of Funny Faces (1906) were film versions of Blackton's "lightning artist" routine, and utilized modified versions of Méliès' early stop-motion techniques to make a series of blackboard drawings appear to move and reshape themselves. "Humorous Phases of Funny Faces' is regularly cited as the first true animated film, and Blackton is considered the first true animator.
Another French artist, Émile Cohl, began drawing cartoon strips and created a film in 1908 called Fantasmagorie. The film largely consisted of a stick figure moving about and encountering all manner of morphing objects, such as a wine bottle that transforms into a flower. There were also sections of live action where the animator’s hands would enter the scene. The film was created by drawing each frame on paper and then shooting each frame onto negative film, which gave the picture a blackboard look. This makes Fantasmagorie the first animated film created using what came to be known as traditional (hand-drawn) animation.
Following the successes of Blackton and Cohl, many other artists began experimenting with animation. One such artist was Winsor McCay, a successful newspaper cartoonist, who created detailed animations that required a team of artists and painstaking attention for detail. Each frame was drawn on paper; which invariably required backgrounds and characters to be redrawn and animated. Among McCay's most noted films are Little Nemo (1911), Gertie the Dinosaur (1914) and The Sinking of the Lusitania (1918).
The production of animated short films, typically referred to as "cartoons", became an industry of its own during the 1910s, and cartoon shorts were produced to be shown in movie theaters. The most successful early animation producer was John Randolph Bray, who, along with animator Earl Hurd, patented the cel animation process which dominated the animation industry for the rest of the decade.
(Also called cel animation) Traditional animation was the process used for most animated films of the 20th century. The individual frames of a traditionally animated film are photographs of drawings, which are first drawn on paper. To create the illusion of movement, each drawing differs slightly from the one before it. The animators' drawings are traced or photocopied onto transparent acetate sheets called cels, which are filled in with paints in assigned colors or tones on the side opposite the line drawings. The completed character cels are photographed one-by-one onto motion picture film against a painted background by a rostrum camera.
The traditional cel animation process became obsolete by the beginning of the 21st century. Today, animators' drawings and the backgrounds are either scanned into or drawn directly into a computer system. Various software programs are used to color the drawings and simulate camera movement and effects. The final animated piece is output to one of several delivery mediums, including traditional 35 mm film and newer media such as digital video. The "look" of traditional cel animation is still preserved, and the character animators' work has remained essentially the same over the past 70 years. Some animation producers have used the term "tradigital" to describe cel animation which makes extensive use of computer technology.
Like stop motion, computer animation encompasses a variety of techniques, the unifying idea being that the animation is created digitally on a computer.


In Greek and Roman mythology, Apollo (in Greek, Ἀπόλλων — Apóllōn or Ἀπέλλων — Apellōn), is one of the most important and many-sided of the Olympian deities. The ideal of the kouros (a beardless youth), Apollo has been variously recognized as a god of light and the sun; truth and prophecy; archery; medicine and healing; music, poetry, and the arts; and more. Apollo is the son of Zeus and Leto, and has a twin sister, the chaste huntress Artemis. Apollo is known in Greek-influenced Etruscan mythology as Apulu. In Roman mythology he is known as Apollo.
As the patron of Delphi (Pythian Apollo), Apollo was an oracular god — the prophetic deity of the Delphic Oracle. Medicine and healing were associated with Apollo, whether through the god himself or mediated through his son Asclepius. Apollo was also seen as a god who could bring ill-health and deadly plague as well as one who had the ability to cure. Amongst the god's custodial charges, Apollo became associated with dominion over colonists, and as the patron defender of herds and flocks. As the leader of the Muses (Apollon Musagetes) and director of their choir, Apollo functioned as the patron god of music and poetry. Hermes created the lyre for him, and the instrument became a common attribute of Apollo. Hymns sung to Apollo were called paeans.
In Hellenistic times, especially during the third century BCE, as Apollo Helios he became identified among Greeks with Helios, god of the sun, and his sister Artemis similarly equated with Selene, goddess of the moon. In Latin texts, however, Joseph Fontenrose declared himself unable to find any conflation of Apollo with Sol among the Augustan poets of the first century, not even in the conjurations of Aeneas and Latinus in Aeneid XII (161-215). Apollo and Helios/Sol remained separate beings in literary and mythological texts until the third century CE.
The etymology of Apollo is uncertain. Several instances of popular etymology are attested from ancient authors. Thus, Plato in Cratylus connects the name with "redeem", with "purification", and with "simple", in particular in reference to the Thessalian form of the name, and finally with "ever-shooting". The ἁ suggestion is repeated by Plutarch in Moralia in the sense of "unity". Hesychius connects the name Apollo with the Doric απελλα, which means "assembly", so that Apollo would be the god of political life, and he also gives the explanation σηκος ("fold"), in which case Apollo would be the god of flocks and herds. It is also possible that apellai derives from an old form of Apollo which can be equated with Appaliunas, an Anatolian god whose name possibly means "father lion" or "father light". The Greeks later associated Apollo's name with the Greek verb απολλυμι (apollymi) meaning "to destroy".
It has also been suggested that Apollo comes from the Hurrian and Hittite divinity, Aplu, who was widely evoked during the "plague years". Aplu, it is suggested, comes from the Akkadian Aplu Enlil, meaning "the son of Enlil", a title that was given to the god Nergal, who was linked to Shamash, Babylonian god of the sun.
It appears that both Greek and Etruscan Apollo came to the Aegean during the Iron Age (i.e. from c.1100 BCE to c. 800 BCE) from Anatolia. Homer pictures him on the side of the Trojans, against the Achaeans, during the Trojan War and he has close affiliations with a Luwian deity, Apaliunas, who in turn seems to have traveled west from further east. The Late Bronze Age (from 1700–1200 BCE) Hittite and Hurrian Aplu, like the Homeric Apollo, was a god of plagues, and resembles the mouse god Apollo Smintheus. Here we have an apotropaic situation, where a god originally bringing the plague was invoked to end it, merging over time through fusion with the Mycenaean "doctor" god Paieon (PA-JA-WO in Linear B); Paean, in Homer, was the Greek physician of the gods. In other writers, the word is a mere epithet of Apollo in his capacity as a god of healing, but it is now known from Linear B that Paean was originally a separate deity.
Homer left the question unanswered, whilst Hesiod separated the two and, in later poetry Paean was invoked independently as a god of healing. It is equally difficult to separate Paean or Paeon in the sense of "healer" from Paean in the sense of "song." It was believed to refer to the ancient association between the healing craft and the singing of spells, but here we see a shift from the concerns to the original sense of "healer" gradually giving way to that of "hymn," from the phrase.
Such songs were originally addressed to Apollo, and afterwards to other gods (i.e. Dionysus, Helios, Asclepius) associated with Apollo. About the fourth century BCE, the paean became merely a formula of adulation; its object was either to implore protection against disease and misfortune, or to offer thanks after such protection had been rendered. It was in this way that Apollo became recognised as the god of music. Apollo's role as the slayer of the Python led to his association with battle and victory; hence it became the Roman custom for a paean to be sung by an army on the march and before entering into battle, when a fleet left the harbour, and also after a victory had been won.
Apollo's links with oracles again seem to be associated with wishing to know the outcome of an illness. Apollo killed the Python of Delphi and took over that oracle, so he is vanquisher of unconscious terrors. He is golden-haired like the sun; he is an archer who shoots arrows of insight and/or death; he is a god of music and the lyre. Healing belongs to his realm: he was the father of Asclepius, the god of medicine. The Muses are part of his retinue, so that music, history, dreams, poetry and dance all belong to him.
Unusually among the Olympic deities, Apollo had two cult sites that had widespread influence: Delos and Delphi. In cult practice, Delian Apollo and Pythian Apollo (the Apollo of Delphi) were so distinct that they might both have shrines in the same locality. Theophoric names such as Apollodorus or Apollonios and cities named Apollonia are met with throughout the Greek world. Apollo's cult was already fully established when written sources commenced, about 650 BCE.
Apollo had a famous oracle in Delphi, and other notable ones in Clarus and Branchidae. His oracular shrine in Abae in Phocis, where he bore the toponymic epithet Abaeus (, Apollon Abaios) was important enough to be consulted by Croesus (Herodotus, 1.46).
Oracles were also given by sons of Apollo.
The chief Apollonian festivals were the Boedromia, Carneia, Carpiae, Daphnephoria, Delia, Hyacinthia, Metageitnia, Pyanepsia, Pythia and Thargelia.
Apollo's most common attributes were the bow and arrow. Other attributes of his included the kithara (an advanced version of the common lyre), the plectrum and the sword. Another common emblem was the sacrificial tripod, representing his prophetic powers. The Pythian Games were held in Apollo's honor every four years at Delphi. The bay laurel plant was used in expiatory sacrifices and in making the crown of victory at these games. The palm was also sacred to Apollo because he had been born under one in Delos. Animals sacred to Apollo included wolves, dolphins, roe deer, swans, cicadas (symbolizing music and song), hawks, ravens, crows, snakes (referencing Apollo's function as the god of prophecy), mice and griffins, mythical eagle-lion hybrids of Eastern origin.
As god of colonization, Apollo gave oracular guidance on colonies, especially during the height of colonization, 750–550 BCE. According to Greek tradition, he helped Cretan or Arcadian colonists found the city of Troy. However, this story may reflect a cultural influence which had the reverse direction: Hittite cuneiform texts mention a Minor Asian god called Appaliunas or Apalunas in connection with the city of Wilusa attested in Hittite inscriptions, which is now generally regarded as being identical with the Greek Ilion by most scholars. In this interpretation, Apollo’s title of Lykegenes can simply be read as "born in Lycia", which effectively severs the god's supposed link with wolves (possibly a folk etymology).
In literary contexts, Apollo represents harmony, order, and reason—characteristics contrasted with those of Dionysus, god of wine, who represents ecstasy and disorder. The contrast between the roles of these gods is reflected in the adjectives Apollonian and Dionysian. However, the Greeks thought of the two qualities as complementary: the two gods are brothers, and when Apollo at winter left for Hyperborea, he would leave the Delphic oracle to Dionysus. This contrast appears to be shown on the two sides of the Borghese Vase.
Apollo is often associated with the Golden Mean. This is the Greek ideal of moderation and a virtue that opposes gluttony.
The Roman worship of Apollo was adopted from the Greeks. As a quintessentially Greek god, Apollo had no direct Roman equivalent, although later Roman poets often referred to him as Phoebus. There was a tradition that the Delphic oracle was consulted as early as the period of the kings of Rome during the reign of Tarquinius Superbus. On the occasion of a pestilence in the 430s BC, Apollo's first temple at Rome was established in the Flaminian fields, replacing an older cult site there known as the "Apollinare". During the Second Punic War in 212 BC, the Ludi Apollinares ("Apollonian Games") were instituted in his honor, on the instructions of a prophecy attributed to one Marcius. In the time of Augustus, who considered himself under the special protection of Apollo and was even said to be his son, his worship developed and he became one of the chief gods of Rome. After the battle of Actium, which was fought near a sanctuary of Apollo, Augustus enlarged Apollo's temple, dedicated a portion of the spoils to him, and instituted quinquennial games in his honour. He also erected a new temple to the god on the Palatine hill. Sacrifices and prayers on the Palatine to Apollo and Diana formed the culmination of the Secular Games, held in 17 BCE to celebrate the dawn of a new era.
In art, Apollo is depicted as a handsome beardless young man, often with a kithara (as Apollo Citharoedus) or bow in his hand, or reclining on a tree (the Lycian Apollo and Apollo Sauroctonos types). The Apollo Belvedere is a marble sculpture that was rediscovered in the late 15th century; for centuries it epitomized the ideals of Classical Antiquity for Europeans, from the Renaissance through the nineteenth century. The marble is a Hellenistic or Roman copy of a bronze original by the Greek sculptor Leochares, made between 350 and 325 BC.
The lifesize so-called "Adonis" found in 1780 on the site of a villa suburbana near the Via Labicana in the Roman suburb of Centocelle now in the Ashmolean Museum, Oxford, (illustration, left) is identified as an Apollo by modern scholars. It was probably never intended as a cult object, but was a pastiche of several fourth-century and later Hellenistic model types, intended to please a Roman connoisseur of the second century AD, and to be displayed in his villa.
In the late second century CE floor mosaic from El Djem, Roman Thysdrus (illustration, above right), he is identifiable as Apollo Helios by his effulgent halo, though now even a god's divine nakedness is concealed by his cloak, a mark of increasing conventions of modesty in the later Empire. Another haloed Apollo in mosaic, from Hadrumentum, is in the museum at Sousse. The conventions of this representation, head tilted, lips slightly parted, large-eyed, curling hair cut in locks grazing the neck, were developed in the third century BCE to depict Alexander the Great (Bieber 1964, Yalouris 1980). Some time after this mosaic was executed, the earliest depictions of Christ will be beardless and haloed.
When Hera discovered that Leto was pregnant and that Zeus was the father, she banned Leto from giving birth on "terra firma", or the mainland, or any island. In her wanderings, Leto found the newly created floating island of Delos, which was neither mainland nor a real island, and she gave birth there. The island was surrounded by swans. Afterwards, Zeus secured Delos to the bottom of the ocean. This island later became sacred to Apollo.
It is also stated that Hera kidnapped Ilithyia, the goddess of childbirth, to prevent Leto from going into labor. The other gods tricked Hera into letting her go by offering her a necklace, nine yards long, of amber. Mythographers agree that Artemis was born first and then assisted with the birth of Apollo, or that Artemis was born one day before Apollo, on the island of Ortygia and that she helped Leto cross the sea to Delos the next day to give birth to Apollo. Apollo was born on the seventh day () of the month Thargelion —according to Delian tradition— or of the month Bysios— according to Delphian tradition. The seventh and twentieth, the days of the new and full moon, were ever afterwards held sacred to him.
In his youth, Apollo killed the chthonic dragon Python, which lived in Delphi beside the Castalian Spring. This was the spring which emitted vapors that caused the oracle at Delphi to give her prophesies. Apollo killed Python but had to be punished for it, since Python was a child of Gaia.
Apollo has his ominous aspects, too. Marsyas, a satyr who dared challenge him to a music contest, was flayed after he lost. Apollo brought down arrows of plague upon the Greeks because they dishonored his priest Chryses. Apollo's arrows of plague struck Niobe, who, excessively proud of her seven sons and seven daughters, had disparaged Apollo's mother, Leto, for having only two children (Apollo and Artemis).
When Zeus struck down Apollo's son Asclepius, with a lightning bolt for resurrecting the dead (transgressing Themis by stealing Hades's subjects), Apollo in revenge killed the Cyclops, who had fashioned the bolt for Zeus. Apollo would have been banished to Tartarus forever, but was instead sentenced to one year of hard labor as punishment, thanks to the intercession of his mother, Leto. During this time he served as shepherd for King Admetus of Pherae in Thessaly. Admetus treated Apollo well, and, in return, the god conferred great benefits on Admetus.
Apollo helped Admetus win Alcestis, the daughter of King Pelias and later convinced the Fates to let Admetus live past his time, if another took his place. But when it came time for Admetus to die, his parents, whom he had assumed would gladly die for him, refused to cooperate. Instead, Alcestis took his place, but Heracles managed to "persuade" Thanatos, the god of death, to return her to the world of the living.
Apollo shot arrows infected with the plague into the Greek encampment during the Trojan War in retribution for Agamemnon's insult to Chryses, a priest of Apollo whose daughter Chryseis had been captured. He demanded her return, and the Achaeans complied, indirectly causing the anger of Achilles, which is the theme of the Iliad.
When Diomedes injured Aeneas (Iliad), Apollo rescued him. First, Aphrodite tried to rescue Aeneas but Diomedes injured her as well. Aeneas was then enveloped in a cloud by Apollo, who took him to Pergamos, a sacred spot in Troy.
Apollo aided Paris in the killing of Achilles by guiding the arrow of his bow into Achilles' heel. One interpretation of his motive is that it was in revenge for Achilles' sacrilege in murdering Troilus, the god's own son by Hecuba, on the very altar of the god's own temple.
A queen of Thebes and wife of Amphion, Niobe boasted of her superiority to Leto because she had fourteen children (Niobids), seven male and seven female, while Leto had only two. Apollo killed her sons as they practiced athletics, with the last begging for his life, and Artemis her daughters. Apollo and Artemis used poisoned arrows to kill them, though according to some versions of the myth, a number of the Niobids were spared (Chloris, usually). Amphion, at the sight of his dead sons, either killed himself or was killed by Apollo after swearing revenge. A devastated Niobe fled to Mount Sipylon in Asia Minor and turned into stone as she wept. Her tears formed the river Achelous. Zeus had turned all the people of Thebes to stone and so no one buried the Niobids until the ninth day after their death, when the gods themselves entombed them.
Love affairs ascribed to Apollo are a late development in Greek mythology. Their vivid anecdotal qualities have made some of them favourites of painters since the Renaissance, so that they stand out more prominently in the modern imagination.
In explanation of the connection of Apollon with daphne, the Laurel whose leaves his priestess employed at Delphi, it was told by Libanius, a fourth-century CE teacher of rhetoric, that Apollo chased a nymph, Daphne, daughter of Peneus, who had scorned him. In Ovid's telling for a Roman audience, Phoebus Apollo chaffs Cupid for toying with a man's weapon suited to a man, whereupon Cupid wounds him with an arrow with a golden dart; simultaneously, however, Eros had shot a leaden arrow into Daphne, causing her to be repulsed by Apollo. Following a spirited chase by Apollo, Daphne prayed to Mother Earth, or, alternatively, her father — a river god — to help her and he changed her into the Laurel tree, sacred to Apollo.
Apollo had an affair with a human princess named Leucothea, daughter of Orchamus and sister of Clytia. Leucothea loved Apollo who disguised himself as Leucothea's mother to gain entrance to her chambers. Clytia, jealous of her sister because she wanted Apollo for herself, told Orchamus the truth, betraying her sister's trust and confidence in her. Enraged, Orchamus ordered Leucothea to be buried alive. Apollo refused to forgive Clytia for betraying his beloved, and a grieving Clytia wilted and slowly died. Apollo changed her into an incense plant, either heliotrope or sunflower, which follows the sun every day.
Marpessa was kidnapped by Idas but was loved by Apollo as well. Zeus made her choose between them, and she chose Idas on the grounds that Apollo, being immortal, would tire of her when she grew old.
Castalia was a nymph whom Apollo loved. She fled from him and dived into the spring at Delphi, at the base of Mt. Parnassos, which was then named after her. Water from this spring was sacred; it was used to clean the Delphian temples and inspire poets.
By Cyrene, Apollo had a son named Aristaeus, who became the patron god of cattle, fruit trees, hunting, husbandry and bee-keeping. He was also a culture-hero and taught humanity dairy skills and the use of nets and traps in hunting, as well as how to cultivate olives.
With Hecuba, wife of King Priam of Troy, Apollo had a son named Troilus. An oracle prophesied that Troy would not be defeated as long as Troilus reached the age of twenty alive. He was ambushed and killed by Achilles.
Apollo also fell in love with Cassandra, daughter of Hecuba and Priam, and Troilus' half-sister. He promised Cassandra the gift of prophecy to seduce her, but she rejected him afterwards. Enraged, Apollo indeed gifted her with the ability to know the future, with a curse that she could only see the future tragedies and that no one would ever believe her.
Coronis, daughter of Phlegyas, King of the Lapiths, was another of Apollo's liaisons. Pregnant with Asclepius, Coronis fell in love with Ischys, son of Elatus. A crow informed Apollo of the affair. When first informed he disbelieved the crow and turned all crows black (where they were previously white) as a punishment for spreading untruths. When he found out the truth he sent his sister, Artemis, to kill Coronis. As a result he also made the crow sacred and gave them the task of announcing important deaths. Apollo rescued the baby and gave it to the centaur Chiron to raise. Phlegyas was irate after the death of his daughter and burned the Temple of Apollo at Delphi. Apollo then killed him for what he did.
In Euripides' play Ion, Apollo fathered Ion by Creusa, wife of Xuthus. Creusa left Ion to die in the wild, but Apollo asked Hermes to save the child and bring him to the oracle at Delphi, where he was raised by a priestess.
One of his other liaisons was with Acantha, the spirit of the acanthus tree. Upon her death, Apollo transformed her into a sun-loving herb.
Apollo, the eternal beardless kouros himself, had the most prominent male relationships of all the Greek Gods. That was to be expected from a god who was god of the palaestra, the athletic gathering place for youth who all competed in the nude, a god said to represent the ideal educator and therefore the ideal erastes, or lover of a boy (Sergent, p.102). All his lovers were younger than him, in the style of the Greek pederastic relationships of the time. Many of Apollo's young beloveds died "accidentally", a reflection on the function of these myths as part of rites of passage, in which the youth died in order to be reborn as an adult.
Hyacinth was one of his male lovers. Hyacinthus was a Spartan prince, beautiful and athletic. The pair were practicing throwing the discus when Hyacinthus was struck in the head by a discus blown off course by Zephyrus, who was jealous of Apollo and loved Hyacinthus as well. When Hyacinthus died, Apollo is said in some accounts to have been so filled with grief that he cursed his own immortality, wishing to join his lover in mortal death and made Zephyrus into the wind so that he could never truly touch or speak to anyone again. Out of the blood of his slain lover Apollo created the hyacinth flower as a memorial to his death, and his tears stained the flower petals with άί άί, meaning alas. The Festival of Hyacinthus was a celebration of Sparta.
Another male lover was Cyparissus, a descendant of Heracles. Apollo gave the boy a tame deer as a companion but Cyparissus accidentally killed it with a javelin as it lay asleep in the undergrowth. Cyparissus asked Apollo to let his tears fall forever. Apollo turned the sad boy into a cypress tree, which was said to be a sad tree because the sap forms droplets like tears on the trunk.
Hermes was born on Mount Cyllene in Arcadia. The story is told in the Homeric Hymn to Hermes. His mother, Maia, had been secretly impregnated by Zeus. Maia wrapped the infant in blankets but Hermes escaped while she was asleep. Hermes ran to Thessaly, where Apollo was grazing his cattle. The infant Hermes stole a number of his cows and took them to a cave in the woods near Pylos, covering their tracks. In the cave, he found a tortoise and killed it, then removed the insides. He used one of the cow's intestines and the tortoise shell and made the first lyre. Apollo complained to Maia that her son had stolen his cattle, but Hermes had already replaced himself in the blankets she had wrapped him in, so Maia refused to believe Apollo's claim. Zeus intervened and, claiming to have seen the events, sided with Apollo. Hermes then began to play music on the lyre he had invented. Apollo, a god of music, fell in love with the instrument and offered to allow exchange of the cattle for the lyre. Hence, Apollo became a master of the lyre and Hermes invented a kind of pipes-instrument called a syrinx.
Later, Apollo exchanged a caduceus for a syrinx from Hermes.
Apollo gave the order through the Oracle at Delphi, for Orestes to kill his mother, Clytemnestra, and her lover, Aegisthus. Orestes was punished fiercely by the Erinyes (the Furies, female personifications of vengeance) for this crime. Relentlessly pursued by the Furies, Orestes asked for the intercession of Athena, who decreed that he be tried by a jury of his peers, with Apollo acting as his attorney.
In the Odyssey, Odysseus and his surviving crew landed on an island sacred to Helios the sun god, where he kept sacred cattle. Though Odysseus warned his men not to (as Tiresias and Circe had told him), they killed and ate some of the cattle and Helios had Zeus destroy the ship and all the men save Odysseus.
Apollo also had a lyre-playing contest with Cinyras, his son, who committed suicide when he lost.
Apollo killed the Aloadae when they attempted to storm Mt. Olympus.
It was also said that Apollo rode on the back of a swan to the land of the Hyperboreans during the winter months, a swan that he also lent to his beloved Hyacinthus to ride.
Apollo turned Cephissus into a sea monster.
Once Pan had the audacity to compare his music with that of Apollo, and to challenge Apollo, the god of the kithara, to a trial of skill. Tmolus, the mountain-god, was chosen to umpire. Pan blew on his pipes, and with his rustic melody gave great satisfaction to himself and his faithful follower, Midas, who happened to be present. Then Apollo struck the strings of his lyre. Tmolus at once awarded the victory to Apollo, and all but Midas agreed with the judgment. He dissented, and questioned the justice of the award. Apollo would not suffer such a depraved pair of ears any longer, and caused them to become the ears of a donkey.
Marsyas was a satyr who challenged Apollo to a contest of music. He had found an aulos on the ground, tossed away after being invented by Athena because it made her cheeks puffy. Marsyas lost and was flayed alive in a cave near Calaenae in Phrygia for his hubris to challenge a god. His blood turned into the river Marsyas.
Another variation is that Apollo played his instrument (the lyre) upside down. Marsyas could not do this with his instrument (the flute), and so Apollo hung him from a tree and flayed him alive.
Apollo, like other Greek deities, had a number of epithets applied to him, reflecting the variety of roles, duties, and aspects ascribed to the god. However, while Apollo has a great number of appellations in Greek myth, only a few occur in Latin literature, chief among them Phoebus ("shining one"), which was very commonly used by both the Greeks and Romans in Apollo's role as the god of light.
In Apollo's role as healer, his appellations included Akesios, Iatros, and Acestor meaning "healer". He was also called Alexikakos ("restrainer of evil") and Apotropaeus ("he who averts evil"), and was referred to by the Romans as Averruncus ("averter of evils"). As a plague god and defender against rats and locusts, Apollo was known as Smintheus ("mouse-catcher") and Parnopius ("grasshopper"). The Romans also called Apollo Culicarius ("driving away midges"). In his healing aspect, the Romans referred to Apollo as Medicus ("the Physician"), and a temple was dedicated to Apollo Medicus at Rome, probably next to the temple of Bellona. As a sun-god he was worshiped as Aegletes, the radiant god.
As a god of archery, Apollo was known as Aphetoros ("god of the bow") and Argurotoxos ("with the silver bow"). The Romans referred to Apollo as Articenens ("carrying the bow") as well. As a pastoral shepherd-god, Apollo was known as Nomios ("wandering").
Apollo was also known as Archegetes ("director of the foundation"), who oversaw colonies. He was known as Klarios, from the Doric klaros ("allotment of land"), for his supervision over cities and colonies.
He was known as Delphinios ("Delphinian"), meaning "of the womb", in his association with Delphoi (Delphi). At Delphi, he was also known as Pythios ("Pythian"). An aitiology in the Homeric hymns connects the epitheton to dolphins. Kynthios, another common epithet, stemmed from his birth on Mt. Cynthus. He was also known as Lyceios or Lykegenes, which either meant "wolfish" or "of Lycia", Lycia being the place where some postulate that his cult originated.
Specifically as god of prophecy, Apollo was known as Loxias ("the obscure"). He was also known as Coelispex ("he who watches the heavens") to the Romans. Apollo was attributed the epithet Musagetes as the leader of the muses, and Nymphegetes as "nymph-leader".
Acesius was the epithet of Apollo worshipped in Elis, where he had a temple in the agora. This surname, which has the same meaning as akestor and alezikakos, characterized the god as the averter of evil. Acraephius or Acraephiaeus was his epithet worshipped in the Boeotian town of Acraephia, reputedly founded by his son, Acraepheus. Actiacus was his epithet in Actium, one of the principal places of his worship.
Apollo was worshipped throughout the Roman Empire. In the traditionally Celtic lands he was most often seen as a healing and sun god. He was often equated with Celtic gods of similar character.
Apollo Atepomarus ("the great horseman" or "possessing a great horse"). Apollo was worshipped at Mauvrieres (Indre) under this name. Horses were, in the Celtic world, closely linked to the sun.
Apollo Belenus ('bright' or 'brilliant'). This epithet was given to Apollo in parts of Gaul, North Italy and Noricum (part of modern Austria. Apollo Belenus was a healing and sun god.
Apollo Cunomaglus ('hound lord'). A title given to Apollo at a shrine in Wiltshire. Apollo Cunomaglus may have been a god of healing. Cunomaglus himself may originally have been an independent healing god.
Apollo Maponus. A god known from inscriptions in Britain. This may a local fusion of Apollo and Maponus.
Apollo Moritasgus ('masses of sea water'). An epithet for Apollo at Alesia, where he was worshipped as god of healing and, possibly, of physicians.
Apollo Vindonnus ('clear light'). Apollo Vindonnus had a temple at Essarois, near Chatillon-sur-Seine in Burgundy. He was a god of healing, especially of the eyes.
Apollo has often featured in postclassical art and literature. Percy Bysshe Shelley composed a "Hymn of Apollo" (1820), and the god's instruction of the Muses formed the subject of Igor Stravinsky's Apollon musagète (1927–1928). Apollo also gave his name to NASA's Apollo Lunar program in the 1960s.


Andre Kirk Agassi (born April 29 1970) is a former World No. 1 professional American tennis player who won eight Grand Slam singles tournaments and an Olympic gold medal in singles. He is one of only five male players to have won all four Grand Slam singles events during his career. He is the only player in the open era to have won every Grand Slam singles title, to have won the Tennis Masters Cup, to have been part of a winning Davis Cup team, and to have won an Olympic gold medal. He won 17 ATP Masters Series tournaments, more than any other player. TENNIS Magazine has named him the 7th greatest male player from 1965 through 2005.
Because of sciatica caused by two bulging discs in his back, a spondylolisthesis (vertebral displacement), and a bone spur that interferes with the nerve, Agassi retired from professional tennis on September 3, 2006, after losing in the third round of the U.S. Open. Agassi is married to Steffi Graf and has two children. He is the founder of the Andre Agassi Charitable Foundation, which has raised over $60 million for at-risk children in Southern Nevada. In 2001, the Foundation opened the Andre Agassi College Preparatory Academy in Las Vegas, a K-12 public charter school for at-risk children.
Agassi was born in Las Vegas, Nevada to Emmanuel "Mike" Aghassian and Elizabeth "Betty" Agassi (maiden name Dudley). His father is an Iranian of Armenian and Assyrian ancestry, and represented Iran in boxing at the 1948 and 1952 Olympic Games before emigrating to the United States. He was intent on having a child win all four tennis Grand Slam tournaments. He learned tennis by watching tapes of champions and took a very systematic approach to the game. He called Agassi's two older siblings "guinea pigs" in the development of his coaching techniques. He honed Andre's eye-coordination when he was an infant by hanging tennis balls above his crib. He gave Agassi paddles and balloons when he was still in a high chair. When Agassi started playing tennis, his ball collection filled 60 garbage cans with 300 balls per can, and Agassi would hit 3,000-5,000 balls every day. When Andre was five years old, he was already practicing with pros such as Jimmy Connors and Roscoe Tanner. Later, Mike began working in one of the Las Vegas casinos that belonged to Armenian American tycoon Kirk Kerkorian. Mike and Kirk became good friends, and Andre's middle name "Kirk" is actually after Kirk Kerkorian.
Agassi was unhappy at the academy and grew rebellious. He drank beer, smashed racquets, and grew a mohawk haircut. At a televised tournament, he wore ripped denim jeans and, knowing his father's homophobia, wore pink lipstick and grew out his pinkie fingernail and painted it pink. After a year at the academy, Agassi became emotionless and depressed. Bollettieri eventually lost his temper and told Agassi to leave. He saw Agassi's indifference and then asked what he wanted. Agassi replied, "leaving here and turning pro." He turned professional at the age of 16. His first tournament was in La Quinta, California. He won his first match against John Austin, 6-4 6-2 but then lost his second match to Mats Wilander 6-1, 6-1. By the end of the year, Agassi was ranked #91 in the world.
Agassi employed a baseline style of play, but unlike most such players, he typically made contact with the ball inside the baseline — exceptionally difficult even for professionals as this requires great reaction time. This was possible because of his short backswing and his extraordinary hand-eye coordination. These same attributes helped him aggressively return serves. John McEnroe, Jim Courier and others have called Agassi the best service returner ever to play tennis. Many, including Brad Gilbert, call him the best ball striker in the history of tennis.
Agassi was known for his ability to hit sharply angled winners from the baseline. Early on in his career, Agassi would look to end points quickly, typically by inducing a weak return with a deep, hard shot, and then playing a winner at an extreme angle. In 1995, he added a backhand drop shot to his repertoire, which was one of the most effective drop shots on tour (partly due to the fact that Agassi's groundstrokes forced most opponents to play far behind the baseline). On the rare occasion that he charged the net, Agassi liked to take the ball in the air and hit a swinging volley for the winner. This requires exceptional timing and reflexes, which Agassi was famous for; he once entered a batting cage and hit 90 mph fastballs with a bat while running toward the machine.
After Agassi's rededication to tennis in 1998, he focused more on physical conditioning than in the past and became one of the fittest players on the tour. He had remarkable endurance and rarely appeared tired on court.
In the last year of his career, various injuries, most notably in his back, robbed Agassi of consistent speed and court coverage. As a result, players who were able to consistently hit at sharp angles with pace, particularly those who could do this on the run, gave him trouble. To make up for this weakness, Agassi began playing more aggressive shots, to keep his opponent on the defensive and deny them opportunities to run Agassi around the court. This both limited his options from the baseline and increased his errors.
Agassi's serve was never the strength of his game, but it improved steadily over the course of his career, and went from being a liability to being an average serve. His most effective serve was a hard slice, which he would use to ace opponents in the ad court, and to send his opponent wide off the court when serving on the deuce side, followed by a shot to the opposite corner to send his opponent scrambling. He relied on a heavy kick serve for his second serve, particularly early in his career.
Agassi turned professional in 1986 and won his first top-level singles title in 1987 at Itaparica. He ended the year ranked #25. He won six further tournaments in 1988, and, by December of that year, he had surpassed U.S. $2 million in career prize money after playing in just 43 tournaments – the fastest anyone in history had reached that level. His year-end ranking was #3, behind Ivan Lendl at #2 and Mats Wilander at #1.
As a young up-and-coming player, Agassi embraced a rebel image. He grew his hair to rocker length, sported an earring, and wore colorful shirts that pushed tennis' still-strict sartorial boundaries. He boasted of a cheeseburger diet and endorsed the Canon "Rebel" camera. "Image is everything" was the ad's line, and it became Agassi's as well.
In addition to not playing the Australian Open (which would later become his best Grand Slam event) for the first eight years of his career, Agassi chose not to play at Wimbledon from 1988 through 1990 and publicly stated that he did not wish to play there because of the event's traditionalism, particularly its "predominantly white" dress code to which players at the event are required to conform. Many observers at the time speculated that Agassi's real motivation was that his strong baseline game would not be well suited to Wimbledon's grass court surface.
Strong performances on the tour meant that Agassi was quickly tipped as a future Grand Slam champion. While still a teenager, he reached the semifinals of both the French Open and the U.S. Open in 1988, and the U.S. Open again in 1989. He began the 1990s, however, with a series of near-misses. He reached his first Grand Slam final in 1990 at the French Open, where he lost in four sets to Andrés Gómez. His second Grand Slam final was against Pete Sampras at the U.S. Open. The last time Agassi had played Sampras, he won 6-1, 6-1. After that match, he told his coach that he felt bad for Sampras because he was never going to make it. Looking at the draw, Agassi was happy that he did not have to face Lendl or McEnroe in the final, and he planned to make Sampras hit more balls than he could handle. Despite being the favorite in the match, he lost to Sampras 6-4, 6-3, 6-2. The rivalry between these two American players became the dominant rivalry in tennis over the rest of the decade. Also in 1990, Agassi helped the United States win its first Davis Cup in 8 years.
In 1991, Agassi reached his second consecutive French Open final, where he faced fellow Bollettieri Academy alumnus Jim Courier. Courier emerged the victor in a five set final. Agassi decided to play at Wimbledon in 1991, leading to weeks of speculation in the media about the clothes he would wear. He eventually emerged for the first round in a completely white outfit. He went on to reach the quarterfinals on that occasion.
To the surprise of many, Agassi's Grand Slam breakthrough came at Wimbledon, not at the French Open or the U.S. Open where he had enjoyed so much success. In 1992, he defeated Goran Ivanišević in a five set final. Along the way, Agassi dispatched two former Wimbledon champions in Boris Becker and John McEnroe. No other baseliner would triumph at Wimbledon until Lleyton Hewitt ten years later, on slower, higher bouncing grass better suited for baseline play. Agassi was named the BBC Overseas Sports Personality of the Year in 1992.
Agassi once again was a key player on the United States' Davis Cup winning team in 1992. It was their second Davis cup title in three years.
1993 saw Agassi win the only doubles title of his career, at the Cincinnati Masters, partnered with Petr Korda. Agassi missed much of the early part of this year with injury troubles and struggled at the major events. After a first-round exit at the U.S. Open, he had wrist surgery late in the year.
Agassi started slowly in 1994, losing in the first week at the French Open and Wimbledon. Nevertheless, Agassi emerged during the hard court season, winning the Canada Masters event. His comeback culminated in his becoming the first man to capture the U.S. Open as an unseeded player, beating Michael Stich in the final. Agassi's run included a 5 set fourth-round victory against compatriot Michael Chang.
In 1995, Agassi shaved his balding head, breaking with his old "image is everything" style. Agassi attended the Australian Open for the first time and won it in his first attempt, beating Sampras in a four set final. Agassi and Sampras met in five tournament finals in 1995, all on hardcourt, with Agassi winning three of the five. Agassi won three Masters Series events in 1995 - the Cincinnati Masters, the Miami Masters, and the Canada Masters, and seven titles total. Agassi compiled a career-best 26-match winning streak during the summer hardcourt circuit, which ended when he lost in a hugely anticipated U.S. Open final to Sampras.
Agassi reached the World No. 1 ranking for the first time in April 1995. He held the No. 1 ranking until November, for a total of 30 weeks. In terms of win/loss record, 1995 was Agassi's best year. He won 72 matches and lost only 10. This was a higher winning percentage than Sampras’ best season, 1994, in which he won 77 matches and lost 12. Agassi was also once again a key player on the United States Davis Cup winning team - the third and final Davis Cup title of Agassi's career.
1996 was a less successful year for Agassi, as he failed to reach any Grand Slam finals. He suffered two surprise early round losses at the hands of compatriots Chris Woodruff and Doug Flach at the French Open and Wimbledon respectively. The clear high point for Agassi was winning the men's singles gold medal at the Olympic Games in Atlanta, beating Sergi Bruguera of Spain in the final 6-2, 6-3, 6-1. Agassi also successfully defended his singles titles at the Cincinnati Masters and the Miami Masters.
1997 was the low point of Agassi's career. His wrist injury resurfaced, and he played only 24 matches on the year. He won no top-level titles and his ranking sank to World No. 141 in November. Agassi was also subject to intense publicity surrounding his high-profile and turbulent marriage to actress Brooke Shields (a marriage that ended in divorce).
In 1998, Agassi rededicated himself to tennis. He began a rigorous conditioning program and worked his way back up the rankings by playing in Challenger Series tournaments (a circuit for professional players ranked outside the world's top 50). Perhaps most remarkably, the one-time rebel emerged as a gracious and thoughtful athlete, admired by younger players. After winning matches, he bowed and blew two-handed kisses to spectators on each side of the court, a gesture seen as a rather humble acknowledgement of their support for him and for tennis. He played some classic matches in this period, most notably against his old rival Pete Sampras and popular Australian Patrick Rafter.
In 1998, Agassi won five titles and leapt from World No. 141 at the start of the year to World No. 6 at the end of it, making it the highest jump into the top 10 made by any player during a single calendar year. He won five titles in ten finals and was runner-up at the Miami Masters, losing to Marcelo Ríos, who became World No. 1 as a result of winning that tournament.
Agassi entered the history books in 1999 when he came back from two sets to love down to beat Andrei Medvedev in a five-set French Open final, thereby becoming only the fifth male player (joining Rod Laver, Fred Perry, Roy Emerson, and Don Budge) to have won all four Grand Slam singles titles during his career. He is however, the only male player in history to have won all four Grand Slam titles on three different surfaces (clay, grass and hard courts), a tribute to his adaptability, as the other four men won their Grand Slam titles on clay and grass courts. Agassi also became the first male tennis player to win the Career Golden Slam.
He followed his 1999 French Open victory by reaching the Wimbledon final, where he lost to Sampras 6-3, 6-4, 7-5. He rebounded from his Wimbledon defeat by winning the U.S. Open, beating Todd Martin in five sets (rallying from a 2 sets to 1 deficit) in the final. Agassi ended 1999 as the World No. 1, ending Sampras's record of six consecutive year-ending top rankings (1993-1998). This was the only time Agassi ended the year at number one.
Agassi began 2000 by capturing his second Australian Open title, beating Sampras in a five-set semifinal and Yevgeny Kafelnikov in a four-set final. He was the first male player to have reached four consecutive Grand Slam finals since Rod Laver achieved the Grand Slam in 1969. At the time, Agassi was also only the third player since Laver to be the reigning champion of three of four Grand Slam events, missing only the Wimbledon title.
2000 also saw Agassi reach the semifinals at Wimbledon, where he lost in five sets to Rafter in a match considered by many to be one of the best ever played at Wimbledon. At the inaugural Tennis Masters Cup in Lisbon, Agassi reached the final after defeating Marat Safin 6-3, 6-3 in the semifinals to end the Russian's hopes to become the youngest World No. 1 in the history of tennis. Agassi eventually lost to Gustavo Kuerten 6-4, 6-4, 6-4. This loss allowed Kuerten to be crowned year-end World No. 1. Agassi finished 2000 ranked World No. 6, becoming the only male tennis player to have been ranked in the Top 10 in three different decades (1980’s - finishing No. 3 & 7 in 1988 and 1989; 1990’s - No. 4 in 1990, No. 10 in 1991, No. 9 in 1992, No. 2 in 1994 & 1995, No. 8 in 1996, No. 6 in 1998, and No. 1 in 1999; 2000’s - No. 6 in 2000, No. 3 in 2001, No. 2 in 2002, No. 4 in 2003, No. 8 in 2004, and No.7 in 2005).
Agassi opened 2001 by successfully defending his Australian Open title with a straight-sets final win over Arnaud Clément. Enroute, he beat a cramping Rafter (7-5, 2-6, 6-7, 6-2, 6-3) in front of a sell out crowd in what turned out to be the Aussie's last Australian Open. At Wimbledon, they met again in the semifinals, where Agassi lost another close match to Rafter, 8-6 in the fifth set. At the U.S. Open, Agassi lost in the quarterfinals to Sampras 6-7, 7-6, 7-6, 7-6, with no breaks of serve during the entire match.
2002 opened with disappointment for Agassi, as injury forced him to skip the Australian Open, where he was a two-time defending champion. The last duel between Agassi and Sampras came in the final of the U.S. Open. The battle saw Sampras emerge victorious in four sets and left Sampras with a 20-14 edge in their 34 career meetings. The match proved to be the last of Sampras's career. Agassi's U.S. Open finish, along with his victories at the Miami Masters, Rome Masters, and Madrid Masters, helped him finish 2002 as the oldest year-end No. 2 at 32 years and 8 months.
In 2003, Agassi won the eighth (and final) Grand Slam title of his career at the Australian Open, where he beat Rainer Schüttler in straight sets in the final. In March, he won his sixth career and third consecutive Miami Masters, in the process surpassing wife Steffi Graf who was a 5-time winner of the event. The final was his 18th straight win in that tournament, which broke the previous record of 17 set by Sampras from 1993-1995. (Agassi's winning streak continued to 20 after winning his first two matches at the 2004 Miami Masters before bowing to Agustin Calleri.) With the victory, Agassi became the youngest (19 years old) and oldest (32) winner of the Miami Masters. In May, he recaptured the World No. 1 ranking after a quarterfinal victory over Xavier Malisse at the Queen's Club Championships to become the oldest top ranked male player ever at 33 years and 13 days. He held the No. 1 ranking on that occasion for 14 weeks. Agassi's ranking slipped when injuries forced him to withdraw from many events. He did manage to reach the U.S. Open semifinals, where he lost to Juan Carlos Ferrero and surrendered his World No. 1 ranking to Ferrero. At the year-end Tennis Masters Cup, Agassi lost in the final to Federer and finished the year ranked World No. 4.
In 2004, the 34-year-old Agassi won the Cincinnati Masters to bring his career total to 59 top-level singles titles and a record 17 ATP Masters Series titles, having already won seven of the nine ATP Masters tournament -- all except Monte Carlo and Hamburg. He became the second-oldest singles champion in Cincinnati tournament history (the tournament began in 1899), surpassed only by Ken Rosewall who won the title in 1970 at age 35.
Agassi's 2005 began with a quarterfinal loss to Federer at the Australian Open. Agassi had several other deep runs at tournaments, but had to withdraw from several events due to injury. He won his fourth title in Los Angeles and reached the finals of the Rogers Cup before falling to World No. 2 Rafael Nadal.
Still, Agassi's 2005 was defined by an improbable run to the U.S. Open final. After beating Razvan Sabau and Ivo Karlovic in straight sets and Tomas Berdych in four sets, Agassi won three consecutive five set matches to advance to the final. The most notable of these matches was his quarterfinal victory over James Blake, where he rallied from two sets down to win 3-6, 3-6, 6-3, 6-3, 7-6(6). His other five-set victims were Xavier Malisse in the fourth round and Robby Ginepri in the semifinals. In the final, Agassi faced Federer, who was seeking his second consecutive U.S. Open title and his fifth Grand Slam title in two years. Federer defeated Agassi in four sets, although Agassi gave him a scare when Agassi was up a break in the third set after splitting the first two sets.
Before the 2005 Tennis Masters Cup in Shanghai, Agassi rolled his ankle in a racquetball accident and tore several ligaments. He was unable to walk for weeks. He nevertheless committed to the tournament, in which he was seeded third, and played Nikolay Davydenko in his first round robin match. Agassi's movement was noticeably hindered, particularly on his backhand return of serve, and he lost in straight sets. He then withdrew from the tournament, to the criticism of the tournament director who had already dealt with several other withdrawals.
Agassi finished 2005 ranked No. 7, his 16th time in the year-end top 10 rankings, which tied Connors for the most times ranked in the top 10 at year's end. In 2005, Agassi left Nike after 17 years and signed an endorsement deal with Adidas.
Agassi had a poor start to 2006. He was still recovering from an ankle injury and also suffering from back and leg pain and lack of match play. Agassi withdrew from the Australian Open because of the ankle injury, and his back injury and other pains forced him to withdraw from several other events, eventually skipping the entire clay court season, including the French Open. This caused his ranking to drop out of the top 10 for the last time.
Agassi returned for the grass court season, playing a tune-up and then Wimbledon. At Wimbledon, Agassi announced his plans to retire following the U.S. Open. He was defeated in the third round by world #2 (and eventual finalist) Rafael Nadal, 7-6(5), 6-2, 6-4. Against conventions, Agassi, the losing player, was interviewed on court after the match.
Agassi played only two events during the summer hardcourt season, with his best result being a quarterfinal loss in the Countrywide Classic in Los Angeles to Fernando González of Chile 6-4, 3-6, 7-5. As a result, he was unseeded at the U.S. Open.
Agassi had a short but dramatic run in his final U.S. Open. Due to extreme back pain, Agassi was forced to receive anti-inflammatory injections after every match. After a tough four-set win against Andrei Pavel, Agassi faced #8 seed Marcos Baghdatis, who had earlier in 2006 advanced to the Australian Open finals and Wimbledon semifinals, in the second round. Agassi, nevertheless, won 6-4, 6-4, 3-6, 5-7, 7-5 as the younger Baghdatis succumbed to muscle cramping in the final set.
In his last match, Agassi was in obvious pain on court and fell to 112th ranked big-serving Benjamin Becker of Germany in four sets. Agassi received an 8 minute standing ovation from the crowd after the match and delivered a memorable retirement speech.
Agassi earned more than US$30 million in prize-money throughout his career, third only to Sampras and Federer. In addition, Agassi earned over US$25 million a year through endorsements, the most by any tennis player, during his career and fourth in all sports at the time.
Since retiring after the 2006 U.S. Open, Agassi has participated in a series of charity tournaments and continues his work with his own charity. On September 5, 2007, Agassi was a surprise guest commentator for the Andy Roddick/Roger Federer 2007 U.S. Open quarterfinal.
Agassi dated famed American singer Barbra Streisand in the early 1990s before marrying actress Brooke Shields on April 19, 1997. That February, they had filed suit against The National Enquirer claiming it printed "false and fabricated" statements about the couple. The case was dismissed. He later filed for divorce from Shields, which was granted on April 9, 1999.
At the 1999 French Open, Agassi and Steffi Graf were the surprise champions, since he had not won a grand slam title since 1995 and she since 1996. At the winners' ball, they danced the traditional champions dance. After that evening they began dating. Graf retired after they both reached the Wimbledon final in July. They were married on October 22, 2001. Their son, Jaden Gil, was born on October 26 of the same year. Their daughter, Jaz Elle, was born on October 3, 2003. The couple live in the Las Vegas area and own several vacation homes.
Agassi's older sister, Rita, was married to the late former tennis legend Pancho Gonzales. In 1995, when Gonzales died in Las Vegas, Agassi paid for the funeral.
Agassi is also a staunch Democrat and has donated over $100,000 to different Democratic candidates.
Agassi has participated in many charity organizations and founded the Andre Agassi Charitable Association in 1994, which assists the youth of Las Vegas. He was awarded the ATP Arthur Ashe Humanitarian award in 1995 for his efforts to help disadvantaged youth. He is regularly cited as the most charitable and socially involved player in professional tennis.
Agassi's charity often takes the form of assisting children with their athletic potential. His Boys & Girls Club sees 2,000 children throughout the year and boasts a world class junior tennis team. It also has a basketball program (the Agassi Stars) and a rigorous system that encourages a mix of academics and athletics.
In 2001, Agassi opened up the Andre Agassi College Preparatory Academy in Las Vegas, a tuition-free charter school for at-risk children in the area. Ironically, Agassi never finished his own formal education due to his decision to turn pro.
In 2007, Agassi, Muhammad Ali, Lance Armstrong, Warrick Dunn, Jeff Gordon, Mia Hamm, Tony Hawk, Andrea Jaeger, Jackie Joyner-Kersee, Mario Lemieux, Alonzo Mourning, and Cal Ripken, Jr. founded Athletes for Hope, a charitable organization, which helps professional athletes get involved in charitable causes and inspires millions of non-athletes to volunteer and support the community.
Note: "Tournaments were designated as the 'Masters Series' only after the ATP took over the running of the men's tour in 1990.
1This event was held in Stockholm through 1994, Essen in 1995, and Stuttgart from 1996 through 2001.

The Austro-Asiatic languages are a large language family of Southeast Asia, and also scattered throughout India and Bangladesh. The name comes from the Latin word for "south" and the Greek name of Asia, hence "South Asia". Among these languages, only Vietnamese, Khmer, and Mon have a long recorded history, and only Vietnamese and Khmer have official status (in Vietnam and Cambodia, respectively). The rest of the languages are spoken by minority groups.
Austro-Asiatic languages have a disjunct distribution across India, Bangladesh and Southeast Asia, separated by regions where other languages are spoken. It is widely believed that the Austro-Asiatic languages are the autochthonous languages of Southeast Asia and the eastern Indian subcontinent, and that the other languages of the region, including the Indo-European, Tai-Kadai, Dravidian, and Sino-Tibetan languages, are the result of later migrations of people. (There are, for example, Austro-Asiatic words in the Tibeto-Burman languages of eastern Nepal.) Some linguists have attempted to prove that Austro-Asiatic languages are related to Austronesian languages, thus forming the Austric superfamily.
Linguists traditionally recognize two primary divisions of Austro-Asiatic: the Mon-Khmer languages of Southeast Asia, Northeast India and the Nicobar Islands, and the Munda languages of East and Central India and parts of Bangladesh. Ethnologue identifies 168 Austro-Asiatic languages, of which 147 are Mon-Khmer and 21 are Munda. However, no evidence for this classification has ever been published, and it is possible that the linguistic classification has been influenced by researchers' subjective perception of a racial dichotomy between the speakers of languages that have traditionally been classified as Mon-Khmer and those that have traditionally been classified as Munda.
Each of the families that is written in boldface type below is accepted as a valid clade. However, the relationships between these families within Austro-Asiatic is debated; in addition to the traditional classification, two recent proposals are given, neither of which accept traditional Mon-Khmer as a valid unit. It should be noted that little of the data used for competing classifications has ever been published, and therefore cannot be evaluated by peer review.
There are in addition several unclassified languages of southern China.

The Afro-Asiatic languages constitute a language family with about 375 languages (SIL estimate) and more than 300 million speakers spread throughout North Africa, East Africa, West Africa, Central Africa, and Southwest Asia (including some 200 million speakers of Arabic).
The term "Afro-Asiatic" was coined by Joseph Greenberg to replace the earlier term "Hamito-Semitic".
Other names sometimes given to this family include "Afrasian", "Lisramic" (Hodge 1972), and "Erythraean" (Tucker 1966).
Many people regard the Ongota language as Omotic, but its classification within the family remains controversial, partly for lack of data. Harold Fleming tentatively suggests treating it as an independent branch of non-Omotic Afro-Asiatic.
No agreement exists on where Proto-Afro-Asiatic speakers lived (i.e. the Afro-Asiatic Urheimat), though the language is generally believed to have originated in Northeast Africa. Some scholars (such as Igor Diakonoff and Lionel Bender) have proposed Ethiopia, because it includes the majority of the diversity of the Afro-Asiatic language family and has very diverse groups in close geographic proximity, often considered a telltale sign for a linguistic geographic origin. Other researchers (such as Christopher Ehret) have put forward the western Red Sea coast and the Sahara. A minority (such as Alexander Militarev) suggest a linguistic homeland in the Levant (specifically, he identifies Afro-Asiatic with the Natufian culture), with Semitic being the only branch to stay put.
The Semitic languages form the only Afro-Asiatic subfamily extant outside of Africa. Some scholars believe that, in historical or near-historical times, Semitic speakers crossed from South Arabia back into Ethiopia and Eritrea, while others, such as A. Murtonen, dispute this view, suggesting that the Semitic branch may have originated in Ethiopia. A third view, based upon similarities between Semitic and ancient Egyptian, is that the two languages developed from a common ancestral tongue along the Nile, crossing the Sinai with the dry phase from 6,000-5,800 BCE, at the end of the pre-pottery neolithic (PPNB) phase in the Levant. Hunter-gatherers of the el-Harif mesolithic culture, crossing the Sinai and from Northern Egypt, and adopting animal domestication but not agriculture could then have created what Juris Yarins calls the Syro-Arabian nomadic pastoralism complex, spreading south along the shore of the Red Sea, and north eastwards around the edge of the "fertile crescent". In the Levant this development appears as the Minhata, and later Yarmoukian culture, which came from the same semi-arid zone as did the later Ghassulian and Semitic Amorites cultures.
Tonal languages appear in the Omotic, Chadic, and Cushitic branches of Afro-Asiatic, according to Ehret (1996). The Semitic, Berber, and Egyptian branches do not use tones phonemically.
Given the diversity that exists within the Afro-Asiatic group, and the lack of common vocabulary for agricultural items, it is suggested that the languages dispersed before the commencement of the Neolithic. The finding of a common vocabulary for pottery containers, however, suggests that this technology was known.
For example Proto-Semitic "*k'ad-ah- "vessel", found in Arabic kadah "drinking bowl, cup, goblet, glass, tumbler"; Sabaean m-kdh(m,n) "cup; Ethiopic / Geez kadho "vessel, gourd", ma-kdeht "jar, jug, bucket"; Lowland East Cushitic *k'adad- "vessel, gourd; Oromo "k'odaa "vessel, gourd; Egyptian qd "pot"; Lowland East Kushitic "*k'od- "receptical"; Oromo k'odaa "receptacle"; West Chadic *k'wad- "calabash"; Dangla koda "pot" gives Proto-Afro-Asiatic *k'ud-/*k'od- "Vessel, pot".
Ehret suggests that early Afro-Asiatic languages were involved in the domestication of Ethiopian food crops, but this is disputed by others who suggest these words were found only in the Cushitic and possibly Omotic families, and common cognates for agriculture are not present. Given that wavy line pottery is found widely in the Sahara from 8,000 BCE, and that the neolithic agriculture technologies arrived 5000 BCE, this sets a possible context for Proto-Afro-Asiatic dispersal. As it is known that the Ethiopian farmers moved into the highlands from the direction of Nubian Sudan, and attempts to translate the Meroitic script found in this area show significant Afro-Asiatic characteristics, linguist Lionel Bender suggests that it was out of this area of the Southern Nile that was the centre for dispersion of the Afro-Asiatic languages occurred. The dates of pottery and agriculture set approximate early and late dates for this linguistic dispersal. Climatically this was a period of a "wet Sahara" phase with large rivers and lakes. The dispersal of Afro-Asiatic may thus have been a response to the recent operation of the "Sahara pump".
All Afro-Asiatic subfamilies show evidence of a causative affix s, but a similar suffix also appears in other groups, such as the Niger-Congo languages.
Semitic, Berber, Cushitic (including Beja), and Chadic support possessive suffixes.
Medieval scholars sometimes linked two or more branches of Afro-Asiatic together; as early as the 9th century the Hebrew grammarian Judah ibn Quraysh of Tiaret in Algeria perceived a relationship between Berber and Semitic (the latter group known to him through Arabic, Hebrew, and Aramaic).
Leo Reinisch (1909) proposed to link Cushitic and Chadic, while urging a more distant affinity with Egyptian and Semitic, thus foreshadowing Greenberg; but his suggestion found little resonance. Marcel Cohen (1924) rejected the idea of a distinct "Hamitic" subgroup, and included Hausa (a Chadic language) in his comparative Hamito-Semitic vocabulary. Joseph Greenberg (1950) strongly confirmed Cohen's rejection of "Hamitic", added (and sub-classified) the Chadic languages, and proposed the new name Afro-Asiatic for the family; almost all scholars have accepted his classification. In 1969 Harold Fleming proposed the recognition of Omotic as a fifth branch, rather than (as previously believed) a subgroup of Cushitic, and this has met with general acceptance. Several scholars, including Harold Fleming and Robert Hetzron, have since questioned the traditional inclusion of Beja in Cushitic, but this view has yet to gain general acceptance.


Andorra (Catalan: Andorra), officially the Principality of Andorra (Catalan: "Principat d'Andorra") is a small landlocked country in western Europe, located in the eastern Pyrenees mountains and bordered by Spain (Catalonia) and France (Northern Catalonia and old Occitania). Once isolated, it is currently a prosperous country mainly because of tourism and its status as a tax haven. The people of Andorra are currently listed as having the highest human life expectancies on Earth, at an average of 83.52 years at birth(2007 est).
The name "Andorra" is of unknown origin but (according to Joan Coromines) clearly pre-Roman. The name Andorra may be derived from al-Darra, the Arabic word for forest. Many of the local toponyms are of Iberian origin.
Tradition holds that Charles the Great (Charlemagne) granted a charter to Andorran people in return for fighting against the Moors. Overlordship of the territory passed to the local count of Urgell and eventually to the bishop of the diocese of Urgell. In the eleventh century a dispute arose between the bishop and his northern neighbour over Andorra.
The conflict was resolved in 1278 by the signing of a paréage, which provided that Andorra's sovereignty be shared between the count of Foix (whose title would ultimately transfer to the French head of state) and the bishop of La Seu d'Urgell, in Catalonia, Spain. This gave the small principality its territory and political form.
Over the years the title passed to the kings of Navarre. After Henry of Navarre became King Henry IV of France, he issued an edict (1607) that established the head of the French state and the Bishop of Urgell as co-princes of Andorra.
In the period 1812–13, the First French Empire annexed Catalonia and divided it in four départements. Andorra was also annexed and made part of the district of Puigcerdà (département of Sègre).
Andorra declared war on Imperial Germany during World War I but did not actually take part in the fighting. It remained in an official state of belligerency until 1957 as it was not included in the Versailles Peace Treaty.
In 1933 France occupied Andorra as a result of social unrest before elections. On July 12, 1934, an adventurer named Boris Skossyreff issued a proclamation in Urgell, declaring himself Boris I, sovereign prince of Andorra, simultaneously declaring war on the bishop of Urgell. He was arrested by Spanish authorities on July 20 and ultimately expelled from Spain. From 1936 to 1940, a French detachment was garrisoned in Andorra to prevent influences of the Spanish Civil War and Franco's Spain.
Francoist troops reached the Andorran border in the later stages of the war.
During World War II, Andorra remained neutral and was an important smuggling route between Vichy France and Spain.
Given its relative isolation, Andorra has existed outside the mainstream of European history, with few ties to countries other than France and Spain. In recent times, however, its thriving tourist industry along with developments in transportation and communications have removed the country from its isolation. Its political system was thoroughly modernized in 1993, the year in which it became a member of the United Nations.
Andorra is a co-principality with the President of France and the Bishop of Urgell, Spain as co-princes, in a duumvirate. The politics of Andorra take place in a framework of a parliamentary representative democracy, whereby the Prime Minister of Andorra is the head of government, and of a pluriform multi-party system. Executive power is exercised by the government. Legislative power is vested in both the government and parliament. The Judiciary is independent of the executive and the legislature.
Responsibility for defending Andorra rests with Spain and France. Andorra currently has no military force.
Due to its location in the eastern Pyrenees mountain range, Andorra consists predominantly of rugged mountains of an average height of 1,996 m with the highest being the Coma Pedrosa at 2,946 m. These are dissected by three narrow valleys in a Y shape that combine into one as the main stream, the Valira river, leaves the country for Spain (at Andorra's lowest point of 870 m). Andorra's surface area is 468 km².
Andorra's climate is similar to that of its neighbours' temperate climates, but its higher altitude means there is, on average, more snow in winter and it is slightly cooler in summer.
Tourism, the mainstay of Andorra's tiny, well-to-do economy, accounts for roughly 80% of GDP. An estimated 9 million tourists visit annually, attracted by Andorra's duty-free status and by its summer and winter resorts. Andorra's comparative advantage has recently eroded as the economies of adjoining France and Spain have been opened up, providing broader availability of goods and lower tariffs.
Andorra is not a full member of the European Union, but enjoys a special relationship with it, such as being treated as an EU member for trade in manufactured goods (no tariffs) and as a non-EU member for agricultural products. Andorra lacks a currency of its own and uses that of its two surrounding nations. Prior to 1999 these were the French franc and the Spanish peseta, which have since been both replaced by the EU's single currency, the euro.
Andorrans are a minority in their own country; Spaniards, Portuguese, Frenchmen, Britons, and Italians resident in Andorra make up 67.7% of the population. According to the U.S. Census Bureau, Andorra has the longest life expectancy – 83.5 years.
The national language is Catalan, a Romance language. Andorra is one of only four nations (together with France, Monaco, and Turkey) that never signed the Council of Europe Framework Convention on National Minorities.
The population of Andorra is predominantly Roman Catholic.
The official and historic language is Catalan. Other languages stemming from immigration, historical links and close geographic proximity, such as Spanish and French are also commonly spoken.
Andorra's long history has provided it with a rich folklore and an abundance of folk tales, with roots originating as far as Andalusia in the south and the Netherlands in the north.
Andorran culture is Catalan in essence. It has given a significant and easily identifiable contribution to the conglomerate of Catalan culture.
Two writers renowned in Catalonia and the region, Michèle Gazier and Ramon Villeró, both come from Andorra.
Andorra is home to folk dances like the contrapàs and marratxa, which survive in Sant Julià de Lòria especially. Andorran folk music has similarities to all of its neighbors, but is especially Catalan in character, especially in the presence of dances like the sardana. Other Andorran folk dances include contrapàs in Andorra la Vella and Saint Anne's dance in Escaldes-Engordany.
Andorra's national holiday is Our Lady of Meritxell Day, September 8.

In mathematics and statistics, the arithmetic mean (or simply the mean) of a list of numbers is the sum of all the members of the list divided by the number of items in the list. If the list is a statistical population, then the mean of that population is called a population mean. If the list is a statistical sample, we call the resulting statistic a sample mean.
The mean is the most commonly-used type of average and is often referred to simply as the average. The term "mean" or "arithmetic mean" is preferred in mathematics and statistics to distinguish it from other averages such as the median and the mode.
If we denote a set of data by X = (x1, x2,., xn), then the sample mean is typically denoted with a horizontal bar over the variable (, enunciated "x bar").
The symbol μ (Greek: mu) is used to denote the arithmetic mean of an entire population. Or, for a random number that has a defined mean, μ is the probabilistic mean or expected value of the random number. If the set X is a collection of random numbers with probabilistic mean of μ, then for any individual sample, xi, from that collection, μ = E{xi} is the expected value of that sample.
In practice, the difference between μ and is that μ is typically unobservable because one observes only a sample rather than the whole population, and if the sample is drawn randomly, then one may treat, but not μ, as a random variable, attributing a probability distribution to it (the sampling distribution of the mean).
If X is a random variable, then the expected value of X can be seen as the long-term arithmetic mean that occurs on repeated measurements of X. This is the content of the law of large numbers. As a result, the sample mean is used to estimate unknown expected values.
Note that several other "means" have been defined, including the generalized mean, the generalized f-mean, the harmonic mean, the arithmetic-geometric mean, and various weighted means.
While the mean is often used to report central tendency, it may not be appropriate for describing skewed distributions, because it is easily misinterpreted. The arithmetic mean is greatly influenced by outliers. These distortions can occur when the mean is different from the median. When this happens the median may be a better description of central tendency.
A classic example is average income. The arithmetic mean may be misinterpreted to imply that most people's incomes are higher than is in fact the case. When presented with an "average" one may be led to believe that most people's incomes are near this number. This "average" (arithmetic mean) income is higher than most people's incomes, because high income outliers skew the result higher (in contrast, the median income "resists" such skew). However, this "average" says nothing about the number of people near the median income (nor does it say anything about the modal income that most people are near). Nevertheless, because one might carelessly relate "average" and "most people" one might incorrectly assume that most people's incomes would be higher (nearer this inflated "average") than they are. For instance, reporting the "average" net worth in Medina, Washington as the arithmetic mean of all annual net worths would yield a surprisingly high number because of Bill Gates. Consider the scores (1, 2, 2, 2, 3, 9). The arithmetic mean is 3.17, but five out of six scores are below this.
In certain situations, the arithmetic mean is the wrong measure of central tendency altogether. For example, if a stock fell 10 % in the first year, and rose 30 % in the second year, then it would be incorrect to report its "average" increase per year over this two year period as the arithmetic mean (&minus;10 % + 30 %)/2 = 10 %; the correct average in this case is the geometric mean which yields an average increase per year of only 8.2 %. The reason for this is that each of those percents have different starting points. If the stock starts at $30 and falls 10 %, it is now at $27. If the stock then rises 30 %, it is now $35.1. The arithmetic mean of those rises is 10 %, but since the stock rose by $5.1 in 2 years, an average of 8.2 % would result in the final $35.1 figure [$30(1-10 %)(1+30 %) = $30(1+8.2 %)(1+8.2 %) = $35.1]. If one used the arithmetic mean 10 % in the same way, one would not get the actual increase [$30(1+10 %)(1+10 %) = $36.3].
Particular care must be taken when using cyclic data such as phases or angles. Taking the arithmetic mean of 1 degree and 359 degrees yields a result of 180 degrees, whereas 1 and 359 are both adjacent to 360 degrees which may be a more correct average value. In general application such an oversight will lead to the average value artificially moving towards the middle of the numerical range. A solution to this problem is to use the optimization formulation, and redefine the difference as a modular distance.


The American Football Conference (AFC) is one of the two conferences of the National Football League (NFL). The AFC was created after the NFL merged with the American Football League (AFL) in early 1970. The NFL's Cleveland Browns, Pittsburgh Steelers, and the then-Baltimore Colts agreed to join the new AFC along with the 10 former AFL teams. All of the other NFL teams formed the National Football Conference (NFC). Initially, this alignment was unpopular with fans in these cities.
Since the merger, five expansion teams have joined the AFC and two have left, thus making the current total 16. When the Seattle Seahawks and the Tampa Bay Buccaneers joined the league in 1976, they were temporarily placed in the NFC and AFC respectively. This arrangement lasted for one season only before the two teams switched conferences. The Seahawks eventually returned to the NFC as a result of the 2002 realignment. The expansion Jacksonville Jaguars later joined the AFC in 1995.
Due to the relocation controversy of the Cleveland Browns, a new AFC franchise called the Baltimore Ravens was officially established in 1996 while the Browns were "reactivated" in 1999.
When the Oilers left Houston in 1997, no arrangement similar to the Browns/Ravens was made to retain the franchise name. When Oilers owner Bud Adams changed the name of his team to the Tennessee Titans in 1999, he specifically precluded any NFL team from ever using the name "Oilers" again. As a result, when the league did eventually put a new AFC expansion team into Houston in 2002, it was named the Houston Texans.
The current 16 teams are organized into four divisions (North, South, East, and West) of four teams each. Each team plays the other teams in their division twice (home and away) during the regular season in addition to 10 other games/teams assigned to their schedule by the NFL the previous May. Two of these games are assigned on the basis of the team's final division standing in the previous season. The remaining 8 games are split between the roster of two other NFL divisions. This assignment shifts each year. For instance, in the 2007 regular season, each team in the AFC West will play a game apiece against each team in both the AFC South and the NFC North. In this way division competition consists of common opponents, with the exception of the 2 games assigned on the strength of each team's prior division standing. (i.e. the division winner will face the other two division winners in the AFC divisions that they are not scheduled to play) The NFC operates according to the same system.
At the end of each football season, there are playoff games involving the top six teams in the AFC (the four division champions by place standing and the top two remaining non-division-champion teams ("wild cards") by record). The last two teams remaining play in the AFC Championship game with the winner receiving the Lamar Hunt Trophy. The AFC champion plays the NFC champion in the Super Bowl. After Super Bowl XLI The AFC has won 20 Super Bowls while the NFC has won 21. Since losing 13 consecutive Super Bowls in the 1980s and 1990s (XIX-XXXI), the AFC has won eight of the last ten. The losing coach of the AFC Championship game is the coach of the Pro Bowl the week after the Super Bowl.


Animal Farm is a novella by George Orwell, and is the most famous satirical allegory of Soviet totalitarianism. Published in 1945, the book reflects events leading up to and during the Stalin era. Orwell, a democratic socialist, and a member of the Independent Labour Party for many years, was a critic of Josef Stalin, and was suspicious of Moscow-directed Stalinism after his experiences with the NKVD during the Spanish Civil War.
The book was chosen by Time Magazine as one of the 100 best English-language novels (1923 to 2005) and was number 31 on the Modern Library List of Best 20th-Century Novels.
The plot is an allegory in which animals play the roles of the Bolshevik revolutionaries and overthrow and oust the human owners of the farm, setting it up as a commune in which, at first, all animals are equal; soon disparities start to emerge between the different species or classes. The novel describes how a society's ideologies can be changed and manipulated by individuals in positions of Political power, including how the idea of utopia is seemingly impossible with the corruption of power.
The events and characters in Animal Farm parallel the early history of the Soviet Union; Orwell makes this explicit in the case of Napoleon, whom he directly connects to Stalin in a letter of 17 March 1945 to the publisher. Of course the dogs are also important characters in this novella who enable George Orwell to be able to discover and express more of what had happened in Russia.
The other characters have their parallels in the real world, but care should be taken with these comparisons, as Orwell's intent was not always explicit and they often simply represent generalised concepts.
Hitchens goes on to agree, however, that in the book "the aims and principles of the Russian Revolution are given face-value credit throughout; this is a revolution betrayed, not a revolution that is monstrous from its inception". Though Old Major is presented positively, Orwell does slip in some flaws, such as his admission that he has largely been free of the abuse the rest of the animals have had to suffer.
Snowball, a white boar, is Napoleon's rival. He is inspired by Leon Trotsky. He wins over most animals, but is driven out of the farm in the end by Napoleon. Snowball genuinely works for the good of the farm and devises plans to help the animals achieve their vision of a utopia but is chased from the farm by Napoleon and his dogs and rumours are spread about him (by Napoleon) to make him seem evil and corrupt and that he is secretly sabotaging the animal's efforts to improve the farm.
Squealer, a small fat porker, serves as Napoleon's public speaker. Inspired by Vyacheslav Molotov and the Russian paper Pravda, Squealer twists and abuses the language to excuse, justify, and extol all of Napoleon's actions. He represents all the propaganda Stalin used to justify his actions. In all of his work, George Orwell made it a point to show how politicians used language. Squealer limits debate by complicating it, and he confuses and disorients, making claims that the pigs need the extra luxury they are taking in order to function properly, for example. However, when questions persist, he usually uses the threat of Mr. Jones's return as justification for the pigs' privileges. Squealer uses statistics to convince the animals that life is getting better and better. Most of the animals have only dim memories of life before the revolution; therefore they are convinced.
Minimus is a poetical pig who writes the second and third national anthems of Animal Farm after the singing of "Beasts of England" is banned, representing admirers of Stalin both inside and outside the USSR such as Maxim Gorky. As Minimus composed the replacement of "Beasts of England", he may equate to the three main composers of the National Anthem of the Soviet Union which replaced The Internationale -- Gabriel El-Registan, Alexander Vasilyevich Alexandrov, and Sergey Mikhalkov.
Pinkeye is a small piglet who tastes Napoleon's food for poisoning.
The Piglets are hinted to be the children of Napoleon (albeit not truly noted in the novel), and are the first generation of animals to actually be subjugated to his idea of animal inequality.
The Rebel Pigs are pigs who complain about Napoleon's takeover of the farm but are quickly silenced and later executed. This is based on the Great Purge during Stalin's regime. The closest parallels to the Rebel Pigs may be Nikolai Bukharin, Alexei Rykov, Grigory Zinoviev, and Lev Kamenev.
Mr. Jones represents Nicholas II of Russia, the deposed Tsar, who had been facing severe financial difficulties in the days leading up to the 1917 Revolution. The character is also a nod towards Louis XVI. There are also several implications that he represents an autocratic but ineffective capitalist, incapable of running the farm and looking after the animals properly. Jones is a very heavy drinker and the animals revolt on him after he drinks so much that he does not feed them nor does he take care of them. Ironically Napoleon himself becomes almost obsessed with drinking.
Mr. Frederick is the tough owner of Pinchfield, a well-kept neighbouring farm. He represents Adolf Hitler and the Nazi Party in general.
Mr. Pilkington is the easy-going but crafty owner of Foxwood, a neighbouring farm overgrown with weeds, as described in the book. He represents the western powers, such as Britain and the U.S. The card game at the very end of the novel is a metaphor for the Tehran Conference, where the parties flatter each other, all the while cheating at the game. The irony in this last scene is present because of all of the Pigs being civil and kind to the humans, defying all for which they had fought. This was present in the Tehran Conference with the Alliance that the Soviet Union formed with the United States and Britain; capitalist countries that the Soviet Union had fought in the early years of the revolution. At the end of the novel, both Napoleon and Pilkington draw the Ace of Spades (which in most games, is the highest-ranking card) at the same time and begin fighting loudly, symbolizing the beginning of tension between the U.S. and Soviet superpowers.
Mr. Whymper is a man hired by Napoleon to represent Animal Farm in human society. He is loosely based on Western intellectuals such as George Bernard Shaw and, especially, Lincoln Steffens, who visited the U.S.S.R. in 1919.
Boxer is one of the main characters. He is the tragic avatar of the working class, or proletariat: loyal, kind, dedicated, and the most physically-strong animal on the farm, but naive and slow. His ignorance and blind trust towards his leaders led to his death and their profit. In particular, his heroic physical work represents the Stakhanovite movement. His maxim of "I will work harder" is reminiscent of Jurgis Rudkus from the Upton Sinclair novel The Jungle.
Clover is Boxer's friend and a fellow draft horse. She helps and cares for Boxer when he splits his hoof. She blames herself for forgetting the original Seven Commandments when Squealer revises them. Clover is compassionate, as is shown when she protects the baby ducklings during Major's speech; albeit made out to be somewhat vain in the opening of the novel by the narrator, who remarks that she never "recovered" her figure after giving birth to her fourth foal. She is also upset when animals are executed by the dogs, and is held in great respect by three younger horses who ultimately replace Boxer.
Mollie is a self-centered and vain white mare who likes wearing ribbons in her mane, eating sugar cubes (which represent luxury) and being pampered and groomed by humans. She represents upper-class people, the bourgeoisie and nobility who fled to the West after the Russian Revolution and effectively dominated the Russian diaspora. Accordingly, she quickly leaves for another farm and is only once mentioned again.
Benjamin is a wise, old donkey that shows little emotion. The animals often question him about his lack of expression but always answers with: 'Donkeys live a long life. None of you have ever seen a dead donkey.' He is dedicated to Boxer and is dearly upset when Boxer is taken away. Benjamin has known about the pigs' wrong doing the whole time. He represents the cynics in society. It has also been speculated that Benjamin could also represent the role of Jews in society.
Moses: He represents the role of the church (most likely the Russian Orthodox Church) in Russia. He also represents Rasputin.
Pigeons: Snowball and Napoleon regularly send out pigeons to spread the word of the animals' rebellion at Animal Farm. They represent the Comintern, which was an organization of Communist parties whose goal was to spread Communism.
The allegory that the book employs allows it to be read on a variety of different levels.
Orwell wrote the book following his experiences during the Spanish Civil War, which are described in another one of his books, Homage to Catalonia. He intended it to be a strong condemnation of what he saw as the Stalinist corruption of the original socialist ideals. For the preface of a Ukrainian edition he prepared in 1947, Orwell described what gave him the idea of setting the book on a farm.
This Ukrainian edition was an early propaganda use of the book. It was printed to be distributed among the Soviet citizens of Ukraine who were some of the many millions of displaced persons throughout Europe at the end of the Second World War. The American occupation forces considered the edition to be propaganda printed on illegal presses, and handed 1,500 confiscated copies of Animal Farm over to the Soviet authorities. The politics in the book also affected Britain, with Orwell reporting that Ernest Bevin was "terrified" that it may cause embarrassment if published before the 1945 general election.
In recent years the book has been used to compare new movements that overthrow heads of a corrupt and undemocratic government or organization, only to eventually become corrupt and oppressive themselves as they succumb to the trappings of power and begin using violent and dictatorial methods to keep it. Such analogies have been used for many former African colonies such as Zimbabwe and the Democratic Republic of Congo, whose succeeding African-born rulers were accused of being as corrupt as, or worse than, the European colonists they supplanted.
The book also clearly ponders whether a focus of power in one person is healthy for a society. The book leaves the ending slightly ambiguous in this regard.
Perhaps the largest overriding theme in "Animal Farm" is the famous quote by Lord Acton, "Power tends to corrupt, and absolute power corrupts absolutely".
During World War II it became apparent to Orwell that anti-Russian literature was not something which most major publishing houses would touch — including his regular publisher Gollancz. One publisher he sought rejected his book on the grounds of government advice — although the assumed civil servant who gave the order was later found to be a Soviet spy.
Orwell originally prepared a preface which complains about British government suppression of his book, self-imposed British self-censorship and how the British people were suppressing criticism of the USSR, their World War II ally. "The sinister fact about literary censorship in England is that it is largely voluntary.. [Things are] kept right out of the British press, not because the Government intervened but because of a general tacit agreement that ‘it wouldn’t do’ to mention that particular fact." Somewhat ironically, the preface itself was censored and is not published with most editions of the book.
References to the novella are frequent in other works of popular culture, particularly in popular music and television series.


Amphibians (class Amphibia; from Greek αμφις "both" and βιος "life") are a taxon of animals that include all living tetrapods (four-legged vertebrates) that do not have amniotic eggs, are ectothermic (term for the animals whose body heat is regulated by the external environment; previously known as cold-blooded), and generally spend part of their time on land. Most amphibians do not have the adaptations to an entirely terrestrial existence found in most other modern tetrapods (amniotes). There are around 6,200 described, living species of amphibians. The study of amphibians and reptiles is known as herpetology. Amphibians are able to breathe by using lungs or gills or through their skin.
Of these only the last subclass includes recent species.
All recent amphibians are included in the subclass Lissamphibia, superorder Salientia, which is usually considered a clade (which means that it is thought that they evolved from a common ancestor apart from other extinct groups), although it has also been suggested also that salamanders arose separately from a temnospondyl-like ancestor (Carroll, 2007).
Authorities also disagree on whether Salientia is a Superorder that includes the order Anura, or whether Anura is a sub-order of the order Salientia. Practical considerations seem to favour using the former arrangement now.
The Lissamphibia, superorder Salientia, are traditionally divided into three orders, but an extinct salamander-like family, the Albanerpetontidae, is now considered part of the Lissamphibia, besides the superorder Salientia. Furthermore, Salientia includes all three recent orders plus a single Triassic proto-frog, Triadobatrachus.
The actual number of species partly also depends on the taxonomic classification followed, the two most common classifications being the classification of the website AmphibiaWeb, University of California (Berkeley) and the classification by herpetologist Darrel Frost and The American Museum of Natural History, available as the online reference database Amphibian Species of the World (see external links below). The numbers of species cited above follow Frost.
For the purpose of reproduction most amphibians are bound to fresh water. A few tolerate brackish water, but there are no true seawater amphibians. Several hundred frog species in adaptive radiations (e.g. Eleutherodactylus, the Pacific Platymantines, the Australo-Papuan microhylids, and many other tropical frogs), however, do not need any water whatsoever. They reproduce via direct development, an ecological and evolutionary adaptation that has allowed them to be completely independent from free-standing water. Almost all of these frogs live in wet tropical rainforests and their eggs hatch directly into miniature versions of the adult, passing through the tadpole stage within the egg. Several species have also adapted to arid and semi-arid environments, but most of them still need water to lay their eggs. Symbiosis with single celled algae that lives in the jelly-like layer of the eggs has evolved several times. The larvae (tadpoles or polliwogs) breathe with exterior gills. After hatching, they start to transform gradually into the adult's appearance. This process is called metamorphosis. Typically, the animals then leave the water and become terrestrial adults, but there are many interesting exceptions to this general way of reproduction.
Interestingly, recent scienctific evidence put forward by East Carolina University suggests that some species of frogs, like the Dendrobates captivus, often engage in homosexual activity, and as a result their reproduction rate per year has been slowly decreasing.
Dramatic declines in amphibian populations, including population crashes and mass localized extinction, have been noted in the past two decades from locations all over the world, and amphibian declines are thus perceived as one of the most critical threats to global biodiversity. A number of causes are believed to be involved, including habitat destruction and modification, over-exploitation, pollution, introduced species, climate change, destruction of the ozone layer (ultraviolet radiation has shown to be especially damaging to the skin, eyes, and eggs of amphibians), and diseases like chytridiomycosis. However, many of the causes of amphibian declines are still poorly understood, and are a topic of ongoing discussion. A global strategy to stem the crisis has been released in the form of the Amphibian Conservation Action Plan (available at www.amphibians.org). Developed by over 80 leading experts in the field, this call to action details what would be required to curtail amphibian declines and extinctions over the next 5 years - and how much this would cost. The Amphibian Specialist Group of the World Conservation Union (IUCN) is spearheading efforts to implement a comprehensive global strategy for amphibian conservation.
include: the Chinese giant salamander, a distant relative of the newt, the tiny Gardiner's Seychelles, the limbless Sagalla caecilian, South African ghost frogs, lungless Mexican salamanders, the Malagasy rainbow frog, Chile's Darwin frog (Rhinoderma rufum) and the Betic Midwife Toad.
The first major groups of amphibians developed in the Devonian Period from fishes similar to the modern coelacanth where the fins had evolved into legs. These amphibians were around five meters long in length. The land safe as the giant fishes and sharks in the ocean could not come onto land. However, there were two problems with living out their entire lives on land. Primarily, the food that these amphibians consumed was in the water, but also at this point the skin on most of these amphibians was not water-tight.


Alaska (, ) is a state in the United States of America, in the northwest of the North American continent. It is the largest U.S. state by area (by a substantial margin), and one of the wealthiest (per capita) and most racially diverse.
The area that became Alaska was purchased from the Russian Empire on March 30 1867. The land went through several administrative changes before becoming an organized territory on May 11, 1912 and the 49th state of the U.S. on January 3, 1959. The name "Alaska" is derived from the Aleut alaxsxaq, meaning "the mainland," or more literally, "the object towards which the action of the sea is directed." It is also known as Alyeska, the "great land", an Aleut word derived from the same root.
Alaska is one of two U.S. states not bordered by another state, Hawaii being the other. Alaska has more coastline than all the other U.S. states combined. It is the only non-contiguous U.S. state on continental North America; about 500 mi of Canadian territory separate Alaska from Washington State. Alaska is thus an exclave of the United States, part of the continental U.S. but is not part of the contiguous U.S. Alaska's capital city, though located on the mainland of the North American continent, is inaccessible by land — no roads connect Juneau to the rest of the North American highway system.
The state is bordered by Yukon Territory and British Columbia, Canada, to the east, the Gulf of Alaska and the Pacific Ocean to the south, the Bering Sea, Bering Strait, and Chukchi Sea to the west and the Beaufort Sea and the Arctic Ocean to the north.
Alaska is the largest state in the United States in land area at 570380 sqmi, more than twice as large as Texas, the next largest state. It is larger than all but 18 sovereign nations.
The northeast corner of Alaska is covered by the Arctic National Wildlife Refuge, which covers 19049236 acre. Much of the northwest is covered by the larger National Petroleum Reserve–Alaska, which covers around 23000000 acre million acres. The Arctic is Alaska's most remote wilderness. A location in the National Petroleum Reserve–Alaska is 120 mi miles from any town or village, the geographic point most remote from permanent habitation in the USA.
With its numerous islands, Alaska has nearly 34000 mi of tidal shoreline. The island chain extending west from the southern tip of the Alaska Peninsula is called the Aleutian Islands. Many active volcanoes are found in the Aleutians. For example, Unimak Island is home to Mount Shishaldin, a moderately active volcano that rises to 9980 ft above sea level. The chain of volcanoes extends to Mount Spurr, west of Anchorage on the mainland.
Alaska has 3.5 million lakes of 20 acre or larger. Marshlands and wetland permafrost cover 188320 sqmi (mostly in northern, western and southwest flatlands). Frozen water, in the form of glacier ice, covers some 16000 sqmi of land and 1200 sqmi of tidal zone. The Bering Glacier complex near the southeastern border with Yukon, Canada, covers 2250 sqmi alone.
The Aleutian Islands cross longitude 180°, so Alaska can be considered the easternmost state as well as the westernmost. Alaska, and especially the Aleutians, are one of the extreme points of the United States. The International Date Line jogs west of 180° to keep the whole state, and thus the entire continental United States, within the same legal day.
According to an October 1998 report by the United States Bureau of Land Management, approximately 65% of Alaska is owned and managed by the U.S. federal government as public lands, including a multitude of national forests, national parks, and national wildlife refuges. Of these, the Bureau of Land Management manages 87 million acres (350,000 km²), or 23.8% of the state. The Arctic National Wildlife Refuge is managed by the United States Fish and Wildlife Service.
Of the remaining land area, the State of Alaska owns 24.5%; another 10% is managed by 13 regional and dozens of local Native corporations created under the Alaska Native Claims Settlement Act. Various private interests own the remaining land, totaling less than 1%.
Alaska is administratively divided into "boroughs", as opposed to "counties." The function is the same, but whereas some states use a three-tiered system of decentralization — state/county/township — most of Alaska uses only two tiers — state/borough. Owing to the low population density, most of the land is located in the Unorganized Borough which, as the name implies, has no intermediate borough government of its own, but is administered directly by the state government. Currently (2000 census) 57.71% of Alaska's area has this status, with 13.05% of the population. For statistical purposes the United States Census Bureau divides this territory into census areas. Anchorage merged the city government with the Greater Anchorage Area Borough in 1971 to form the Municipality of Anchorage, containing the city proper and the bedroom communities of Eagle River, Chugiak, Peters Creek, Girdwood, Bird, and Indian. Fairbanks has a separate borough (the Fairbanks North Star Borough) and municipality (the City of Fairbanks).
The climate in Juneau and the southeast panhandle is best described as a cooler version of Seattle. It is a mid-latitude oceanic climate (Köppen climate classification Cfb) in the southern sections and a subarctic oceanic climate (Köppen Cfc) in the northern parts. On an annual basis, this is both the wettest and warmest part of Alaska with milder temperatures in the winter and high precipitation throughout the year. Juneau averages over 50 in of precipitation a year, while other areas receive over 275 in. This is also the only region in Alaska in which the average daytime high temperature is above freezing during the winter months.
The climate of Anchorage and south central Alaska is mild by Alaskan standards due to the region's proximity to the seacoast. While the area does not get nearly as much rain as southeast Alaska, it does get more snow, although days tend to be clearer. On average, Anchorage receives 16 in of precipitation a year, with around 75 in of snow, although there are areas in the south central which receive far more snow. It is a subarctic climate (Köppen Dfc) due to its short, cool summers.
The climate of Western Alaska is determined in large part by the Bering Sea and the Gulf of Alaska. It is a subarctic oceanic climate in the southwest and a continental subarctic climate farther north. The temperature is somewhat moderate considering how far north the area is. This area has a tremendous amount of variety in precipitation. The northern side of the Seward Peninsula is technically a desert with less than 10 in of precipitation annually, while some locations between Dillingham and Bethel average around 100 in of precipitation.
The climate of the interior of Alaska is best described as extreme and is the best example of a true subarctic climate. Some of the hottest and coldest temperatures in Alaska occur around the area near Fairbanks. The summers can have temperatures reaching into the 80s°F (near 30 °C), while in the winter, the temperature can fall below −60 °F (-52 °C). Precipitation is not much in the Interior, often less than 10 in a year, but what precipitation falls in the winter tends to stay the entire winter.
The highest and lowest recorded temperatures in Alaska are both in the Interior. The highest is 100 °F (38 °C) in Fort Yukon on June 27, 1915, tied with Pahala, Hawaii as the lowest high temperature in the United States. The lowest Alaska temperature is −80 °F (-64 °C) in Prospect Creek on January 23, 1971, one degree above the lowest temperature recorded in North America (in Snag, Yukon, Canada).
The climate in the extreme north of Alaska is as expected for an area north of the Arctic Circle. It is an Arctic climate (Köppen ET) with long, very cold winters and short, cool summers. Even in July, the average low temperature is barely above freezing in Barrow, at 34 °F (2 °C). Precipitation is light in this part of Alaska, with many places averaging less than 10 in per year, mostly in the form of snow which stays on the ground almost the entire year.
At the end of the Upper Paleolithic Period (around 12,000 BC), Asiatic groups crossed the Bering Land Bridge into what is now western Alaska. At the time of European contact by the Russian explorers, the area was populated by Alaska Native groups.
The first European contact with Alaska occurred in the year 1741, when Vitus Bering led an expedition for the Russian Navy aboard the St. Peter. After his crew returned to Russia bearing sea otter pelts judged to be the finest fur in the world, small associations of fur traders began to sail from the shores of Siberia towards the Aleutian islands. The first permanent European settlement was founded in 1784, and the Russian-American Company carried out an expanded colonization program during the early to mid-1800s. Despite these efforts, the Russians never fully colonized Alaska, and the colony was never very profitable. William H. Seward, the U.S. Secretary of State, engineered the Alaskan purchase in 1867 for $7.2 million.
In the 1890s, gold rushes in Alaska and the nearby Yukon Territory brought thousands of miners and settlers to Alaska. Alaska was granted territorial status in 1912.
During World War II, three of the outer Aleutian Islands — Attu, Agattu and Kiska — were the only part of the continental United States occupied by the enemy during the war. Their recovery became a matter of national pride. The construction of military bases contributed to the population growth of some Alaskan cities.
Alaska was granted statehood on January 3, 1959.
In 1964, the massive "Good Friday Earthquake" killed 131 people and leveled several villages.
The 1968 discovery of oil at Prudhoe Bay and the 1977 completion of the Trans-Alaska Pipeline led to an oil boom. In 1989, the Exxon Valdez hit a reef in the Prince William Sound, spilling between 11 and 35 million US gallons (42,000-130,000 m³) of crude oil over 1,100 miles (1,600 km) of coastline. Today, the battle between philosophies of development and conservation is seen in the contentious debate over oil drilling in the Arctic National Wildlife Refuge.
In 2006 Alaska had an estimated population of 670,053, an increase of 6,392 (0.96%) from 2005 and 43,121 (6.9%) from 2000. In 2000 Alaska ranked 48th out of 50 states by population. Alaska is the least densely populated state, at 0.42 people per square kilometer (1.1 per square mile), with the next state, Wyoming, at 1.97 (5.1 per square mile), and the most densely populated, New Jersey, at 437.6 people per square kilometer (1,134.4 per square mile).
According to the 2000 U.S. Census, 75% of Alaska residents are white. 15.6% are American Indian or Alaska Native, the largest proportion of any state. Multiracial/Mixed-Race people are the third largest group of people in the state, totaling 6.9% of the population. The largest self-reported ancestry groups in the state are German (16.6%), Alaska Native or American Indian (15.6%), Irish (10.8%), British (9.6%), American (5.7%), and Norwegian (4.2%).
The vast sparsely populated regions of northern and western Alaska are primarily inhabited by Alaska Natives, who are also numerous in the southeast. Anchorage, Fairbanks, and other parts of south-central and southeast Alaska have many whites of northern and western European ancestry. The Wrangell-Petersburg area has many residents of Scandinavian ancestry and the Aleutians contain a large Filipino population. Most of the state's black population lives in Anchorage, though Fairbanks also has a sizable black population.
According to the 2000 U.S. Census, 85.7% of Alaska residents aged 5 and older speak English at home. The next most common languages are Spanish (2.88%), Yupik (2.87%), Tagalog (1.54%), and Iñupiaq (1.06%). A total of 5.2% of Alaskans speak one of the state's 22 indigenous languages, known locally as Native languages.
Alaska has been identified, along with Pacific Northwest states Washington and Oregon, as being the least religious in the U.S. According to statistics collected by the Association of Religion Data Archives, only about 39% of Alaska residents were members of religious congregations. Evangelical Protestants had 78,070 members, Roman Catholics had 54,359, and mainline Protestants had 37,156. After Catholics, the largest single denominations were Southern Baptists with 22,959, Orthodox with 20,000, and Mormons with 19,019. The large Eastern Orthodox population is a result of early Russian colonization and missionary work among Alaska Natives. In 1795, the First Russian Orthodox Church was established in Kodiak. Intermarriage with Alaskan Natives helped the Russian immigrants integrate into society. As a result, more and more Russian Orthodox churches gradually became established within Alaska. Alaska also has the largest Quaker population (by percentage) of any state. In 2003 there were 3,000 Jews in Alaska.
The 2005 gross state product was $39.9 billion. Its per-capita GSP for 2005 was $60,079, 3rd in the nation. Alaska's economy relies heavily on petroleum extraction, with more than 80% of the state's revenues derived from this industry. Alaska's main export product (excluding oil and natural gas) is seafood, primarily salmon, cod, pollock and crab. Agriculture represents only a fraction of the Alaskan economy. Agricultural production is primarily for consumption within the state and includes nursery stock, dairy products, vegetables, and livestock. Manufacturing is limited, with most foodstuffs and general goods imported from elsewhere. Employment is primarily in government and industries such as natural resource extraction, shipping, and transportation. Military bases are a significant component of the economy in both Fairbanks and Anchorage. Its industrial outputs are crude petroleum, natural gas, coal, gold, precious metals, zinc and other mining, seafood processing, timber and wood products. There is also a growing service and tourism sector. Tourists have contributed to the economy by supporting local lodging.
Alaska's economy is heavily dependent on increasingly expensive diesel fuel for heating, transportation, electric power and light. Though wind and hydroelectric power are abundant and underutilized, proposals for state-wide energy systems (e.g. with special low-cost electric interties) were judged uneconomical (at the time of the report, 2001) due to low (<$0.50/Gal) fuel prices, long distances and low population. The cost of a gallon of gas in urban Alaska today is usually $0.30-$0.60 higher than the national average; prices in rural areas are generally significantly higher but vary widely depending on transportation costs, seasonal usage peaks, nearby petroleum development infrastructure and many other factors.
The Alaska Permanent Fund is a legislatively controlled appropriation established in 1976 to manage a surplus in state petroleum revenues from the recently constructed Trans-Alaska Pipeline System. From its initial principal of $734,000, the fund has grown to $38 billion as a result of oil royalties and capital investment programs. Starting in 1982, dividends from the fund's annual growth have been paid out each year to eligible Alaskans, ranging from $331.29 in 1984 to $1963.86 in 2000.
The cost of goods in Alaska has long been higher than in the contiguous 48 states. This has changed for the most part in Anchorage and to a lesser extent in Fairbanks, where the cost of living has dropped somewhat in the past five years. Federal Government employees, particularly United States Postal Service (USPS) workers and active-duty military members, receive a Cost Of Living Allowance usually set at 25% of base pay because, while the cost of living has gone down, it is still one of the highest in the country.
The introduction of big-box stores in Anchorage, Fairbanks (Wal-Mart in March of 2004), and Juneau also did much to lower prices. However, rural Alaska suffers from extremely high prices for food and consumer goods, compared to the rest of the country due to the relatively limited transportation infrastructure. Many rural residents come in to these cities and purchase food and goods in bulk from warehouse clubs like Costco and Sam's Club. Some have embraced the free shipping offers of some online retailers to purchase items much more cheaply than they could in their own communities, if they are available at all.
Alaska has the lowest individual tax burden in the US, and is one of only six states with no state sales tax and one of seven states that do not levy an individual income tax. To finance state government operations, Alaska depends primarily on petroleum revenues. The Department of Revenue Tax Division reports regularly on the state's revenue sources. The Department also issues an annual overview of its operations, including new state laws that directly affect the tax division.
While Alaska has no state sales tax, 89 municipalities collect a local sales tax, from 1% to 7%, typically 3% to 5%. Other local taxes levied include raw fish taxes, hotel, motel, and B&B "bed" taxes, severance taxes, liquor and tobacco taxes, gaming (pull tabs) taxes, tire taxes and fuel transfer taxes. A percentage of revenue collected from certain state taxes and license fees (such as petroleum, aviation motor fuel, telephone cooperative) is shared with municipalities in Alaska.
Property taxes are relatively low, with only 25 of 161 incorporated municipalities or boroughs in the state assessing property taxes. Fairbanks has one of the highest property taxes in the state as no sales or income taxes are assessed in the Fairbanks North Star Borough (FNSB). A sales tax for the FNSB has been voted on many times, but has yet to be approved, leading law makers to increase taxes dramatically on other goods such as liquor and tobacco. The average per capita property tax paid in all municipalities, excluding oil and gas properties, was US$999 (2003 data).
In 2008 the Tax Foundation ranked Alaska as having the 4th most "business friendly" tax policy. Superior states were Wyoming, Nevada, and South Dakota.
Alaska has few road connections compared to the rest of the U.S. The state's road system covers a relatively small area of the state, linking the central population centers and the Alaska Highway, the principal route out of the state through Canada. The state capital, Juneau, is not accessible by road, which has spurred several debates over the decades about moving the capital to a city on the road system. One unique feature of the road system is the Anton Anderson Memorial Tunnel which links the Seward Highway south of Anchorage with the relatively isolated community of Whittier. At nearly 2.5 mi the tunnel was the longest road tunnel in North America until completion of the 3.5 mile (5.6 km) Interstate 93 tunnel as part of the "Big Dig" project in Boston, Massachusetts. The tunnel is the longest combination road and rail tunnel in North America.
The Alaska Railroad runs from Seward through Anchorage, Denali, and Fairbanks to North Pole, with spurs to Whittier and Palmer (locally known as "The Railbelt"). The railroad is famous for its summertime passenger services and also plays a vital part in moving Alaska's natural resources, such as coal and gravel, to ports in Anchorage, Whittier, and Seward. The Alaska Railroad was one of the last railroads in North America to use cabooses in regular service and still uses them on certain gravel trains, and it offers one of the last flag stop routes in the country. A stretch of about 60 mi of track along an area inaccessible by road is the only transportation to cabins in the area.
Most cities and villages in the state are accessible only by sea or air. Alaska has a well-developed ferry system, known as the Alaska Marine Highway, which serves the cities of Southeast and the Alaska Peninsula. The system also operates a ferry service from Bellingham, Washington via the Inside Passage to Skagway. The Inter-Island Ferry Authority also serves as an important marine link for many communities in the Prince of Wales Island region of Southeast and works in concert with the Alaska Marine Highway. Tourist sea travel is also popular on Alaska cruises.
Cities not served by road or sea can be reached only by air, accounting for Alaska's extremely well-developed Bush air services—an Alaskan novelty. Anchorage itself, and to a lesser extent Fairbanks, are serviced by many major airlines. Air travel is the cheapest and most efficient form of transportation in and out of the state. Anchorage recently completed extensive remodeling and construction at Ted Stevens Anchorage International Airport to help accommodate the upsurge in tourism (in 2000-2001, the latest year for which data is available, 2.4 million total arrivals to Alaska were counted, 1.7 million via air travel; 1.4 million were visitors).
Another Alaskan transportation method is the dogsled. In modern times, dog mushing is more of a sport than a true means of transportation. Various races are held around the state, but the best known is the Iditarod Trail Sled Dog Race, a 1150-mile (1850 km) trail from Anchorage to Nome. The race commemorates the famous 1925 serum run to Nome in which mushers and dogs like Togo and Balto took much-needed medicine to the diphtheria-stricken community of Nome when all other means of transportation had failed. Mushers from all over the world come to Anchorage each March to compete for cash, prizes, and prestige.
In areas not served by road or rail, primary transportation in summer is by all-terrain vehicle and in winter by snowmobile or "snow machine," as it is commonly referred to in Alaska.
Alaska is often described as a Republican-leaning state with strong Libertarian tendencies. In presidential elections, the state's electoral college votes have been almost always won by a Republican nominee. Only once has Alaska supported a Democratic nominee, when it supported Lyndon B. Johnson in the landslide year of 1964, although the 1960 and 1968 elections were close. No state has voted for a Democratic presidential candidate fewer times. President George W. Bush won the state's electoral votes in 2004 by a margin of 25 percentage points with 61.1% of the vote. The city of Juneau and Midtown Anchorage are strongholds of the Democratic party. Matanuska-Susitna Borough and South Anchorage typically have the strongest Republican showing. As of 2004, well over half of all registered voters choose "Non-Partisan" or "Undeclared" as their affiliation, despite recent attempts to close primaries. Alaska is one of the states with a more relaxed marijuana policy, where one can possess up to one ounce of the substance legally. Alaska possesses a pervasively strong independence movement favoring secession from the US, with the Alaskan Independence Party labeled one of the "the most significant state-level third parties operating in the 20th century".
December 4 2006, Sarah Palin was sworn in as the first woman and youngest Governor of Alaska. Her running mate was Lieutenant Governor Sean Parnell. Palin is the former two-term mayor of Wasilla, Alaska.
The Alaska State Legislature consists of a 20-member Senate, whose members serve four-year terms, and 40-member House of Representatives, who serve two-year terms. It has been dominated by conservatives, generally Republicans. Recent state governors have been mostly conservatives, although not always elected under the official Republican banner. Republican Wally Hickel was elected to the office for a second term in 1990 after jumping the Republican ship and briefly joining the Alaskan Independence Party ticket just long enough to be reelected. He subsequently officially rejoined the Republican fold in 1994.
Alaska's court system has four levels: the Alaska Supreme Court, the court of appeals, the superior courts and the district courts. The superior and district courts are trial courts. Superior courts are courts of general jurisdiction, while district courts only hear certain types of cases, including misdemeanor criminal cases and civil cases valued up to $100,000. The supreme court and the court of appeals are appellate courts. The court of appeals is required to hear appeals from certain lower-court decisions, including those regarding criminal prosecutions, juvenile delinquency, and habeas corpus. The supreme court hears civil appeals and may in its discretion hear criminal appeals.
Local political communities often work on issues related to land use development, fishing, tourism, and individual rights. Alaska Natives, while organized in and around their communities, are often active within the Native corporations which have been given ownership over large tracts of land, and thus need to deliberate resource conservation and development issues.
Alaska's members of the U.S. Congress are all Republican. U.S. Senator Ted Stevens was appointed to the position following the death of U.S. Senator Bob Bartlett in December 1968, and has not lost a re-election campaign since. As the longest-serving Republican in the Senate (sometimes nicknamed "Senator-For-Life"), Stevens has been a crucial force in gaining federal money for his state.
Until his resignation from the U.S. Senate after being elected governor in 2002, Republican Frank Murkowski held the state's other senatorial position and, as governor, appointed his daughter, State Representative Lisa Murkowski as his successor (under public pressure, the State legislature amended the constitution to eliminate gubernatorial appointments in the future). She won a full six-year term on her own in 2004.
Alaska's sole U.S. Representative, Don Young, was re-elected to his 17th consecutive term, also in 2004. His seniority in House makes him one of the most influential Republican House members.
Alaska's most populous city is Anchorage, home to 260,283 people in 2000, 225,744 of whom live in the urbanized area. The richest location in Alaska by per capita income is Halibut Cove ($89,895). Sitka, Juneau, and Anchorage are the three largest cities in the U.S. by area.
Also notable is the rapid growth of towns in the Mat-Su Valley. Wasilla and Palmer are projected to experience over 100% population growth between 2000 and 2010.
The Alaska Department of Education and Early Development administers many school districts in Alaska. In addition, the state operates several boarding schools, including Mt. Edgecumbe High School in Sitka, Nenana Student Living Center in Nenana, and Galena High School in Galena.
There are more than a dozen colleges and universities in Alaska. Accredited universities in Alaska include the University of Alaska Anchorage, University of Alaska Fairbanks, University of Alaska Southeast, Sheldon Jackson College and Alaska Pacific University. 43% of the population attends or attended college.
Alaska has long had a problem with alcohol use and abuse. Many rural communities in Alaska have outlawed its import. "Dry", "wet", and "damp" are terms describing a community's laws on liquor consumption. This problem directly relates to Alaska's high rate of Fetal alcohol syndrome (FAS) as well as contributing to the high rate of suicides. This is a controversial topic for many residents.
Alaska has also had a problem with "brain drain" as many of its young people, including most of the highest academic achievers, leave the state upon graduating high school. While for many this functions as a sort of walkabout, many do not return to the state. The University of Alaska has been successfully combating this by offering partial four-year scholarships to the top 10% of Alaska high school graduates, via the Alaska Scholars Program.
Domestic abuse and other violent crimes are also at notoriously high levels in the state; this is in part linked to alcohol abuse.
Some of Alaska's popular annual events are the World Ice Art Championships in Fairbanks, the Alaska Hummingbird Festival in Ketchikan, the Sitka Whale Fest, and the Stikine River Garnet Fest in Wrangell. The Stikine River features the largest springtime concentration of American Bald Eagles in the world.
The Alaska Native Heritage Center celebrates the rich heritage of Alaska's 11 cultural groups. Their purpose is to enhance self-esteem among Native people and to encourage cross-cultural exchanges among all people.
The four main libraries in the state are the Alaska State Library in Juneau, the Elmer E. Rasmuson Library in Fairbanks, the Z. J. Loussac Library in Anchorage, and the UAA/APU Consortium Library, also in Anchorage. Alaska is one of three states (the others are Delaware and Rhode Island) that does not have a Carnegie library.
Due to the northern climate and steep terrain, relatively little farming occurs in Alaska. Most farms are in either the Mat-Su Valley near Anchorage, or on the Kenai Peninsula. The short summer limits the types of crops that can be grown - primary crops are potatoes, carrots, lettuce, and cabbage. But the long days of summer can allow these vegetables to reach record size.
Alaska has an abundance of seafood, with the primary fisheries in the Bering Sea, and seafood is one of the few food items that is often cheaper within the state than outside it.
Hunting for subsistence, primarily caribou, moose, and sheep is still fairly common in the state, particularly in remote Bush communities. An example of a traditional native food is Akutaq, the Eskimo ice cream, consisting of reindeer fat and seal oil and local berries.
Most food in Alaska is transported into the state from outside, and is relatively expensive due to the high shipping costs.
Influences on music in Alaska include the traditional music of Alaska Natives as well as folk music brought by later immigrants from Russia and Europe. Prominent musicians from Alaska include singer Jewel, traditional Aleut flautist Mary Youngblood, folk singer-songwriter Libby Roderick, the group Pamyua, and the metal band 36 Crazyfists.
There are many established music festivals in Alaska, including the Alaska Folk Festival, the Fairbanks Summer Arts Festival the Anchorage Folk Festival, the Athabascan Old-Time Fiddling Festival, the Sitka Jazz Festival, and the Sitka Summer Music Festival. The most prominent symphony in Alaska is the Anchorage Symphony Orchestra, though the Fairbanks Symphony Orchestra and Juneau Symphony are also notable. The Anchorage Opera is currently the state's only professional opera company, though there are several volunteer and semi-professional organizations in the state as well.
The official state song of Alaska is "Alaska's Flag", which was adopted in 1955; it celebrates the flag of Alaska.
Two of the most prominent movies filmed in Alaska were Into the Wild and MGM's Academy Award winning classic "Eskimo/Mala The Magnificent" starring Alaska's own Ray Mala. In 1932 an expedition set out from MGM's studios in Hollywood to Alaska to film what was then billed as "The Biggest Picture Ever Made". Upon arriving in Alaska, they set up "Camp Hollywood" in Northwest Alaska where they lived during the duration of the filming. Louis B. Mayer spared no expense in making sure they had everything they needed during their stay -- he even sent the famous chef from the Hotel Roosevelt on Hollywood Blvd (the site of the first Oscars) with them to Alaska to cook for them. When "Eskimo" premiered at the famed Astor Theatre in Times Square, New York, the studio received the largest amount of feedback in the history of the studio up to that time. "Eskimo" was critically acclaimed and released worldwide; as a result Inupiat Eskimo actor Ray Mala became an international movie star. "Eskimo" is significant for the following: winning the very first Oscar for Best Film Editing at the Academy Awards, for forever preserving Inupiat culture on film, and for being the first motion picture to be filmed in an all native language (Inupiat).
The psychological thriller, Insomnia, starring Al Pacino and Robin Williams was extensively shot in Canada, but was set in Alaska. The 2007 horror feature 30 Days of Night, is set in Barrow, Alaska but was filmed in New Zealand.
The 1991 film "White Fang" starring Ethan Hawke was filmed in and around Haines, Alaska.
The 1999 John Sayles film "Limbo" starring David Strathairn, Mary Elizabeth Mastrantonio and Kris Kristofferson was filmed in Juneau.


Architecture is the art and science of design and structure.

Agriculture is the production of food, feed, fiber and other goods by the systematic growing/harvesting of plants, animals and other life forms. "Agriculture" may commonly refer to the study of the practice of agriculture (also, "agronomy" or "agricultural science").
Agriculture encompasses many subjects, including aquaculture, cultivation, animal husbandry, and horticulture. Each of these subjects can be further partitioned: for example, cultivation includes both organic farming and intensive farming, and animal husbandry includes ranching, herding, and intensive pig farming. Agricultural products include fodder, (starch, sugar, alcohols and resins), fibers (cotton, wool, hemp, silk and flax), fuels (methane from biomass, ethanol, biodiesel), cut flowers, ornamental and nursery plants, tropical fish and birds for the pet trade, and both legal and illegal drugs (biopharmaceuticals, tobacco, marijuana, opium, cocaine).
The history of agriculture is a central element of human history, as agricultural progress has been a crucial factor in worldwide socio-economic change. Wealth-building and militaristic specializations rarely seen in hunter-gatherer cultures are commonplace in agricultural and agro-industrial societies—when farmers became capable of producing food beyond the needs of their own families, others in the tribe/village/City-state/nation/empire were freed to devote themselves to projects other than food acquisition. Jared Diamond, among others, has argued that the development of civilization required agriculture.
As of 2006, an estimated 36 percent of the world's workers are employed in agriculture (down from 42% in 1996). However, the relative significance of farming has dropped steadily since the beginning of industrialization, and in 2006 – for the first time in history – the services sector overtook agriculture as the economic sector employing the most people worldwide. Despite the fact that agriculture employs over one-third of the world's population, agricultural production accounts for less than five percent of the gross world product (an aggregate of all gross domestic products).
Agriculture has played a key role in the development of human civilization—it is widely believed that the domestication of plants and animals allowed humans to settle and give up their previous hunter-gatherer lifestyle during the Neolithic Revolution. Until the Industrial Revolution, the vast majority of the human population labored in agriculture. Development of agricultural techniques has steadily increased agricultural productivity, and the widespread diffusion of these techniques during a time period is often called an agricultural revolution. A remarkable shift in agricultural practices has occurred over the past century in response to new technologies. In particular, the Haber-Bosch method for synthesizing ammonium nitrate made the traditional practice of recycling nutrients with crop rotation and animal manure less necessary. Synthetic nitrogen, along with mined rock phosphate, pesticides and mechanization, have greatly increased crop yields in the early 20th century. Increased supply of grains has led to cheaper livestock as well. Further, global yield increases were experienced later in the 20th century when high-yield varieties of common staple grains such as rice, wheat, and corn were introduced as a part of the Green Revolution. The Green Revolution exported the technologies (including pesticides and synthetic nitrogen) of the developed world out to the developing world. Thomas Malthus famously predicted that the Earth would not be able to support its growing population, but technologies such as the Green Revolution have allowed the world to produce a surplus of food.
Many governments have subsidized agriculture to ensure an adequate food supply. These agricultural subsidies are often linked to the production of certain commodities such as wheat, corn, rice, soybeans, and milk. These subsidies, especially when done by developed countries have been noted as protectionist, inefficient, and environmentally damaging. In the past century agriculture has been characterized by enhanced productivity, the use of synthetic fertilizers and pesticides, selective breeding, mechanization, water contamination, and farm subsidies. Proponents of organic farming such as Sir Albert Howard argued in the early 1900s that the overuse of pesticides and synthetic fertilizers damages the long-term fertility of the soil. While this feeling lay dormant for decades, as environmental awareness has increased recently there has been a movement towards sustainable agriculture by some farmers, consumers, and policymakers. In recent years there has been a backlash against perceived external environmental effects of mainstream agriculture, particularly regarding water pollution, resulting in the organic movement. One of the major forces behind this movement has been the European Union, which first certified organic food in 1991 and began reform of its Common Agricultural Policy (CAP) in 2005 to phase out commodity-linked farm subsidies, also known as decoupling. The growth of organic farming has renewed research in alternative technologies such as integrated pest management and selective breeding. Recent mainstream technological developments include genetically modified food.
As of late 2007, increased farming for use in biofuels has pushed up the price of grain used to feed poultry and dairy cows and other cattle, causing higher prices of wheat (up 58%), soybean (up 32%), and maize (up 11%) over the year. An epidemic of stem rust on wheat caused by race UG99 is currently spreading across Africa and into Asia and is causing major concern. Approximately 40% of the world's agricultural land is seriously degraded. In Africa, if current trends of soil degradation continue, the continent might be able to feed just 25% of its population by 2025, according to UNU's Ghana-based Institute for Natural Resources in Africa.
Agricultural practices lie on a spectrum dependent upon the intensity and technology of the methods. At the one end lies the subsistence farmer who farms a small area with limited inputs and produces only enough food to meet the needs of his or her family. At the other end lies intensive agriculture which includes traditional labor intensive farming (e.g. South-East Asia rice paddies), and modern agriculture which includes industrial agriculture, organic farming and sustainable farming. Industrial agriculture involves large fields and/or numbers of animals, high resource inputs (pesticides, fertilizers, etc.), and a high level of mechanization. These operations achieve economies of scale and require large amounts of capital in the form of land and machinery.
The twentieth century saw changes in agricultural practice, particularly in agricultural chemistry and in mechanization. Agricultural chemistry includes the application of chemical fertilizer, chemical insecticides (see pest control), and chemical fungicides, analysis of soil makeup and nutritional needs of farm animals.
Mechanization has increased farm efficiency and productivity in most regions of the world, due especially to the tractor and various "gins" (short for "engine") such as the cotton gin, semi-automatic balers and threshers and, above all, the combine (see agricultural machinery). According to the National Academy of Engineering in the United States, agricultural mechanization is one of the 20 greatest engineering achievements of the 20th century. Early in the century, it took one American farmer to produce food for 2.5 people. By 1999, due to advances in agricultural technology, a single farmer could feed over 130 people.
Other recent changes in agriculture include hydroponics, plant breeding, hybridization, gene manipulation, better management of soil nutrients, and improved weed control. Genetic engineering has yielded crops which have capabilities beyond those of naturally occurring plants, such as higher yields and disease resistance. Modified seeds germinate faster, and thus can be grown on an accelerated schedule. Genetic engineering of plants has proven controversial, particularly in the case of herbicide-resistant plants.
Genetic engineers at companies such as Monsanto are working to develop plants for irrigation, drainage, conservation and sanitary engineering, particularly important in normally arid areas which rely upon constant irrigation, and on large scale farms.
The processing, packing and marketing of agricultural products are closely related activities also influenced by science. Methods of quick-freezing and dehydration have increased the markets for many farm products (see food preservation and meat packing industry).
Animals, including horses, mules, oxen, camels, llamas, alpacas, and dogs, are often used to help cultivate fields, harvest crops, wrangle other animals, and transport farm products to buyers. Animal husbandry not only refers to the breeding and raising of animals for meat or to harvest animal products (like milk, eggs, or wool) on a continual basis, but also to the breeding and care of species for work and companionship.
Airplanes, helicopters, trucks, tractors, and combines are used in Western (and, increasingly, Eastern) agriculture for seeding, spraying operations for insect and disease control, harvesting, aerial topdressing and transporting perishable products. Radio and television disseminate vital weather reports and other information such as market reports that concern farmers. Computers have become an essential tool for farm management.
In recent years, some aspects of intensive industrial agriculture have been the subject of increasing debate. The widening sphere of influence held by large seed and chemical companies, meat packers and food processors has been a source of concern both within the farming community and for the general public. Another issue is the type of feed given to some animals that can cause bovine spongiform encephalopathy in cattle. There has also been concern over the effect of intensive agriculture on the environment.
The patent protection given to companies that develop new types of seed using genetic engineering has allowed seed to be licensed to farmers in much the same way that computer software is licensed to users. This has changed the balance of power in favor of the seed companies, allowing them to dictate terms and conditions previously unheard of. The Indian activist and scientist Vandana Shiva argues that these companies are guilty of biopiracy.
Soil conservation and nutrient management have been important concerns since the 1950s, with the most advanced farmers taking a stewardship role with the land they use. However, increasing contamination of waterways and wetlands by nutrients like nitrogen and phosphorus are concerns that can only be addressed by "enlightenment" of farmers and/or far stricter law enforcement in many countries.
Increasing consumer awareness of agricultural issues has led to the rise of community-supported agriculture, local food movement, "Slow Food", and commercial organic farming.
The word agriculture is the English adaptation of Latin agricultūra, from ager, "a field", and cultūra, "cultivation" in the strict sense of "tillage of the soil". Thus, a literal reading of the word yields "tillage of a field / of fields".
Developed independently by geographically distant populations, systematic agriculture first appeared in Southwest Asia in the Fertile Crescent, particularly in modern-day Iraq and Syria/Israel. Around 9500 BCE, proto-farmers began to select and cultivate food plants with desired characteristics. Though there is evidence of earlier sporadic use of wild cereals, it was not until after 9500 BCE that the eight so-called founder crops of agriculture appear: first emmer and einkorn wheat, then hulled barley, peas, lentils, bitter vetch, chick peas and flax.
By 7000 BCE, small-scale agriculture reached Egypt. From at least 7000 BCE the Indian subcontinent saw farming of wheat and barley, as attested by archaeological excavation at Mehrgarh in Balochistan. By 6000 BCE, mid-scale farming was entrenched on the banks of the Nile. About this time, agriculture was developed independently in the Far East, with rice, rather than wheat, as the primary crop. Chinese and Indonesian farmers went on to domesticate mung, soy, azuki and taro. To complement these new sources of carbohydrates, highly organized net fishing of rivers, lakes and ocean shores in these areas brought in great volumes of essential protein. Collectively, these new methods of farming and fishing inaugurated a human population boom dwarfing all previous expansions, and is one that continues today.
By 5000 BCE, the Sumerians had developed core agricultural techniques including large scale intensive cultivation of land, mono-cropping, organized irrigation, and use of a specialized labour force, particularly along the waterway now known as the Shatt al-Arab, from its Persian Gulf delta to the confluence of the Tigris and Euphrates. Domestication of wild aurochs and mouflon into cattle and sheep, respectively, ushered in the large-scale use of animals for food/fiber and as beasts of burden. The shepherd joined the farmer as an essential provider for sedentary and semi-nomadic societies.
Maize, manioc, and arrowroot were first domesticated in the Americas as far back as 5200 BCE. The potato, tomato, pepper, squash, several varieties of bean, Canna, tobacco and several other plants were also developed in the New World, as was extensive terracing of steep hillsides in much of Andean South America.
During the Middle Ages, Muslim farmers in North Africa and the Near East developed and disseminated agricultural technologies including irrigation systems based on hydraulic and hydrostatic principles, the use of machines such as norias, and the use of water raising machines, dams, and reservoirs. They also wrote location-specific farming manuals, and were instrumental in the wider adoption of crops including sugar cane, rice, citrus fruit, apricots, cotton, artichokes, aubergines, and saffron. Muslims also brought lemons, oranges, cotton, almonds, figs and sub-tropical crops such as bananas to Spain.
The invention of a three field system of crop rotation during the Middle Ages, and the importation of the Chinese-invented moldboard plow, vastly improved agricultural efficiency.
After 1492, a global exchange of previously local crops and livestock breeds occurred. Key crops involved in this exchange included the tomato, maize, potato, cocoa and tobacco going from the New World to the Old, and several varieties of wheat, spices, coffee, and sugar cane going from the Old World to the New. The most important animal exportations from the Old World to the New were those of the horse and dog (dogs were already present in the pre-Columbian Americas but not in the numbers and breeds suited to farm work). Although not usually food animals, the horse (including donkeys and ponies) and dog quickly filled essential production roles on western hemisphere farms.
By the early 1800s, agricultural techniques, implements, seed stocks and cultivars had so improved that yield per land unit was many times that seen in the Middle Ages. With the rapid rise of mechanization in the late 19th and 20th centuries, particularly in the form of the tractor, farming tasks could be done with a speed and on a scale previously impossible. These advances have led to efficiencies enabling certain modern farms in the United States, Argentina, Israel, Germany, and a few other nations to output volumes of high quality produce per land unit at what may be the practical limit.
In 2005, the agricultural output of China was the largest in the world, accounting for almost one-sixth world share followed by the EU, India and the USA, according to the International Monetary Fund.
Specific crops are cultivated in distinct growing regions throughout the world. In millions of metric tons, based on FAO estimates.
Domestication of plants has, over the centuries increased yield, improved disease resistance and drought tolerance, eased harvest and improved the taste and nutritional value of crop plants. Careful selection and breeding have had enormous effects on the characteristics of crop plants. Plant breeders use greenhouses (known as glasshouses or hothouses in some areas) and other techniques to get as many as three generations of plants per year towards the continued effort of improvement.
Plant selection and breeding in the 1920s and 1930s improved pasture (grasses and clover) in New Zealand. Extensive X-ray an ultraviolet induced mutagenesis efforts (i.e. primitive genetic engineering) during the 1950s produced the modern commercial varieties of grains such as wheat, corn and barley.
For example, average yields of corn (maize) in the USA have increased from around 2.5 tons per hectare (t/ha) (40 bushels per acre) in 1900 to about 9.4 t/ha (150 bushels per acre) in 2001. Similarly, worldwide average wheat yields have increased from less than 1 t/ha in 1900 to more than 2.5 t/ha in 1990. South American average wheat yields are around 2 t/ha, African under 1 t/ha, Egypt and Arabia up to 3.5 to 4 t/ha with irrigation. In contrast, the average wheat yield in countries such as France is over 8 t/ha. Variation in yields are due mainly to variation in climate, genetics, and the level of intensive farming techniques (use of fertilizers, chemical pest control, growth control to avoid lodging).
After mechanical tomato-harvesters were developed in the early 1960s, agricultural scientists bred tomatoes that were more resistant to mechanical handling. These varieties have been criticized as being harder and having poor texture.
More recently, genetic engineering has begun to be employed in large parts of the world to speed up the selection and breeding process. One widely used modification is a herbicide resistance gene that allows plants to tolerate exposure to glyphosate, a non-systemic (i.e kills all plants) chemical used to control weeds in a crop such as oilseed rape. Normally, expensive systemic herbicides would have to be applied to kill the weeds without harming the crop. Relatively cheap and safe glyphosate may be applied to the modified crops, efficiently killing weeds without harming the resistant crop. Another modification causes the plant to produce a toxin to reduce damage from insects (c.f. Starlink). This, in contrast, requires fewer insecticides to be applied to the crop.
Aquaculture, the farming of fish, shrimp, and algae, is closely associated with agriculture.
Apiculture, the culture of bees, traditionally for honey—increasingly for crop pollination.
The farming practices of livestock vary dramatically world-wide and between different types of animals. Livestock are generally kept in an enclosure, are fed by human-provided food and are intentionally bred, but some livestock are not enclosed, or are fed by access to natural foods, or are allowed to breed freely, or all three. Approximately 68% of all agricultural land is used in the production of livestock as permanent pastures.
According to the United Nations, the livestock sector (primarily cows, chickens, and pigs) emerges as one of the top two or three most significant contributors to our most serious environmental problems, at every scale from local to global. Livestock production occupies 70% of all land used for agriculture, or 30% of the land surface of the planet.It is one of the largest sources of greenhouse gases—responsible for 18% of the world’s greenhouse gas emissions as measured in CO2 equivalents. By comparison, all transportation emits 13.5% of the CO2. It produces 65% of human-related nitrous oxide (which has 296 times the global warming potential of CO2) and 37% of all human-induced methane (which is 23 times as warming as CO2). It also generates 64% of the ammonia, which contributes to acid rain and acidification of ecosystems.
Genetic erosion in crops and livestock biodiversity is propelled by several major factors such as variety replacement, land clearing, overexploitation of species, population pressure, environmental degradation, overgrazing, policy and changing agricultural systems.
The main factor, however, is the replacement of local varieties of domestic plants and animals by high yielding or exotic varieties or species. A large number of varieties can also often be dramatically reduced when commercial varieties (including GMOs) are introduced into traditional farming systems. Many researchers believe that the main problem related to agro-ecosystem management is the general tendency towards genetic and ecological uniformity imposed by the development of modern agriculture.
In agriculture and animal husbandry, the green revolution popularized the use of conventional hybridization to increase yield many folds by creating "high-yielding varieties". Often the handful of breeds of plants and animals hybridized originated in developed countries and were further hybridized with local varieties in the rest of the developing world to create high yield strains resistant to local climate and diseases. Hybridization of local breeds to improve performance may lead to the loss of the local breed over time and consequently the loss of the genetic material that adapted that breed specifically to the local conditions. When viewed across the world as a whole, the consequent loss in genetic diversity and biodiversity could be placing the food supply in jeopardy, as a highly specialized breed may not contain sufficient genetic material to adapt to new diseases or environments even with an intensive breeding program.
A Genetically Modified Organism (GMO) is an organism whose genetic material has been altered using the genetic engineering techniques generally known as recombinant DNA technology. Genetic Engineering today has become another serious and alarming cause of genetic pollution because artificially created and genetically engineered plants and animals in laboratories, which could never have evolved in nature even with conventional hybridization, can live and breed on their own and what is even more alarming interbreed with naturally evolved wild varieties. Genetically Modified (GM) crops today have become a common source for genetic pollution, not only of wild varieties but also of other domesticated varieties derived from relatively natural hybridization.
Since the 1940s, agriculture has dramatically increased its productivity, due largely to the use of petrochemical derived pesticides, fertilizers, and increased mechanization. This has allowed world population to grow more than double over the last 50 years. Every energy unit delivered in food grown using modern techniques requires over ten energy units to produce and deliver. The vast majority of this energy input comes from fossil fuel sources. Because of modern agriculture's current heavy reliance on petrochemicals and mechanization, there are warnings that the ever decreasing supply of oil (the dramatic nature of which is known as peak oil) will inflict major damage on the modern industrial agriculture system, and could cause large food shortages.
Farmers have also begun raising crops such as corn for non-food use in an effort to help mitigate peak oil. This has led to a 60% rise in wheat prices recently, and has been indicated as a possible precursor to "serious social unrest in developing countries." Such situations would be exacerbated in the event of future rises in food and fuel costs, factors which have already impacted the ability of charitable donors to send food aid to starving populations.
Agriculture is the most dangerous industry for young workers, accounting for 42% of all work-related fatalities of young workers in the U.S. between 1992 and 2000. Unlike other industries, half the young victims in agriculture were under age 15.


Aldous Leonard Huxley (26 July 1894 – 22 November 1963) was an English writer and one of the most prominent members of the famous Huxley family. He spent the latter part of his life in the United States, living in Los Angeles from 1937 until his death in 1963. Best known for his novels and wide-ranging output of essays, he also published short stories, poetry, travel writing, and film stories and scripts.
Huxley was a humanist but was also interested towards the end of his life in spiritual subjects such as parapsychology and philosophical mysticism. By the end of his life Huxley was considered, in some academic circles, a leader of modern thought and an intellectual of the highest rank. He was also well known for advocating and taking LSD, including on his death bed.
Aldous Huxley was born in Godalming, Surrey, England in 1894. He was the third son of the writer and professional herbalist Leonard Huxley and first wife, Julia Arnold who founded Prior's Field School and also the niece of Matthew Arnold and sister of Mrs. Humphrey Ward. He was grandson of Thomas Henry Huxley, one of the most prominent English naturalists of the 19th century, a man known as "Darwin's Bulldog." His brother Julian Huxley was also a noted biologist.
Huxley began his learning in his father's well-equipped botanical laboratory, then continued in a school named Hillside. His teacher was his mother who supervised him for several years until she became terminally ill. After Hillside, he was educated at Eton College. Huxley's mother died in 1908, when he was fourteen. Three years later he suffered an illness (keratitis punctata) which "left [him] practically blind for two to three years". Aldous's near-blindness disqualified him from service in World War I. Once his eyesight recovered sufficiently, he was able to study English literature at Balliol College, Oxford. He graduated in 1916 with First Class Honours.
Following his education at Balliol, Huxley was financially indebted to his father and had to earn a living. He taught French for a year at Eton, where Eric Blair (later known by the pen name George Orwell) was among his pupils, but was remembered by another as an incompetent and hopeless teacher who couldn’t keep discipline. Nevertheless, Blair and others were impressed by his use of words. For a short while in 1918, he was employed acquiring provisions at the Air Ministry. But never desiring a career in administration (or in business), Huxley's lack of inherited means propelled him into applied literary work.
Huxley completed his first (unpublished) novel at the age of seventeen and began writing seriously in his early twenties. His earlier work includes important novels on the dehumanizing aspects of scientific progress, most famously Brave New World, and on pacifist themes (for example, Eyeless in Gaza). In Brave New World Huxley portrays a society operating on the principles of mass production and Pavlovian conditioning. Huxley was strongly influenced by F. Matthias Alexander and included him as a character in Eyeless in Gaza.
During World War I, Huxley spent much of his time at Garsington Manor, home of Lady Ottoline Morrell, working as a farm labourer. Here he met several Bloomsbury figures including D.H. Lawrence, Bertrand Russell and Clive Bell. Later, in Crome Yellow (1921) he caricatured the Garsington lifestyle. In 1919 he married Maria Nijs, a Belgian woman he had met at Garsington. They had one child, Matthew Huxley (1920 – 2005), who had a career as an epidemiologist. The family lived in Italy part of the time in the 1920s, where Huxley would visit his friend D. H. Lawrence. Following Lawrence's death in 1930, he edited his letters (1933).
In 1937, Huxley moved to Hollywood, California with his wife Maria, son Matthew, and friend Gerald Heard. At this time Huxley wrote Ends and Means, while living in Taos, New Mexico; in this work he explores the fact that although most people in modern civilization agree that they want a world of 'liberty, peace, justice, and brotherly love', they have not been able to agree on how to achieve it. Heard introduced Huxley to Vedanta, meditation and vegetarianism through the principle of ahimsa. In 1938 Huxley befriended J. Krishnamurti, whose teachings he greatly admired. He also became a Vedantist in the circle of Swami Prabhavananda, and introduced Christopher Isherwood to this circle. Not long after, Huxley wrote his book on widely held spiritual values and ideas, The Perennial Philosophy, which discussed the teachings of renowned mystics of the world.
Aldous Huxley was close friends with Occidental College president Remsen Bird during Huxley's time living in Southern California. He spent much time at the college, which is located in the Eagle Rock neighborhood of Los Angeles, and the college is portrayed under the name of Tarzana College in his satircal novel After Many a Summer Dies the Swan (1939), for which he collected that year's James Tait Black Memorial Prize for fiction. Huxley also incorporated Bird into the novel.
During this period he was also able to tap into some Hollywood income using his writing skills, thanks to an introduction into the business by his friend Anita Loos, the prolific novelist and screenwriter. He received screen credit for Pride and Prejudice (1940) and was paid for his work on a number of other films. However, his experience in Hollywood was not a success. When he wrote a synopsis of Alice in Wonderland, Walt Disney rejected it on the grounds that "he could only understand every third word". Huxley's leisurely development of ideas, it seemed, was not suitable for the movie moguls, who demanded fast, dynamic dialogue above all else.
For most of his life since the illness in his teens which left Huxley nearly blind, his eyesight was poor (despite the partial recovery which had enabled him to study at Oxford). Around 1939, Huxley encountered the Bates Method for better eyesight, and a teacher (Margaret Corbett) who was able to teach him in the method. In 1940, relocating from Hollywood to a forty-acre ranchito in the high desert hamlet of Llano, California, in northernmost Los Angeles County, Huxley claimed his sight improved dramatically as a result of using the Bates Method, particularly utilizing the extreme and pure natural lighting of the Southwestern American desert. He reported that for the first time in over 25 years, he was able to read without glasses and without strain. He even tried driving a car along the dirt road beside the ranch. He wrote a book about his successes with the Bates Method, The Art of Seeing which was published in 1942 (US), 1943 (UK).
On October 21 1949 Huxley wrote to George Orwell, author of Nineteen Eighty-Four, congratulating Orwell on "how fine and how profoundly important the book is". His letter to Orwell contained the prediction that: "Within the next generation I believe that the world's leaders will discover that infant conditioning and narco-hypnosis are more efficient, as instruments of government, than clubs and prisons, and that the lust for power can be just as completely satisfied by suggesting people into loving their servitude as by flogging them and kicking them into obedience".
After World War II Huxley applied for United States citizenship, but was denied because he would not say he would take up arms to defend America. Nevertheless he remained in the United States and in 1959 he turned down an offer of a Knight Bachelor by the Macmillan government. During the 1950s, Huxley's interest in the field of psychical research grew keener and his later works are strongly influenced by both mysticism and his experiences with the psychedelic drugs.
In October 1930, the Mystic Aleister Crowley dined with Huxley in Berlin, and to this day rumours persist that Crowley introduced Huxley to peyote on that occasion. He was introduced to mescaline by the psychiatrist Humphry Osmond in 1953; on December 24 1955, Huxley took his first dosage of LSD. Indeed Huxley was a pioneer of self-directed psychedelic drug use "in a search for enlightenment", famously taking 100 micrograms of LSD as he lay dying. His psychedelic drug experiences are described in the essays The Doors of Perception (the title deriving from some lines in the book The Marriage of Heaven and Hell by William Blake) and Heaven and Hell. Some of his writings on psychedelics became frequent reading among early hippies. While living in Los Angeles, Huxley was a friend of Ray Bradbury. According to Sam Weller's biography of Bradbury, the latter was dissatisfied with Huxley, especially after Huxley encouraged Bradbury to take psychedelic drugs.
In 1955 Huxley's wife, Maria, died of breast cancer. In 1956 he married Laura Archera (1911-2007), also an author. She wrote a biography of Huxley. In 1960, Huxley himself was diagnosed with cancer and, in the years that followed, with his health deteriorating, he wrote the Utopian novel Island, and gave lectures on "Banana Potentialities" at the Esalen institute which were foundational to the forming of the Human Potential Movement. On his deathbed, unable to speak, Huxley made a written request to his wife for "LSD, 100ug, intramuscular.". According to her account of his death (in her book This Timeless Moment), she obliged with an injection at 11:45 am and another a couple of hours later. He died at 5:21 pm on November 22 1963, aged 69. Media coverage of his death was overshadowed by news of the assassination of President John F. Kennedy, which occurred on the same day, as did the death of the Irish author C. S. Lewis. Huxley's ashes were interred in the family grave at the Watts Cemetery, Compton, Guildford, Surrey, England.
Huxley's only child, Matthew Huxley (d. February 10 2005) was also an author, as well as an educator, anthropologist and prominent epidemiologist. His work ranged from promoting universal health care to establishing standards of care for nursing home patients and the mentally ill to investigating the question of what is a socially sanctionable drug. Matthew's first marriage, to documentary filmmaker Ellen Hovde, ended in divorce. His second wife died in 1983. He was survived by his third wife, Franziska Reed Huxley; and two children from his first marriage, Trevenen Huxley and Tessa Huxley.
Huxley's reputation for iconoclasm and emancipation grew. He was condemned for his explicit discussion of sex and free thought in his fiction. Antic Hay, for example, was burned in Cairo and in the years that followed many of Huxley's books were received with disapproval or banned at one time or another. Following the exclusion of Brave New World, Point Counter Point and even Island from Time magazine's list of 'All-Time 100 Novels' there was uproar. One critic became particularly incensed, proclaiming such a decision to be "blasphemous".
Huxley, however, said that a novel should be full of interesting opinions and arresting ideas, describing his aim as a novelist as being 'to arrive, technically, at a perfect fusion of the novel and the essay'; and with Point Counter Point (1928), Huxley wrote his first true 'novel of ideas', the type of thought-provoking fiction with which he is now associated.
One of his main ideas was pessimism about the cultural future of society, a pessimism which sprang largely from his visit to the United States between September 1925 and June 1926. He recounted his experiences in Jesting Pilate (1926): 'The thing which is happening in America is a revaluation of values, a radical alteration (for the worse) of established standards', and it was soon after this visit that he conceived the idea of writing a satire of what he had encountered.".
A widespread fear of Americanization had already existed in Europe since the mid-nineteenth century and Brave New World (1932) as well as Island (1962) form the cornerstone of Huxley's damning indictment of American commercialism. Brave New World (as well as Orwell's Nineteen Eighty-Four and Yevgeni Zamyatin's We) helped form the anti-utopian or dystopian tradition in literature and has become synonymous with a future world in which the human spirit is subject to conditioning and control. Island acts as an antonym to Brave New World; it is described as "one of the truly great philosophical novels".
He devoted his time at his small house at Llano in the Mojave Desert to a life of contemplation, mysticism and experimentation with hallucinogenic drugs. His suggestions in The Doors of Perception (1954) that mescalin and lysergic acid were 'drugs of unique distinction' which should be exploited for the 'supernaturally brilliant' visionary experience they offered provoked even more outrage than his passionate defense of the Bates method in The Art of Seeing (1942). However, the book went on to become a cult text in the psychedelic 1960s, and Huxley appears on the sleeve of the Beatles' landmark 1967 album "Sgt. Pepper's Lonely Hearts Club Band".
In 1959 Aldous Huxley received the American Academy of Arts and Letters Award of Merit for the novel 'Brave New World'.
Notable works include the original screenplay for Disney's animated Alice in Wonderland (which was rejected because it was too literary), two productions of Brave New World, one of Point Counter Point, one of Eyeless in Gaza, and one of Ape and Essence. He was one of the screenwriters for Pride and Prejudice (1940), co-authored the screenplay for Jane Eyre (1944) with John Houseman, and worked on the screenplay of Madame Curie (1943) without credit.
Director Ken Russell's 1971 film The Devils, starring Vanessa Redgrave, was adapted from Huxley's The Devils of Loudun. A made-for-television adaptation of Brave New World was made in 1990.





Algae are a large and diverse group of simple plant-like organisms, ranging from unicellular to multicellular forms. The largest and most complex marine forms are called seaweeds. They are considered "plant-like" because of their photosynthetic ability, and "simple" because they lack the distinct organs of higher plants such as leaves and vascular tissue. Though the prokaryotic Cyanobacteria (commonly referred to as Blue-green algae) were traditionally included as "algae" in older textbooks, many modern sources regard this as outdated and restrict the term algae to eukaryotic organisms. All true algae therefore have a nucleus enclosed within a membrane and chloroplasts bound in one or more membranes. Algae constitute a paraphyletic and polyphyletic group: they do not represent a single evolutionary direction or line, but a level or grade of organization that may have developed several times in the early history of life on Earth.
Algae lack leaves, roots, and other organs that characterize higher plants. They are distinguished from protozoa in that they are photosynthetic. Many are photoautotrophic, although some groups contain members that are mixotrophic, deriving energy both from photosynthesis and uptake of organic carbon either by osmotrophy, myzotrophy, or phagotrophy. Some unicellular species rely entirely on external energy sources and have reduced or lost their photosynthetic apparatus.
All algae have photosynthetic machinery ultimately derived from the cyanobacteria, and so produce oxygen as a byproduct of photosynthesis, unlike other photosynthetic bacteria such as purple and green sulfur bacteria.
Algae are most prominent in bodies of water, but are also common in terrestrial environments. However, terrestrial algae are usually rather inconspicuous and far more common in moist, tropical regions than dry ones, because algae lack vascular tissues and other adaptations to live on land. Algae are also found in other situations, such as on snow and on exposed rocks in symbiosis with a fungus as lichen.
The various sorts of algae play significant roles in aquatic ecology. Microscopic forms that live suspended in the water column — called phytoplankton — provide the food base for most marine food chains. In very high densities (so-called algal blooms) these algae may discolor the water and outcompete, poison, or asphyxiate other life forms. Seaweeds grow mostly in shallow marine waters, however some have been recorded to a depth of 300 m.Some are used as human food or harvested for useful substances such as agar, carrageenan, or fertilizer.
The study of marine and freshwater algae is called phycology or algology.
The US Algal Collection is represented by almost 300,000 accessioned and inventoried herbarium specimens.
While Cyanobacteria have been traditionally included among the algae, referred to as the Cyanophytes or blue-green algae, recent works on algae usually exclude them due to large differences such as the lack of membrane-bound organelles, the presence of a single circular chromosome, the presence of peptidoglycan in the cell walls, and ribosomes different in size and content from eukaryotes. Rather than in chloroplasts, they conduct photosynthesis on specialized infolded cytoplasmic membranes called thylakoid membranes. Therefore, they differ significantly from the algae despite occupying similar ecological niches.
By modern definitions algae are eukaryotes and conduct photosynthesis within membrane-bound organelles called chloroplasts. Chloroplasts contain circular DNA and are similar in structure to cyanobacteria, presumably representing reduced cyanobacterial endosymbionts. The exact nature of the chloroplasts is different among the different lines of algae, reflecting different endosymbiotic events. The table below lists the three major groups of algae and their lineage relationship is shown in the figure on the left. Note many of these groups contain some members that are no longer photosynthetic. Some retain plastids, but not chloroplasts, while others have lost them entirely.
It was W.H.Harvey (1811 — 1866) who first divided the algae into four divisions based on their pigmentation. This is the first use of a biochemical criterion in plant systematics. Harvey's four divisions were: red algae (Rhodophyta), brown algae (Heteromontophyta), green algae (Chlorophyta) and Diatomaceae (Dixon, 1973 p.232).
In three lines even higher levels of organization have been reached, with full tissue differentiation. These are the brown algae —some of which may reach 50 m in length (kelps)—the red algae, and the green algae. The most complex forms are found among the green algae (see Charales and Charophyta), in a lineage that eventually led to the higher land plants. The point where these non-algal plants begin and algae stop is usually taken to be the presence of reproductive organs with protective cell layers, a characteristic not found in the other alga groups.
The first plants on earth evolved from shallow freshwater algae much like Chara some 400 million years ago. These probably had an isomorphic alternation of generations and were probably heterotrichous. Fossils of isolated land plant spores suggest land plants may have been around as long as 475 million years ago.
Rhodophyta, Chlorophyta and Heterokontophyta, the three main algal Phyla, have life-cycles which show tremendous variation with considerable complexity. In general there is an asexual phase where the seaweed's cells are diploid, a sexual phase where the cells are haploid followed by fusion of the male and female gametes. Asexual reproduction is advantageous in that it permits efficient population increases, but less variation is possible. Sexual reproduction allows more variation but is more costly because of the waste of gametes that fail to mate, among other things. Often there is no strict alternation between the sporophyte and gametophyte phases and also because there is often an asexual phase, which could include the fragmentation of the thallus.
In the British Isles the UK Biodiversity Steering Group Report estimated there to be 20,000 algal species in the UK, freshwater and marine, about 650 of these are seaweeds. Another checklist of freshwater algae reported only about 5000 species. It seems therefore that the 20,000 is an overestimate or an error (John, 2002 p.1).
The Smithsonian collection of algae has over 300,000 specimens.
World-wide it is thought that there are over 5,000 species of red algae, 1,500 — 2,000 of brown algae and 8,000 of green algae. In Australia it is estimated that there are over 1,300 species of red algae, 350 species of brown algae and approximately 2,000 species of green algae totalling 3,650 species of algae in Australia.
Around 400 species appear to be an average figure for the coastline of South African west coast.
669 marine species have been described from California (U.S.A.).
642 entities are listed in the check-list of Britain and Ireland (Hardy and Guiry, 2006).
No publication has been found which attempts to discuss the general distribution of algae in the seas world-wide. However, notes and comments have been made by some authors.
The floristic discontinuities may appear to determined by geographical features such as Antarctica, long distances of ocean or general land masses. However, the distances between Norway, the Faroes and Iceland do not show great changes in distribution.
There has been dispersal in some species by ships, water currents and the like; further, some algae can quickly become entangled and make drifting mats. Two red species have been introduced from the Pacific to Europe and the Mediterranean: Bonnemaisonia hamifera Hariot and Asparagopsis armata Harvey, A. armata is a native of Australia.Colpomenia peregrina is a native of the Pacific but has also invaded Europe.
For centuries seaweed has been used as a fertilizer; Orwell writing in the 16th Century referring to drift weed in South Wales: "This kind of ore they often gather and lay in heaps where it heats and rots, and will have a strong and loathsome smell; when being so rotten they cast it on the land, as they do their muck, and thereof springeth good corn, especially barley" and "After spring tides or great rigs of the sea, they fetch it in sacks on horse brackets, and carry the same three, four, or five miles, and cast it on the lande, which doth very much better the ground for corn and grass" (Chapman p.35).
Algae are used by humans in many ways. They are used as fertilizers, soil conditioners and are a source of livestock feed. Because many species are aquatic and microscopic, they are cultured in clear tanks or ponds and either harvested or used to treat effluents pumped through the ponds. Algaculture on a large scale is an important type of aquaculture in some places.
Maerl is commonly used as a soil conditioner, it is dredged from the sea floor and crushed to form a powder. It is still harvested around the coasts of Brittany in France and off Falmouth, Cornwall (also extensively in western Ireland) and is a popular fertilizer in these days of organic gardening investigated Falmouth maerl and found that L. corallioides predominated down to 6 m and P. calcareum from 6-10 m (Blunden et al. 1981).
Chemical analysis of maerl showed that it contained 32.1% CaCO3 and 3.1% MgCO3 (dry weight).
Chondrus crispus, (probably confused with Mastocarpus stellatus, common name: Irish moss), is also used as "carrageen". The name carrageenan comes from the Irish Gaelic for Chondrus crispus. It is an excellent stabiliser in milk products - it reacts with the milk protein caesin, other products include: petfoods, toothpaste, ice-creams and lotions etc. Alginates in creams and lotions are absorbable through the skin.
Seaweeds are an important source of food, especially in Asia; They are excellent sources of many vitamins including: A, B1, B2, B6, niacin and C. They are rich in iodine, potassium, iron, magnesium and calcium.
Algae is commercially cultivated as a nutritional supplement. One of the most popular microalgal species is Spirulina (Arthrospira platensis), which is a Cyanobacteria (known as blue-green algae), and has been hailed by some as a superfood. Other algal species cultivated for their nutritional value include; Chlorella (a green algae), and Dunaliella (Dunaliella salina), which is high in beta-carotene and is used in vitamin C supplements.
In China at least 70 species of algae are eaten as is the Chinese "vegetable" known as fat choy (which is actually a cyanobacterium). Roughly 20 species of algae are used in everyday cooking in Japan.
Certain species are edible; the best known, especially in Ireland is Palmaria palmata (Linnaeus) O. Kuntze (Rhodymenia palmata (Linnaeus) Kuntze, common name: dulse). This is a red alga which is dried and may be bought in the shops in Ireland. It is eaten raw, fresh or dried, or cooked like spinach. Similarly, Durvillaea Antarctica is eaten in Chile, common name: cochayuyo.
Porphyra (common name: purple laver), is also collected and used in a variety of ways (e.g. "laver bread" in the British Isles). In Ireland it is collected and made into a jelly by stewing or boiling. Preparation also involves frying with fat or converting to a pinkish jelly by heating the fronds in a saucepan with a little water and beating with a fork. It is also collected and used by people parts of Asia, specifically China, Korea (gim and Japan (nori) and along most of the coast from California to British Columbia. The Hawaiians and the Maoris of New Zealand also use it.
One particular use is in "instant" puddings, sauces and creams. Ulva lactuca (common name: sea lettuce), is used locally in Scotland where it is added to soups or used in salads. Alaria esculenta (common name: badderlocks or dabberlocks), is used either fresh or cooked, in Greenland, Iceland, Scotland and Ireland.
The oil from some algae have high levels of unsaturated fatty acids. Arachidonic acid (a polyunsaturated fatty acid), is very high in Parietochloris incisa", (a green alga) where it reaches up to 47% of the triglyceride pool (Bigogno C et al. Phytochemistry 2002, 60, 497).
It is a known fact that fish oil contains the omega-3 fatty acids docosahexaenoic acid, commonly known as DHA and eicosapentaenoic acid, or EPA; but The Martek Biosciences Corporation who discovered the source of DHA to be from algae manufactures DHA from algae, which is where fish get their DHA, explains J. Casey Lippmeier, Martek's senior scientist.
The algae are eaten by smaller marine life such as copepods, "and those are eaten by slightly larger fish," says Lippmeier. The DHA gets passed along the food chain, all the way up to the biggest fish, but the original source is the algae.
You can refer to the following npr.org link for an article on algae and omega-3 fatty acids; http://www.npr.org/templates/story/story.php?storyId=15823852.
There are also commercial uses of algae as agar.
Some Cosmetics can come from microalgae as well.
In Israel, a species of green algae is grown in water tanks, then exposed to direct sunlight and heat which causes it to become bright red in color. It is then harvested and used as a natural pigment for foods such as Salmon.
Between 100,000 and 170,000 wet tons of Macrocystis are harvested annually in California for alginate extraction and abalone feed.
Seaweed specimens can be collected and preserved for research. Such preserved specimens will keep for two or three hundred years. Those of Carl von Linné (1707 — 1778) are still available for reference, and are used. Specimens may be collected from the shore; those below low tide must be collected by diving or dredging. The whole algal specimen should be collected, that is the holdfast, stipe and lamina. Specimens of algae reproducing will be the more useful for identification and research. When collected the details of the location and site should be noted. They can then be preserved pressed on paper or in a preserving liquid such as alcohol or solution of 5 per cent formalin/seawater. However, formalin is reported to be carcinogenic.
The ecology of the shores of the British Isles, including a discussion of the different shores from sheltered to exposed along with an exposure scale, is given by Lewis (1964). An exposure scale of five stages is given:- Very Exposed Shores; Exposed Shores; Semi-exposed Shores; Sheltered Shores and Very Sheltered Shores. Factors indicating the differences between these exposure scales are detailed. Very Exposed Shores have a wide Verrucaria zone entirely above the upper tide level, a Porphyra zone above the barnacle level and Lichina pygmaea is locally abundant. The eulittoral zone is dominated by barnacles and limpets with a coralline belt in the very low littoral along with other Rhodophyta and Alaria in the upper sublittoral. Exposed shores show a Verrucaria belt mainly above the high tide, with Porphyra and Lichina pygmaea. The mid shore is dominated by barnacles, limpets and some Fucus. Some Rhodophyta. Himanthalia and some Rhodophyta such as Mastocarpus and Corallina are found in the low littorral with Himanthalia, Alaria and Laminaria digitata dominant in the upper sublittoral. The semi-exposed shores show a Verrucaria belt just above high tide with clear Pelvetia in the upper-littoral and Fucus serratus in the lower-littoral. Limpets, barnacles and short Fucus vesiculosus midshore. Fucus serratus with Rhodophyta, (Laurencia, Mastocarpus stellatus, Rhodymenia and Lomentaria). Laminaria and Saccorhiza polyschides and small algae common in the sublittoral. The sheltered shores show a narrow Verrucaria zone at high water and a full sequence of fucoids: Pelvetia, Fucus spiralis, Fucus vesiculosus, Fucus serratus, Ascophyllum nodosum. Laminaria digitata is dominant the upper sublittoral. The very sheltered shores show a very narrow zone of Verrucaria, the dominance of the littoral by a full sequence of the fucoids and Ascophyllum covering the rocks. Laminaria saccharina, Halidrys, Chondrus and or Furcellaria.

In statistics, analysis of variance (ANOVA) is a collection of statistical models, and their associated procedures, in which the observed variance is partitioned into components due to different explanatory variables. The initial techniques of the analysis of variance were developed by the statistician and geneticist R. A. Fisher in the 1920s and 1930s, and is sometimes known as "'Fisher's ANOVA or Fisher's analysis of variance"', due to the use of Fisher's F-distribution as part of the test of statistical significance.
The fixed-effects model of analysis of variance applies to situations in which the experimenter applies several treatments to the subjects of the experiment to see if the response variable values change. This allows the experimenter to estimate the range of response variable values that the treatment would generate in the population as a whole.
Random effects models are used when the treatments are not fixed. This occurs when the various treatments (also known as factor levels) are sampled from a larger population. Because the treatments themselves are random variables, some assumptions and the method of contrasting the treatments differ from Anova model 1.
Most random-effects or mixed-effects models are not concerned with making inferences concerning the particular sampled factors. For example, consider a large manufacturing plant in which many machines produce the same product. The statistician studying this plant would have very little interest in comparing the three particular machines to each other. Rather, inferences that can be made for all machines are of interest, such as their variability and the overall mean.
Anova 2 and 3 have more complex assumptions about the expected value and variance of the residuals since the factors themselves may be drawn from a population.
The fundamental technique is a partitioning of the total sum of squares into components related to the effects used in the model. For example, we show the model for a simplified ANOVA with one type of treatment at different levels.
The number of degrees of freedom (abbreviated ) can be partitioned in a similar way and specifies the chi-square distribution which describes the associated sums of squares.
to the F-distribution with I-1,nT degrees of freedom. Using the F-distribution is a natural candidate because the test statistic is the quotient of two mean sums of squares which have a chi-square distribution.
As first suggested by Conover and Iman in 1981, in many cases when the data do not meet the assumptions of ANOVA, one can replace each original data value by its rank from 1 for the smallest to N for the largest, then run a standard ANOVA calculation on the rank-transformed data. "Where no equivalent nonparametric methods have yet been developed such as for the two-way design, rank transformation results in tests which are more robust to non-normality, and resistant to outliers and non-constant variance, than is ANOVA without the transformation." (Helsel & Hirsch, 2002, Page 177).
However Seaman et al. (1994) noticed that the rank transformation of Conover and Iman (1981) is not appropriate for testing interactions among effects in a factorial design as it can cause an increase in Type I error (alpha error). Furthermore, if both main factors are significant there is little power to detect interactions.
A variant of rank-transformation is 'quantile normalization' in which a further transformation is applied to the ranks such that the resulting values have some defined distribution (often a normal distribution with a specified mean and variance). Further analyses of quantile-normalized data may then assume that distribution to compute significance values.
Source for measure was taken from the following article in the data analysis section.
Group A is given vodka, Group B is given gin, and Group C is given a placebo. All groups are then tested with a memory task. A one-way ANOVA can be used to assess the effect of the various treatments (that is, the vodka, gin, and placebo).
Group A is given vodka and tested on a memory task. The same group is allowed a rest period of five days and then the experiment is repeated with gin. The procedure is repeated using a placebo. A one-way ANOVA with repeated measures can be used to assess the effect of the vodka versus the impact of the placebo.
Each group is then tested on a memory task. The advantage of this design is that multiple variables can be tested at the same time instead of running two different experiments. Also, the experiment can determine whether one variable affects the other variable (known as interaction effects). A factorial ANOVA (2×2)"' can be used to assess the effect of expecting vodka or the placebo and the actual reception of either.

Alkanes, also known as paraffins, are chemical compounds that consist only of the elements carbon (C) and hydrogen (H) (i.e. hydrocarbons), wherein these atoms are linked together exclusively by single bonds (i.e. they are saturated compounds) without any cyclic structure (i.e. loops). Alkanes belong to a homologous series of organic compounds in which the members differ by a constant relative atomic mass of 14.
Each carbon atom must have 4 bonds (either C-H or C-C bonds), and each hydrogen atom must be joined to a carbon atom (H-C bonds). A series of linked carbon atoms is known as the carbon skeleton or carbon backbone. In general, the number of carbon atoms is often used to define the size of the alkane (e.g. C2-alkane).
An alkyl group is a functional group or side-chain that, like an alkane, consists solely of singly-bonded carbon and hydrogen atoms, for example a methyl or ethyl group.
Saturated hydrocarbons can be linear (general formula 'CnH2n+2) wherein the carbon atoms are joined in a snake-like structure, branched (general formula CnH2n+2, n>3) wherein the carbon backbone splits off in one or more directions, or cyclic (general formula CnH2n, n>2') wherein the carbon backbone is linked so as to form a loop. According to the definition by IUPAC, the former two are alkanes, whereas the third group is called cycloalkanes. In other words, saturated hydrocarbons are divided into alkanes and cycloalkanes, depending on whether or not they have cyclic structures, and, in the technical sense, cycloalkanes are not alkanes. However, cycloalkanes are sometimes called cyclic alkanes, which can be confusing when "real" alkanes are called acyclic alkanes. Saturated hydrocarbons can also combine any of the linear, cyclic (e.g. polycyclic) and branching structures, and they are still alkanes (no general formula) as long as they are acyclic (i.e. having no loops).
The simplest possible alkane (the parent molecule) is methane, CH4. There is no limit to the number of carbon atoms that can be linked together, the only limitation being that the molecule is acyclic, is saturated, and is a hydrocarbon. Saturated oils and waxes are examples of larger alkanes where the number of carbons in the carbon backbone tends to be greater than 10.
Alkanes are not very reactive and have little biological activity. Alkanes can be viewed as a molecular scaffold upon which can be hung the interesting biologically-active/reactive portions (functional groups) of the molecule.
In addition to these isomers, the chain of carbon atoms may form one or more loops. Such compounds are called cycloalkanes.
The IUPAC nomenclature (systematic way of naming compounds) for alkanes is based on identifying hydrocarbon chains. Unbranched, saturated hydrocarbon chains are named systematically with a Greek numerical prefix denoting the number of carbons and the suffix "-ane".
August Wilhelm von Hofmann suggested systematizing nomenclature by using the whole sequence of vowels a, e, i, o and u to create suffixes -ane, -ene, -ine (or -yne), -one, -une, for the hydrocarbons. The first three name hydrocarbons with single, double and triple bonds; "-one" represents a ketone; "-ol" represents an alcohol or OH group; "-oxy-" means an ether and refers to oxygen between two carbons, so that methoxy-methane is the IUPAC name for dimethyl ether.
It is difficult or impossible to find compounds with more than one IUPAC name. This is because shorter chains attached to longer chains are prefixes and the convention includes brackets. Numbers in the name, referring to which carbon a group is attached to, should be as low as possible, so that 1- is implied and usually omitted from names of organic compounds with only one side-group; "1-" is implied in Nitro-octane. Symmetric compounds will have two ways of arriving at the same name.
Straight-chain alkanes are sometimes indicated by the prefix n- (for normal) where a non-linear isomer exists. Although this is not strictly necessary, the usage is still common in cases where there is an important difference in properties between the straight-chain and branched-chain isomers, e.g. n-hexane or 2- or 3-methylpentane.
with elision of any terminal vowel (-a or -o) from the basic numerical term. Hence, pentane, C5H12; hexane, C6H14; heptane, C7H16; octane, C8H18; etc. For a more complete list, see List of alkanes.
Simple branched alkanes often have a common name using a prefix to distinguish them from linear alkanes, for example n-pentane, isopentane, and neopentane.
IUPAC naming conventions can be used to produce a systematic name.
So-called cyclic alkanes are, in the technical sense, not alkanes, but cycloalkanes. They are hydrocarbons just like alkanes, but are containing one or more rings.
Simple cycloalkanes have a prefix "cyclo-" to distinguish them from alkanes. Cycloalkanes are named as per their acyclic counterparts with respect to the number of carbon atoms, e.g. cyclopentane (C5H10) is a cycloalkane with 5 carbon atoms just like pentane (C5H12), but they are joined up in a five-membered ring. In a similar manner, propane and cyclopropane, butane and cyclobutane, etc.
Substituted cycloalkanes are named similar to substituted alkanes — the cycloalkane ring is stated, and the substituents are according to their position on the ring, with the numbering decided by Cahn-Ingold-Prelog rules.
The trivial (non-systematic) name for alkanes is "paraffins." Together, alkanes are known as the paraffin series. Trivial names for compounds are usually historical artifacts. They were coined before the development of systematic names, and have been retained due to familiar usage in industry. Cycloalkanes are also called naphthenes.
It is almost certain that the term paraffin stems from the petrochemical industry. Branched-chain alkanes are called isoparaffins. The use of the term "paraffin" is a general term and often does not distinguish between a pure compounds and mixtures of isomers with the same chemical formula (i.e. like a chemical anagram), e.g. pentane and isopentane.
Alkanes form a significant portion of the atmospheres of the outer gas planets such as Jupiter (0.1% methane, 0.0002% ethane), Saturn (0.2% methane, 0.0005% ethane), Uranus (1.99% methane, 0.00025% ethane) and Neptune (1.5% methane, 1.5 ppm ethane). Titan (1.6% methane), a satellite of Saturn, was examined by the Huygens probe, which indicate that Titan's atmosphere periodically rains liquid methane onto the moon's surface. Also on Titan, a methane-spewing volcano was spotted and this volcanism is believed to be a significant source of the methane in the atmosphere. There also appear to be Methane/Ethane lakes near the north polar regions of Titan, as discovered by Cassini's radar imaging. Methane and ethane have also been detected in the tail of the comet Hyakutake. Chemical analysis showed that the abundances of ethane and methane were roughly equal, which is thought to imply that its ices formed in interstellar space, away from the Sun, which would have evaporated these volatile molecules. Alkanes have also been detected in meteorites such as carbonaceous chondrites.
Traces of methane gas (about 0.0001% or 1 ppm) occur in the Earth's atmosphere, produced primarily by organisms such as Archaea, found for example in the gut of cows.
These hydrocarbons collected in porous rocks, located beneath an impermeable cap rock and so are trapped. Unlike methane, which is constantly reformed in large quantities, higher alkanes (alkanes with 9 or more carbon atoms) rarely develop to a considerable extent in nature. These deposits, e.g. oil fields, have formed over millions of years and once exhausted cannot be readily replaced. The depletion of these hydrocarbons is the basis for what is known as the energy crisis.
Solid alkanes are known as tars and are formed when more volatile alkanes such as gases and oil evaporate from hydrocarbon deposits. One of the largest natural deposits of solid alkanes is in the asphalt lake known as the Pitch Lake in Trinidad and Tobago.
Methane is also present in what is called biogas, produced by animals and decaying matter, which is a possible renewable energy source.
Alkanes have a low solubility in water, so the content in the oceans is negligible; however, at high pressures and low temperatures (such as at the bottom of the oceans), methane can co-crystallize with water to form a solid methane hydrate. Although this cannot be commercially exploited at the present time, the amount of combustible energy of the known methane hydrate fields exceeds the energy content of all the natural gas and oil deposits put together;methane extracted from methane hydrate is considered therefore a candidate for future fuels.
Although alkanes occur in nature in various way, they do not rank biologically among the essential materials. Cycloalkanes with 14 to 18 carbon atoms occur in musk, extracted from deer of the family Moschidae. All further information refers to (acyclic) alkanes.
Certain types of bacteria can metabolise alkanes: they prefer even-numbered carbon chains as they are easier to degrade than odd-numbered chains.
Methanogens are also the producers of marsh gas in wetlands, and release about two billion tonnes of methane per year — the atmospheric content of this gas is produced nearly exclusively by them. The methane output of cattle and other herbivores, which can release up to 150 litres per day, and of termites, is also due to methanogens. They also produce this simplest of all alkanes in the intestines of humans. Methanogenic archaea are, hence, at the end of the carbon cycle, with carbon being released back into the atmosphere after having been fixed by photosynthesis. It is probable that our current deposits of natural gas were formed in a similar way.
Alkanes also play a role, if a minor role, in the biology of the three eukaryotic groups of organisms: fungi, plants and animals. Some specialised yeasts, e.g. Candida tropicale, Pichia sp. Rhodotorula sp. can use alkanes as a source of carbon and/or energy. The fungus Amorphotheca resinae prefers the longer-chain alkanes in aviation fuel, and can cause serious problems for aircraft in tropical regions.
In plants, it is the solid long-chain alkanes that are found; they form a firm layer of wax, the cuticle, over areas of the plant exposed to the air. This protects the plant against water loss, while preventing the leaching of important minerals by the rain. It is also a protection against bacteria, fungi, and harmful insects — the latter sink with their legs into the soft waxlike substance and have difficulty moving. The shining layer on fruits such as apples consists of long-chain alkanes. The carbon chains are usually between twenty and thirty carbon atoms in length and are made by the plants from fatty acids. The exact composition of the layer of wax is not only species-dependent, but changes also with the season and such environmental factors as lighting conditions, temperature or humidity.
acts by smell over longer distances, a useful characteristic for pest control.
which will be dispersed after the departure of the frustrated male to different blooms.
The Fischer-Tropsch process is a method to synthesize liquid hydrocarbons, including alkanes, from carbon monoxide and hydrogen. This method is used to produce substitutes for petroleum distillates.
Alkanes or alkyl groups can also be prepared directly from alkyl halides in the Corey-House-Posner-Whitesides reaction. The Barton-McCombie deoxygenation removes hydroxyl groups from alcohols e.g.
The applications of a certain alkane can be determined quite well according to the number of carbon atoms. The first four alkanes are used mainly for heating and cooking purposes, and in some countries for electricity generation. Methane and ethane are the main components of natural gas; they are normally stored as gases under pressure. It is, however, easier to transport them as liquids: This requires both compression and cooling of the gas.
Propane and butane can be liquefied at fairly low pressures, and are well known as liquified petroleum gas (LPG). Propane, for example, is used in the propane gas burner, butane in disposable cigarette lighters. The two alkanes are used as propellants in aerosol sprays.
From pentane to octane the alkanes are reasonably volatile liquids. They are used as fuels in internal combustion engines, as they vaporise easily on entry into the combustion chamber without forming droplets, which would impair the unifomity of the combustion. Branched-chain alkanes are preferred, as they are much less prone to premature ignition, which causes knocking than their straight-chain homologue. This propensity to premature ignition is measured by the octane rating of the fuel, where 2,2,4-trimethylpentane (isooctane) has an arbitrary value of 100, and heptane has a value of zero. Apart from their use as fuels, the middle alkanes are also good solvents for nonpolar substances.
Alkanes from nonane to, for instance, hexadecane (an alkane with sixteen carbon atoms) are liquids of higher viscosity, less and less suitable for use in gasoline. They form instead the major part of diesel and aviation fuel. Diesel fuels are characterised by their cetane number, cetane being an old name for hexadecane. However, the higher melting points of these alkanes can cause problems at low temperatures and in polar regions, where the fuel becomes too thick to flow correctly.
Alkanes from hexadecane upwards form the most important components of fuel oil and lubricating oil. In latter function, they work at the same time as anti-corrosive agents, as their hydrophobic nature means that water cannot reach the metal surface. Many solid alkanes find use as paraffin wax, for example, in candles. This should not be confused however with true wax, which consists primarily of esters.
Alkanes with a chain length of approximately 35 or more carbon atoms are found in bitumen, used, for example, in road surfacing. However, the higher alkanes have little value and are usually split into lower alkanes by cracking.
Some synthetic polymers such as polyethylene and polypropylene are alkanes with chains containing hundreds of thousands of carbon atoms. These materials are used in innumerable applications, and billions of kilograms of these materials are made and used each year.
Alkanes experience inter-molecular van der Waals forces. Stronger inter-molecular van der Waals forces give rise to greater boiling points of alkanes.
Under standard conditions, from CH4 to C4H10 alkanes are gaseous; from C5H12 to C17H36 they are liquids; and after C18H38 they are solids. As the boiling point of alkanes is primarily determined by weight, it should not be a surprise that the boiling point has almost a linear relationship with the size (molecular weight) of the molecule. As a rule of thumb, the boiling point rises 20 - 30 °C for each carbon added to the chain; this rule applies to other homologous series.
A straight-chain alkane will have a boiling point higher than a branched-chain alkane due to the greater surface area in contact, thus the greater van der Waals forces, between adjacent molecules. For example, compare isobutane and n-butane, which boil at -12 and 0 °C, and 2,2-dimethylbutane and 2,3-dimethylbutane which boil at 50 and 58 °C, respectively. For the latter case, two molecules 2,3-dimethylbutane can "lock" into each other better than the cross-shaped 2,2-dimethylbutane, hence the greater van der Waals forces.
On the other hand, cycloalkanes tend to have higher boiling points than their linear counterparts due to the locked conformations of the molecules, which give a plane of intermolecular contact.
The melting points of the alkanes follow a similar trend to boiling points for the same reason as outlined above. That is, (all other things being equal) the larger the molecule the higher the melting point. There is one significant difference between boiling points and melting points. Solids have more ridged and fixed structure than liquids. This rigid structure requires energy to break down. Thus the stronger better put together solid structures will require more energy to break apart. For alkanes, this can be seen from the graph above (i.e. the blue line). The odd-numbered alkanes have a lower trend in melting points that even numbered alkanes. This is because even numbered alkanes pack well in the solid phase, forming a well-organised structure, which requires more energy to break apart. The odd-number alkanes pack less well and so the "looser" organised solid packing structure requires less energy to break apart.
The melting points of branched-chain alkanes can be either higher or lower than those of the corresponding straight-chain alkanes, again depending on the ability of the alkane in question to packing well in the solid phase: This is particularly true for isoalkanes (2-methyl isomers), which often have melting points higher than those of the linear analogues.
Alkanes do not conduct electricity, nor are they substantially polarized by an electric field. For this reason they do not form hydrogen bonds and are insoluble in polar solvents such as water. Since the hydrogen bonds between individual water molecules are aligned away from an alkane molecule, the coexistence of an alkane and water leads to an increase in molecular order (a reduction in entropy). As there is no significant bonding between water molecules and alkane molecules, the second law of thermodynamics suggests that this reduction in entropy should be minimised by minimising the contact between alkane and water: Alkanes are said to be hydrophobic in that they repel water.
Their solubility in nonpolar solvents is relatively good, a property that is called lipophilicity. Different alkanes are, for example, miscible in all proportions among themselves.
The density of the alkanes usually increases with increasing number of carbon atoms, but remains less than that of water. Hence, alkanes form the upper layer in an alkane-water mixture.
The molecular structure of the alkanes directly affects their physical and chemical characteristics. It is derived from the electron configuration of carbon, which has four valence electrons. The carbon atoms in alkanes are always sp³ hybridised, that is to say that the valence electrons are said to be in four equivalent orbitals derived from the combination of the 2s orbital and the three 2p orbitals. These orbitals, which have identical energies, are arranged spatially in the form of a tetrahedron, the angle of cos−1(−⅓) ≈ 109.47° between them.
An alkane molecule has only C – H and C – C single bonds. The former result from the overlap of a sp³-orbital of carbon with the 1s-orbital of a hydrogen; the latter by the overlap of two sp³-orbitals on different carbon atoms. The bond lengths amount to 1.09×10−10 m for a C – H bond and 1.54×10−10 m for a C – C bond.
The spatial arrangement of the bonds is similar to that of the four sp³-orbitals — they are tetrahedrally arranged, with an angle of 109.47° between them. Structural formulae that represent the bonds as being at right angles to one another, while both common and useful, do not correspond with the reality.
The structural formula and the bond angles are not usually sufficient to completely describe the geometry of a molecule. There is a further degree of freedom for each carbon – carbon bond: the torsion angle between the atoms or groups bound to the atoms at each end of the bond. The spatial arrangement described by the torsion angles of the molecule is known as its conformation.
Ethane forms the simplest case for studying the conformation of alkanes, as there is only one C – C bond. If one looks down the axis of the C – C bond, one will see the so-called Newman projection. The hydrogen atoms on both the front and rear carbon atoms have an angle of 120° between them, resulting from the projection of the base of the tetrahedron onto a flat plane. However, the torsion angle between a given hydrogen atom attached to the front carbon and a given hydrogen atom attached to the rear carbon can vary freely between 0° and 360°. This is a consequence of the free rotation about a carbon – carbon single bond. Despite this apparent freedom, only two limiting conformations are important: eclipsed conformation and staggered conformation.
The two conformations, also known as rotamers, differ in energy: The staggered conformation is 12.6 kJ/mol lower in energy (more stable) than the eclipsed conformation (the least stable).
This difference in energy between the two conformations, known as the torsion energy, is low compared to the thermal energy of an ethane molecule at ambient temperature. There is constant rotation about the C-C bond. The time taken for an ethane molecule to pass from one staggered conformation to the next, equivalent to the rotation of one CH3-group by 120° relative to the other, is of the order of 10−11 seconds.
The case of higher alkanes is more complex but based on similar principles, with the antiperiplanar conformation always being the most favoured around each carbon-carbon bond. For this reason, alkanes are usually shown in a zigzag arrangement in diagrams or in models. The actual structure will always differ somewhat from these idealised forms, as the differences in energy between the conformations are small compared to the thermal energy of the molecules: Alkane molecules have no fixed structural form, whatever the models may suggest.
Virtually all organic compounds contain carbon – carbon and carbon – hydrogen bonds, and so show some of the features of alkanes in their spectra. Alkanes are notable for having no other groups, and therefore for the absence of other characteristic spectroscopic features.
The carbon – hydrogen stretching mode gives a strong absorption between 2850 and 2960 nanometres, while the carbon – carbon stretching mode absorbs between 800 and 1300 nm. The carbon – hydrogen bending modes depend on the nature of the group: methyl groups show bands at 1450 nm and 1375 nm, while methylene groups show bands at 1465 nm and 1450 nm. Carbon chains with more than four carbon atoms show a weak absorption at around 725 nm.
The proton resonances of alkanes are usually found at δH = 0.5 – 1.5. The carbon-13 resonances depend on the number of hydrogen atoms attached to the carbon: δC = 8 – 30 (primary, methyl, -CH3), 15 – 55 (secondary, methylene, -CH2-), 20 – 60 (tertiary, methyne, C-H) and quaternary. The carbon-13 resonance of quaternary carbon atoms is characteristically weak, due to the lack of Nuclear Overhauser effect and the long relaxation time, and can be missed in weak samples, or sample that have not been run for a sufficiently long time.
Alkanes have a high ionisation energy, and the molecular ion is usually weak. The fragmentation pattern can be difficult to interpret, but, in the case of branched chain alkanes, the carbon chain is preferentially cleaved at tertiary or quaternary carbons due to the relative stability of the resulting free radicals. The fragment resulting from the loss of a single methyl group (M−15) is often absent, and other fragment are often spaced by intervals of fourteen mass units, corresponding to sequential loss of CH2-groups.
In general, alkanes show a relatively low reactivity, because their C bonds are relatively stable and cannot be easily broken. Unlike most other organic compounds, they possess no functional groups.
They react only very poorly with ionic or other polar substances. The acid dissociation constant (pKa) values of all alkanes are above 60, hence they are practically inert to acids and bases (see: carbon acids). This inertness is the source of the term paraffins (with the meaning here of "lacking affinity"). In crude oil the alkane molecules have remained chemically unchanged for millions of years.
However redox reactions of alkanes, in particular with oxygen and the halogens, are possible as the carbon atoms are in a strongly-reduced condition; in the case of methane, the lowest possible oxidation state for carbon (−4) is reached. Reaction with oxygen leads to combustion without any smoke; with halogens, substitution. In addition, alkanes have been shown to interact with, and bind to, certain transition metal complexes in (See: carbon-hydrogen bond activation).
Free radicals, molecules with unpaired electrons, play a large role in most reactions of alkanes, such as cracking and reformation where long-chain alkanes are converted into shorter-chain alkanes and straight-chain alkanes into branched-chain isomers.
In highly-branched alkanes, the bond angle may differ significantly from the optimal value (109.5°) in order to allow the different groups sufficient space. This causes a tension in the molecule, known as steric hindrance, and can substantially increase the reactivity.
See the alkane heat of formation table for detailed data.
The standard enthalpy change of combustion, ΔcHo, for alkanes increases by about 650 kJ/mol per CH2 group. Branched-chain alkanes have lower values of ΔcHo than straight-chain alkanes of the same number of carbon atoms, and so can be seen to be somewhat more stable.
Alkanes react with halogens in a so-called free radical halogenation reaction. The hydrogen atoms of the alkane are progressively replaced by halogen atoms. Free-radicals are the reactive species that participate in the reaction, which usually leads to a mixture of products. The reaction is highly exothermic, and can lead to an explosion.
Cracking breaks larger molecules into smaller ones. This can be done with a thermal or catalytic method. The thermal cracking process follows a homolytic mechanism with formation of free-radicals. The catalytic cracking process involves the presence of acid catalysts (usually solid acids such as silica-alumina and zeolites), which promote a heterolytic (asymmetric) breakage of bonds yielding pairs of ions of opposite charges, usually a carbocation and the very unstable hydride anion. Carbon-localized free-radicals and cations are both highly unstable and undergo processes of chain rearrangement, C-C scission in position beta (i.e. cracking) and intra- and intermolecular hydrogen transfer or hydride transfer. In both types of processes, the corresponding reactive intermediates (radicals, ions) are permanently regenerated, and thus they proceed by a self-propagating chain mechanism. The chain of reactions is eventually terminated by radical or ion recombination.
Isomerization and reformation are processes in which straight-chain alkanes are heated in the presence of a platinum catalyst. In isomerization, the alkanes become branched-chain isomers. In reformation, the alkanes become cycloalkanes or aromatic hydrocarbons, giving off hydrogen as a by-product. Both of these processes raise the octane number of the substance.
Alkanes will react with steam in the presence of a nickel catalyst to give hydrogen. Alkanes can by chlorosulfonated and nitrated, although both reactions require special conditions. The fermentation of alkanes to carboxylic acids is of some technical importance. In the Reed reaction, sulfur dioxide, chlorine and light convert hydrocarbons to sulfonyl chlorides.
Methane is explosive when mixed with air (1 – 8% CH4) and is a strong greenhouse gas: Other lower alkanes can also form explosive mixtures with air. The lighter liquid alkanes are highly flammable, although this risk decreases with the length of the carbon chain. Pentane, hexane, heptane, and octane are classed as dangerous for the environment and harmful. The straight-chain isomer of hexane is a neurotoxin, and therefore rarely used commercially.


In law, an appeal is a process for requesting a formal change to an official decision.
The specific procedures for appealing, including even whether there is a right of appeal from a particular type of decision, can vary greatly from country to country. Even within a jurisdiction, the nature of an appeal can vary greatly depending on the type of case.
An appellate court is a court that hears cases on appeal from another court. Depending on the particular legal rules that apply to each circumstance, a party to a court case who is unhappy with the result might be able to challenge that result in an appellate court on specific grounds. These grounds typically could include errors of law, fact, or procedure (in the United States, due process).
In different jurisdictions, appellate courts are also called appeals courts, courts of appeals, superior courts, or supreme courts.
A party who files an appeal is called an appellant or petitioner, and a party on the other side is called a respondent (in most common-law countries) or an appellee (in the United States). A cross-appeal is an appeal brought by the respondent. For example, suppose at trial the judge found for the plaintiff and ordered the defendant to pay $50,000. If the defendant files an appeal arguing that he should not have to pay any money, then the plaintiff might file a cross-appeal arguing that the defendant should have to pay $200,000 instead of $50,000.
The appellant is the party who, having lost part or all their claim in a lower court decision, is appealing to a higher court to have their case reconsidered. This is usually done on the basis that the lower court judge erred in the application of law, but it may also be possible to appeal on the basis of court misconduct, or that a finding of fact was entirely unreasonable to make on the evidence.
The appellant in the new case can be either the plaintiff (or claimant), defendant, or respondent (appellee) from the lower case, depending on who was the losing party. The winning party from the lower court, however, is now the respondent. In unusual cases the appellant can be the victor in the court below, but still appeal. For example, in Doyle v Olby (Ironmongers) Ltd [1969] 2 QB 158, the claimant appealed (successfully) on the basis that, although he won in the court below, the lower court had applied the wrong measure of damages and he had not been fully recompensed.
An appellee is the party to an appeal in which the lower court judgment was in its favor. The appellee is required to respond to the petition, oral arguments, and legal briefs of the appellant. In general, the appellee takes the procedural posture that the lower court's decision should be affirmed.
An appeal as of right is one that is guaranteed by statute or some underlying constitutional or legal principle. The appellate court cannot refuse to listen to the appeal. An appeal by leave or permission requires the appellant to move for leave to appeal; in such a situation either or both of the lower court and the appellate court may have the discretion to grant or refuse the appellant's demand to appeal the lower court's decision.
In tort, equity, or other civil matters either party to a previous case may file an appeal. In criminal matters, however, the state or prosecution generally has no appeal as of right. And due to the double jeopardy principle, the state or prosecution may never appeal a jury or bench verdict. But in some jurisdictions, the state or prosecution may appeal as of right from a trial court's dismissal of an indictment in whole or in part or from a trial court's granting of a defendant's suppression motion. Likewise, in some jurisdictions, the state or prosecution may appeal an issue of law by leave from the trial court and/or the appellate court.
By convention in some law reports, the appellant is named first. This can mean that where it is the defendant who appeals, the name of the case in the law reports reverses (in some cases twice) as the appeals work their way up the court hierarchy. This is not always true, however. In the United States federal courts, the parties names always stay in the same order as the lower court when an appeal is taken to the circuit courts of appeals, and are re-ordered only if the appeal reaches the United States Supreme Court.
Many jurisdictions recognize two types of appeals, particularly in the criminal context. The first is the traditional "direct" appeal in which the appellant files an appeal with the next higher court of review. The second is the collateral appeal or post-conviction petition, in which the petitioner-appellant files the appeal in a court of first instance--usually the court that tried the case.
The key distinguishing factor between direct and collateral appeals is that the former only reviews evidence that was presented in the trial court, but the latter allows review of evidence dehors the record: depositions, affidavits, and witness statements that did not come in at trial. The standard for post-conviction relief is high, typically requiring the petitioner to demonstrate that the evidence presented was not available in the usual course of trial discovery.
Relief in post-conviction is rare and is most often found in capital or violent felony cases. The typical scenario involves an incarcerated defendant locating DNA evidence demonstrating the defendant's actual innocence.
A notice of appeal is a form or document that in many cases is required to begin an appeal. The form is completed by the appellant or by the appellant's legal representative. The nature of this form can vary greatly from country to country and from court to court within a country.
The specific rules of the legal system will dictate exactly how the appeal is officially begun. For example, the appellant might have to file the notice of appeal with the appellate court, or with the court from which the appeal is taken, or both.
Some courts have samples of a notice of appeal on the court's own web site.
The deadline for beginning an appeal can often be very short: traditionally, it is measured in days, not years. This can vary from country to country, as well as within a country, depending on the specific rules in force.
Generally speaking the appellate court examines the record of evidence presented in the trial court and the law that the lower court applied and decides whether that decision was legally sound or not. The appellate court will typically be deferential to the lower court's findings of fact (such as whether a defendant committed a particular act), unless clearly erroneous, and so will focus on the court's application of the law to those facts (such as whether the act found by the court to have occurred fits a legal definition at issue).
If the appellate court finds no defect, it "affirms" the judgment. If the appellate court does find a legal defect in the decision "below" (i.e. in the lower court), it may "modify" the ruling to correct the defect, or it may nullify ("reverse" or "vacate") the whole decision or any part of it. It may, in addition, send the case back ("remand" or "remit") to the lower court for further proceedings to remedy the defect.
In some cases, an appellate court may review a lower court decision de novo (or completely), challenging even the lower court's findings of fact. This might be the proper standard of review, for example, if the lower court resolved the case by granting a pre-trial motion to dismiss or motion for summary judgment which is usually based only upon written submissions to the trial court and not on any trial testimony.
Another situation is where appeal is by way of re-hearing. Certain jurisdictions permit certain appeals to cause the trial to be heard afresh in the appellate court. An example would be an appeal from a Magistrates' court to the Crown Court in England and Wales.
Sometimes, the appellate court finds a defect in the procedure the parties used in filing the appeal and dismisses the appeal without considering its merits, which has the same effect as affirming the judgment below. (This would happen, for example, if the appellant waited too long, under the appellate court's rules, to file the appeal.) In England and many other jurisdictions, however, the phrase appeal dismissed is equivalent to the U.S. term affirmed; and the phrase appeal allowed is equivalent to the U.S. term reversed.
Generally, there is no trial in an appellate court, only consideration of the record of the evidence presented to the trial court and all the pre-trial and trial court proceedings are reviewed — unless the appeal is by way of re-hearing, new evidence will usually only be considered on appeal in very rare instances, for example if that material evidence was unavailable to a party for some very significant reason such as prosecutorial misconduct.
In some systems, an appellate court will only consider the written decision of the lower court, together with any written evidence that was before that court and is relevant to the appeal. In other systems, the appellate court will normally consider the record of the lower court. In those cases the record will first be certified by the lower court.
The appellant has the opportunity to present arguments for the granting of the appeal and the appellee (or respondent) can present arguments against it. Arguments of the parties to the appeal are presented through their appellate lawyers, if represented, or pro se if the party has not engaged legal representation. Those arguments are presented in written briefs and sometimes in oral argument to the court at a hearing. At such hearings each party is allowed a brief presentation at which the appellate judges ask questions based on their review of the record below and the submitted briefs.
It is important to note that in an adversarial system appellate courts do not have the power to review lower court decisions unless a party appeals it. Therefore if a lower court has ruled in an improper manner or against legal precedent that judgment will stand even if it might have been overturned on appeal.
The United States legal system generally recognizes two types of appeals: a trial de novo or an appeal on the record.
A trial de novo is usually available for review of informal proceedings conducted by some minor judicial tribunals in proceedings that do not provide all the procedural attributes of a formal judicial trial. If unchallenged, these decisions have the power to settle more minor legal disputes once and for all. If a party is dissatisfied with the finding of such a tribunal, one generally has the power to request a trial de novo by a court of record. In such a proceeding, all issues and evidence may be developed newly, as though never heard before, and one is not restricted to the evidence heard in the lower proceeding. Sometimes, however, the decision of the lower proceeding is itself admissible as evidence, thus helping to curb frivolous appeals.
In an appeal on the record from a decision in a judicial proceeding, both appellant and respondent are bound to base their arguments wholly on the proceedings and body of evidence as they were presented in the lower tribunal. Each seeks to prove to the higher court that the result they desired was the just result. Precedent and case law figure prominently in the arguments. In order for the appeal to succeed, the appellant must prove that the lower court committed reversible error, that is, an impermissible action by the court acted to cause a result that was unjust, and which would not have resulted had the court acted properly. Some examples of reversible error would be erroneously instructing the jury on the law applicable to the case, permitting seriously improper argument by an attorney, admitting or excluding evidence improperly, acting outside the court's jurisdiction, injecting bias into the proceeding or appearing to do so, juror misconduct, etc. The failure to formally object at the time, to what one views as improper action in the lower court, may result in the affirmance of the lower court's judgment on the grounds that one did not "preserve the issue for appeal" by objecting.
In cases where a judge rather than a jury decided issues of fact, an appellate court will apply an abuse of discretion standard of review. Under this standard, the appellate court gives deference to the lower court's view of the evidence, and reverses its decision only if it were a clear abuse of discretion. This is usually defined as a decision outside the bounds of reasonableness. On the other hand, the appellate court normally gives less deference to a lower court's decision on issues of law, and may reverse if it finds that the lower court applied the wrong legal standard.
In some rare cases, an appellant may successfully argue that the law under which the lower decision was rendered was unconstitutional or otherwise invalid, or may convince the higher court to order a new trial on the basis that evidence earlier sought was concealed or only recently discovered. In the case of new evidence, there must be a high probability that its presence or absence would have made a material difference in the trial. Another issue suitable for appeal in criminal cases is effective assistance of counsel. If a defendant has been convicted and can prove that his lawyer did not adequately handle his case and that there is a reasonable probability that the result of the trial would have been different had the lawyer given competent representation, he is entitled to a new trial.
After an appeal is heard, the mandate is a formal notice of a decision by a court of appeal; this notice is transmitted to the trial court and, when filed by the clerk of the trial court, constitutes the final judgment on the case, unless the appeal court has directed further proceedings in the trial court. The mandate is distinguished from the appeal court's opinion, which sets out the legal reasoning for its decision. In some U.S. jurisdictions the mandate is known as the remittitur.
Appellate review is the general term for the process by which courts with appellate jurisdiction take jurisdiction of matters decided by lower courts. It is distinguished from judicial review, which refers to the court's overriding constitutional or statutory right to determine if a legislative act or administrative decision is defective for jurisdictional or other reasons (which may vary by jurisdiction).
In most jurisdictions the normal and preferred way of seeking appellate review is by filing an appeal of the final judgment. Generally, an appeal of the judgment will also allow appeal of all other orders or rulings made by the trial court in the course of the case. This is because such orders cannot be appealed as of right. However, certain critical interlocutory court orders, such as the denial of a request for an interim injunction, or an order holding a person in contempt of court, can be appealed immediately although the case may otherwise not have been fully disposed of.
In American law, there are two distinct forms of appellate review, direct and collateral. For example, a criminal defendant may be convicted in state court, and lose on direct appeal to higher state appellate courts, and if unsuccessful, mount a collateral action such as filing for a writ of habeas corpus in the Federal courts. Generally speaking, "[d]irect appeal statutes afford defendants the opportunity to challenge the merits of a judgment and allege errors of law or fact.. [Collateral review], on the other hand, provide[s] an independent and civil inquiry into the validity of a conviction and sentence, and as such are generally limited to challenges to constitutional, jurisdictional, or other fundamental violations that occurred at trial." Graham v. Borgen, __ F 3d. __ (7th Cir. 2007) (no. 04-4103) (slip op. at 7) (citation omitted).
In Anglo-American common law courts, appellate review of lower court decisions may also be obtained by filing a petition for review by prerogative writ in certain cases. There is no corresponding right to a writ in any pure or continental civil law legal systems, though some mixed system such as Quebec recognize these prerogative writs.


An answer (derived from and, against, and the same root as swear) was originally a solemn assertion in opposition to some one or something, and thus generally any counter-statement or defence, a reply to a question or objection, or a correct solution of a problem. In the common law, an answer is the first pleading by a defendant, usually filed and served upon the plaintiff within a certain strict time limit after a civil complaint or criminal information or indictment has been served upon the defendant. It may have been preceded by an optional "pre-answer" motion to dismiss or demurrer; if such a motion is unsuccessful, the defendant must file an answer to the complaint or risk an adverse default judgment.
The answer establishes which allegations (cause of action in civil matters) set forth by the complaining party will be contested by the defendant, and states all the defendant's defenses, thus establishing the nature and parameters of the controversy to be decided by the court.
In the case of a criminal case there is usually an arraignment or some other kind of appearance before the court by the defendant. The pleading in the criminal case, which is entered on the record in open court, is either guilty or not guilty. Generally speaking in private, civil cases there is no guilt or innocence. There is only a judgment that grants money damages or some other kind of equitable remedy such as restitution or an injunction. Criminal cases may lead to fines or other punishment, such as imprisonment.
The famous Latin Responsa Prudentium ("answers of the learned ones") were the accumulated views of many successive generations of Roman lawyers, a body of legal opinion which gradually became authoritative.
In music an "answer" (also known as countersubject) is the technical name in counterpoint for the repetition or modification by one part or instrument of a theme proposed by another.
Generally, an answer is a reply to a questions, a solution, retaliation, or response.

An appellate court is any court of law that is empowered to hear an appeal of a trial court or other lower tribunal. In most jurisdictions, the court system is divided into at least three levels: the trial court, which initially hears cases and reviews evidence and testimony to determine the facts of the case; at least one intermediate appellate court; and a supreme court or court of last resort which primarily reviews the decisions of the intermediate courts. A supreme court is therefore itself a kind of appellate court.
Many jurisdictions title their appellate court a Court of Appeal or Court of Appeals. Historically, others have titled their appellate court a Court of Errors (or Court of Errors and Appeals), on the premise that it was intended to correct errors made by lower courts. Examples of such courts include the New Jersey Court of Errors and Appeals (which existed from 1844 to 1947) and the Connecticut Supreme Court of Errors (which has been renamed the Connecticut Supreme Court). In some jurisdictions, courts able to hear appeals are known as an Appellate Division.
Depending on the system, certain courts may serve as both trial courts and appellate courts, hearing appeals of decisions made by courts with more limited jurisdiction. Some jurisdictions have specialized appellate courts, such as the Texas Court of Criminal Appeals, which only hears appeals raised in criminal cases.
The authority of appellate courts to review a decisions of lower courts varies widely from one jurisdication to another. In some places, the appellate court has limited powers of review. For example, in the United States, both state and federal appellate courts are usually restricted to examining whether the court below made the correct legal determinations, rather than hearing direct evidence and determining what the facts of the case were. Furthermore, U.S. appellate courts are usually restricted to hearing appeals based on matters that were originally brought up before the trial court. Hence, such an appellate court will not consider an appellant's argument if it is based on a theory that is raised for the first time in the appeal.


Arraignment is a common law term for the formal reading of a criminal complaint, in the presence of the defendant, to inform him/her of the charges against him or her. In response to arraignment, the accused is expected to enter a plea. Acceptable pleas vary from jurisdiction to jurisdiction, but they generally include "guilty", "not guilty", and the peremptory pleas (or pleas in bar), which set out reasons why a trial cannot proceed. In addition, US jurisdictions allow pleas of "nolo contendere" (no contest) and the "Alford plea" in some circumstances.
In England, Wales and Northern Ireland, arraignment is the first of eleven stages in a criminal trial, and involves the clerk of the court reading out the indictment. The defendant is asked whether they plead guilty or not guilty to each individual charge.
If the defendant pleads guilty an evidentiary hearing usually follows. The court is not required to accept a guilty plea. During that hearing the judge will assess the offense, mitigating factors, and the defendant's character; and then pass sentence. If the defendant pleads not guilty, a date will be set for a preliminary hearing or trial.
In the past, a defendant who refused to plead (or "stood mute") would be subject to peine forte et dure (Law French for "strong and hard punishment"). But today in all common law jurisdictions, defendants who refuse to enter a plea will have a plea of not guilty entered for them on their behalf.


"America the Beautiful" is an American patriotic song.
On that mountain, the words of the poem started to come to her, and she wrote them down upon returning to her hotel room at the original Antlers Hotel. The poem was initially published two years later in The Congregationalist, to commemorate the Fourth of July. It quickly caught the public's fancy. Amended versions were published in 1904 and 1913.
Several existing pieces of music were adapted to the poem. The Hymn tune composed in 1882 by Samuel A. Ward, was generally considered the best music as early as 1910 and is still the popular tune today. Ward had been similarly inspired. The tune came to him while he was on a ferryboat trip from Coney Island back to his home in New York City after a leisurely summer day, and he immediately wrote it down. Ward died in 1903, not knowing the national stature his music would attain. Miss Bates was more fortunate, as the song's popularity was well-established by her death in 1929.
At various times in the more than 100 years that have elapsed since the song as we know it was born, particularly during the John F. Kennedy administration, there have been efforts to give "America the Beautiful" legal status either as a national hymn, or as a national anthem equal to, or in place of, "The Star-Spangled Banner", but so far this has not succeeded. Proponents prefer "America the Beautiful" for various reasons, saying it is easier to sing, more melodic, and more adaptable to new orchestrations while still remaining as easily recognizable as "The Star-Spangled Banner." Some prefer "America the Beautiful" over "The Star-Spangled Banner" due to the latter's war-oriented imagery. (Others prefer "The Star-Spangled Banner" for the same reason.) While that national dichotomy has stymied any effort at changing the tradition of the national anthem, "America the Beautiful" continues to be held in high esteem by a large number of Americans.
Popularity of the song increased greatly following the September 11, 2001 attacks; at some sporting events it was sung in addition to the traditional singing of the national anthem. During the first taping of the Late Show with David Letterman following the attacks, CBS newsman Dan Rather cried briefly as he quoted the fourth verse.
Ray Charles is credited with the song's most well known rendition in current times (although Elvis Presley had a good success with it in the 1970s). His recording is very commonly played at major sporting events, such as the Super Bowl; Charles gave a live performance of the song prior to Super Bowl XXXV, the last Super Bowl played before the September 11 terrorist attacks. His unique take on it places the third verse first, after which he sings the usual first verse. In the third verse (see below), the author scolds the materialistic and self-serving robber barons of her day, and urges America to live up to its noble ideals and to honor, with both word and deed, the memory of those who died for their country. Symbolically, Marian Anderson (a noted opera singer of her day) sang a rendition of America on the steps of the Lincoln Memorial in 1939 after being refused use of Constitution Hall by the Daughters of the American Revolution because of her skin color.
It is often included in songbooks in a wide variety of religious congregations in the United States.
It has also become a tradition for the song to be performed at the start of the WWE event WrestleMania. Such artists to perform the song at the event include Ray Charles, Aretha Franklin, Gladys Knight, Reba McEntire, Little Richard, Boyz II Men, Ashanti, The Boys Choir of Harlem, Mariah Carey, Lilian Garcia and Michelle Williams.
"From sea to shining sea" is an American idiom meaning from the Pacific Ocean to the Atlantic Ocean (or vice versa). Many songs have used this term, including the American patriotic songs "America, The Beautiful" and "God Bless the USA". In addition to these, it is also featured in Schoolhouse Rock's "Elbow Room". Although the United States has borders with the Arctic Ocean and the Gulf of Mexico, the phrase refers only to the West and East coasts of the Continental U.S. A term similar to this is the Canadian motto A Mari Usque Ad Mare ("From sea to sea.") See also Manifest Destiny.
Note: some sources omit the second verse, and substitute its refrain for that of the fourth verse.

An artificial language is a language created by a person or a group of people for a certain purpose, usually when this purpose is hard to achieve by using a natural language.

Assistive technology is a generic term that includes assistive, adaptive, and rehabilitative devices and the process used in selecting, locating, and using them. AT promotes greater independence for people with disabilities by enabling them to perform tasks that they were formerly unable to accomplish, or had great difficulty accomplishing, by providing enhancements to or changed methods of interacting with the technology needed to accomplish such tasks. Although, Cook & Hussey (2001) report this term is usually not used for rehabilitative devices and for devices that able-bodied find useful. According to disability advocates, technology is often created without regard to people with disabilities, creating unnecessary barriers to hundreds of millions of people.
Universal (or broadened) accessibility, or universal design means greater usability, particularly for people with disabilities. But universally accessible technology yields great rewards to the typical user as well; good accessible design is universal design. One example is the "curb cuts" (or dropped curbs) in the sidewalk at street crossings. While these curb cuts enable pedestrians with mobility impairments to cross the street, these also aid parents with carriages and strollers, shoppers with carts, and travellers and workers with pull-type bags.
As an example, the modern telephone is inaccessible to people who are deaf or hard of hearing. Combined with a text telephone (also known as a TDD Telecommunications device for the deaf and in the USA generally called a TTY[TeleTYpewriter]), which converts typed characters into tones that may be sent over the telephone line, a deaf person is able to communicate immediately at a distance. Together with "relay" services, in which an operator reads what the deaf person types and types what a hearing person says, the deaf person is then given access to everyone's telephone, not just those of people who possess text telephones. Many telephones now have volume controls, which are primarily intended for the benefit of people who are hard of hearing, but can be useful for all users at times and places where there is significant background noise. Some have larger keys well-spaced to facilitate accurate dialling.
Also, a person with a mobility impairment can have difficulty using calculators. Speech recognition software could recognize short commands and make use of calculators easier.
Toys which have been adapted to be used by children with disabilities may have advantages for "typical" children as well. The Lekotek movement assists parents by lending assistive technology toys and expertise to families.
Telecare is a particular sort of assistive technology that uses electronic sensors connected to an alarm system to help caregivers manage risk and help vulnerable people stay independent at home longer. An example would be the systems being put in place for senior people such as fall detectors, thermometers (for hypothermia risk), flooding and unlit gas sensors (for people with mild dementia). Notably, these alerts can be customized to the particular person's risks. When the alert is triggered, a message is sent to a carer or contact centre who can respond appropriately.
Technology similar to Telecare can also be used to act within a person's home rather than just to respond to a detected crisis. Using one of the examples above, unlit gas sensors for people with dementia can be used to trigger a device that turns off the gas and tells someone what has happened.
Designing for people with dementia is a good example of how the design of the interface of a piece of AT is critical to its usefulness. People with dementia or any other identified user group must be involved in the design process to make sure that the design is accessible and usable. In the example above, a voice message could be used to remind the person with dementia to turn off the gas himself, but whose voice should be used, and what should the message say? Questions like these must be answered through user consultation, involvement and evaluation.
Sitting at a desk with a QWERTY keyboard and a mouse remains the dominant way of interacting with a personal computer. Some AT reduces the strain of this way of work through ergonomic accessories with height-adjustable furniture, footrests, wrist rests, and arm supports to ensure correct posture. Keyguards fits over the keyboard to help prevent unintentional keypresses.
More ambitiously, and quite crucially when keyboard or mouse prove unusable, AT can also replace the keyboard and mouse with alternative devices: trackballs, joysticks, graphics tablets, touchpads, touch screens, a microphone with speech recognition software, sip-and-puff input, and switch access.
Choice of appropriate hardware and software will depend on the user's level of functional vision.
Augmentative and alternative communication is a well defined specialty within AT.


An abacus (plurals abacuses or abaci), also called a counting frame, is a calculating tool for performing arithmetic processes. Nowadays, abaci are often constructed as a wooden frame with beads sliding on wires, but originally they were beads or stones moved in grooves in sand or on tablets of wood, stone, or metal. The abacus was in use centuries before the adoption of the written modern numeral system and is still widely used by merchants and clerks in China, Japan, Africa, India and elsewhere.
The user of an abacus is called an abacist; he or she slides the beads of the abacus by hand.
The first abacus was almost certainly based on a flat stone covered with sand or dust. Words and letters were drawn in the sand; eventually numbers were added and pebbles used to aid calculations. The Babylonians used this dust abacus as early as 2400 BC. The origin of the counter abacus with strings is obscure, but India, Mesopotamia or Egypt are seen as probable points of origin. China played an essential part in the development and evolution of the abacus.
From this, a variety of abaci were developed; the most popular were based on the bi-quinary system, using a combination of two bases (base-2 and base-5) to represent decimal numbers. But the earliest abaci used first in Mesopotamia and later by scribes in Egypt and Greece used sexagesimal numbers represented with factors of 5, 2, 3, and 2 for each digit.
The use of the word abacus dates from before 1387, when a Middle English work borrowed the word from Latin to describe a sandboard abacus. The Latin word came from abakos, the Greek genitive form of abax ("calculating-table"). Because abax also had the sense of "table sprinkled with sand or dust, used for drawing geometric figures", some linguists speculate that the Greek word may be derived from a Semitic root (cf. Phoenician abak, "sand", Hebrew ābāq (pronounced "a-vak"), "dust"). The preferred plural of abacus is a subject of disagreement, but both abacuses and abaci are in use.
Babylonians may have used the abacus for the operations of addition and subtraction. However, this primitive device proved difficult to use for more complex calculations. Some scholars point to a character from the Babylonian cuneiform which may have been derived from a representation of the abacus.
The use of the abacus in ancient Egypt is mentioned by the Greek historian Crabertotous, who writes that the manner of this disk's usage by the Egyptians was opposite in direction when compared with the Greek method. Archaeologists have found ancient disks of various sizes that are thought to have been used as counters. However, wall depictions of this instrument have not been discovered, casting some doubt over the extent to which this instrument was used.
A tablet found on the Greek island Salamis in 1846 dates back to 300 BC, making it the oldest counting board discovered so far. It is a slab of white marble 149 cm long, 75 cm wide, and 4.5 cm thick, on which are 5 groups of markings. In the center of the tablet is a set of 5 parallel lines equally divided by a vertical line, capped with a semi-circle at the intersection of the bottom-most horizontal line and the single vertical line. Below these lines is a wide space with a horizontal crack dividing it. Below this crack is another group of eleven parallel lines, again divided into two sections by a line perpendicular to them, but with the semi-circle at the top of the intersection; the third, sixth and ninth of these lines are marked with a cross where they intersect with the vertical line.
The normal method of calculation in ancient Rome, as in Greece, was by moving counters on a smooth table. Originally pebbles, calculi, were used. Later, and in medieval Europe, jetons were manufactured. Marked lines indicated units, fives, tens etc. as in the Roman numeral system. This system of 'counter casting' continued into the late Roman empire and in medieval Europe, and persisted in limited use into the nineteenth century.
In addition to the more common method using loose counters, several specimens have been found of a Roman abacus, shown here in reconstruction. It has eight long grooves containing up to five beads in each and eight shorter grooves having either one or no beads in each.
The groove marked I indicates units, X tens, and so on up to millions. The beads in the shorter grooves denote fives—five units, five tens etc. essentially in a bi-quinary coded decimal system, obviously related to the Roman numerals. The short grooves on the right may have been used for marking Roman ounces.
1st century sources, such as the Abhidharmakosa describe the knowledge and use of abacus in India. Around the 5th century, Indian clerks were already finding new ways of recording the contents of the Abacus. Hindu texts used the term shunya(means Zero) to indicate the empty column on the abacus.
The earliest mention of a suanpan is found in a First Century book of the Eastern Han Dynasty, namely Supplementary Notes on the Art of Figures written by Xu Yue. However, the exact design of this suanpan is not known.
Usually, a suanpan is about 20 cm tall and it comes in various widths depending on the operator. It usually has more than seven rods. There are two beads on each rod in the upper deck and five beads each in the bottom for both decimal and hexadecimal computation. Modern abacuses have one bead on the top deck and four beads on the bottom deck. The beads are usually rounded and made of a hardwood. The beads are counted by moving them up or down towards the beam. If you move them high, you count their value. If you move them down, you don't count their value. The suanpan can be reset to the starting position instantly by a quick jerk along the horizontal axis to spin all the beads away from the horizontal beam at the center.
Suanpans can be used for functions other than counting. Unlike the simple counting board used in elementary schools, very efficient suanpan techniques have been developed to do multiplication, division, addition, subtraction, square root and cube root operations at high speed.
In the famous long scroll Riverside Scenes at Qingming Festival painted by Zhang Zeduan (1085-1145) during the Song Dynasty (960-1297), a suanpan is clearly seen lying beside an account book and doctor's prescriptions on the counter of an apothecary's (Feibao).
The similarity of the Roman abacus to the Chinese one suggests that one could have inspired the other, as there is some evidence of a trade relationship between the Roman Empire and China. However, no direct connection can be demonstrated, and the similarity of the abaci may be coincidental, both ultimately arising from counting with five fingers per hand. Where the Roman model (like most modern Japanese) has 4 plus 1 bead per decimal place, the standard suanpan has 5 plus 2, allowing less challenging arithmetic algorithms, and also allowing use with a hexadecimal numeral system. Instead of running on wires as in the Chinese and Japanese models, the beads of Roman model run in groves, presumably making arithmetic calculations much slower.
Another possible source of the suanpan is Chinese counting rods, which operated with a decimal system but lacked the concept of zero as a place holder. The zero was probably introduced to the Chinese in the Tang Dynasty (618-907) when travel in the Indian Ocean and the Middle East would have provided direct contact with India and Islam allowing them to acquire the concept of zero and the decimal point from Indian and Islamic merchants and mathematicians.
The Chinese abacus migrated from China to Korea around the year 1400. Koreans call it jupan (주판), supan (수판) or jusan (주산).
A soroban (算盤, そろばん, lit. "Counting tray") is a Japanese-modified version of the Chinese abacus. It is devised from the suanpan, imported from China to Japan before 16th century. However, accurate transmission age and the route are uncertain because there is no specific record. Like the suanpan, the soroban is still used in Japan today, even with the proliferation, practicality, and affordability of pocket electronic calculators.
Korea also has its own called the supan (수판), which is basically the soroban before it took its modern form in the 1930s. The modern soroban also goes by this Korean name.
Some sources mention the use of an abacus called a nepohualtzintzin in ancient Aztec culture. This Mesoamerican abacus used a 5-digit base-20 system.
The quipu of the Incas was a system of knotted cords used to record numerical data, like advanced tally sticks—but not used to perform calculations. Calculations were carried out using a yupana (quechua for "counting tool"; see figure) which was still in use after the conquest of Peru. The working principle of a yupana is unknown, but in 2001 an explanation of the mathematical basis of these instruments was proposed. By comparing the form of several yupanas, researchers found that calculations were based using the Fibonacci sequence 1,1,2,3,5 and powers of 10, 20 and 40 as place values for the different fields in the instrument. Using the Fibonacci sequence would keep the number of grains within any one field at minimum.
The Russian abacus, the schoty (счёты), usually has a single slanted deck, with ten beads on each wire (except one wire which has four beads, for quarter-ruble fractions). This wire is usually near the user. (Older models have another 4-bead wire for quarter-kopeks, which were minted until 1916.) The Russian abacus is often used vertically, with wires from left to right in the manner of a book. The wires are usually bowed to bulge upward in the center, in order to keep the beads pinned to either of the two sides. It is cleared when all the beads are moved to the right. During manipulation, beads are moved to the left. For easy viewing, the middle 2 beads on each wire (the 5th and 6th bead) usually have a colour different from the other 8 beads. Likewise, the left bead of the thousands wire (and the million wire, if present) may have a different color.
The Russian abacus was in use in all shops and markets throughout the former Soviet Union, and the usage of it was taught in most schools till 1990s.
Today it is regarded as an archaism and replaced by microcalculator. In school the usage of calculator is taught since 1990s.
Around the world, abaci have been used in pre-schools and elementary schools as an aid in teaching the numeral system and arithmetic. In Western countries, a bead frame similar to the Russian abacus but with straight wires and a vertical frame has been common (see image). It is still often seen as a plastic or wooden toy.
The type of abacus shown here is often used to represent numbers without the use of place value. Each bead and each wire has the same value and used in this way it can represent numbers up to 100.
The most significant educational advantage of using an abacus, rather than loose beads or counters, when practicing counting and simple addition is that it gives the student an awareness of the groupings of 10 which are the foundation of our number system. Although adults take this base 10 structure for granted, it is actually difficult to learn. Many 6-year-olds can count to 100 by rote with only a slight awareness of the patterns involved.
An adapted abacus, invented by Helen Keller, called a Cranmer abacus is still commonly used by individuals who are blind. A piece of soft fabric or rubber is placed behind the beads so that they do not move inadvertently. This keeps the beads in place while the users feel or manipulate them. They use an abacus to perform the mathematical functions multiplication, division, addition, subtraction, square root and cubic root.
Although blind students have benefited from talking calculators, the abacus is still very often taught to these students in early grades, both in public schools and state schools for the blind. The abacus teaches math skills that can never be replaced with talking calculators and is an important learning tool for blind students. Blind students also complete math assignments using a braille-writer and Nemeth code (a type of braille code for math) but large multiplication and long division problems can be long and difficult. The abacus gives blind and visually impaired students a tool to compute math problems that equals the speed and mathematical knowledge required by their sighted peers using pencil and paper. Many blind people find this number machine a very useful tool throughout life.


An acid (often represented by the generic formula HA [H+A-]) is traditionally considered any chemical compound that, when dissolved in water, gives a solution with a hydrogen ion activity greater than in pure water, i.e. a pH less than 7.0. That approximates the modern definition of Johannes Nicolaus Brønsted and Martin Lowry, who independently defined an acid as a compound which donates a hydrogen ion (H+) to another compound (called a base). Common examples include acetic acid (in vinegar) and sulfuric acid (used in car batteries). Acid/base systems are different from redox reactions in that there is no change in oxidation state.
Although not the most general theory, the Brønsted-Lowry definition is the most widely used definition. The strength of an acid may be understood by this definition by the stability of hydronium and the solvated conjugate base upon dissociation. Increasing or decreasing stability of the conjugate base will increase or decrease the acidity of a compound. This concept of acidity is used frequently for organic acids such as carboxylic acid. The molecular orbital description, where the unfilled proton orbital overlaps with a lone pair, is connected to the Lewis definition.
Strong acids and many concentrated acids are dangerous, causing severe burns for even minor contact. Acids are corrosive. Generally, acid burns are treated by rinsing the affected area abundantly with running water (15 minutes) and followed up with immediate medical attention. In the case of highly concentrated acids, the acid should first be wiped off as much as possible, otherwise the exothermic mixing of the acid and the water could cause severe thermal burns. Acids may also be dangerous for reasons not related to their acidity, see an appropriate MSDS for more detailed information.
In the classical naming system, acids are named according to their anions. That ionic suffix is dropped and replaced with a new suffix (and sometimes prefix), according to the table below. For example, HCl has chloride as its anion, so the -ide suffix makes it take the form hydrochloric acid. In the IUPAC naming system, "aqueous" is simply added to the name of the ionic compound. Thus, for hydrogen chloride, the IUPAC name would be aqueous hydrogen chloride.
Strong acids have large Ka values (i.e. the reaction equilibrium lies far to the right; the acid is almost completely dissociated to H3O+ and A-). Strong acids include the heavier hydrohalic acids: hydrochloric acid (HCl), hydrobromic acid (HBr), and hydroiodic acid (HI). (However, hydrofluoric acid, HF, is relatively weak.) For example, the Ka value for hydrochloric acid (HCl) is 107.
Weak acids have small Ka values (i.e. at equilibrium significant amounts of HA and A− exist together in solution; modest levels of H3O+ are present; the acid is only partially dissociated). For example, the Ka value for acetic acid is 1.8 x 10-5. Most organic acids are weak acids. Oxoacids, which tend to contain central atoms in high oxidation states surrounded by oxygen may be quite strong or weak. Nitric acid, sulfuric acid, and perchloric acid are all strong acids, whereas nitrous acid, sulfurous acid and hypochlorous acid are all weak.
Polyprotic acids are able to donate more than one proton per acid molecule, in contrast to monoprotic acids that only donate one proton per molecule. Specific types of polyprotic acids have more specific names, such as diprotic acid (two potential protons to donate) and triprotic acid (three potential protons to donate).
A diprotic acid (here symbolized by H2A) can undergo one or two dissociations depending on the pH. Each dissociation has its own dissociation constant, Ka1 and Ka2.
The first dissociation constant is typically greater than the second; i.e. Ka1 > Ka2. For example, sulfuric acid (H2SO4) can donate one proton to form the bisulfate anion (HSO4−), for which Ka1 is very large; then it can donate a second proton to form the sulfate anion (SO42−), wherein the Ka2 is intermediate strength. The large Ka1 for the first dissociation makes sulfuric a strong acid. In a similar manner, the weak unstable carbonic acid (H2CO3) can lose one proton to form bicarbonate anion (HCO3−) and lose a second to form carbonate anion (CO32−). Both Ka values are small, but Ka1 > Ka2.
A triprotic acid (H3A) can undergo one, two, or three dissociations and has three dissociation constants, where Ka1 > Ka2 > Ka3.
An inorganic example of a triprotic acid is orthophosphoric acid (H3PO4), usually just called phosphoric acid. All three protons can be successively lost to yield H2PO4−, then HPO42−, and finally PO43−, the orthophosphate ion, usually just called phosphate. An organic example of a triprotic acid is citric acid, which can successively lose three protons to finally form the citrate ion. Even though the positions of the protons on the original molecule may be equivalent, the successive Ka values will differ since it is energetically less favorable to lose a proton if the conjugate base is more negatively charged.
Neutralization is the basis of titration, where a pH indicator shows equivalence point when the equivalent number of moles of a base have been added to an acid. It is often wrongly assumed that neutralization should result in a solution with pH 7.0, which is only the case with similar acid and base strengths during a reaction.
Neutralization with a base weaker than the acid results in a weakly acidic salt. An example is the weakly acidic ammonium chloride, which is produced from the strong acid hydrogen chloride and the weak base ammonia. Conversely, neutralizing a weak acid with a strong base gives a weakly basic salt, e.g. sodium fluoride from hydrogen fluoride and sodium hydroxide.
In order to lose a proton, it is necessary that the pH of the system rise above the pKa of the protonated acid. The decreased concentration of H+ in that basic solution shifts the equilibrium towards the conjugate base form (the deprotonated form of the acid). In lower-pH (more acidic) solutions, there is a high enough H+ concentration in the solution to cause the acid to remain in its protonated form, or to protonate its conjugate base (the deprotonated form).
Solutions of weak acids and salts of their conjugate bases form buffer solutions.
There are numerous uses for acids. Acids are often used to remove rust and other corrosion from metals in a process known as pickling. They may be used as an electrolyte in a wet cell battery, such as sulfuric acid in a car battery. In humans and many other animals, hydrochloric acid is a part of the gastric acid secreted within the stomach to help hydrolyze proteins and polysaccharides, as well as converting the inactive pro-enzyme, pepsinogen into the enzyme, pepsin. Acids are used as catalysts; for example, sulfuric acid is used in very large quantities in the alkylation process to produce gasoline.


Asphalt is a sticky, black and highly viscous liquid or semi-solid that is present in most crude petroleums and in some natural deposits sometimes termed asphaltum. It is most commonly modeled as a colloid, with asphaltenes as the dispersed phase and maltenes as the continuous phase (though there is some disagreement amongst chemists regarding its structure). In U.S. terminology, asphalt (or asphalt cement) is the carefully refined residue from the distillation process of selected crude oils. Outside North America, the product is called bitumen.
The primary use of asphalt (Bitumen) is in road construction, where it is used as the glue or binder for the aggregate particles. The road surfacing material is usually called 'asphalt concrete' in North America or simply 'asphalt' elsewhere. The apparent interchangeability of the words 'asphalt' and 'bitumen' causes confusion outside of the road construction industry despite quite clear definitions within industry circles.
Asphalt or bitumen can sometimes be confused with tar, which is a similar black thermo-plastic material produced by the destructive distillation of coal. During the early and mid twentieth century when town gas was produced, tar was a readily available product and extensively used as the binder for road aggregates. The addition of tar to macadam roads led to the word tarmac, which is now used in common parlance to refer to road making materials. However, since the 1970s, when natural gas succeeded town gas, asphalt (bitumen) has completely overtaken the use of tar in these applications.
Asphalt can be separated from the other components in crude oil (such as naphtha, gasoline and diesel) by the process of fractional distillation, usually under vacuum conditions. A better separation can be achieved by further processing of the heavier fractions of the crude oil in a de-asphalting unit, which uses either propane or butane in a supercritical phase to dissolve the lighter molecules which are then separated. Further processing is possible by "blowing" the product: namely reacting it with oxygen. This makes the product harder and more viscous.
Natural deposits of asphalt include lake asphalts (primarily from the Pitch Lake in Trinidad and Tobago and Bermudez Lake in Venezuela), Gilsonite, the Dead Sea between Israel & Jordan, and Tar Sands.
Asphalt is typically stored and transported at temperatures around 150 degrees Celsius (300 °F). Sometimes diesel oil or kerosene are mixed in before shipping to retain liquidity; upon delivery, these lighter materials are separated out of the mixture. This mixture is often called bitumen feedstock, or BFS. Some dump trucks route the hot engine exhaust through pipes in the dump body to keep the material warm. The backs of tippers carrying asphalt, as well as some handling equipment, are also commonly sprayed with a releasing agent before filling to aid release. Diesel oil is sometimes used as a release agent, although it can mix with and thereby reduce the quality of the asphalt.
In the ancient Middle East, natural asphalt deposits were used for mortar between bricks and stones, ship caulking, and waterproofing. The Persian word for asphalt is mumiya, which may be related to the English word mummy. Asphalt was also used by ancient Egyptians to embalm mummies.
In the ancient Far East, natural asphalt was slowly boiled to get rid of the higher fractions, leaving a material of higher molecular weight which is thermoplastic and when layered on objects, became quite hard upon cooling. This was used to cover scabbards and other objects that needed water-proofing. Statuettes of household deities were also cast with this type of material in Japan, and probably also in China.
Poured bitumen has also been used as a damp-proof course in building.
The largest use of asphalt is for making asphalt concrete for road surfaces and accounts for approximately 80% of the asphalt consumed in the United States. Roofing shingles account for most of the remaining asphalt consumption. Other uses include cattle sprays, fence post treatments, and waterproofing for fabrics.
Asphalt road surface is the most widely recycled material in the US, both by gross tonnage and by percentage. According to a report issued by the Federal Highway Administration and the United States Environmental Protection Agency, 80% of the asphalt from road surfaces' that is removed each year during widening and resurfacing projects is reused as part of new roads, roadbeds, shoulders and embankments.
Mastic asphalt is a type of asphalt which differs from dense graded asphalt (asphalt concrete) in that it has a higher bitumen (binder) content, usually around 7-10% of the whole aggregate mix, as opposed to roller asphalt, which has only around 5% added bitumen. Another asphalt which is fast gaining global popularity is stone mastic asphalt (SMA). SMA's advantages over rolled asphalt is its high anti skid qualities due to its high aggregate density and the lack of void content (air pockets). Another advantage of SMA is its longer durability over alternative road asphalt surfaces, but its manufacture and application, if not controlled closely, can result in slippery road surfaces due to excess bitumen pooling (bleeding) onto the surface.
A number of technologies allow asphalt to be mixed at much lower temperatures. These involve mixing the asphalt with petroleum solvents to form "cutbacks" with reduced melting point or mixtures with water to turn the asphalt into an emulsion. Asphalt emulsions contain up to 70% asphalt and typically less than 1.5% chemical additives. There are two main types of emulsions with different affinity for aggregates, cationic and anionic. Asphalt emulsions are used in a wide variety of applications. Chipseal involves spraying the road surface with asphalt emulsion followed by a layer of crushed rock or gravel. Slurry Seal involves the creation of a mixture of asphalt emulsion and fine crushed aggregate that is spread on the surface of a road. Cold mixed asphalt can also be made from asphalt emulsion to create pavements similar to hot-mixed asphalt, several inches in depth and asphalt emulsions are also blended into recycled hot-mix asphalt to create low cost pavements.
Sometimes asphalt can be mixed with the output from low-temperature thermal desorption.
The world has become increasingly concerned over the global climate change problem in recent years due to the pollution that is released into the atmosphere. Most of the emissions are derived primarily from burning fossil fuels. This has led to the introduction of bitumen alternatives that are more environmentally friendly and non toxic. Bitumen can now be made from non-petroleum based renewable resources such as sugar, molasses and rice, corn and potato starches etc. To further help the environment bitumen can also be made from the waste material vacuum tower bottoms produced in the process of cleaning used motor oils which helps the recycling industries, this waste is normally disposed by burning or dumping into land fills.
These new non-petroleum based bitumen binders can be colored, which thereby help reduce the temperatures of road surfaces which contribute to the Urban heat island which in turn contributes to global climate change.
For millions of people living in and around cities, heat islands are of growing concern. This phenomenon describes urban and suburban temperatures that are 2 to 10°F (1 to 6°C) hotter than nearby rural areas Elevated temperatures can impact communities by increasing peak energy demand, air conditioning costs, air pollution levels, and heat-related illness and mortality. Fortunately, there are common-sense measures that communities can take to reduce the negative effects of heat islands, such as replacing conventional black asphalt road surfaces with the new pigmentable bitumen that gives lighter colors.
Asphalt made from non-petroleum based renewable resources is world first breakthrough asphalt bitumen technology which was invented and pioneered in Australia by Ecopave AustraliaTM with the first field trial laid in the 1980's and early 1990's. The bitumen asphalt called GEO320TM is made from water soluble plant and vegetable based waste materials such as molasses, sugar, palm oil waste, peanut oil waste, corn oil waste etc and vegetable oils and starches such as from corn, rice and potato's and the waste material derived from the distillation process of cleaning used motor oils (bottoms).
Asphalt made with vegetable based binders was patented by Colas SA in France in 2004 (Vegecol), Colas was originally owned by the Royal Dutch Shell.
A number of homeowners seeking an environmentally-friendly alternative to asphalt for paving have experimented with waste vegetable oil as a binder for driveways and parking areas in single-family applications. The earliest known test occurred in 2002 in Ohio, where the homeowner combined waste vegetable oil with dry aggregate to create a low-cost and non-polluting paving material for his 200-foot driveway. After five years, he reports the driveway is performing as well or better than petroleum-based materials.
This movement has led the Shell Oil Company (see also, Controversies surrounding Royal Dutch Shell) to pave two public roads in Sweden in 2007 with the Colas vegetable-oil-based asphalt.
Results of this study are still premature.
The word asphalt is derived from the late Middle English : from French asphalte, based on late Latin asphalton, asphaltum, from Greek asphalton, asphaltos (άσφαλτος), ásphaltos, -on, akin to asphalízein to make firm, to secure.

The American National Standards Institute or ANSI () is a private non-profit organization that oversees the development of voluntary consensus standards for products, services, processes, systems, and personnel in the United States. The organization also coordinates U.S. standards with international standards so that American products can be used worldwide. For example, standards make sure that people who own cameras can find the film they need for them anywhere around the globe.
ANSI accredits standards that are developed by representatives of standards developing organizations, government agencies, consumer groups, companies, and others. These standards ensure that the characteristics and performance of products are consistent, that people use the same definitions and terms, and that products are tested the same way. ANSI also accredits organizations that carry out product or personnel certification in accordance with requirements defined in international standards.
The organization's headquarters are in Washington, DC. ANSI's operations office is located in New York City.
ANSI was formed in 1918 when five engineering societies and three government agencies founded the American Engineering Standards Committee (AESC). The AESC became the American Standards Association (ASA) in 1928. In 1966, the ASA was reorganized and became the United States of America Standards Institute (USASI). The present name was adopted in 1969.
ANSI's membership comprises government agencies, organizations, corporations, academic and international bodies, and individuals. In total, the Institute represents the interests of more than 125,000 companies and 3.5 million professionals.
Though ANSI itself does not develop standards, the Institute facilitates the development of American National Standards, also known as ANS, by accrediting the procedures of standards developing organizations. ANSI accreditation signifies that the procedures used by standards setting organizations meet the Institute's requirements for openness, balance, consensus, and due process.
Voluntary consensus standards quicken the market acceptance of products while making clear how to improve the safety of those products for the protection of consumers. There are approximately 10,500 American National Standards that carry the ANSI designation.
In addition to facilitating the formation of standards in the U.S. ANSI promotes the use of U.S. standards internationally, advocates U.S. policy and technical positions in international and regional standards organizations and encourages the adoption of international standards as national standards where appropriate.
The Institute is the official U.S. representative to the two major international standards organizations, the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC), via the U.S. National Committee (USNC). ANSI participates in almost the entire technical program of both the ISO and the IEC, and administers many key committees and subgroups. In many instances, U.S. standards are taken forward to ISO and IEC, through ANSI or the USNC, where they are adopted in whole or in part as international standards.
Each of the panels works to identify, coordinate, and harmonize voluntary standards relevant to these areas.

In general parlance, an argument is a discussion involving conflicting points of view.


The Apollo 11 mission was the first manned mission to land on the Moon. It was the fifth human spaceflight of the Apollo program and the third human voyage to the moon. Launched on July 16, 1969, it carried Commander Neil Alden Armstrong, Command Module Pilot Michael Collins and Lunar Module Pilot Edwin Eugene 'Buzz' Aldrin, Jr. On July 20, Armstrong and Aldrin became the first humans to land on the Moon, while Collins orbited above.
The mission fulfilled President John F. Kennedy's goal of reaching the moon by the end of the 1960s. In a 1961 speech he had proposed - "I believe that this nation should commit itself to achieving the goal, before this decade is out, of landing a man on the Moon and returning him safely to the Earth".
Number in parentheses indicates number of spaceflights by each individual prior to and including this mission.
The lunar module was named Eagle after the bald eagle depicted on the insignia; the bald eagle is the national bird of the United States. The command module was named Columbia, a traditional, feminized name for the United States used in song and poetry. It was also a reference to the 'columbiad' cannon used to launch the moonships in Jules Verne's novel From the Earth to the Moon. Some internal NASA planning documents referred to the call signs as Snowcone and Haystack but these were quietly changed before being announced to the press.
In addition to one million people crowding the highways and beaches near the launch site, an estimated audience of over 700 million people viewed the event on television, a new record at that time. President Richard Nixon viewed the proceedings from the Oval Office of the White House.
A Saturn V launched Apollo 11 from the Kennedy Space Center on July 16, 1969 at 13:32 UTC (9:32 a.m. local time). It entered Earth's orbit 12 minutes later. After one and a half orbits, the S-IVB third-stage engine pushed the spacecraft onto its trajectory toward the Moon with the Trans Lunar Injection burn. About 30 minutes later the command/service module pair separated from the last remaining Saturn V stage and docked with the lunar module still nestled in the Lunar Module Adaptor.
On July 19 Apollo 11 passed behind the Moon and fired its service propulsion engine to enter lunar orbit. In the thirty orbits that followed, the crew saw passing views of their landing site in the southern Sea of Tranquility about 20 kilometers (12 mi) southwest of the crater Sabine D (0.67408N, 23.47297E). The landing site was selected in part because it had been characterized as relatively flat and smooth by the automated Ranger 8 and Surveyor 5 landers along with the Lunar Orbiter mapping spacecraft. It was therefore unlikely to present major landing or extra-vehicular activity (EVA) challenges.
On July 20, 1969 the lunar module Eagle separated from the command module Columbia. Collins, alone aboard Columbia, inspected Eagle as it pirouetted before him to ensure the craft was not damaged. Armstrong and Aldrin used Eagle's descent engine to right themselves and descend to the lunar surface.
As the landing began Armstrong reported they were "running long." Eagle was 4 seconds further along its descent trajectory than planned and would land miles west of the intended site. The LM navigation and guidance computer reported several unusual "program alarms" as it guided the LM's descent, drawing the crew's attention from the scene outside as the descent continued. Inside NASA's Mission Control Center in Houston, Texas, computer engineer Jack Garman told guidance officer Steve Bales it was safe to continue the descent in spite of the alarms. When Armstrong returned his attention to the view outside it was apparent the computer was guiding them towards a large crater with rocks scattered around it. Armstrong took manual control of the lunar module and with Aldrin calling out data from the radar and computer, guided it to a landing at 20:17 UTC on July 20 with about 30 seconds of fuel left.
The program alarms were "executive overflows" indicating the computer was not completing all its processing tasks. The cause was later traced to a training error: The computer spent unplanned time processing extra data from the LM rendezvous radar which had been left on during descent. Although Apollo 11 landed with less fuel than other missions, they also encountered a premature low fuel warning. It was later found to be caused by the lunar gravity permitting greater propellant 'slosh' which had uncovered a fuel sensor. On future missions extra baffles were added to the tanks.
Armstrong's first words after landing were, "Houston, Tranquility Base here. The Eagle has landed." This partially confused the staff at Mission Control since Armstrong had only given the name Tranquility Base to the landing site immediately after touchdown.
"This is the LM pilot. I'd like to take this opportunity to ask every person listening in, whoever and wherever they may be, to pause for a moment and contemplate the events of the past few hours and to give thanks in his or her own way.
At 2:56 UTC on July 21, Armstrong made his descent to the Moon's surface and spoke his famous line "That's one small step for [a] man, one giant leap for mankind" exactly six and a half hours after landing. Aldrin joined him, saying, "Beautiful. Beautiful. Magnificent desolation". Then for two-and-a-half hours, they took notes, photographed what they saw, and drilled core samples.
They planned placement of the Early Apollo Scientific Experiment Package (EASEP) and the U.S. flag by studying their landing site through Eagle's twin triangular windows, which gave them a 60° field of view. Preparation required longer than the two hours scheduled. Armstrong initially had some difficulties squeezing through the hatch with his Portable Life Support System (PLSS). According to veteran moonwalker John Young, a redesign of the LM to incorporate a smaller hatch was not followed by a redesign of the PLSS backpack, so some of the highest heart rates recorded from Apollo astronauts occurred during LM egress and ingress.
The Remote Control Unit controls on Armstrong's chest prevented him from seeing his feet. While climbing down the nine-rung ladder, Armstrong pulled a D-ring to deploy the Modular Equipment Stowage Assembly (MESA) folded against Eagle's side and activate the TV camera. The first images used a Slow-scan television system which was incompatible with commercial broadcast technology at the time so the images rebroadcast were played on screens mounted in front of conventional television cameras. The signal was picked up at Goldstone in the USA but with better fidelity by Honeysuckle Creek Tracking Station in Australia. Minutes later the TV was switched to normal television, and the feed was switched to the more sensitive radio telescope station at the Parkes Observatory in Australia. Despite some technical and weather difficulties, ghostly black and white images of the first lunar EVA were received and were immediately broadcast to at least 600 million people on Earth.
After describing the surface dust ("fine and powdery.. I only go in a small fraction of an inch, but I can see the footprints of my boots"), Armstrong stepped off Eagle's footpad and into history as the first human to set foot on another world, famously describing it as "one small step for (a) man, one giant leap for mankind." He reported that moving in the Moon's gravity, one-sixth of Earth's, was "even perhaps easier than the simulations.. It's absolutely no trouble to walk around".
In addition to fulfilling President John F. Kennedy's mandate to land a man on the Moon before the end of the 1960s, Apollo 11 was an engineering test of the Apollo system; therefore, Armstrong snapped photos of the LM so engineers would be able to judge its post-landing condition. He then collected a contingency soil sample using a sample bag on a stick. He folded the bag and tucked it into a pocket on his right thigh. He removed the TV camera from the MESA, made a panoramic sweep, and mounted it on a tripod 12 m (40 ft) from the LM. The TV camera cable remained partly coiled and presented a tripping hazard throughout the EVA.
Aldrin joined him on the surface and tested methods for moving around, including two-footed kangaroo hops. The PLSS backpack created a tendency to tip backwards, but neither astronaut had serious problems maintaining balance. Loping became the preferred method of movement. The astronauts reported that they needed to plan their movements six or seven steps ahead. The fine soil was quite slippery. Aldrin remarked that moving from sunlight into Eagle's shadow produced no temperature change inside the suit, though the helmet was warmer in sunlight, so he felt cooler in shadow.
They then took a phone call from President Richard Nixon after planting the U.S. flag together on the Moon's surface.
The MESA failed to provide a stable work platform and was in shadow, slowing work somewhat. As they worked, the moonwalkers kicked up gray dust which soiled the outer part of their suits, the integrated thermal meteoroid garment.
They deployed the EASEP, which included a passive seismograph and a laser ranging retroreflector. Then Armstrong loped about 120 m (400 ft) from the LM to snap photos at the rim of East Crater while Aldrin collected two core tubes. He used the geological hammer to pound in the tubes - the only time the hammer was used on Apollo 11. The astronauts then collected rock samples using scoops and tongs on extension handles. Many of the surface activities took longer than expected, so they had to stop documented sample collection halfway through the allotted 34 min.
During this period Mission Control used a coded phrase to warn Armstrong that his metabolic rates were high and that he should slow down. He was moving rapidly from task to task as time ran out. Rates remained generally lower than expected for both astronauts throughout the walk, however, so Mission Control granted the astronauts a 15-minute extension.
Aldrin entered Eagle first. With some difficulty the astronauts lifted film and two sample boxes containing more than 22 kg (48 lb) of lunar surface material to the LM hatch using a flat cable pulley device called the Lunar Equipment Conveyor. Armstrong reminded Aldrin of a bag of memorial items in his suit pocket sleeve, and Aldrin tossed the bag down; Armstrong then jumped to the ladder's third rung and climbed into the LM. After transferring to LM life support, the explorers lightened the ascent stage for return to lunar orbit by tossing out their PLSS backpacks, lunar overshoes, one Hasselblad camera, and other equipment. They then repressurised the LM, and settled down to sleep.
While moving in the cabin Aldrin accidentally broke the circuit breaker that armed the main engine for lift off from the moon. There was initial concern this would prevent firing the engine, which would strand them on the moon. Fortunately a felt-tip pen was sufficient to activate the switch. Had this not worked, the Lunar Module circuitry could have been reconfigured to allow firing the ascent engine.
After about seven hours of rest, they were awakened by Houston to prepare for the return flight. Two and a half hours later, at 17:54 UTC, they lifted off in Eagle's ascent stage, carrying 21.5 kilograms of lunar samples with them, to rejoin CMP Michael Collins aboard Columbia in lunar orbit.
After more than 2½ hours on the lunar surface, they had left behind scientific instruments such as a retroreflector array used for the Lunar Laser Ranging Experiment. They also left an American flag, an Apollo 1 mission patch, and a plaque (mounted on the LM Descent Stage ladder) bearing two drawings of Earth (of the Western and Eastern Hemispheres), an inscription, and signatures of the astronauts and Richard Nixon. The inscription read Here Men From The Planet Earth First Set Foot Upon the Moon, July 1969 A.D. We Came in Peace For All Mankind.
Film taken from the LM Ascent Stage upon liftoff from the moon reveal the American flag, planted some 25 ft from the descent stage, whipping violently in the exhaust of the ascent stage engine. As the landing site receded out of the camera field of view, the flag appeared ready to topple, but whether it did in fact fall or not is unknown. (However, according to Buzz Aldrin, during the lunar ascent, "The ascent stage of the LM separated…I was concentrating on the computers, and Neil was studying the attitude indicator, but I looked up long enough to see the flag fall over.") Subsequent Apollo missions usually planted the American flags at least 100 ft from the LM to avoid being blown over by the ascent engine exhaust.
After rendezvous with Columbia, Eagle LM was jettisoned into lunar orbit at 21 July 1969 at 23:41 UT (7:41 PM EDT). Just before the Apollo 12 flight, it was noted that Eagle was still orbiting the moon. Later NASA reports mentioned that Eagle's orbit had decayed resulting in it impacting in an "uncertain location" on the lunar surface.
On July 24, the astronauts returned home and were immediately put in quarantine. The splashdown point was, 2,660 km (1,440 nm) east of Wake Island, or 380 km (210 nm) south of Johnston Atoll, and 24 km (15 mi) from the recovery ship, USS Hornet. After recovery by helicopter approximately one hour after splashdown, the astronauts were placed in a trailer that had been designed as a quarantine facility. President Richard Nixon was aboard the recovery vessel to personally welcome the astronauts back to Earth.
The astronauts were placed in quarantine after their landing on the moon due to fears that the moon might contain undiscovered pathogens, and that the astronauts were exposed to them during their moon walks. However, after almost three weeks in confinement (first in their trailer and later in the Lunar Receiving Laboratory at the Lyndon B. Johnson Space Center), the astronauts were given a clean bill of health. On August 13 1969, the astronauts exited quarantine to the cheers of the American public. Parades were held in their honor in New York, Chicago, and Los Angeles on the same day. A few weeks later, they were invited by Mexico for a parade honoring them in Mexico City.
That evening in Los Angeles there was an official State Dinner to celebrate Apollo 11, attended by Members of Congress, 44 Governors, the Chief Justice, and ambassadors from 83 nations. President Richard Nixon and Vice President Spiro T. Agnew honored each astronaut with a presentation of the Presidential Medal of Freedom. This celebration was the beginning of a 45-day "Giant Leap" tour that brought the astronauts to 25 foreign countries and included visits with prominent leaders such as Queen Elizabeth II of the United Kingdom. Many nations would honor the first manned moon landing by issuing Apollo 11 commemorative postage stamps or coins.
On September 16 1969, the three astronauts spoke before a Joint Session of Congress on Capitol Hill. They presented two U.S. flags, one to the House of Representatives and the other to the Senate, that had been carried to the surface of the moon with them.
The command module is displayed at the National Air and Space Museum, Washington, D.C. It is placed in the central exhibition hall in front of the Jefferson Drive entrance, and shares the main hall with other pioneering flight vehicles such as the Spirit of St. Louis, the Bell X-1, the North American X-15, Mercury capsule Friendship 7, and Gemini 4. The quarantine trailer is displayed at the Smithsonian's Udvar-Hazy Center annex near Washington Dulles International Airport in Virginia.
Early in the planning of Project Apollo, NASA decided to combine all communications between the spacecraft and Earth into a single multiplexed feed called 'The Unified S-Band System', including audio communications, television images, crew medical telemetry and the spacecraft systems telemetry.
The signal was picked up by three purpose-built stations, called Goldstone (California), Honeysuckle Creek (Australia) and Fresnedillas (Spain), and backed-up by the three nearby deep space network stations (known as 'wing stations'). All of the signals were routed to NASA's communications center (now the Goddard Space Flight Center) in Greenbelt, Maryland.
Intelsat satellites began taking over the trans-oceanic transmissions toward the end of the 1960s, and NASA ended its contracts for the submarine telephone circuits, which were then reallocated by telephone administrations for normal voice use.
On 14 July 1969, two days before last day of the launch window, the INTELSAT III satellite over the Atlantic failed, cutting off the link between the dish in Spain and Greenbelt, Maryland. It was decided that the problem needed to be fixed by two hours before launch time, or the launch would be scrubbed.
The Early Bird satellite was activated, but there were concerns that it might not have enough power to get a signal to the United States. So, with great difficulty, twelve undersea telephone circuits were made available to NASA from six countries, for their inverse multiplexed signal. An official with the Spanish communications authority helped the team secure the circuits with his own personal list of contacts. The last circuit using inverse multiplexing was accepted by NASA just minutes before the time limit.
The familiar patch of Apollo 11 was designed by Collins, who wanted a symbol for "peaceful lunar landing by the United States". He picked an eagle as the symbol, put an olive branch in its beak, and drew a moon background with the earth in the distance. NASA officials said the talons of the eagle looked too "warlike" and after some discussion, the olive branch was moved to the claws. The crew decided the Roman numeral XI would not be understood in some nations and went with Apollo 11; they decided not to put their names on the patch to "allow it to symbolize everyone who worked on the moon landing". All colors are natural, with blue and gold borders around the patch. The LM was named Eagle to match the insignia. When the Eisenhower silver dollar was revived a few years later, the patch design provided the eagle for the back of the coin; the design was kept for the smaller Susan B. Anthony dollar.


Apollo 8 was the first manned voyage to a celestial body. Its three-man crew of Mission Commander Frank Borman, Command Module Pilot James Lovell, and Lunar Module Pilot William Anders became the first humans to see the far side of the Moon. The mission also involved the first manned launch of a Saturn V rocket, and was the second manned mission of the Apollo Program.
Originally planned as a low-earth orbit Lunar Module/Command Module test, the mission profile was changed to the more ambitious lunar orbital flight in August 1968 when the Lunar Module scheduled for the flight became delayed. The new mission's profile, procedures and personnel requirements left an uncharacteristically short time-frame for training and preparation.
After launching on December 21, 1968, the crew took three days to travel to the Moon. They orbited ten times over the course of 20 hours, during which the crew made a Christmas Eve television broadcast in which they read from the book of Book of Genesis. At the time, the broadcast was the most watched TV program ever. Apollo 8's successful mission paved the way for Apollo 11 to fulfill U.S. President John F. Kennedy's goal of landing a man on the Moon before the end of the decade.
The National Aeronautics and Space Administration (NASA) announced the primary crew for Apollo 8 on December 22, 1966, selecting astronauts Frank Borman, Michael Collins and Bill Anders.
Borman, a veteran of Gemini 7, was selected as the Mission Commander. Bill Anders was named the Lunar Module Pilot, in what would be his first spaceflight. Collins, originally named the Command Module Pilot, was replaced in July 1968, after suffering a cervical disc herniation that required surgery to repair. Jim Lovell, the backup Command Module Pilot, would join his Gemini 7 commander Frank Borman on the primary crew.
The backup crew trained to take the place of the prime crew in case of illness or death. For Apollo 8, the backup crew included Neil Armstrong as Mission Commander, Buzz Aldrin as backup Command Module Pilot, and Fred Haise as backup Lunar Module Pilot. Upon his recovery from back surgery, Astronaut Michael Collins would join backup crew members Armstrong and Aldrin as the primary crew for Apollo 11. During the mission, backup crew members would serve as members of the support crew.
The Earth-based mission control teams for Apollo 8 consisted of astronauts assigned to the support crew, as well as non-astronaut flight directors and their staffs. The support crew members were not trained to fly the mission, but were able to stand in for astronauts in meetings and be involved in the minutiae of mission planning, while the prime and backup crews trained. They also served as capcoms during the mission. For Apollo 8, these crew members included astronauts John S. Bull, Vance D. Brand, Gerald P. Carr, and Ken Mattingly. The mission control teams on Earth rotated in three shifts, each led by a flight director. The directors for Apollo 8 included Cliff Charlesworth (Green team), Glynn Lunney (Black team), and Milton Windler (Maroon team).
The triangular shape of the insignia symbolizes the shape of the Apollo command module. It shows a red figure 8 looping around the earth and moon representing the mission number as well as the circumlunar nature of the mission. On the red number 8 are the names of the three astronauts.
The initial design of the insignia was developed by Jim Lovell. Lovell reportedly sketched the initial design while riding in the backseat of a T-38 flight from California to Houston, shortly after learning of the re-designation of the flight to become a circumlunar mission.
Apollo 4 and Apollo 6 had been "A" missions, each launching an unmanned Block I production model of the Apollo Command and Service Modules into Earth Orbit. scheduled for October 1968, would be a manned Earth Orbit flight of the CSM, completing the objectives for Mission "C".
Further missions relied on the readiness of the Lunar Module (LM). Production of the LM was behind schedule, with the first model arriving at Cape Canaveral in June 1968. Even then, significant defects were discovered, leading Grumman, the lead contractor for the LM, to predict that the first mission-ready LM would not be ready until at least February 1969. This would delaying the proposed "D" mission and endangering the program's goal of a lunar landing before the end of 1969.
George Low, the Manager of the Apollo Spacecraft Program Office, proposed a solution in August. Since the Command/Service Module (CSM) would be ready three months before the Lunar Module, a CSM-only mission could be flown in December 1968. Instead of just repeating the "C" mission flight of Apollo 7, this CSM could be sent all the way to the Moon, with the possibility of entering a lunar orbit. The new mission would also allow NASA to test lunar landing procedures that would otherwise have to wait until Apollo 10, the scheduled "F" mission.
Almost every senior manager at NASA agreed with this new mission, citing both confidence in the hardware and personnel, and the potential for a significant morale boost provided by a circumlunar flight. The only person who needed some convincing was James E. Webb, the NASA administrator. With the rest of his agency in support of the new mission, Webb eventually approved the mission change. The mission was officially changed from a "D" mission to a "C-Prime" Lunar Orbit mission, but was still referred to in press releases as an Earth Orbit mission at Webb's direction. No public announcement was made about the change in mission until November 12, three weeks after Apollo 7's successful Earth Orbit mission and less than 40 days before launch.
With the change in mission for Apollo 8, Director of Flight Crew Operations Deke Slayton decided to swap the crews of the D and E missions. James McDivitt, the original commander of the D mission, has said he was never offered the circumlunar flight, but would probably have turned it down, as he wanted to fly the lunar module. Borman, on the other hand, jumped at the chance: his original mission would just have been a repeat of the previous flight, except in a higher orbit. This swap also meant a swap of spacecraft, requiring Borman's crew to use CSM-103, while McDivitt's crew would use CSM-104.
On September 9, the crew entered the simulators to begin their preparation for the flight. By the time the mission flew, the crew would have spent seven hours training for every actual hour of flight. Although all crew members were trained in all aspects of the mission, it was necessary to specialize. Borman, as commander, was given training on controlling the spacecraft during the re-entry. Lovell was trained on navigating the spacecraft in case communication was lost with the Earth. Anders was placed in charge of checking that the spacecraft was in working order.
The crew, now living in the crew quarters at Kennedy Space Center, received a visit from Charles Lindbergh and his wife, Anne Morrow Lindbergh, the night before the launch. They talked about how before his 1927 flight, Lindbergh had used a piece of string to measure the distance from New York City to Paris on a globe and from that calculated the fuel needed for the flight. The total was a tenth of the amount that the Saturn V would burn every second.
The next day, the Lindberghs watched the launch of Apollo 8 from a nearby dune. Anne Morrow Lindbergh would later write a book about the Apollo program, entitled Earth Shine, which mentions both the launch and the mission.
The Saturn V rocket used by Apollo 8 was designated SA-503, or the "03rd" model of the Saturn V ("5") Rocket to be used in the Saturn-Apollo ("SA") program. When it was erected in the Vertical Assembly Building on December 20, 1967, it was thought that the rocket would be used for an unmanned Earth-orbit test flight carrying a boilerplate Command/Service Module. Apollo 6 had suffered several major problems during its April 1968 flight, including severe pogo oscillation during its first stage, two second stage engine failures, and a third stage that failed to reignite in orbit. Without assurances that these problems had been rectified, NASA administrators could not justify risking a manned mission until additional unmanned test flights proved that the Saturn V was ready.
Teams from the Marshall Space Flight Center (MSFC) went to work on the problems. Of primary concern was the pogo oscillation, which would not only hamper engine performance, but could exert significant g-forces on a crew. A task force of contractors, NASA agency representatives, and MSFC researchers concluded that the engines vibrated at a frequency similar to the frequency at which the spacecraft itself vibrated, causing a resonance effect that induced oscillations in the rocket. A system using Helium gas to absorb some of these vibrations was installed.
Of equal importance was the failure of three engines during flight. Researchers quickly determined that a leaking Hydrogen fuel line ruptured when exposed to vacuum, causing a loss of fuel pressure in engine two. When an automatic shutoff attempted to close the Liquid Hydrogen valve and shut down engine two, it accidentally shut down engine three's Liquid Oxygen due to a faulty igniter line. As a result, engine three failed within one second of engine two's shutdown. Further investigation revealed the same problem for the third-stage engine — a faulty igniter line. The team modified the igniter lines and fuel conduits, hoping to avoid similar problems on future launches.
The teams tested their solutions in August 1968 at the Marshall Space Flight Center. A Saturn stage IC was equipped with shock absorbing devices to demonstrate the team's solution to the problem of pogo oscillation, while a Saturn Stage II was retrofitted with modified fuel lines to demonstrate their resistance to leaks and ruptures in vacuum conditions. Once NASA administrators were convinced that the problems were solved, they gave their approval for a manned mission using AS-503.
The Apollo 8 spacecraft was placed on top of the rocket on September 21 and the rocket made the slow 3-mile (5 km) journey to the launch pad on October 9. Testing continued all through December until the day before launch, including various levels of readiness testing from 5 December through 11 December. Final testing of modifications to address the problems of pogo oscillation, ruptured fuel lines, and bad igniter lines took place on 18 December, a mere three days before the scheduled launch.
Apollo 8 launched at 7:51:00 a.m. Eastern Standard Time on December 21, 1968, using the Saturn V's three stages, S-IC, S-II, and S-IVB, to achieve Earth orbit. The launch phase experienced only three minor problems: The engines of the first stage, S-IC, underperformed by 0.75%, causing the engines to burn for 2.45 seconds longer than planned, and toward the end of the second stage burn, S-II, the rocket underwent pogo oscillations. Frank Borman estimated the oscillations were approximately and (±2.5 m/s²). The apogee was also slightly higher than the planned circular orbit of 115 miles (185 km). In its first manned mission, the Saturn V rocket placed Apollo 8 into a 112.8 miles by 118.9 miles (181.5 km by 191.3 km) Earth orbit within 88 minutes and 10 seconds.
All three rocket stages fired during launch; the S-IC and S-II detached during launch. The S-IC impacted the Atlantic Ocean at and the S-II second stage at. The third stage of the rocket, S-IVB, assisted in driving the craft into Earth orbit but remained attached to later perform the Trans-Lunar Injection (TLI), the burn that would put the spacecraft on a trajectory to the Moon.
Once in Earth orbit, both the Apollo 8 crew and Mission Control spent the next 2 hours and 38 minutes checking that the spacecraft was in proper working order and ready for TLI. At the same time, the Apollo 8 crew transformed the capsule from a rocket payload into a spacecraft. The proper operation of third stage of the rocket, S-IVB was crucial; In the last unmanned test, the S-IVB had failed to re-ignite for TLI.
During the flight, three fellow astronauts served on the ground as capsule communicators (usually referred to as "CAPCOMs") on a rotating schedule. The CAPCOMs were the only people who regularly communicated with the crew. Michael Collins was the first CAPCOM on duty and at 2 hours, 27 minutes and 22 seconds after launch radioed, "Apollo 8. You are Go for TLI". This communication signified that Mission Control had given official permission for Apollo 8 to go to the moon. Over the next twelve minutes before the TLI burn, the Apollo 8 crew continued to monitor the spacecraft and the rocket. The S-IVB third stage rocket ignited on time and burned perfectly for 5 minutes and 17 seconds. The burn increased the velocity of Apollo 8 to 35,505 feet per second (10,822 m/s) and the spacecraft's altitude at the end of the burn was 215.4 miles (346.7 km). At this time, the crew also set the record for the highest speed humans had ever traveled.
After the S-IVB had performed its required tasks, it was jettisoned. The crew then rotated the spacecraft to take some photographs of the spent stage and then practiced flying in formation with it. As the crew rotated the spacecraft, they had their first views of the Earth as they moved away from it. This marked the first time humans could view the entire Earth at once. Borman became worried that the S-IVB was staying too close to the Command/Service Module and suggested to Mission Control that the crew perform a separation maneuver. Mission Control first suggested pointing the spacecraft towards Earth and using the Reaction Control System (RCS) thrusters on the Service Module to add 3 ft/s (0.9 m/s) away from the Earth, but Borman did not want to lose sight of the S-IVB. After discussion, the crew and Mission Control decided to burn in this direction, but at 9 ft/s (2.7 m/s) instead. These discussions put the crew an hour behind their flight plan.
Five hours after launch, Mission Control sent a command to the S-IVB booster to vent its remaining fuel through its engine bell to change the booster's trajectory. This S-IVB would then pass the Moon and enter into a solar orbit, posing no further hazard to Apollo 8. The S-IVB subsequently went into a 0.99 by 0.92 AU solar orbit with an inclination of 23.47° and a period of 340.80 days.
The Apollo 8 crew were the first humans to pass through the Van Allen radiation belts, which extend up to 15,000 miles (25,000 km) from Earth. Scientists predicted that passing through the belts quickly at the spacecraft's high speed would cause a radiation dosage of no more than a chest X-ray, or 1 milligray (during the course of a year, the average human receives a dose of 2 to 3 mGy). To record the actual radiation dosages, each crew member wore a Personal Radiation Dosimeter that transmitted data to Earth as well as three passive film dosimeters that showed the cumulative radiation experienced by the crew. By the end of the mission, the crew experienced an average radiation dose of 1.6 mGy.
Jim Lovell's main job as Command Module Pilot was as navigator. Although Mission Control performed all of the actual navigation calculation, it was necessary to have a crew member serving as navigator the crew could navigate their way home in case of communication loss with Mission Control. Lovell navigated by star sightings using a sextant built into the spacecraft, measuring the angle between a star and the Earth's (or the Moon's) horizon. This task proved to be difficult, as a large cloud of debris around the spacecraft formed by the venting by the S-IVB made it hard to distinguish the stars.
By seven hours into the mission, the crew was about one hour and 40 minutes behind flight plan due to the issues of moving away from the S-IVB and Lovell's obscured star sightings. The crew now placed the spacecraft into Passive Thermal Control (PTC), also known as "barbecue" mode. PTC involved the spacecraft rotating about once per hour along its long axis to ensure even heat distribution across the surface of the spacecraft. In direct sunlight, the spacecraft could be heated to over 200 °C while the parts in shadow would be −100 °C. These temperatures could cause the heat shield to crack or propellant lines to burst. As it was impossible to get a perfect roll, the spacecraft actually swept out a cone as it rotated. The crew had to make minor adjustments every half hour to as the cone pattern got larger and larger.
The first mid-course correction came 11 hours into the flight. Testing on the ground had shown the that the Service Propulsion System (SPS) engine had a small chance of exploding when burned for long periods unless its combustion chamber was "coated" first. Burning the engine for a short period would accomplish coating. This first correction burn was only 2.4 seconds and added about 20.4 ft/s (6.2 m/s) prograde (in the direction of travel). This change was less than the planned 24.8 ft/s (7.5 m/s) due to a bubble of helium in the oxidizer lines causing lower than expected fuel pressure. The crew had to use the small Reaction Control System (RCS) thrusters to make up the shortfall. Two later planned mid-course corrections were canceled as the Apollo 8 trajectory was found to be perfect.
Eleven hours into the flight, the crew had been awake for over 16 hours. Before launch, NASA had decided that at least one crew member should be awake at all times to deal with any issues that might arise. Borman started the first sleep shift, but between the constant radio chatter and mechanical noises, he found sleep difficult.
About an hour after starting his sleep shift, Borman requested clearance to take a Seconal sleeping pill. However, the pill had little effect. Borman eventually fell asleep but then awoke feeling ill. He vomited twice and had a bout of diarrhea that left the spacecraft full of small globules of vomit and feces that the crew cleaned up to the best of their ability. Borman initially decided that he did not want everyone to know about his medical problems, but Lovell and Anders wanted to inform Mission Control. The crew decided to use the Data Storage Equipment (DSE), which could tape voice recordings and telemetry and dump them to Mission Control at high speed. After recording a description of Borman's illness they requested that Mission Control check the recording, stating that they "would like an evaluation of the voice comments".
The Apollo 8 crew and Mission Control medical personnel held a conference using an unoccupied second floor control room (there were two identical control rooms in Houston on the second and third floor, only one of which was used during the course of a mission). The conference participants decided that there was little to worry about and that Borman's illness was either a 24-hour flu, as Borman thought, or a reaction to the sleeping pill. Researchers now believe that he was suffering from space adaptation syndrome, which affects about a third of astronauts during their first day in space as their vestibular system adapts to weightlessness. Space adaptation syndrome had not been an issue on previous spacecraft (Mercury and Gemini), as those astronauts were unable to move freely in the comparatively smaller cabins of those spacecraft. The increased cabin space in the Apollo Command Module afforded astronauts greater freedom of movement, contributing to symptoms of spacesickness for Borman and, later, Astronaut Russell Schweickart during Apollo 9.
The cruise phase was a relatively uneventful part of the flight, except for the crew checking that the spacecraft was in working order and that they were on course. During this time, NASA scheduled a television broadcast for 31 hours after launch. The Apollo 8 crew used a 2 kg camera that broadcast in black-and-white only, using a Vidicon tube. The camera had two lenses, a very wide-angle (160°) lens, and a telephoto (9°) lens.
During this first broadcast, the crew gave a tour of the spacecraft and attempted to show how the Earth appeared from space. However, difficulties aiming the narrow-angle lens without the aid of a monitor to show what it was looking at made showing the Earth impossible. Additionally, the Earth image became saturated by any bright source without proper filters. In the end, all the crew could show the people watching back on Earth was a bright blob. After broadcasting for 17 minutes, the rotation of the spacecraft took the high-gain antenna out of view of the receiving stations on Earth and they ended the transmission with Lovell wishing his mother a happy birthday.
By this time, the crew had completely abandoned the planned sleep shifts. Lovell went to sleep 32½ hours into the flight — 3½ hours before he had planned to. A short while later, Anders also went to sleep after taking a sleeping pill.
The crew was unable to see the Moon for much of the outward cruise. Two factors made the Moon almost impossible to see from inside the spacecraft: three of the five windows fogging up due to out-gassed oils from the silicone sealant, and the attitude required for the PTC. It was not until the crew had gone behind the Moon that they would be able to see it for the first time.
The Apollo 8 made a second television broadcast at 55 hours into the flight. This time, the crew rigged up filters meant for the still cameras so they could acquire images of the Earth through the telephoto lens. Although difficult to aim, as they had to maneuver the entire spacecraft, the crew was able to broadcast back to Earth the first television pictures of the Earth. The crew spent the transmission describing the Earth and what was visible and the colors they could see. The transmission lasted 23 minutes.
At about 55 hours and 40 minutes into the flight, the crew of Apollo 8 became the first humans to enter the gravitational sphere of influence of another celestial body. In other words, the effect of the Moon's gravitational force on Apollo 8 became stronger than that of the Earth. At the time it happened, Apollo 8 was 38,759 miles (62,377 km) from the Moon and had a speed of 3,990 ft/s (1,216 m/s) relative to the Moon. This historic moment was of little interest to the crew since they were still calculating their trajectory with respect to the launch pad at Kennedy Space Center. They would continue to do so until they performed their last mid-course correction, switching to a reference frame based on ideal orientation for the second engine burn they would make in lunar orbit. It was only thirteen hours until they would be in lunar orbit.
The last major event before Lunar Orbit Insertion was a second mid-course correction. It was in retrograde (against direction of travel) and slowed the spacecraft down by 2.0 ft/s (0.6 m/s), effectively lowering the closest distance that the spacecraft would pass the moon. At exactly 61 hours after launch, about 24,200 miles (39,000 km) from the Moon, the crew burned the RCS for 11 seconds. They would now pass 71.7 miles (115.4 km) from the lunar surface.
At 64 hours into the flight, the crew began to prepare for Lunar Orbit Insertion-1 (LOI-1). This maneuver had to be performed perfectly, and due to orbital mechanics had to be on the far side of the Moon, out of contact with the Earth. After Mission Control was polled for a Go/No Go decision, the crew was told at 68 hours, they were Go and "riding the best bird we can find". At 68 hours and 58 minutes, the spacecraft went behind the Moon and out of radio contact with the Earth.
With 10 minutes before the LOI-1, the crew began one last check of the spacecraft systems and made sure that every switch was in the correct place. At that time, they finally got their first glimpses of the Moon. They had been flying over the unlit side, and it was Lovell who saw the first shafts of sunlight obliquely illuminating the lunar surface. The LOI burn was only two minutes away, so the crew had little time to appreciate the view.
The SPS ignited at 69 hours, 8 minutes, and 16 seconds after launch and burned for 4 minutes and 13 seconds, placing the Apollo 8 spacecraft in orbit around the Moon. The crew described the burn as being the longest four minutes of their lives. If the burn had not lasted exactly the correct amount of time, the spacecraft could have ended up in a highly elliptical lunar orbit or even flung off into space. If it lasted too long they could have impacted the Moon. After making sure the spacecraft was working, they finally had a chance to look at the Moon, which they would orbit for the next 20 hours.
On Earth, Mission Control continued to wait. If the crew had not burned the engine or the burn had not lasted the planned length of time, the crew would appear early from behind the Moon. However, this time came and went without Apollo 8 reappearing. Exactly at the predicted moment, the signal was received from the spacecraft, indicating it was in a 193.3 mile by 69.5 mile (311.1 km by 111.9 km) orbit about the Moon.
Lovell continued to describe the terrain they were passing over. One of the crew's major tasks was reconnaissance of planned future landing sites on the Moon, especially one in Mare Tranquillitatis that would be the Apollo 11 landing site. The launch time of Apollo 8 had been chosen to give the best lighting conditions for examining the site. A film camera had been set up in one of the spacecraft windows to record a frame every second of the Moon below. Bill Anders spent much of the next 20 hours taking as many photographs as possible of targets of interest. By the end of the mission the crew had taken 700 photographs of the Moon and 150 of the Earth.
Throughout the hour that the spacecraft was in contact with Earth, Borman kept asking how the data for the SPS looked. He wanted to make sure that the engine was working and could be used to return early to the Earth if necessary. He also asked that they receive a Go/No Go decision before they passed behind the Moon on each orbit.
As they reappeared for their second pass in front of the Moon, the crew set up the equipment to broadcast a view of the lunar surface. Anders described the craters that they were passing over. At the end of this second orbit they performed the eleven-second LOI-2 burn of the SPS to circularize the orbit to 70.0 miles by 71.3 miles (112.6 km by 114.8 km).
Through the next two orbits, the crew continued to keep check of the spacecraft and to observe and photograph the Moon. During the third pass, Borman read a small prayer for his church. He was scheduled to participate in a service at St. Christopher's Episcopal Church near Seabrook, Texas, but due to the Apollo 8 flight was unable. A fellow parishioner and engineer at Mission Control, Rod Rose, suggested that Borman read the prayer which could be recorded and then replayed during the service.
When the spacecraft came out from behind the Moon for its fourth pass across the front, the crew witnessed an event no one had ever seen — Earthrise. Anders glanced out the window and saw a blue and white orb and realized it was the Earth. The crew recognized the significance of the event and the need to take photographs. Anders took both the first photograph, which was black-and-white, and later, the more famous color photo (NASA image AS8-14-2383HR). (After the flight, Borman and Anders both claimed they took the first Earthrise photo — Lovell also did, more as a joke than anything else — but it was determined that it was probably Anders.) Due to the synchronous rotation of the Moon about the Earth, Earthrise is not generally visible from the Lunar surface. Earthrise is generally only visible when orbiting the Moon, other than at selected places near the Moon's limb, where libration carries the Earth slightly above and below the lunar horizon.
Anders continued to take photographs while Lovell assumed control of the spacecraft so Borman could rest. Despite the difficulty resting in the cramped and noisy capsule, Borman was able to sleep for two orbits, awakening periodically to ask questions about their status.
Borman awoke fully, however, when he started to hear his fellow crew members make mistakes. They were beginning to not understand questions and would have to ask for the answers to be repeated. Borman realized that everyone was extremely tired having not had a good night's sleep in over three days. Taking command, he ordered Anders and Lovell to get some sleep and that the rest of the flight plan regarding observing the Moon be scrubbed. At first Anders protested saying that he was fine, but Borman would not be swayed. At last Anders agreed as long as Borman would set up the camera to continue to take automatic shots of the Moon. Borman also remembered that there was a second television broadcast planned, and with so many people expected to be watching he wanted the crew to be alert. For the next two orbits Anders and Lovell slept while Borman sat at the helm. On subsequent Apollo missions, crews would avoid this situation by sleeping on the same schedule.
As they rounded the Moon for the ninth time, the second television transmission began. Borman introduced the crew, followed by each man giving his impression of the lunar surface and what it was like to be orbiting the Moon. Borman described it as being "a vast, lonely, forbidding expanse of nothing." Then, after talking about what they were flying over, Anders said that the crew had a message for all those on Earth. Each man on board read the story of creation from Book of Genesis. Borman finished the broadcast by wishing a Merry Christmas to "all of you, all of you on the good Earth".
The only task left for the crew at this point was to perform the Trans-Earth Injection (TEI), which was scheduled for 2½ hours after the end of the television transmission. The TEI was the most critical burn of the flight, as any failure of the SPS to ignite would strand the crew in Lunar orbit, with little hope of escape. As with the previous burn, the crew had to perform the maneuver above the far side of the Moon, out of contact with Earth.
Later, Lovell used some otherwise idle time to do some navigational sightings, maneuvering the module to view various stars by using the computer keyboard. However, he accidentally erased some of the computer's memory, which caused the inertial measuring unit (IMU) to think the module was in the same relative position it had been in before lift-off and fire the thrusters to "correct" the module's attitude.
Once the crew realized why the computer had changed the module's attitude, they realized they would have to re-enter data that would tell the computer its real position. It took Lovell ten minutes to figure out the right numbers, using the thrusters to get the stars Rigel and Sirius aligned, and another fifteen minutes to enter the corrected data into the computer.
Sixteen months later, Lovell would once again have to perform a similar manual re-alignment, under more critical conditions, during the Apollo 13 mission, after that module's IMU had to be turned off to conserve energy. In his 1994 book, Lost Moon: The Perilous Voyage of Apollo 13, Lovell wrote, "My training [on Apollo 8] came in handy!". In that book he dismissed the incident as a "planned experiment", requested by the ground crew. However, in subsequent interviews Lovell has acknowledged that the incident was an accident, caused by his mistake.
The cruise back to Earth was mostly a time for the crew to relax and monitor the spacecraft. As long as the trajectory specialists had calculated everything correctly, the spacecraft would re-enter 2½ days after TEI and splashdown in the Pacific.
On Christmas afternoon, the crew made their fifth and final television broadcast. This time they gave a tour of the spacecraft, showing how an astronaut lived in space. When they had finished broadcasting they found a small present from Deke Slayton in the food locker—real turkey with stuffing and three miniature bottles of brandy (which remained unopened). There were also small presents to the crew from their wives.
After two uneventful days the crew prepared for re-entry. The computer would control the re-entry and all the crew had to do was put the spacecraft in the correct attitude, blunt end forward. If the computer broke down, Borman would take over.
Once the Command Module was separated from the Service Module, the astronauts were committed to re-entry. Six minutes before they hit the top of the atmosphere, the crew saw the Moon rising above the Earth's horizon, just as had been predicted by the trajectory specialists. As they hit the thin outer atmosphere they noticed it was becoming hazy outside as glowing plasma formed around the capsule. The capsule started slowing down and the deceleration peaked at 6 g (59 m/s²). With the computer controlling the descent by changing the attitude of the capsule, Apollo 8 rose briefly like a skipping stone before descending to the ocean. At 30,000 feet (9 km) the drogue parachute stabilized the spacecraft and was followed at 10,000 feet (3 km) by the three main parachutes. The spacecraft splashdown position was estimated to be.
When it hit the water, the parachutes dragged the spacecraft over and left it upside down, in what was termed Stable 2 position. As they were buffeted by a 10-foot (3 m) swell, Borman was sick, waiting for the three flotation balloons to right the capsule. It was 43 minutes after splashdown before the first frogman from the USS Yorktown arrived, as the capsule had landed before sunrise. Forty-five minutes later, the crew was safe on the deck of the aircraft carrier.
The command module is now displayed at the Chicago Museum of Science and Industry, along with a collection of personal items from the flight donated by Lovell and the spacesuit worn by Frank Borman. Jim Lovell's spacesuit can be found at NASA's Glenn Research Center.
One of the most famous aspects of the flight was the Earthrise picture that was taken as they came around for their fourth orbit of the Moon. Although it was not the first image taken of the whole Earth nor would it be the last, this was the first time that humans had taken such a picture. Some regard the picture as being the start of the environmentalist movement, with the first Earth Day in 1970.
Atheist Madalyn Murray O'Hair later caused controversy by bringing a lawsuit against NASA over the reading from Genesis. O'Hair wished the courts to ban US astronauts — who were all Government employees — from public prayer in space. Though the case was rejected by the US Supreme Court for lack of jurisdiction, it caused NASA to be skittish about the issue of religion throughout the rest of the Apollo program. Buzz Aldrin, on Apollo 11, took communion on the surface of the moon after landing; he refrained from mentioning this publicly for several years, and only obliquely referred to it at the time.
The mission parameters for Apollo 8 differed significantly from those of previous flights, for several reasons. As the first manned spacecraft to orbit multiple celestial bodies, the mission recorded two different sets of orbital parameters. The mission was also the first to execute a translunar injection.
While in parking orbit around the Earth, Apollo 8 maintained altitude between a perigee of 112.8 miles (181.5 km) and an apogee of 118.9 miles (191.3 km). The inclination of this orbit, or its angle in relation to the equator, was 32.51°. Each orbit had a period of 88.17 minutes.
In contrast, the spacecraft orbited the Moon at more varying altitudes. At its lowest altitude above the moon's surface, the spacecraft had a pericynthion of 69.5 miles (111.9 km), while the highest altitude, or apocynthion, was 193.3 miles (311.1 km). The spacecraft took 128.7 minutes to complete each of its 10 circuits around the Moon, at an inclination of 12°.
The spacecraft began its translunar injection burn on December 21, 1968, at 15:41:38 UTC. The burn represented the second of two burns on the Saturn V rocket's S-IVB third stage. The rocket burned for a total of 318 seconds, propelling the 63,531 lb (28,817 kg) spacecraft from an Earth parking orbit velocity of 25,567 ft/s (7793 m/s) to a translunar trajectory velocity of 35,505 ft/s (10,822 m/s).
Apollo 8's historic mission has been shown and referenced in several forms, both documentary and fiction. The various television transmissions and 16 mm footage shot by the crew of Apollo 8 was compiled and released by Spacecraft Films as a three-disc DVD set in 2003. Portions of the Apollo 8 Mission can be seen in the 1989 documentary For All Mankind, which won the Grand Jury Prize at the Sundance Film Festival for Outstanding Documentary.
Portions of the Apollo 8 mission are dramatized in the miniseries From the Earth to the Moon episode "1968". The S-IVB stage of Apollo 8 was also portrayed as the location of an alien device in the 1970 UFO episode "Conflict".


An astronaut or cosmonaut ( ) is a person trained by a human spaceflight program to command, pilot, or serve as a crew member of a spacecraft.
While generally reserved for professional space travelers, the term is sometimes applied to anyone who travels into space, including scientists, politicians, journalists, and tourists.
Until 2003, astronauts were sponsored and trained exclusively by governments, either by the military, or by civilian space agencies. However, with the first sub-orbital flight of the privately-funded SpaceShipOne in 2004, a new category of astronaut was created: the commercial astronaut. With the rise of space tourism, NASA and the Russian Federal Space Agency agreed to use the term "spaceflight participant" to distinguish those space travelers from astronauts on missions coordinated by those two agencies.
The criteria for what constitutes human spaceflight vary. The Fédération Aéronautique Internationale (FAI) defines spaceflight as any flight above an altitude of. However, in the United States, professional, military, and commercial astronauts who travel above an altitude of are awarded astronaut wings.
As of February 7, 2008, a total of 470 humans from 34 countries have reached 100km or more in altitude, of which 467 reached Low Earth orbit or beyond.
Of these, 24 people have traveled beyond Low Earth orbit, to either lunar or trans-lunar orbit or to the surface of the moon; three of the 24 did so twice (Lovell, Young and Cernan).
According to the FAI guideline, 476 people qualify under the U. S. definition as having reached space.
Space travelers have spent over 30,400 astronaut-days (or a cumulative total of over 83 years) in space, including over 100 astronaut-days of spacewalks.
As of 2007, the man with the longest time in space is Sergei K. Krikalev, who has spent 803 days, 9 hours and 39 minutes, or 2.2 years, in space.
Sunita L. Williams holds the record for most time in space by a woman, with 195 days spent in space.
In the United States and many other English-speaking nations, a professional space traveler is called an astronaut. The term derives from the Greek words ástron (star) and nautes (sailor). The first known use of the term "astronaut" in the modern sense was by Neil R. Jones in his short story "The Death's Head Meteor" in 1930. The word itself had been known earlier. For example, in Percy Greg's 1880 book Across the Zodiac, "astronaut" referred to a spacecraft. In "Les Navigateurs de l'Infini (1925) of J.-H. Rosny aîné the word astronautique (astronautic) was used. The word may have been inspired by "aeronaut", an older term for an air traveler first applied (in 1784) to balloonists.
NASA applies the term astronaut to any crew member aboard NASA spacecraft bound for Earth orbit or beyond. NASA also uses the term as a title for those selected to join its Astronaut Corps.
By convention, an astronaut employed by the Russian Federal Space Agency (or its Soviet predecessor) is called a cosmonaut in English texts. The word is an anglicisation of the Russian word космонавт (transliteration: kosmonavt, ), which in turn derives from the Greek words kosmos (universe) and nautes (sailor). For the most part, "cosmonaut" and "astronaut" are synonyms in all languages, and the usage of choice is often dictated by political reasons.
On March 14, 1995, Norman Thagard became the first American to ride to space on board a Russian launch vehicle, arguably becoming the first "American cosmonaut" in the process.
In China, the term "yǔhángyuán" (宇航员) or "hángtiānyuán" (航天员) has long been used for astronauts. The phrase "tàikōng rén" (太空人, literally "space person") is often used in Taiwan and Hong Kong. Official English texts issued by the Chinese government use astronaut while texts in Russian use cosmonaut. The term taikonaut is used by some English-language news media organizations for professional space travelers from China. The origin of the term is unclear; as early as May 1998, Chiew Lee Yih (赵里昱) from Malaysia, used it in newsgroups, while Chen Lan, almost simultaneously, used it in Western media.
While no nation other than Russia (formerly the Soviet Union), the United States, and China has launched a manned spacecraft, several other nations have sent people into space in cooperation with one of these countries. Inspired partly by these missions, other synonyms for astronaut have entered occasional English usage. For example, the term spationaut (French spelling: spationaute) is sometimes used to describe French space travelers, from the Latin word spatium" or "space" and the Malaysian term "angkasawan" is used to describe participants in the Angkasawan program.
The first human in space was Russian Yuri Gagarin, who was launched into space on April 12 1961 aboard Vostok 1. The first woman was Russian Valentina Tereshkova, launched into space in June 1963 aboard Vostok 6.
Alan Shepard became the first American and second person in space on May 5, 1961, while the first American woman in space was Sally Ride, during Space Shuttle Challenger's mission STS-7, on June 18, 1983.
The first mission to orbit the moon was Apollo 8, which included William Anders who was born in Hong Kong, making him the first Asian-born astronaut in 1968. On 15 October 2003, Yang Liwei became China's first astronaut on the Shenzhou 5 spacecraft.
The Soviet Union, through its Intercosmos program, allowed people from other socialist countries to fly on its missions. An example is Vladimir Remek, a Czechoslovak, who became the first non-Soviet European in space in 1978 on a Russian Soyuz rocket.
On July 23, 1980, Pham Tuan of Vietnam became the first Asian in space when he flew aboard Soyuz 37.
Also in 1980, Cuban Arnaldo Tamayo Méndez became the first person of African descent to fly in space (the first person born in Africa to fly in space was Patrick Baudry, in 1985). In 1988, Abdul Ahad Mohmand became the first Afghan to reach space, spending nine days aboard the Mir space station.
With the larger number of seats available on the Space Shuttle, the U.S. began taking international astronauts. In April 1985, Taylor Wang became the first Chinese-born person in space; later that year, Rodolfo Neri Vela became the first Mexican-born person in space. In 1991, Helen Sharman became the first Briton to fly in space.
In 2002, Mark Shuttleworth became the first citizen of an African country to fly in space, as a paying spaceflight participant.
The youngest person to fly in space is Russian Gherman Titov, who was 25 years old when he flew Vostok 2. (Titov was also the first person to suffer space sickness).
The oldest person who has flown in space is John Glenn, who was 77 when he flew on STS-95.
The longest stay in space was 438 days, by Russian Valeri Polyakov.
As of 2006, the most spaceflights by an individual astronaut is seven, a record held by both Jerry L. Ross and Franklin Chang-Diaz. The furthest distance from Earth an astronaut has traveled was 401,056 km, during the Apollo 13 emergency.
The first non-governmental space traveler was Byron K. Lichtenberg, a researcher from the Massachusetts Institute of Technology who flew on STS-9 in 1983. In December 1990, Toyohiro Akiyama became the first paying space traveler as a reporter for Tokyo Broadcasting System, a visit to Mir as part of an estimated $12 million (USD) deal with a Japanese TV station, although at the time, the term used to refer to Akiyama was "Research Cosmonaut". Akiyama suffered severe space-sickness during his mission, which affected his productivity.
The first self-funded space tourist was Dennis Tito onboard the Russian spacecraft Soyuz TM-3 on 28 April 2001.
The first NASA astronauts were selected in 1959. Early in the space program, military jet test piloting and engineering training were often cited as prerequisites for selection as an astronaut at NASA, although neither John Glenn nor Scott Carpenter (of the Mercury Seven) had any university degree, in engineering or any other discipline at the time of their selection. Selection was initially limited to military pilots. The earliest astronauts for both America and Russia tended to be jet fighter pilots, and were often test pilots.
Once selected, NASA astronauts go through 20 months of training in a variety of areas, including training for extra-vehicular activity in a facility such as NASA's Neutral Buoyancy Laboratory. Astronauts-in-training may also experience short periods of weightlessness in aircraft called the "vomit comet", the nickname given to a pair of modified KC-135s (retired in 2000 and 2004 respectively, and replaced in 2005 with a C-9) which perform parabolic flights. Astronauts are also required to accumulate a number of flight hours in high-performance jet aircraft. This is mostly done in T-38 jet aircraft out of Ellington Field, due to its proximity to the Johnson Space Center. Ellington Field is also where the Shuttle Training Aircraft is maintained and developed, although most flights of the aircraft are done out of Edwards Air Force Base.
Mission Specialist Educators, or "Educator Astronauts", were first selected in 2004, and as of 2007, there are three NASA Educator astronauts: Joseph M. Acaba, Richard R. Arnold, and Dorothy Metcalf-Lindenburger.
Barbara Morgan, selected as back-up teacher to Christa McAuliffe in 1985, is considered to be the first Educator astronaut by the media, but she trained as a mission specialist.
The Educator Astronaut program is a successor to the Teacher in Space program from the 1980s.
At NASA, people who complete astronaut candidate training receive a silver lapel pin. Once they have flown in space, they receive a gold pin. U.S. astronauts who also have active-duty military status receive a special qualification badge, known as the Astronaut Badge, after participation on a spaceflight. The United States Air Force also presents an Astronaut Badge to its pilots who exceed 50 miles (80 km) in altitude.

A Modest Proposal: For Preventing the Children of Poor People in Ireland from Being a Burden to Their Parents or Country, and for Making Them Beneficial to the Publick, commonly referred to as A Modest Proposal, is a satirical pamphlet written and published by Jonathan Swift in 1729. Swift suggests in his essay that the Irish might ease their economic troubles by selling children born into poverty as food for rich gentlemen and ladies. The modern phrase "a modest proposal" derives from the work.
Swift goes to great lengths to support his argument, including a list of possible preparation styles for the children, and calculations showing the financial benefits of his suggestion. He uses common methods of argument throughout his essay, such as appealing to the authority of "a very knowing American of my acquaintance in London" and "the famous Psalmanazar, a native of the island Formosa" (who had already confessed to not being from Formosa in 1706). Swift couches his arguments in then-current events, exploiting common prejudice against Papists and pointing out their depredations of England. After enumerating the benefits of his proposal, Swift addresses possible objections including the depopulation of Ireland and a litany of other solutions which he dismisses as impractical.
Even today, readers unacquainted with its reputation as a satirical work often do not immediately realize that Swift was not seriously proposing cannibalism and infanticide. It is no longer true, as it was in Swift's time, that any educated reader would be familiar with the satires of Horace and Juvenal, and so recognize that Swift's essay follows the rules and structure of Latin satires.
often and earnestly invited to it.
into practice.
Most critics have been reluctant to analyze the targets of Swift’s A Modest Proposal because of a misreading of Swift’s intentions. According to Wittkowsky, critics wrongly assumed that A Modest Proposal targeted conditions in Ireland, instead of its true target, the "set of theories and attitudes which rendered such conditions possible".
One of Swift’s overarching targets in A Modest Proposal was the can-do spirit of the times that led people to devise a number of illogical schemes that would purportedly solve social and economic ills. Swift was especially insulted by projects that tried to fix population and labor issues with a simple cure-all solution. A memorable example of these sort of schemes "involved the idea of running the poor through a joint-stock company". In response, Swift’s Modest Proposal was "a burlesque of projects concerning the poor", that were in vogue during the early 18th century.
A Modest Proposal also targets the calculating way people perceived the poor in designing their projects. The pamphlet targets reformers who "regard people as commodities". In the piece, Swift adopts the "technique of a political arithmetician" to try and prove the utter ridiculousness of trying to prove any proposal with dispassionate statistics.
Critics differ about Swift’s intentions in using this faux-mathematical philosophy. Edmund Wilson argues that statistically "the logic of the "Modest proposal" can be compared with Marx's defense of crime in which he argues that crime takes care of the superfluous population". Wittkowsky counters that Swifts satiric use of statistical analysis is an effort to enhance his satire that "springs from a spirit of bitter mockery, not from the delight in calculations for their own sake".
Charles K. Smith argues that Swift’s rhetorical style persuades the reader to detest the speaker and pity the Irish. Swift’s specific strategy is twofold, using a "trap" (Lewis 135) to create sympathy for the Irish and a dislike of the narrator who, in the span of one sentence, "details vividly and with rhetorical emphasis the grinding poverty" but feels emotion solely for members of his own class. Swift’s use of gripping details of poverty and his narrator’s cool approach towards them creates "two opposing points of view" which "alienate the reader, perhaps unconsciously, from a narrator who can view with "melancholy" detachment a subject that Swift has directed us, rhetorically, to see in a much less detached way" (Lewis 136).
Swift has his proposer further degrade the Irish by using language ordinarily reserved for animals. Lewis argues that the speaker uses "the vocabulary of animal husbandry" (Lewis 138) to describe the Irish. Once the children have been commoditized, Swift’s rhetoric can easily turn "people into animals, then meat, and from meat, logically, into tonnage worth a price per pound" (Lewis 138).
Swift uses the Proposer’s serious tone to highlight the absurdity of his proposal. In making his argument, the speaker uses the conventional, text book approved order of argument from Swift’s time (Lewis 139). The contrast between the "careful control against the almost inconceivable perversion of his scheme" and "the ridiculousness of the proposal" create a situation in which the reader has "to consider just what perverted values and assumptions would allow such a diligent, thoughtful, and conventional man to propose so perverse a plan" (Lewis 139).
Some scholars have argued that "A Modest Proposal" was largely influenced and inspired by Tertullian’s Apology. While Tertullian’s Apology is a satirical attack against early Roman persecution of Christianity, Swift’s A Modest Proposal addresses the Anglo-Irish situation in the 1720s. James William Johnson believes that Swift saw major similarities between the two situations. Johnson notes Swift’s obvious affinity for Tertullain and the bold stylistic and structural similarities between the works A Modest Proposal and Apology. In structure, Johnson points out the same central theme; that of cannibalism and the eating of babies; and the same final argument; that "human depravity is such that men will attempt to justify their own cruelty by accusing their victims of being lower than human". Stylistically, Swift and Tertullain share the same command of sarcasm and language. In agreement with Johnson, Donald C. Baker points out the similarity between both author’s tones and use of irony. Baker notes the uncanny way that both authors imply an ironic "justification by ownership" over the subject of sacrificing children—Tertullian while attacking pagan parents, and Swift while attacking the English mistreatment of the Irish poor.
When taking up Jonathan Swift's pamphlet, A Modest Proposal, Robert Phiddian in his article "Have you eaten yet? The Reader in A Modest Proposal" focuses on two aspects of the piece: the voice of Swift and the voice of the Proposer. Phiddian stresses that a reader of the pamphlet must learn to distinguish between the satiric voice of Jonathan Swift and the apparent economic projections of the Proposer. He reminds readers that "there is a gap between the narrator’s meaning and the text’s, and that a moral-political argument is being carried out by means of parody".
While Swift’s proposal is therefore obviously not a serious economic projection, George Wittkowsky, author of "Swift’s Modest Proposal: The Biography of an Early Georgian Pamphlet," argues that it is nevertheless important to understand the economics of Swift’s time in order to fully understand the piece. Wittowsky argues that not enough critics have taken the time to directly focus on the economics of Swift’s historical situation within which A Modest Proposal was written. He states that "if one regards the Modest Proposal simply as a criticism of condition, about all one can say is that conditions were bad and that Swift's irony brilliantly underscored this fact". According to Wittkowsky that has been the understanding most critics have settled with over the years of reading Swift's proposal. On the other hand, Wittkowsky states that it is beneficial for the reader to be familiar with the economics of mercantilism and the theories of labor in 18th century England in order to fully understand the background of A Modest Proposal. He explains that with the start of a new industrial age in the 18th century it was believed that "people are the riches of the nation," and there was a general faith in an economy which paid its workers low wages—high wages meant workers would work less. Furthermore, "in the mercantilist view no child was too young to go into industry." Wittkowsky reminds us that it is important to remember that in the "Age of Swift" the "somewhat more humane attitudes of an earlier day had all but disappeared and the laborer had come to be regarded as a commodity". We can better understand Swift’s satirical cannibalistic proposal when we take into account this idea in his time of the human being as a number or commodity.
Louis A. Landa presents Swift’s A Modest Proposal as a critique of the popular and unjustified maxim of mercantilism in the eighteenth century that "people are the riches of a nation". Swift presents the dire state of Ireland and shows that mere population itself, in Ireland’s case, did not always mean greater wealth and economy. The uncontrolled maxim fails to take into account that a person that does not produce in an economic or political way makes a country poorer, not richer. Swift also recognizes the implications of such a fact in making mercantilist philosophy a paradox: the wealth of a country is based on the poverty of the majority of its citizens. Swift however, Landa argues, is not merely criticizing economic maxims but also addressing the fact that England was denying Irish citizens their natural rights and dehumanizing them by viewing them as a mere commodity.
A Modest Proposal is included in many literature programs as an example of early modern western satire. It also serves as an exceptional introduction to the concept and use of argumentative language, lending itself well to secondary and post-secondary essay courses. Outside of the realm of English studies, A Modest Proposal is a relevant piece included in many comparative and global literature and history courses, as well as those of numerous other disciplines in the arts, humanities, and even the social sciences.
The game Orphan Feast on Cartoon Network's AdultSwim website is loosely based on A Modest Proposal.
The show Sealab 2021 also references A Modest Proposal by the character of Jodene Sparks.
A Modest Proposal is also the name of The University of Texas at Dallas' Alternative Student Newspaper, the monthly opinion paper of the University.
In Hunter S. Thompson's Fear and Loathing in America: The Brutal Odyssey of an Outlaw Journalist, which contains hundreds of private letters written by Thompson over the years, contains a letter in which he uses A Modest Proposal's satire technique against the Vietnam War. Thompson writes a letter to a local Aspen newspaper informing them that on Christmas Eve he was going to burn a number of dogs, and hopefully any humans they find, using napalm to protest the burning of Vietnamese people occurring overseas.


The alkali metals are a series of elements comprising Group 1 (IUPAC style) of the periodic table: lithium (Li), sodium (Na), potassium (K), rubidium (Rb), caesium (Cs), and francium (Fr). (Hydrogen, although nominally also a member of Group 1, very rarely exhibits behavior comparable to the alkali metals). The alkali metals provide one of the best examples of group trends in properties in the periodic table, with well characterized homologous behavior down the group.
The alkali metals are all highly reactive and are rarely found in elemental form in nature. As a result, in the laboratory they are stored under mineral oil. They also tarnish easily and have low melting points and densities. Potassium and rubidium possess a weak radioactive characteristic (harmless) due to the presence of long duration radioactive isotopes.
The alkali metals are silver-colored (cesium has a golden tinge), soft, low-density metals, which react readily with halogens to form ionic salts, and with water to form strongly alkaline (basic) hydroxides. These elements all have one electron in their outermost shell, so the energetically preferred state of achieving a filled electron shell is to lose one electron to form a singly charged positive ion, or cation.
Hydrogen, with a solitary electron, is usually placed at the top of Group 1 of the periodic table, but it is not considered an alkali metal; rather it exists naturally as a diatomic gas. Removal of its single electron requires considerably more energy than removal of the outer electron for the alkali metals. As in the halogens, only one additional electron is required to fill in the outermost shell of the hydrogen atom, so hydrogen can in some circumstances behave like a halogen, forming the negative hydride ion. Binary compounds of hydride with the alkali metals and some transition metals have been prepared. Under extremely high pressure, such as is found at the core of Jupiter, hydrogen does become metallic and behaves like an alkali metal; see metallic hydrogen.
Alkali metals have the lowest ionization potentials in their respective periods, as removing the single electron from the outermost shell gives them the stable inert gas configuration. Their second ionization potentials are very high, as removing an electron from a species having a noble gas configuration is very difficult.
Alkali metals dissolve in liquid ammonia to give blue solutions that are paramagnetic.
As the solution approaches saturation, it becomes deep purple, then metallic.
Because the solution contains free electrons, it occupies more space than the sum of the volumes of the metal and ammonia. The presence of free electrons also makes these solutions very good reducing agents and good electrical conductors. Since they are easier to handle than the metals themselves they are sometimes used as substitutes.

In logic, the argument form or test form of an argument results from replacing the different words, or sentences, that make up the argument with letters, along the lines of algebra; the letters represent logical variables. The sentence forms which classify argument forms of common important arguments are studied in logic.
A All humans are mortal. Socrates is human. Therefore, Socrates is mortal.
All we have done in C is to put 'S' for 'human' and 'humans', 'P' for 'mortal', and a for 'Socrates'; what results, C, is the form of the original argument in A. So argument form C is the form of argument A. Moreover, each individual sentence of C is the sentence form of its respective sentence in A.
Attention is given to argument and sentence form, because form is what makes an argument valid or cogent. Some examples of valid argument forms are modus ponens, modus tollens, and the disjunctive syllogism. Two invalid argument forms are affirming the consequent and denying the antecedent.


An alphabet is a standardized set of letters — basic written symbols — each of which roughly represents a phoneme of a spoken language, either as it exists now or as it was in the past. There are other systems of writing such as logographies, in which each character represents a word, and syllabaries, in which each character represents a syllable, but alphabets are the most widespread writing system. Alphabets are in turn classified according to how they indicate vowels: as equal to consonants, as in Greek, as modifications of consonants, as in Hindi, or not at all, as in Arabic.
The word "alphabet" came into Middle English from the Late Latin Alphabetum, which in turn originated in the Ancient Greek Alphabetos, from alpha and beta, the first two letters of the Greek alphabet. The letters represent the Greek borrowing of the borrowing from Semitic aleph and bet. There are dozens of alphabets in use today. Most of them are composed of lines (linear writing); notable exceptions are Braille, fingerspelling, and Morse code.
The term alphabet prototypically refers to a writing system that has characters (graphemes) for representing both consonant and vowel sounds, even though there may not be a complete one-to-one correspondence between symbol and sound.
A grapheme is an abstract entity which may be physically represented by different styles of glyphs. There are many written entities which do not form part of the alphabet, including numerals, mathematical symbols, and punctuation. Some human languages are commonly written by using a combination of logograms (which represent morphemes or words) and syllabaries (which represent syllables) instead of an alphabet. Egyptian hieroglyphs and Chinese characters are two of the best-known writing systems with predominantly non-alphabetic representations.
Non-written languages may also be represented alphabetically. For example, linguists researching a non-written language (such as some of the indigenous Amerindian languages) will use the International Phonetic Alphabet to enable them to write down the sounds they hear.
Most, if not all, linguistic writing systems have some means for phonetic approximation of foreign words, usually using the native character set.
The history of the alphabet starts in ancient Egypt. By 2700 BCE Egyptian writing had a set of some 22 hieroglyphs to represent syllables that begin with a single consonant of their language, plus a vowel (or no vowel) to be supplied by the native speaker. These glyphs were used as pronunciation guides for logograms, to write grammatical inflections, and, later, to transcribe loan words and foreign names.
However, although seemingly alphabetic in nature, the original Egyptian uniliterals were not a system and were never used by themselves to encode Egyptian speech. In the Middle Bronze Age an apparently "alphabetic" system known as the Proto-Sinaitic script is thought by some to have been developed in central Egypt around 1700 BCE for or by Semitic workers, but only one of these early writings has been deciphered and their exact nature remains open to interpretation. Based on letter appearances and names, it is believed to be based on Egyptian hieroglyphs.
This script eventually developed into the Proto-Canaanite alphabet, which in turn was refined into the Phoenician alphabet. Note that the scripts mentioned above are not considered proper alphabets, as they all lack characters representing vowels. These early vowelless alphabets are called abjads, and still exist in scripts such as Arabic, Hebrew and Syriac.
Phoenician was the first major phonemic script. In contrast to two other widely used writing systems at the time, Cuneiform and Egyptian hieroglyphs, each of which contained thousands of different characters, it contained only about two dozen distinct letters, making it a script simple enough for common traders to learn. Another advantage to Phoenician was that it could be used to write down many different languages, since it recorded words phonemically.
The script was spread by the Phoenicians, whose Thalassocracy allowed the script to be spread across the Mediterranean. In Greece, the script was modified to add the vowels, giving rise to the first true alphabet. The Greeks took letters which did not represent sounds that existed in Greek, and changed them to represent the vowels. This marks the creation of a "true" alphabet, with the presence of both vowels and consonants as explicit symbols in a single script. In its early years, there were many variants of the Greek alphabet, a situation which caused many different alphabets to evolve from it.
The Cumae form was carried over to the Italian peninsula, where it gave rise to a variety of alphabets used to inscribe the Italic languages. One of these became the Latin alphabet, which was spread across Europe as the Romans expanded their empire. Even after the fall of the Roman state, the alphabet survived in intellectual and religious works. It eventually became used for the descendant languages of Latin (the Romance languages), and then for the other languages of Europe.
Another notable script is Elder Futhark, which is believed to have evolved out of one of the Old Italic alphabets. Elder Futhark gave rise to a variety of alphabets known collectively as the Runic alphabets. The Runic alphabets were used for Germanic languages from 100 AD to the late Middle Ages. Its usage was mostly restricted to engravings on stone and jewelry, although inscriptions have also been found on bone and wood. These alphabets have since been replaced with the Latin alphabet, except for decorative usage for which the runes remained in use until the 20th century.
The Glagolitic alphabet was the script of the liturgical language Old Church Slavonic, and became the basis of the Cyrillic alphabet. The Cyrillic alphabet is one of the most widely used modern alphabets, and is notable for its use in Slavic languages and languages within the former Soviet Union. Variants include the Bulgarian and Russian alphabets. The Glagolitic alphabet is believed to have been created by Saints Cyril and Methodius, while the Cyrillic alphabet was invented by the Bulgarian scholar Clement of Ohrid, who was their disciple. They feature many letters that appear to have been borrowed from or influenced by the Greek alphabet and the Hebrew alphabet.
Beyond the logographic Chinese writing, many phonetic scripts are in existence in Asia. The Arabic alphabet, Hebrew alphabet, Syriac alphabet, and other abjads of the Middle East are developments of the Aramaic alphabet, but because these writing systems are largely consonant-based they are often not considered true alphabets.
Most alphabetic scripts of India and Eastern Asia are descended from the Brahmi script, which is often believed to be a descendent of Aramaic, but this link is controversial. These scripts are abugidas, that is, they write syllables instead of individual sounds, so their status as alphabets is disputed.
In Korea, the Hangeul alphabet was created, although it may also have been derived from the Mongolian Phagspa script, which in turn was derived from the Brahmi script. Hangeul is a unique alphabet in a variety of ways: many of the letters are designed off of a sound's place of articulation, it was consciously designed by the government at the time, and it situates individual letters into syllable clusters with equal dimensions as Chinese characters to allow for mixed script writing.
Zhuyin (sometimes called Bopomofo) is an alphabet used to phonetically transcribe Mandarin Chinese in Mainland China and Taiwan, though its use in Mainland China today is limited. It developed out of a form of Chinese shorthand based on Chinese characters in the early 1900s. While Zhuyin is not used as a mainstream writing system, it is still often used in ways similar to a romanization system—that is, for aiding in pronunciation and as an input method for Chinese characters on computers and cell phones.
European alphabets, especially Latin and Cyrillic, have been adapted for many languages of Asia. Arabic is also widely used, sometimes as an abjad (as with Urdu and Persian) and sometimes as a complete alphabet (as with Kurdish and Uyghur).
The term "alphabet" is used by linguists and paleographers in both a wide and narrow sense. In the wider sense, an alphabet is a script that is segmental on the phoneme level, that is, that has separate glyphs for individual sounds and not for larger units such as syllables or words. In the narrower sense, some scholars distinguish "true" alphabets from two other types of segmental script, abjads and abugidas. These three differ from each other in the way they treat vowels: Abjads have letters for consonants and leave most vowels unexpressed; abugidas are also consonant-based, but indicate vowels with diacritics to or a systematic graphic modification of the consonants. In alphabets in the narrow sense, on the other hand, consonants and vowels are written as independent letters. The earliest known alphabet in the wider sense is the Wadi el-Hol script, believed to be an abjad, which through its successor Phoenician is the ancestor of modern alphabets, including Arabic, Greek, Latin (via the Old Italic alphabet), Cyrillic (via the Greek alphabet) and Hebrew (via Aramaic).
Thus the primary classification of alphabets reflects how they treat vowels. For tonal languages, further classification can be based on their treatment of tone, though names do not yet exist to distinguish the various types. Some alphabets disregard tone entirely, especially when it does not carry a heavy functional load, as in Somali and many other languages of Africa and the Americas. Such scripts are to tone what abjads are to vowels. Most commonly, tones are indicated with diacritics, the way vowels are treated in abugidas. This is the case for Vietnamese (a true alphabet) and Thai (an abugida). In Thai, tone is determined primarily by the choice of consonant, with diacritics for disambiguation. In the Pollard script, an abugida, vowels are indicated by diacritics, but the placement of the diacritic relative to the consonant is modified to indicate the tone. More rarely, a script may have separate letters for tones, as is the case for Hmong and Zhuang. For most of these scripts, regardless of whether letters or diacritics are used, the most common tone is not marked, just as the most common vowel is not marked in Indic abugidas; it Zhuyin not only is one of the tones unmarked, but there is a diacritic to indicate lack of tone, like the virama of Indic.
The number of letters in an alphabet can be quite small. The Book Pahlavi script, an abjad, had only twelve letters at one point, and may have had even fewer later on. Today the Rotokas alphabet has only twelve letters. (The Hawaiian alphabet is sometimes claimed to be as small, but it actually consists of 18 letters, including the ʻokina and five long vowels.) While Rotokas has a small alphabet because it has few phonemes to represent (just eleven), Book Pahlavi was small because many letters had been conflated, that is, the graphic distinctions had been lost over time, and diacritics were not developed to compensate for this as they were in Arabic, another script that lost many of its distinct letter shapes. For example, a comma-shaped letter represented g, d, y, k, or j. However, such apparent simplifications can perversely make a script more complicated. In later Pahlavi papyri, up to half of the remaining graphic distinctions of these twelve letters were lost, and the script could no longer be read as a sequence of letters at all, but instead each word had to be learned as a whole – that is, they had become logograms as in Egyptian Demotic.
The largest segmental script is probably an abugida, Devanagari. When written in Devanagari, Vedic Sanskrit has an alphabet of 53 letters, including the visarga mark for final aspiration and special letters for kš and jñ, though one of the letters is theoretical and not actually used. The Hindi alphabet must represent both Sanskrit and modern vocabulary, and so has been expanded to 58 with the khutma letters (letters with a dot added) to represent sounds from Persian and English.
The largest known abjad is Sindhi, with 51 letters. The largest alphabets in the narrow sense include Kabardian and Abkhaz (for Cyrillic), with 58 and 56 letters, respectively, and Slovak (for the Latin alphabet), with 46. However, these scripts either count di- and tri-graphs as separate letters, as Spanish did with ch and ll up to a recent time, or uses diacritics like Slovak č. The largest true alphabet where each letter is graphically independent is probably Georgian, with 41 letters.
Syllabaries typically contain 50 to 400 glyphs (though the Múra-Pirahã language of Brazil would require only 24 if it did not denote tone, and Rotokas would require only 30), and the glyphs of logographic systems typically number from the many hundreds into the thousands. Thus a simple count of the number of distinct symbols is an important clue to the nature of an unknown script.
It is not always clear what constitutes a distinct alphabet. French uses the same basic alphabet as English, but many of the letters can carry additional marks, such as é, à, and ô. In French, these combinations are not considered to be additional letters. However, in Icelandic, the accented letters such as á, í, and ö are considered to be distinct letters of the alphabet. In Spanish, ñ is considered a separate letter, but accented vowels such as á and é are not. Some adaptations of the Latin alphabet are augmented with ligatures, such as æ in Old English and Ȣ in Algonquian; by borrowings from other alphabets, such as the thorn þ in Old English and Icelandic, which came from the Futhark runes; and by modifying existing letters, such as the eth ð of Old English and Icelandic, which is a modified d. Other alphabets only use a subset of the Latin alphabet, such as Hawaiian, or Italian, which only uses the letters j, k, x, y and w in foreign words.
It is unknown if the earliest alphabets had a defined sequence. Some alphabets today, such as Hanunoo, are learned one letter at a time, in no particular order, and are not used for collation where a definite order is required. However, a dozen Ugaritic tablets from the fourteenth century BCE preserve the alphabet in two sequences. One, the ABGDE order later used in Phoenician, has continued with minor changes in Hebrew, Greek, Armenian, Gothic, Cyrillic, and Latin; the other, HMĦLQ, was used in southern Arabia and is preserved today in Ethiopic. Both orders have therefore been stable for at least 3000 years.
The Brahmic family of alphabets used in India abandoned the inherited order for one based on phonology: The letters are arranged according to how and where they are produced in the mouth. This organization is used in Southeast Asia, Tibet, Korean hangul, and even Japanese kana, which is not an alphabet. The historical order was also abandoned in Runic and Arabic, although Arabic retains the traditional "abjadi order" for numbering.
The Phoenician letter names, in which each letter is associated with a word that begins with that sound, continue to be used in Samaritan, Aramaic, Syriac, Hebrew, and Greek. However, they were abandoned in Arabic, Cyrillic, Latin, and Brahmic.
Each language may establish certain general rules that govern the association between letters and phonemes, but, depending on the language, these rules may or may not be consistently followed. In a perfectly phonological alphabet, the phonemes and letters would correspond perfectly in two directions: a writer could predict the spelling of a word given its pronunciation, and a speaker could predict the pronunciation of a word given its spelling. However, languages often evolve independently of their writing systems, and writing systems have been borrowed for languages they were not designed for, so the degree to which letters of an alphabet correspond to phonemes of a language varies greatly from one language to another and even within a single language.
National languages generally elect to address the problem of dialects by simply associating the alphabet with the national standard. However, with an international language with wide variations in its dialects, such as English, it would be impossible to represent the language in all its variations with a single phonetic alphabet.
Some national languages like Finnish have a very regular spelling system with a nearly one-to-one correspondence between letters and phonemes. Strictly speaking, there is no word in the Finnish language corresponding to the verb "to spell" (meaning to split a word into its letters), the closest match being a verb meaning to split a word into its syllables. Similarly, the Italian verb corresponding to 'spell', compitare, is unknown to many Italians because the act of spelling itself is almost never needed: each phoneme of Standard Italian is represented in only one way. However, pronunciation cannot always be predicted from spelling because certain letters are pronounced in more than one way. In standard Spanish, it is possible to tell the pronunciation of a word from its spelling, but not vice versa; this is because certain phonemes can be represented in more than one way, but a given letter is consistently pronounced. French, with its silent letters and its heavy use of nasal vowels and elision, may seem to lack much correspondence between spelling and pronunciation, but its rules on pronunciation are actually consistent and predictable with a fair degree of accuracy.
At the other extreme, however, are languages such as English, where the spelling of many words simply has to be memorized as they do not correspond to sounds in a consistent way. For English, this is because the Great Vowel Shift occurred after the orthography was established, and because English has acquired a large number of loanwords at different times retaining their original spelling at varying levels. However, even English has general, albeit complex, rules that predict pronunciation from spelling, and these rules are successful most of the time. Rules to predict spelling from the pronunciation have a high failure rate for English.
Sometimes, countries have the written language undergo a spelling reform in order to realign the writing with the contemporary spoken language. These can range from simple spelling changes and word forms to switching the entire writing system itself, as when Turkey switched from the Arabic alphabet to the Roman alphabet.
The sounds of speech of all languages of the world can be written by a rather small universal phonetic alphabet. A standard for this is the International Phonetic Alphabet.


In chemistry and physics, the atomic number (also known as the proton number) is the number of protons found in the nucleus of an atom. It is traditionally represented by the symbol Z. The atomic number uniquely identifies a chemical element. In an atom of neutral charge, atomic number is equal to the number of electrons.
The atomic number is closely related to the mass number, which is the number of protons and neutrons in the nucleus of an atom.
The atomic number originally was used to signify the element's location in the periodic table. Dmitri Mendeleev arranged the known elements in increasing order of atomic weight and grouped by their similar chemical properties. However, placing the elements in strict order of atomic weight resulted in some mismatches. Iodine and tellurium, if listed by atomic weight, appeared to be in the wrong order; and would fit better by chemical properties if their places in the table were swapped. Placing them in the order which fit their properties most closely, their number in the table was their atomic number. This number appeared to be related to the mass of the atom but, as the discrepancy showed, reflected some property other than mass.
The anomalies in this sequence were finally explained after research by Henry Gwyn Jeffreys Moseley in 1913. Moseley discovered a strict relationship between the x-ray diffraction spectra of elements, and their correct location in the periodic table. This led to the conclusion that the atomic number corresponds to the electric charge of the nucleus — the charge of the protons. The atomic number is the number of protons that is equal to the number of electrons. The proton charge is positive and the electron charge is negative.
Each element has a specific set of chemical properties as a consequence of the number of protons in its nucleus. The charge of an atom's nucleus defines its electron configuration based on principles of quantum mechanics. The form of each element's electron shells, particularly the valence shell, is the primary factor in determining its chemical bonding behavior.
The quest for new elements is usually described using atomic number. As of early 2007, elements with atomic numbers through 118 (excluding 117) have been discovered. Synthesis of new elements is accomplished by bombarding target atoms of heavy elements with ions, such that the sum of the atomic numbers of the target and ion elements equals the atomic number of the element being created. In general, the half-life becomes shorter as atomic number increases, though an "island of stability" may exist for undiscovered isotopes with certain numbers of protons and neutrons.


Anatomy (from the Greek anatomia, from ana: separate, apart from, and temnein, to cut up, cut open) is a branch of biology that is the consideration of the structure of living things. It is a general term that includes human anatomy, animal anatomy (zootomy) and plant anatomy (phytotomy). In some of its facets anatomy is closely related to embryology, comparative anatomy and comparative embryology, through common roots in evolution.
Anatomy is subdivided into gross anatomy (or macroscopic anatomy) and microscopic anatomy. Gross anatomy (also called topographical anatomy, regional anatomy, or anthropotomy) is the study of anatomical structures that can be seen by unaided vision. Microscopic anatomy is the study of minute anatomical structures assisted with microscopes, which includes histology (the study of the organisation of tissues), and cytology (the study of cells).
The history of anatomy has been characterized, over time, by a continually developing understanding of the functions of organs and structures in the body. Methods have also advanced dramatically, advancing from examination of animals through dissection of cadavers (dead human bodies) to technologically complex techniques developed in the 20th century.
Anatomy should not be confused with anatomical pathology (also called morbid anatomy or histopathology), which is the study of the gross and microscopic appearances of diseased organs.
Superficial anatomy or surface anatomy is important in anatomy being the study of anatomical landmarks that can be readily seen from the contours or the surface of the body. With knowledge of superficial anatomy, physicians or veterinary surgeons gauge the position and anatomy of the associated deeper structures.
Human anatomy, including gross human anatomy and histology, is primarily the scientific study of the morphology of the adult human body.
Generally, students of certain biological sciences, paramedics, physiotherapists, nurses and medical students learn gross anatomy and microscopic anatomy from anatomical models, skeletons, textbooks, diagrams, photographs, lectures and tutorials. The study of microscopic anatomy (or histology) can be aided by practical experience examining histological preparations (or slides) under a microscope; and in addition, medical students generally also learn gross anatomy with practical experience of dissection and inspection of cadavers (dead human bodies).
Human anatomy, physiology and biochemistry are complementary basic medical sciences, which are generally taught to medical students in their first year at medical school. Human anatomy can be taught regionally or systemically; that is, respectively, studying anatomy by bodily regions such as the head and chest, or studying by specific systems, such as the nervous or respiratory systems. The major anatomy textbook, Gray's Anatomy, has recently been reorganized from a systems format to a regional format, in line with modern teaching methods. A thorough working knowledge of anatomy is required by all medical doctors, especially surgeons, and doctors working in some diagnostic specialities, such as histopathology and radiology.
Academic human anatomists are usually employed by universities, medical schools or teaching hospitals. They are often involved in teaching anatomy, and research into certain systems, organs, tissues or cells.
Comparative anatomy relates to the comparison of anatomical structures (both gross and microscopic) in different animals.
Anthropological anatomy or physical anthropology relates to the comparison of the anatomy of different races of humans.
Artistic anatomy relates to anatomic studies for artistic reasons.

Arguments of this form are invalid (except in the rare cases where such an argument also instantiates some other, valid, form). In effect, this means that arguments of this form do not give good reason to establish their conclusions, even if their premises are true.
The name affirming the consequent derives from the premise Q, which affirms the "then" clause of the conditional premise.
But many illnesses cause sore throat, such as the common cold or strep throat. Thus this argument is weak at best.
The above argument may be valid, but only if the claim "if he's outside, then he's not inside" follows from the first premise. Even in such a case, however, the validity stems not from affirming the consequent, but from the form modus ponens.
Although affirming the consequent is an invalid inference, it is defended by some as an acceptable type of inductive reasoning, sometimes under the name "inference to the best explanation".


Andrei Arsenyevich Tarkovsky () (April 4, 1932 - December 29, 1986) was a Russian film director, writer and opera director. Although Tarkovksy directed only seven feature films during his twenty-year active career, he is widely regarded as one of the most important and influential filmmakers of the late 20th century. He attained critical acclaim for directing such films as Andrei Rublev, Solaris and Stalker.
Tarkovsky also worked extensively as a screenwriter, film editor, film theorist and theater director. He directed most of his films in the Soviet Union, with the exception of his last two films which were produced in Italy and Sweden. His films are characterized by Christian spirituality and metaphysical themes, extremely long takes, lack of conventional dramatic structure and plot, and memorable images of exceptional beauty.
Tarkovsky was born in the village of Zavrazhye in Kostroma Province as the child of the poet and translator Arseny Alexandrovich Tarkovsky and Maria Ivanova Vishnyakova, a graduate of the Maxim Gorky Literature Institute. In 1934, his sister Marina was born. He spent his childhood in Yuryevets in the Ivanovo Province. In 1937, his father left the family, subsequently volunteering for the army in 1941. Tarkovsky stayed with his mother, moving with her and his sister to Moscow, where she worked as a proofreader in a printing press. In 1939, Tarkovsky enrolled at the Moscow School № 554. During the war, Tarkovsky, his mother and his sister Marina evacuated to Yuryevets, living with his maternal grandmother. In 1943, the family returned to Moscow. Tarkovsky continued his studies at his old school, where the poet Andrey Voznesensky was one of his classmates. He also learned the piano at a music school and attended classes at an art school. The family lived on Shshipok Street in the Zamoskvorechye District in Moscow. From November 1947 to spring 1948, he was in a hospital with tuberculosis. Many themes of his childhood - the evacuation, his mother and her two children, the withdrawn father, the time in the hospital - feature prominently in his film The Mirror.
Directly after high school graduation, from 1951 to 1952, Tarkovsky studied Arabic at the Oriental Institute in Moscow, a branch of the Academy of Sciences of the USSR. He did not finish his studies and dropped out to work for the Academy of Science Institute for Non-Ferrous Metals and Gold, as a prospector. He participated in a year-long research expedition to the river Kureikye near Turukhansk in the Krasnoyarsk Province. During this time in the Taiga Tarkovsky decided to study film.
Upon return from the research expedition in 1954 Tarkovsky applied at the State Institute of Cinematography (VGIK) and was admitted to the film-directing-program. He was in the same class as Irma Raush, whom he married in April 1957.
The early Khrushchev era offered unique opportunities for young film directors. Before 1953, annual film production was low and most films were directed by veteran directors. After 1953, more films were produced, many of them by young directors. The Khrushchev Thaw opened Soviet society and allowed, to some degree, Western literature, films and music. This allowed Tarkovksy to see films of the Italian neorealists and the French New Wave, and of directors such as Kurosawa, Buñuel, Bergman, Bresson and Mizoguchi. Tarkovsky absorbed the idea of the auteur as a necessary condition for creativity.
Tarkovsky’s teacher and mentor was Mikhail Romm, who taught many film students who would later become famous and influential film directors. In 1956, Tarkovsky directed his first student short film, The Killers, after a short story of Ernest Hemingway. The short film There Will Be No Leave Today and the screenplay Concentrate followed in 1958 and 1959.
During his third year at the VGIK, Tarkovsky met Andrei Konchalovsky. They found that they had much in common as they liked the same film directors and shared the same ideas on cinema and films. In 1959, they wrote the script Antarctica - Distant Country, which was later published in the Moskovskiy Komsomolets. Tarkovsky submitted the script to Lenfilm, but was rejected. They were more successful with the script The Steamroller and the Violin, which they sold to Mosfilm. This film became Tarkovsky’s diploma film, earning him his diploma in 1960 and winning him the first prize at the New York Student Film Festival in 1961.
Tarkovsky's first feature film was "Ivan's Childhood" in 1962. He had inherited the film from director Eduard Abalov, who had to abort the project. The film earned Tarkovksy international acclaim and won him the Golden Lion award at the Venice Film Festival in 1962. In the same year, on September 30, his first son Arseny (called Senka in Tarkovsky's diaries) Tarkovsky was born.
In 1965, he directed the film Andrei Rublev about the life of Andrei Rublev, the 15th century Russian icon painter. Andrei Rublev was not immediately released after completion due to problems with Soviet authorities. Tarkovsky had to cut the film several times, resulting in several different versions of varying lengths. A version of the film was presented at the Cannes Film Festival in 1969 and won the FIPRESCI prize. The film was officially released in the Soviet Union in a cut version in 1971.
He divorced his wife, Irma Raush, in 1970. In the same year, he married Larissa Kizilova (née Egorkina), who had been a production assistant for the film Andrei Rublev. Their son Andrei Tarkovsky Jr. was born in the same year on August 7.
In 1972, he completed his film Solaris, an adaption of the novel Solaris by Stanisław Lem. He had worked on this project together with the screenwriter Fridrikh Gorenshtein as early as 1968. The film was presented at the Cannes Film Festival and won the Grand Prix Spécial du Jury and the FIPRESCI prize and was nominated for the Palme d'Or. From 1973 to 1974, he shot the film The Mirror, a highly autobiographical film drawing on his childhood experience and incorporating some of his father's poems. Tarkovsky had worked on the screenplay for this film since 1967, under the consecutive titles Confession, White day and A white, white day. From the beginning the film was not well received by Soviet authorities due to its content and its perceived elitist nature. Presumably these difficulties made Tarkovsky toy with the idea of going abroad and producing a film outside the Soviet film industry.
During 1975, Tarkovsky also worked on the screenplay Hoffmanniana, about the German writer and poet E. T. A. Hoffmann. In December 1976, he directed Hamlet, his first and only stage play, at the Lenkom Theatre in Moscow. The main role was played by Anatoly Solonitsyn, who also acted in several of Tarkovsky's films. At the end of 1978, he also wrote the screenplay Sardor together with the writer Aleksandr Misharin.
The last film Tarkovsky directed in the Soviet Union was Stalker, inspired by the novel Roadside Picnic by Arkady and Boris Strugatsky. Work on this film began in 1976. The production was mired in troubles; improper development of the negatives had ruined all the exterior shots. Tarkovsky's relationship with the cinematographer Georgy Rerberg deteriorated to the point where Tarkovsky hired Alexander Knyazhinsky as a new first cinematographer. Furthermore, Tarkovsky suffered a heart attack in April 1978, resulting in further delay. The film was completed in 1979 and won the Prize of the Ecumenical Jury at the Cannes Film Festival.
During the summer of 1979, Tarkovsky traveled to Italy, where he shot the documentary Voyage in Time, together with his longtime friend Tonino Guerra. Tarkovksy returned to Italy in 1980 for an extended trip during which he and Tonino Guerra completed the script for the film Nostalghia. During 1981 he traveled to the United Kingdom and Sweden. During his trip to Sweden he had considered defecting the Soviet Union, but ultimately decided to return because of his wife and his son.
Tarkovsky returned to Italy in 1982 to start shooting Nostalghia. He never went back to his home country. As Mosfilm withdrew from the project, he had to complete the film with financial support provided by the Italian RAI. Tarkovsky completed the film in 1983. Nostalghia was presented at the Cannes Film Festival and won the Grand Prix Spécial du Jury, the FIPRESCI prize and the Prize of the Ecumenical Jury. Soviet authorities prevented the film from winning the Palme d'Or, a fact that hardened Tarkovsky's resolve to never work in the Soviet Union again. In the same year, he also arranged the opera Boris Godunov at the Royal Opera House in London under the musical direction of Claudio Abbado.
He spend most of 1984 preparing the film The Sacrifice. At a press conference in Milano on July 10, 1984 he announced that he would never return to the Soviet Union and would remain in the West. At that time, his son Andrei Jr. was still in the Soviet Union and not allowed to leave the country.
During 1985, he shot the film The Sacrifice in Sweden. At the end of the year he was diagnosed with terminal lung cancer. In January 1986, he began treatment in Paris, and was joined there by his wife and his son, who were finally allowed to leave the Soviet Union. The Sacrifice was presented at the Cannes Film Festival and received the Grand Prix Spécial du Jury, the FIPRESCI prize and the Prize of the Ecumenical Jury. As Tarkovsky was unable to attend due to his illness, the prizes were collected by his son, Andrei Jr.
Tarkovsky kept fairly regular diaries from 1970 until shortly before his death. The last entry was on December 15, 1986. His last words are "But now I have no strength left - that is the problem". The diaries are sometimes also known as Martyrolog and have been published posthumously in 1989, and in English in 1991.
Tarkovsky died on December 29, 1986 in Paris at age 54. He was buried on January 3, 1987 in the Sainte-Geneviève-des-Bois Russian Cemetery in Sainte-Geneviève-des-Bois in France. The inscription on his grave stone, which was created by the Russian sculptor Ernst Neizvestny, reads To the man who saw the Angel.
Tarkovsky is mainly known as a director of films. During his career he directed only seven feature films, and three short films during his time at the film school. He also wrote several screenplays, directed stage play Hamlet in Moscow, the opera Boris Godunov in London, and directed a radio production of the short story Turnabout by William Faulkner. He also wrote Sculpting In Time, a book on film theory.
Tarkovsky's first feature film was "Ivan's Childhood in 1962. He then directed in the Soviet Union Andrei Rublev in 1966, Solaris in 1972, Mirror in 1975 and Stalker in 1979. The documentary Voyage in Time was produced in Italy in 1982, as was Nostalghia in 1983. His last film The Sacrifice" was produced in Sweden in 1986. Tarkovsky was personally involved in writing the screenplays for all his films, sometimes together with a co-writer. To Tarkovsky a director who realizes somebody else's screenplay without being involved in the creation of the screenplay becomes a mere illustrator, resulting in dead and monotonous films.
Tarkovsky became a film director during the mid and late 1950s, a period during which Soviet society opened to foreign films, literature and music. This allowed Tarkovksy to see films of European, American and Japanese directors, an experience which influenced his own film making. His teacher and mentor at the film school, Mikhail Romm, allowed his students considerable freedom and emphasized the independence of the film director.
Tarkovsky was, according to Shavka Abdusalmov, a fellow student at the film school, fascinated by Japanese films. He was amazed by how every character on the screen is exceptional and how everyday events such as a Samurai cutting bread with his sword are elevated to something special and put into the limelight.
In 1972, Tarkovsky told film historian Leonid Kozlov his ten favorite films. The list includes Diary of a country priest and Mouchette by Robert Bresson, Winter Light, Wild Strawberries and Persona by Ingmar Bergman, Nazarin by Luis Buñuel, City Lights by Charlie Chaplin, Ugetsu by Kenji Mizoguchi, Seven Samurai by Akira Kurosawa and Woman in the Dunes by Hiroshi Teshigahara. Among his favorite directors were Luis Buñuel, Kenji Mizoguchi, Ingmar Bergman, Robert Bresson, Akira Kurosawa, Michelangelo Antonioni, Jean Vigo and Carl Theodor Dreyer.
With the exception of City Lights, the list does not contain any films or directors of the early silent era. The reason is that Tarkovsky saw film as an art as only a relatively recent phenomenon, with the early film-making forming only a prelude. The list has also no films or directors from Tarkovsky's native Russia, although he rated Soviet directors such as Boris Barnet and Alexander Dovzhenko highly.
Tarkovsky's films are characterised by Christian and metaphysical themes, extremely long takes, and memorable images of exceptional beauty. Recurring motifs in his films are dreams, memory, childhood, running water accompanied by fire, rain indoors, reflections, levitation, and characters re-appearing in the foreground of long panning movements of the camera.
Tarkovsky included levitation scenes into several of his films, most notably Solaris. To him these scenes possess great power and are used for its photogenic value and its magic inexplicability. Likewise, water is also used by him for its photogenic value and its beauty, in particular in the form of brooks or running water.
Tarkovsky developed a theory of cinema that he called "sculpting in time". By this he meant that the unique characteristic of cinema as a medium was to take our experience of time and alter it. Unedited movie footage transcribes time in real time. By using long takes and few cuts in his films, he aimed to give the viewers a sense of time passing, time lost, and the relationship of one moment in time to another.
Up to, and including, his film Mirror, Tarkovsky focused his cinematic works on exploring this theory. After Mirror, he announced that he would focus his work on exploring the dramatic unities proposed by Aristotle: a concentrated action, happening in one place, within the span of a single day.
Several of Tarkovsky's films are shot both in color and black and white, including for example Andrei Rublev which features an epilogue in color, and Solaris and Mirror, which feature several black and white sequences. In 1966, in an interview conducted shortly after finishing Andrei Rublev, Tarkovsky dismisses color film as a "commercial gimmick" and doubts that contemporary films meaningfully use color. He claims that in everyday life one does not consciously notice colors most of the time. Hence in film color should be used mainly to emphasize certain moments, but not all the time as this distracts the viewer. To him, films in color are like moving paintings or photographs, which are too beautiful to be a realistic depiction of life.
Numerous awards were bestowed on Tarkovsky throughout his lifetime. At the Venice Film Festival he was awarded the Golden Lion. At the Cannes Film Festival he won several times the FIPRESCI prize, the Prize of the Ecumenical Jury and the Grand Prix Spécial du Jury. He was also nominated for the "Palme d'Or two times. In 1987, the British Academy of Film and Television Arts awarded the BAFTA Award for Best Foreign Language Film to The Sacrifice.
Under the influence of Glasnost and Perestroika, Tarkovsky was finally recognized in the Soviet Union in the fall of 1986, shortly before his death, by a retrospective of his films in Moscow. After his death, an entire issue of the film magazine Iskusstvo Kino was devoted to Tarkovsky. In their obituaries, the film committee of the Council of Ministers of the USSR and the Union of Soviet Film Makers expressed their sorrow that Tarkovsky had to spend the last years of his life in exile.
Posthumously, he was awarded the USSR State Prize in 1989 and the Lenin Prize in 1990, the two highest state honors in the Soviet Union. In 1989 the Andrei Tarkovsky Memorial Prize was established, with its first recipient being the Russian animator Yuriy Norshteyn. Since 1993, the Moscow International Film Festival awards the annual Andrei Tarkovsky Award". In 1996 the Andrei Tarkovsky Museum opened in Yuryevets, his childhood town. A minor planet, 3345 Tarkovskij, discovered by Soviet astronomer Lyudmila Georgievna Karachkina in 1982 has also been named after him.
Tarkovsky has been the subject of several documentaries. Most notable are the 1988 documentary Moscow Elegy, by the Russian film director Alexander Sokurov. Sokurov's own work has been heavily influenced by Tarkovsky. The film consists mostly of narration over stock footage from Tarkovsky's films. Directed by Andrei Tarkovsky is 1988 documentary film by Michal Leszczylowski, an editor of the film The Sacrifice. Film director Chris Marker produced the television documentary One Day in the Life of Andrei Arsenevich as an homage to Andrei Tarkovsky in 2000.


Ambiguity is the property of being ambiguous, where a word, term, notation, sign, symbol, phrase, sentence, or any other form used for communication, is called ambiguous if it can be interpreted in more than one way. Ambiguity is distinct from vagueness, which arises when the boundaries of meaning are indistinct. Ambiguity is context-dependent: the same communication may be ambiguous in one context and unambiguous in another context. For a word, ambiguity typically refers to an unclear choice between different definitions as may be found in a dictionary. A sentence may be ambiguous due to different ways of parsing the same sequence of words.
Lexical ambiguity arises when context is insufficient to determine the sense of a single word that has more than one meaning. For example, the word "bank" has several distinct definitions, including "financial institution" and "edge of a river," but if someone says "I deposited $100 in the bank," most people would not think you used a shovel to dig in the mud. The word "run" has 130 ambiguous definitions in some lexicons. "Biweekly" can mean "fortnightly" (once every two weeks - 26 times a year), OR "twice a week" (104 times a year). Stating a specific context like "meeting schedule" does NOT disambiguate "biweekly." Many people believe that such lexically-ambiguous, miscommunication-prone words should be avoided altogether, since the user generally has to waste time, effort, and attention span to define what is meant when they are used.
The use of multi-defined words requires the author or speaker to clarify their context, and sometimes elaborate on their specific intended meaning (in which case, a less ambiguous term should have been used). The goal of clear concise communication is that the receiver(s) have no misunderstanding about what was meant to be conveyed. An exception to this could include a politician whose "wiggle words" and obfuscation are necessary to gain support from multiple constituent (politics) with mutually exclusive conflicting desires from their candidate of choice. Ambiguity is a powerful tool of political science.
More problematic are words whose senses express closely-related concepts. "Good," for example, can mean "useful" or "functional" (That’s a good hammer), "exemplary" (She’s a good student), "pleasing" (This is good soup), "moral" (a good person versus the lesson to be learned from a story), "righteous", etc. "I have a good daughter" is not clear about which sense is intended. The various ways to apply prefixes and suffixes can also create ambiguity ("unlockable" can mean "capable of being unlocked" or "impossible to lock", and therefore should not be used).
Syntactic ambiguity arises when a sentence can be parsed in more than one way. "He ate the cookies on the couch," for example, could mean that he ate those cookies which were on the couch (as opposed to those that were on the table), or it could mean that he was sitting on the couch when he ate the cookies.
Spoken language can contain many more types of ambiguities, where there is more than one way to compose a set of sounds into words, for example "ice cream" and "I scream." Such ambiguity is generally resolved based on the context. A mishearing of such, based on incorrectly-resolved ambiguity, is called a mondegreen.
Semantic ambiguity arises when a word or concept has an inherently diffuse meaning based on widespread or informal usage. This is often the case, for example, with idiomatic expressions whose definitions are rarely or never well-defined, and are presented in the context of a larger argument that invites a conclusion.
For example, "You could do with a new automobile. How about a test drive?" The clause "You could do with" presents a statement with such wide possible interpretation as to be essentially meaningless. Lexical ambiguity is contrasted with semantic ambiguity. The former represents a choice between a finite number of known and meaningful context-dependent interpretations. The latter represents a choice between any number of possible interpretations, none of which may have a standard agreed-upon meaning. This form of ambiguity is closely related to vagueness.
Semantic ambiguity reveals usually in funny forms at the translation to other languages; and especially at the multiple translations, for example, from language A to language B and then from language B to language C. (The resulting C-code is unlikely to run well!).
Words "run", "flesh", "file", "archieve" provide rich filed for ambiguity. Imagine, how can sound the sentence about electric cirquits in railroads: "the naked conductor runs along the wagon".
Philosophers (and other users of logic) spend a lot of time and effort searching for and removing (or intentionally adding) ambiguity in arguments, because it can lead to incorrect conclusions and can be used to deliberately conceal bad arguments. For example, a politician might say "I oppose taxes that hinder economic growth." Some will think he opposes taxes in general, because they hinder economic growth. Others may think he opposes only those taxes that he believes will hinder economic growth (although in writing, the correct insertion or omission of a comma after "taxes" and the use of "which" can help reduce ambiguity here. For the first meaning, ", which" is properly used in place of "that"), or restructure the sentence to completely eliminate possible misinterpretation. The devious politician hopes that each constituent (politics) will interpret the above statement in the most desirable way, and think the politician supports everyone's opinion. However, the opposite can also be true - An opponent can turn a positive statement into a bad one, if the speaker uses ambiguity (intentionally or not). The logical fallacies of amphiboly and equivocation rely heavily on the use of ambiguous words and phrases.
In literature and rhetoric, on the other hand, ambiguity can be a useful tool. Groucho Marx’s classic joke depends on a grammatical ambiguity for its humor, for example: "Last night I shot an elephant in my pajamas. What he was doing in my pajamas I’ll never know." Ambiguity can also be used as a comic device through a genuine intention to confuse, as does Magic: The Gathering's Unhinged © Ambiguity, which makes puns with homophones, mispunctuation, and run-ons: "Whenever a player plays a spell that counters a spell that has been played[,] or a player plays a spell that comes into play with counters, that player may counter the next spell played[,] or put an additional counter on a permanent that has already been played, but not countered." Songs and poetry often rely on ambiguous words for artistic effect, as in the song title "Don’t It Make My Brown Eyes Blue" (where "blue" can refer to the color, or to sadness).
In narrative, ambiguity can be introduced in several ways: motive, plot, character. F. Scott Fitzgerald uses the latter type of ambiguity with notable effect in his novel The Great Gatsby.
All religions debate the orthodoxy or heterodoxy of ambiguity. Christianity and Judaism employ the concept of paradox synonymously with 'ambiguity'. Ambiguity within Christianity (and other religions) is resisted by the conservatives and fundamentalists, who regard the concept as equating with 'contradiction'. Non-fundamentalist Christians and Jews endorse Rudolf Otto's description of the sacred as 'mysterium tremendum et fascinans', the awe-inspiring mystery which fascinates humans.
Abbreviations form one of the richest sources of ambiguity, see List of classical abbreviations, (which is still far from complete).
For example, AU may mean Atomic Unit, Astronomical unit, as well as Arbitrary Unit, American University, and a lot of other things. Simple transmutation of the same two letters gives University of Arizona (which is 200 km away from the Arizona State University), United Airlines, Unidad Administrativa (Spanish) and so on.
Many cryptic acronyms spell words that also have a different meaning, such as the "Rental Update Notification," "Research Unit in Networking," or "Resource Utilization Number" (RUN), which also has 130 other formally-defined meanings. Common words like "RUN" make very-poor miscommunition-prone acronyms, and therefore should generally be avoided. The "IBM" TLA is very well known in most contexts, but Acronym Finder has over 200 definitions for IBM.
One of the humorous statements is: "All TLAs are ambiguous." TLA may mean Two-Letter Acronym, Three-Letter Acronym, etc. either one of which is true. BUT, the unique airport code for Teller Alaska (TLA) is not ambiguous (within an airplane navigation system database).
Metonymy involves the use of the name of a subcomponent part as an abbreviation, or jargon, for the name of the whole object (for example "wheels" to refer to a car, or "flowers" to refer to beautiful offspring, an entire plant, or a collection of blooming plants). In modern vocabulary critical semiotics, metonymy encompasses any potentially-ambiguous word substitution that is based on contextual contiguity (located close together), or a function or process that an object performs, such as "sweet ride" to refer to a nice car. Metonym miscommunication is considered a primary mechanism of linguistic humour. but ambiguity has often led to serious/expensive/deadly mistakes.
(1) Autonomous departments can have many different meanings for the same word: i.e. different point of view (view (database), model-view-controller), levels of abstraction / context-specific detail, or homonyms (like "2", "two", "to", and "too"; "your" and "you're"). Spell checkers can misinterpret these ambiguities, contractions, and improper usage. Computer-automated voice dictation systems (like NaturallySpeaking) require sophisticated context-analysis algorithms with user-specific usage customization preferences, and they still make some mistakes.
(2) The same concept (object, process, or thing) may have two-or-more very-different synonym names within the enterprise, industry and government.
These types of ambiguity are further compounded by the common use of departmental abbreviations, jargon, or acronyms that are quite context-specific. Familiar abbreviations accelerate communication within a well-known context (department), but they INCREASE critical enterprise miscommunication between departments.
An Enterprise Architecture glossary must disambiguate such miscommunication, specify context for every important definition (and possibly hyperlink to more-detailed documentation, or the named system, process, or form itself). The Internet / Intranet now makes this much easier to do, and enterprise internal-and-external communication quality. Enterprise application integration and inter-departmental metadata management are therefore improving greatly. The enterprise disambiguation glossary acts somewhat like a vocabulary-based search engine, to help improve reuse of previously-developed concepts. The glossary is also reducing redundancy and reinventing the wheel, to cut costs, and improve quality, consistency and productivity.
(2) Eliminate the need for each piece of internal documentation to develop its own unique context-specific glossary attachment (saving even more time, effort, and redundant, inconsistent, voluminous, information storage space, publication fees, access time, and data-retrieval transportation cost).
An increasing amount of research is concentrating on how people react and respond to ambiguous and uncertain situations. Much of this focuses on ambiguity tolerance. A number of correlations have been found between an individual’s reaction and tolerance to ambiguity and a range of factors.
Apter and Desselles (2001) for example, found a strong correlation with such attributes and factors like a greater preference for safe as opposed to risk based sports, a preference for endurance type activities as opposed to explosive activities, a more organised and less casual lifestyle, greater care and precision in descriptions, a lower sensitivity to emotional and unpleasant words, a less acute sense of humour, engaging a smaller variety of sexual practices than their more risk comfortable colleagues, a lower likelihood of the use of drugs, pornography and drink, a greater likelihood of displaying obsessional behaviour.
In the field of leadership Wilkinson (2006) found strong correlations between an individual leaders reaction to ambiguous situations and the Modes of Leadership they use, the type of creativity (Kirton (2003) and how they relate to others.
Ambiguity, in law, is of two kinds, patent and latent.
Patent ambiguity is that ambiguity which is apparent on the face of an instrument to any one perusing it, even if he be unacquainted with the circumstances of the parties. In the case of a patent ambiguity parol evidence is admissible to explain only what has been written, not what it was intended to write. For example, in Saunderson v. Piper, 18 39, 5 B.N.C. 425, where a bill was cdrawn in figures for X245 and in words for two hundred pounds, evidence that "and forty-five" had been omitted by mistake was rejected. But where it appears from the general context of the instrument what the parties really meant, the instrument will be construed as if there was no ambiguity, as in Saye and Sele's case, io Mod. 46, where the name of the grantor had been omitted in the operative part of a grant, but, as it was clear from another part of the grant who he was, the deed was held to be valid.
Latent ambiguity is where the wording of an instrument is on the face of it clear and intelligible, but may, at the same time, apply equally to two different things or subject matters, as where a legacy is given "to my nephew, John," and the testator is shown to have two nephews of that name. A latent ambiguity may be explained by parol evidence, for, as the ambiguity has been brought about by circumstances extraneous to the instrument, the explanation must necessarily be sought for from such circumstances.
Some languages have been created with the intention of avoiding ambiguity, especially lexical ambiguity. Lojban and Loglan are two related languages which have been created with this in mind. The languages can be both spoken and written. These languages are intended to provide a greater technical precision over natural languages, although historically, such attempts at language improvement have been criticized. Languages composed from many diverse sources contain much ambiguity and inconsistity. The many exceptions to syntax and semantic rules are time-consuming and difficult to learn.
Mathematical notation, widely used in physics and other sciences, avoids many ambiguities compared to expression in natural language. However, for various reasons, several lexical, syntactic and semantic ambiguities remain.
Argument.
The concept of mathematical functions uses the term argument, it is independent variable; and the dependent variable is experessed as function of argument.
Also, dealing with complex numbers, various representations are used:.
Real numbers and are called real part and imaginary part., or, causing confusions.
Ambiguous espressions often appear in physical and mathematical texts.
It is common practice to omit multiplication signs in mathematical expressions. Also, it is common, to give the same name to a variable and a function, for example, Then, if one sees, there is no way to distinguish, does it mean multiplied by, or function evaluated at argument equal to. In each case of use of such notations, the reader is supposed to be able to perform the deduction and reveal the true meaning.
Creators of algorithmic languages try to avoid ambiguities. Many algorithmic languages (C++, MATLAB, Fortran, Maple) require the character * as symbol of multiplication. The language Mathematica allows the user to omit the multiplication symbol, but requires square brackets to indicate the argument of a function; square brackets are not allowed for grouping of expressions. Fortran, in addition, does not allow use of the same name (identifier) for different objects, for example, function and variable; in particular, the expression f=f(x) is qualified as an error.
The order of operations may depend on the context. In most programming languages, the operations of division and multiplication have equal priority and are executed from left to right. Until the last century, many editorials assumed that multiplication is performed first, for example, is interpreted as ; in this case, the insertion of parentheses is required when translating the formulas to an algorithmic language. In addition, it is common to write an argument of a function without parenthesis, which also may lead to ambiguity.
Sometimes, one uses italics letters to denote elementary functions. although in a slideshow, it may mean.
Comma in subscripts and superscripts sometimes is omitted; it is also ambiguous notation. and, or it is indication to a three-valent tensor.
The writing of instead of may mean that the writer either is stretched in space (for example, to reduce the publication fees, or aims to increase number of publications without considering readers. The same may apply to any other use of ambiguous notations. which could be understood to mean either or. which by convention means, though it might be thought to mean since means.
It is common to define the coherent states in quantum optics with and states with fixed number of photons with. Then, there is an "unwritten rule": the state is coherent if there are more Greek characters than Latin characters in the argument, and photon state if the Latin characters dominate. The ambiguity becomes even worse, if is used for the states with certain value of the coordinate, and means the state with certain value of the momentum, which may be used in books on quantum mechanics. Such ambiguities easy lead to confusions, especially if some normalized adimensional, dimensionless variables are used.
Some physical quantities do not yet have established notations; their value (and sometimes even dimension, as in the case of the Einstein coefficients) depends on the system of notations.
A highly confusing term is gain. For example, the sentence "the gain of a system should be doubled", without context, means close to nothing.
It may mean that the ratio of the output voltage of an electric circuit to the input voltage should be doubled.
It may mean that the ratio of the output power of an electric or optical circuit to the input power should be doubled.
It may mean that the gain of the laser medium should be doubled, for example, doubling the population of the upper laser level in a quasi-two level system (assuming negligible absorption of the ground-state).
Also, confusions may be related with the use of atomic percent as measure of concentration of a dopant, or resolution of an imaging system, as measure of the size of the smallest detail which still can be resolved at the background of statistical noise. See also Accuracy and precision and its talk.
Many terms are ambiguous. Each use of an ambiguous term should be preceded by the definition, suitable for a specific case.
The Berry paradox arises as a result of systematic ambiguity. In various formulations of the Berry paradox, such as one that reads: The number not nameable in less than eleven syllables the term nameable is one that has this systematic ambiguity. Terms of this kind give rise to vicious circle fallacies. Other terms with this type of ambiguity are: satisfiable, definable, true, false, function, property, class, relation, cardinal, and ordinal.
) depend on the character used to denote its argument.
The first function is assumed, if the expression in the argument contains more characters or, than characters, and the second function is assumed in the opposite case. Expressions like or contain symbols and in equal amounts; they are ambiguous and should be avoided in serious deduction.
it is reference, which states that practically only 10 laser can be combined; not 10000000000 lasers?). Recently, OSA journals improved the style to avoid such ambiguity; since 2007, the cites appear in squared parentheses.




The Aardvark (Orycteropus afer) ("Digging foot") is a medium-sized, burrowing, nocturnal mammal native to Africa. It is sometimes called "antbear", "anteater", "Cape anteater" (after the Cape of Good Hope), "earth hog" or "earth pig". The name comes from the Afrikaans/ Dutch for "earth pig" (aarde earth, varken pig), because early settlers from Europe thought it resembled a pig. However, the aardvark is not closely related to the pig; rather, it is the sole recent representative of the obscure mammalian order Tubulidentata, in which it is usually considered to form a single variable species of the genus Orycteropus, coextensive with the family Orycteropodidae. Nor is the aardvark closely related to the South American anteater, despite sharing some characteristics and a superficial resemblance. The closest living relatives of the aardvark are the elephant shrews, along with the sirenians, hyraxes, tenrecs and elephants.
Genetically speaking, the Aardvark is a living fossil, as its chromosomes are highly conserved, reflecting much of the early eutherian arrangement before the divergence of the major modern mammalian taxa.
The Aardvark is vaguely pig-like. Its body is stout with an arched back and is sparsely covered with coarse hairs. The limbs are of moderate length. The front feet have lost the pollex (or 'thumb') — resulting in four toes — but the rear feet have all five toes. Each toe bears a large, robust nail which is somewhat flattened and shovel-like, and appears to be intermediate between a claw and a hoof. The ears are disproportionately long, and the tail is very thick at the base and gradually tapers. The greatly elongated head is set on a short, thick neck, and the end of the snout bears a disc, which houses the nostrils. The mouth is small and tubular, typical of species that feed on termites. The aardvark has a long, thin, snakelike, protruding tongue and elaborate structures supporting a keen sense of smell.
An aardvark's weight is typically between 40 and 65 kg. An aardvark's length is usually between 1 and 1.3 meters, and can reach lengths of 2.2 meters when its tail (which can be up to 70 centimeters) is taken into account. The aardvark is pale yellowish gray in color,and often stained reddish-brown by soil. The aardvark's coat is thin and the animal's primary protection is its tough skin. The aardvark has been known to sleep in a recently excavated ant nest, which also serves as protection. The number of aardvarks has nearly doubled since 2002.
The Aardvark is nocturnal and is a solitary creature that feeds almost exclusively on ants and termites (formicivore); the only fruit eaten by aardvarks is the aardvark cucumber. An aardvark emerges from its burrow in the late afternoon or shortly after sunset, and forages over a considerable home range encompassing 10 to 30 kilometers, swinging its long nose from side to side to pick up the scent of food. When a concentration of ants or termites is detected, the Aardvark digs into it with its powerful front legs, keeping its long ears upright to listen for predators, and takes up an astonishing number of insects with its long, sticky tongue — as many as 50,000 in one night have been recorded. It is an exceptionally fast digger, but otherwise moves fairly slowly. Its claws enable it to dig through the extremely hard crust of a termite or ant mound quickly, avoiding the dust by sealing the nostrils. When successful, the aardvark's long (as long as 30 centimeters) tongue licks up the insects; the termites' biting, or the ants' stinging attacks are rendered futile by the tough skin. Its keen hearing warns it of predators: lions, leopards, hyenas, and pythons.
Aside from digging out ants and termites, the aardvark also excavates burrows in which to live: temporary sites are scattered around the home range as refuges, and a main burrow is used for breeding. Main burrows can be deep and extensive, have several entrances and can be as long as 13 meters. The Aardvark changes the layout of its home burrow regularly, and from time to time moves on and makes a new one; the old burrows are then inhabited by smaller animals like the African Wild Dog. Only mothers and young share burrows. If attacked in the tunnel, it will seal the tunnel off behind itself or turn around and attack with its claws.
Aardvarks only pair during the breeding season; after a gestation period of 7 months, a single cub weighing around 2 kg is born, and is able to leave the burrow to accompany its mother after only two weeks, and is eating termites at 14 weeks and is weaned by 16 weeks. At six months of age it is able to dig its own burrows, but it will often remain with the mother until the next mating season, and is sexually capable by the season after that.
Aardvarks can live to be over 24 years old in captivity.
The aardvark's main predators are lions, leopards, hunting dogs and pythons. Aardvarks can dig fast or run in zigzag fashion to elude enemies, but if all else fails, they will strike with their claws, tail and shoulders, sometimes flipping onto their backs to lash with all fours. Their thick skin also protects them to some extent.
Aardvarks live in Subsaharan Africa, where there is suitable habitat for them to live, such as savannas, grasslands, woodlands and bushland, and available food (i.e. ants and termites).
In African folklore the aardvark is much admired because of its diligent quest for food and its fearless response to soldier ants. Hausa magicians make a charm from the heart, skin, forehead, and nails of the aardvark, which they then proceed to pound together with the root of a certain tree. Wrapped in a piece of skin and worn on the chest the charm is said to give the owner the ability to pass through walls or roofs at night. The charm is said to be used by burglars and those seeking to visit young girls without their parent's permission.


The aardwolf (Proteles cristatus) is a small insectivorous hyena-like mammal, native to Eastern and Southern Africa. The name means "earth wolf" in Afrikaans/Dutch. It is also called "maanhaar-jackal" and "protelid". Unlike other hyenas (subfamily Hyaeninae), the diet of the aardwolf almost completely consists of termites, other insect larvae and carrion.
The aardwolf is the only surviving species of the subfamily Protelinae. Two geographically separate subspecies are recognized: Proteles cristatus cristatus of Southern Africa, and Proteles cristatus septentrionalis of Eastern and Northeastern Africa. It is usually placed in the Hyaenidae, though formerly separated in another family (Protelidae).
The aardwolf looks most like the Striped Hyena, but is significantly smaller and has a more pointed muzzle, sharper ears used for listening for harvester termites, black vertical stripes on a coat of yellowish fur, and a long, distinct mane down the middle line of the neck and back, which is raised during a confrontation to make the aardwolf's size appear bigger. It is 55–80 cm long, excluding its bushy 20–30 cm tail, stands about 40–50 cm at the shoulder, and weighs between 9 and 14 kg. Its front feet have 5 toes. Its teeth and skull are similar to that of the hyena, although the cheek teeth are specialised for eating insects, and its tongue for licking them up. As the aardwolf ages, it will normally lose some of its teeth, though this has little impact on their feeding habits due to the soft nature of the insects they consume. It has two glands at the rear that secrete a musky fluid for marking territory and communicating with other aardwolves.
The aardwolf lives on open, dry plains and bushland, while avoiding mountainous areas. Due to its specific food requirements, the animal is only found in regions where termites of the family Hodotermitidae occur. Termites of this family depend on dead and withered grass and are most populous in heavily grazed grasslands and savannas, including farmland. For most of the year, aardwolves spend time in shared territories consisting of up to a dozen dens which are occupied for six weeks at a time.
There are two distinct populations: one in Southern Africa, and another in East and Northeast Africa. The species does not occur in the intermediary miombo forests.
Aardwolves are shy and nocturnal, sleeping in underground burrows by day. They usually use existing burrows of aardvarks, Old World porcupines or springhares, despite being capable of creating their own. By night, an aardwolf can consume up to 200,000 harvester termites using its sticky, long tongue. They take special care not to destroy the termite mound or consume the entire colony, which ensures that the termites can rebuild and provide a continuous supply of food. They will often memorise and return to nests to save the trouble of finding a new one. They are also known to feed on other insects, larvae, and eggs, and occasionally small mammals and birds. Unlike other hyenas, aardwolves do not scavenge or kill larger animals.
The aardwolf is primarily solitary (especially with the males), but a mating pair will occupy the same territory with their young. Young aardwolves generally achieve sexual maturity after two years, and the breeding season varies depending on their location, but normally takes place during the autumn or spring. During the breeding season, male aardwolves will search their own territory as well as others' for a female to mate with. This can often result in conflict between two male aardwolves when one has wandered into another's territory. Gestation lasts between 90 and 110 days, producing 1 to 5 cubs (though it is normally between 2 and 3) during the rainy season when termites are active. The first six to eight weeks are spent in the den with the mother. After three months, they begin supervised foraging and by four months are normally independent. However, they will often use the same den as their mother until the next breeding season. They can achieve a lifespan of up to 15 years when in captivity.
The aardwolf has taken advantage of the development of agriculture in the continent. They are often considered useful, non-dangerous animals by farmers. However, in some areas the aardwolf is hunted for its fur. Encounters with dogs are another threat.

An adobe is a natural building material mixed from sand, clay, and straw, dung or other fibrous materials, which is shaped into bricks using frames and dried in the sun. It is similar to cob and mudbrick. Adobe structures are extremely durable and account for the oldest extant buildings on the planet. Adobe buildings also offer significant advantages in hot, dry climates, as they remain cooler since adobe stores and releases heat very slowly.
Buildings made of sun-dried earth are common in the Middle East, North Africa, south America and in Spain (usually in the Mudéjar style), but adobe had been in use by indigenous peoples of the Americas in the Southwestern United States, Mesoamerica, and the Andean region of South America for several thousand years, although often substantial amounts of stone are used in the walls of Pueblo buildings. This method of brickmaking was imported to Spain in the 16th century by Spaniards who had traveled to Mexico and Peru.
A distinction is sometimes made between the smaller adobes, which are about the size of ordinary baked bricks, and the larger adobines, some of which are as much as from one to two yards (2 m) long.
The word Adobe ([əˈdəʊbiː] or [əˈdoʊbi]) has come to us over some 4000 years with little change in either pronunciation or meaning: the word can be traced from the Middle Egyptian (c. 2000 BC) word dj-b-t "mud [i.e. sun-dried] brick." As Middle Egyptian evolved into Late Egyptian, Demotic, and finally Coptic (c. 600 BC), dj-b-t became tobe "[mud] brick." This in evolved into Arabic at-tub (al "the" + tub "brick") "[mud] brick," which was assimilated into Old Spanish as adobe [aˈdobe], still with the meaning "mud brick." English borrowed the word from Spanish in the early 18th century.
In more modern usage, the term "adobe" has come to mean a style of architecture that is popular in the desert climates of North America, especially in New Mexico. (Compare with stucco).
An adobe brick is made of clay mixed with water and an organic material such as straw or animal dung. The soil composition typically contains clay and sand. Straw is useful in binding the brick together and allowing the brick to dry evenly. Dung offers the same advantage and is also added to repel insects. The mixture is roughly half sand (50%), one-third clay (35%), and one-sixth straw (15%).
Bricks are made in an open frame, 25 cm (10 inches) by 36 cm (14 inches) being a reasonable size, but any convenient size is acceptable. The mixture is molded by the frame, and then the frame is removed quickly. After drying a few hours, the bricks are turned on edge to finish drying. Slow drying in shade reduces cracking.
The same mixture to make bricks, without the straw, is used for mortar and often for plaster on interior and exterior walls. Some ancient cultures used lime-based cement for the plaster to protect against rain damage.
The brick’s thickness is preferred partially due to its thermal capabilities, and partially due to the stability of a thicker brick versus a more standard size brick. Depending on the form that the mixture is pressed into, adobe can encompass nearly any shape or size, provided drying time is even and the mixture includes reinforcement for larger bricks. Reinforcement can include manure, straw, cement, rebar or wooden posts. Experience has shown that straw, cement, or manure added to a standard adobe mixture can all produce a strong brick. A general testing is done on the soil content first. To do so, a sample of the soil is mixed into a clear container with some water, creating an almost completely saturated liquid. After the jar is sealed the container is shaken vigorously for at least one minute. It is then allowed to sit on a flat surface until the soil sediment has either collected on the bottom or remained a blended liquid. If the sediment collects on the bottom, that indicates there is a high clay content and is good for adobe. If the mixture remains a liquid, then there is little clay in the soil and using it would yield weak bricks.
The largest structure ever made from adobe (bricks) was the Bam Citadel, which suffered serious damage (up to 80%) by an earthquake on December 262003. Other large adobe structures are the Huaca del Sol in Peru, with 100 million signed bricks, the ciudellas of Chan Chan and Tambo Colorado, both in Peru.
An adobe wall can serve as a significant heat reservoir. A south-facing (in the Northern Hemisphere) adobe wall may be left uninsulated to moderate heating and cooling. Ideally, it should be thick enough to remain cool on the inside during the heat of the day but thin enough to transfer heat through the wall during the evening. The exterior of such a wall can be covered with glass to increase heat collection. In a passive solar home, this is called a Trombe wall. Adobe has a relatively dense thermal mass, and is most useful in tropical climates. In temperate climates it is less effective to heat a structure this way due to heat leaching by the ground and walls.
When building an adobe structure, the ground should be compressed because the weight of adobe bricks is significantly greater than a frame house and may cause cracking in the wall. The footing is dug and compressed once again. Footing depth depends on the region and its ground frost level. The footing and stem wall are commonly 24" and 14", much larger than a frame house because of the weight of the walls. Adobe bricks are laid by course. Each course is laid the whole length of the wall, overlapping at the corners on a layer of adobe mortar. Adobe walls usually never rise above 2 stories because they're load bearing and have low structural strength. When placing window and door openings, a lintel is placed on top of the opening to support the bricks above. Within the last courses of brick, bond beams are laid across the top of the bricks to provide a horizontal bearing plate for the roof to distribute the weight more evenly along the wall. To protect the interior and exterior adobe wall, finishes can be applied, such as mud plaster, whitewash or stucco. These finishes protect the adobe wall from water damage, but need to be reapplied periodically, or the walls can be finished with other nontraditional plasters providing longer protection.
The traditional adobe roof has been generally constructed using a mixture of soil/clay, water, sand, and other available organic materials. The mixture was then formed and pressed into wood forms producing rows of dried, earth bricks that would then be laid across a support structure of wood and plastered into place with more adobe. For a deeper understanding of adobe, one might examine a cob building. Cob, a close cousin to adobe, contains proportioned amounts of soil, clay, water, manure, and straw. This is blended, but not formed like adobe. Cob is spread and piled around a frame and allowed to air dry for several months before habitation. Adobe, then, can be described as dried bricks of cob, stacked and mortared together with more adobe mixture to create a thick wall and/or roof.
Depending on the materials available, a roof can be assembled using lengths of wood or metal to create a frame work to begin layering adobe bricks. Depending on the thickness of the adobe bricks, the frame work has been performed using a steel framing and a layering of a metal fencing or wiring over the framework to allow an even load as masses of adobe are spread across the metal fencing like cob and allowed to air dry accordingly. This method was demonstrated with an adobe blend heavily impregnated with cement to allow even drying and prevent major cracking.
More traditional adobe roofs were often flatter than the familiar steeped roof as the native climate yielded more sun and heat than mass amounts of snow or rain that would find use in precipitous roofs. Moisture, however, is often foe to a composite of mud and organic matter, so the introduction of cement is often more common to help ward off any undue water damage. It is at this turn that sense is required before the construction of any adobe is begun, be sure that the location for such a structure is similar to the climate it naturally comes from, that is, a hot, arid climate. Cool and moist climates would do well with moisture precautions planned out.
To raise a flattened adobe roof, beams of wood or metal should be assembled and span the extent of the building. The ends of the beams should then be fixed to the tops of the walls using the builder’s preferred choice of attachments. Taking into account the material the beams and walls are made from, choosing the attachments may prove difficult. In combination to the bricks and adobe mortar that are laid across the beams creates an even load-bearing pressure that can last for many years depending on attrition.
Once the beams are laid across the building, it is then time to begin the placing of adobe bricks to create the roof. An adobe roof is often laid with bricks slightly larger in width to ensure a larger expanse is covered and when placing the bricks onto the beams. This wider shape also provides the future homeowner with thermal protection enough to stabilize an even temperature through out the year. Following each individual brick should be a layer of adobe mortar, recommended to be at least an inch thick to make certain there is ample strength between the brick’s edges and also to provide a relative moisture barrier during the seasons where the arid climate does produce rain.
Adobe roofs can be inherently fire-proof, an attribute well received when the fireplace is kept lit during the cold nights, depending on the materials used. This feature leads the homeowner and builders to begin thinking about the installation of a chimney, a feat regarded as a necessity in any adobe building. The construction of the chimney can also greatly influence the construction of the roof supports, creating an extra need for care in choosing the right materials. An adobe chimney can be made from simple adobe bricks and stacked in similar fashion as the surrounding walls. Basically outline the location and perimeter of the hearth, minding the safety elements common to a fireplace, and begin to stack and mortar the walls with pre-made adobe bricks, cut to size.


An adventure is an activity that comprises risky, dangerous and uncertain experiences. The term is more popularly used in reference to physical activities that have some potential for danger, such as skydiving, mountain climbing, and extreme sports. The term is broad enough to refer to any enterprise that is potentially fraught with risk, such as a business venture or a major life undertaking. An adventurer is a person who bases their lifestyle or their fortunes on adventurous acts.
Adventurous experiences create psychological and physiological arousal, which can be interpreted as negative (e.g. fear) or positive (e.g. flow), and which can become a detriment as per the Yerkes-Dodson law. For some people, adventure becomes a major pursuit in and of itself.
Adventurous activities are typically undertaken for the purposes of recreation or excitement, such as multi-sport adventure racing or a traveler's adventure tourism. However, an adventurous activity can lead to gains in knowledge, such as in the case of the numerous pioneers who have explored and charted the Earth and, in recent times, traveled into space and to the Moon. As a more modern example, adventure education makes use of challenging experiences for learning.
Moreover, adventure and be describing an unusual experience or participating in exciting undertakings. An adventure action can be involving risky undertaking or an action without concerning outcome. In addition, taking an adventure can be illustrating taking the chance or to adventure an opinion.



Agave is a succulent plant of a large botanical genus of the same name, belonging to the family Agavaceae.
Chiefly Mexican, agaves occur also in the southern and western United States and in central and tropical South America. The plants have a large rosette of thick fleshy leaves, each ending generally in a sharp point and with a spiny margin; the stout stem is usually short, the leaves apparently springing from the root. Along with plants from the related genus Yucca, various Agave species are popular ornamental plants.
Each rosette is monocarpic and grows slowly to flower only once. During flowering a tall stem or "mast" grows from the center of the leaf rosette and bears a large number of shortly tubular flowers. After development of fruit the original plant dies, but suckers are frequently produced from the base of the stem which become new plants.
It is a common misconception that Agaves are cacti. Agaves are closely related to the lily and amaryllis families, and are not related to cacti.
Agave species are used as food plants by the larvae of some Lepidoptera species including Batrachedra striolata, which has been recorded on A shawii.
The most commonly grown species include Agave americana, Agave angustifolia, Blue agave (Agave tequilana), and Agave attenuata.
One of the most familiar species is Agave americana, a native of tropical America. Common names include Century Plant, Maguey (in Mexico), or American Aloe (it is not, however, closely related to the genus Aloe). The name "Century Plant" refers to the long time the plant takes to flower, although the number of years before flowering occurs depends on the vigor of the individual, the richness of the soil and the climate; during these years the plant is storing in its fleshy leaves the nourishment required for the effort of flowering.
Agave americana, century plant, was introduced into Europe about the middle of the 16th century and is now widely cultivated for its handsome appearance; in the variegated forms the leaf has a white or yellow marginal or central stripe from base to apex. As the leaves unfold from the center of the rosette the impression of the marginal spines is very conspicuous on the still erect younger leaves. The tequ plants are usually grown in tubs and put out in the summer months, but in the winter require protection from frost. They mature very slowly and die after flowering, but are easily propagated by the offsets from the base of the stem.
A. attenuata is a native of central Mexico and is uncommon in its natural habitat. Unlike most species of Agave, A. attenuata has a curved flower spike from which it derives one of its numerous common names - the foxtail agave.
A. attenuata is also commonly grown as a garden plant. Unlike many agaves, A. attenuata has no teeth or terminal spines making it an ideal plant for areas adjacent to footpaths. Like all agaves, A. attenuata is a succulent and requires little water or maintenance once established.
Agave is a genus within the family Agavaceae, which is currently placed within the order Asparagales. Agaves were once classified in Liliaceae, but most references now include them in their own family, Agavaceae. The genus Agave is divided into two subgenera: Agave and Littaea.
Agaves have long presented special difficulties for taxonomy; variations within a species may be considerable, and a number of named species are of unknown origin and may just be variants of original wild species.
Spanish and Portuguese explorers probably brought agave plants back to Europe with them, but the plants became popular in Europe during the 19th century when many types were imported by collectors. Some have been continuously propagated by offset since then, and do not consistently resemble any species known in the wild, although this may simply be due to the differences in growing conditions in Europe.
There are many species of Agave, see the List of Agave species.


Asia is the world's largest and most populous continent. It covers 8.6% of the Earth's total surface area (or 29.4% of its land area) and, with almost 4 billion people, it contains more than 60% of the world's current human population. Chiefly in the eastern and northern hemispheres, Asia is traditionally defined as part of the landmass of Eurasia – with the western portion of the latter occupied by Europe – lying east of the Suez Canal, east of the Ural Mountains, and south of the Caucasus Mountains and the Caspian and Black Seas. It is bounded to the east by the Pacific Ocean, to the south by the Indian Ocean, and to the north by the Arctic Ocean. Russia is considered a transcontinental country, as are Turkey, Georgia, Azerbaijan, Kazakhstan, and others, all of which include territories in Asia and in Europe. Given its size and diversity, Asia – a toponym dating back to classical antiquity – is more a cultural concept incorporating a number of regions and peoples than a homogeneous physical entity (see Subregions of Asia, Asian people).
The word Asia originated from the Ancient Greek word "Ασία", first attributed to Herodotus (about 440 BC) in reference to Anatolia or, for the purposes of describing the Persian Wars, to the Persian Empire, in contrast to Greece and Egypt. Herodotus comments that he is puzzled as to why three women's names are used to describe one enormous and substinant land mass (Europa, Asia, and Libya, referring to Africa), stating that most Greeks assumed that Asia was named after the wife of Prometheus but that the Lydians say it was named after Asias, son of Cotys who passed the name on to a tribe in Sardis.
Even before Herodotus, Homer knew of a Trojan ally named Asios and elsewhere he describes a marsh as ασιος (Iliad 2, 461). The Greek term may be derived from Assuwa, a 14th century BC confederation of states in Western Anatolia. Hittite assu- = "good" is probably an element in that name.
Alternatively, the ultimate etymology of the term may be from the Akkadian word (w)aṣû(m), which means "to go outside" or "to ascend", referring to the direction of the sun at sunrise in the Middle East, and also likely connected with the Phoenician word asa meaning east. This may be contrasted to a similar etymology proposed for Europe, as being from Akkadian erēbu(m) "to enter" or "set" (of the sun). However, this etymology is considered doubtful, because it does not explain how the term "Asia" first came to be associated with Anatolia, which is west of the Semitic-speaking areas, unless they refer to the viewpoint of a Phoenician sailor sailing through the straits between the Mediterranean Sea and the Black Sea.
It is interesting to note, in Icelandic Saga, ancient Teutons separated Asia from Europe by the river Tanakvisl (or Vanakvisl), which flows into the Black Sea. Eastward across the River (in Asia), so legend tells, was a land known as Asaheim or Asaland, where dwelt Odin, chief god, in his citadel named Asgard. However, Aesir and all its forms are related to Sanskrit asura and Avestan ahura, the local reflexes of the name of a class of divine beings.
Medieval Europeans considered Asia as a continent – a distinct landmass. The European concept of the three continents in the Old World goes back to Classical Antiquity, but during the Middle Ages was notably due to Isidore of Sevilla (see T and O map). The demarcation between Asia and Africa (to the southwest) is the Isthmus of Suez and the Red Sea. The boundary between Asia and Europe is conventionally considered to run through the Dardanelles, the Sea of Marmara, the Bosporus, the Black Sea, the Caucasus Mountains, the Caspian Sea, the Ural River to its source, and the Ural Mountains to the Kara Sea near Kara, Russia. While this interpretation of tripartite continents (i.e. of Asia, Europe, and Africa) remains common in modernity, discovery of the extent of Africa and Asia have made this definition somewhat anachronistic. This is especially true in the case of Asia, which would have several regions that would be considered distinct landmasses if these criteria were used (for example, Southern Asia and Eastern Asia).
In the far northeast of Asia, Siberia is separated from North America by the Bering Strait. Asia is bounded on the south by the Indian Ocean (specifically, from west to east, the Gulf of Aden, Arabian Sea, and Bay of Bengal); on the east by the waters of the Pacific Ocean (including, counterclockwise, the South China Sea, East China Sea, Yellow Sea, Sea of Japan, Sea of Okhotsk, and Bering Sea); and on the north by the Arctic Ocean. Australia (or Oceania) is to the southeast.
Some geographers do not consider Asia and Europe to be separate continents, as there is no logical physical separation between them. Physiographically, Asia is the major eastern constituent of the continent of Eurasia – with Europe being a northwestern peninsula of the landmass – or of Afro-Eurasia: geologically, Asia, Europe, and Africa comprise a single continuous landmass (save the Suez Canal) and share a common continental shelf. Almost all of Europe and most of Asia sit atop the Eurasian Plate, adjoined on the south by the Arabian and Indian Plates, and with the easternmost part of Siberia (east of the Cherskiy Range) on the North American Plate.
In geography, there are two schools of thought. One school follows historical convention and treats Europe and Asia as different continents, categorizing subregions within them for more detailed analysis. The other school equates the word "continent" with a geographical region when referring to Europe, and use the term "region" to describe Asia in terms of physiography. Since, in linguistic terms, "continent" implies a distinct landmass, it is becoming increasingly common to substitute the term "region" for "continent" to avoid the problem of disambiguation altogether.
Given the scope and diversity of the landmass, it is sometimes not even clear exactly what "Asia" consists of. Some definitions exclude Turkey, the Middle East, Central Asia, and Russia while only considering the Far East, Southeast Asia and the Indian subcontinent to compose Asia, especially in the United States after World War II. The term is sometimes used more strictly in reference to the Asia-Pacific region, which does not include the Middle East or Russia, but does include islands in the Pacific Ocean — a number of which may also be considered part of Australasia or Oceania, although Pacific Islanders are commonly not considered Asian.
The demonym 'Asian' is often used colloquially to refer to people from a subregion of Asia instead of for anyone from Asia. Thus, in British English, 'Asian' can mean South Asian, but may also refer to other Asian groups. In the United States, 'Asian American' can mean East Asian Americans, due to the historical and cultural influences of China and Japan on the U.S. up to the 1960s and in preference to the terms 'Oriental' and 'Asiatic'. However, the term is increasingly taken to include Southeast Asian Americans and South Asian Americans, due to the increasing numbers of them.

Aruba is a 33 km-long island of the Lesser Antilles in the southern Caribbean Sea, 27 km north of the Paraguaná Peninsula, Falcón State, Venezuela. A country within the Kingdom of the Netherlands, Aruba has no administrative subdivisions. Unlike much of the Caribbean region, Aruba has a dry climate and an arid, cactus-strewn landscape. This climate has helped tourism as visitors to the island can reliably expect warm sunny weather. It has a land area of 193 sqkm and lies outside the hurricane belt.
Aruba's first inhabitants were the Caquetios Amerindians from the Arawak tribe, who migrated there from Venezuela to escape attacks by the Caribs. Fragments of the earliest known Indian settlements date back from 1,000 AD. The Caquetios remained more tied to South America than the Caribbean, due to Aruba's distance from other Caribbean islands and sea currents which made canoe travel to other islands difficult.
Europeans first learned of Aruba when Amerigo Vespucci and Alonso de Ojeda came across it in August 1499. Vespucci in one of his four letters to Lorenzo di Pierfrancesco de' Medici described his voyage to the islands along the coast of Venezuela. He wrote about an island where most trees are of brazilwood and, from this island, he went to one ten leagues away, where they had houses built as in Venice. In another letter he described a small island inhabited by very large people, which the expedition thought was not inhabited.
Another governor appointed by Spain was Juan Martinez de Ampues. A "cédula real" decreed in November 1525 gave Ampués, factor of Española, the right to repopulate the depopulated islands of Aruba, Curaçao and Bonaire. The natives under Spanish rule enjoyed more liberty than the average northern European farmer of the period.
In 1528, Ampues was replaced by a representative of the "House of Welser". Aruba has been under Dutch administration since 1647, initially under Peter Stuyvesant. Stuyvesant was on a special mission in Aruba in November and December 1642.
Under the Dutch W.I.C. administration, as "New Netherlands and Curacao" from 1648 to 1664 and the Dutch government regulations of 1629, also applied in Aruba. The Dutch administration appointed an Irishman as "Commandeur" in Aruba in 1667.
Britain occupied Aruba from 1799 to 1802, and from 1805 to 1816.
In August 1806, General Francisco de Miranda and a group of 200 freedom fighters on their voyage to liberate Venezuela from Spain stayed in Aruba for several weeks.
In 1933 Aruba sent its first petition for Aruba's separate status and autonomy to the Queen.
During World War II, together with Curaçao the then world-class exporting oil refineries were the main suppliers of refined products to the Allies. Aruba became a British protectorate from 1940 to 1942 and a US protectorate from 1942 to 1945. On February 16, 1942, its oil processing refinery was attacked by a German submarine (U-156) under the command of Werner Hartenstein. Miraculously, the mission failed. The U-156 was later destroyed by a US plane as the crew was sunbathing; only one survived. In March 1944, Eleanor Roosevelt briefly visited American troops stationed in Aruba. In attendance were: His Excellency, Dr. P. Kasteel, the Governor of Curaçao, and his aide, Lieutenant Ivan Lansberg; Rear Admiral T. E. Chandler and his Aide, Lieutenant W. L. Edgington; Captain Jhr. W. Boreel and his aide, Lieutenant E. O. Holmberg; and the Netherlands aide to Mrs. Roosevelt, Lieutenant Commander v.d. Schatte Olivier.
The island's economy has been dominated by five main industries: gold mining, phosphate mining (The Aruba Phosphaat Maatschappij), aloe export, petroleum (The Lago Oil & Transport Company and the Arend Petroleum Maatschappij Shell Co.), and tourism.
As a Constituent Country of the Kingdom of the Netherlands, Aruba's politics take place within a framework of a 21-member Parliament and an eight-member Cabinet. The governor of Aruba is appointed for a six-year term by the monarch, and the prime minister and deputy prime minister are elected by the Staten (or "Parlamento") for four-year terms. The Staten is made up of 21 members elected by direct, popular vote to serve a four-year term.
Together, the State of the Netherlands, the State of the Netherlands Antilles, and the State of Aruba form a Commonwealth. As they share the same Dutch citizenship, these three countries still also share the Dutch passport as the Kingdom of the Netherlands passport. As Aruba and the Antilles have small populations, the two countries had to limit immigration. To protect their population, they have the right to control the admission of Netherlands nationals. There is the supervision of the admission and expulsion of Netherlands nationals and the setting of general conditions for the admission and expulsion of aliens.
In August 1947, Aruba presented its first "Staatsreglement (constitution)", for Aruba's "status aparte" as the status of a completely separate and autonomous state within the Kingdom of the Netherlands, under the authority of the Dutch crown. This is the same as in Britain's Statute of Westminster, an equal status of the Dominion Parliaments with the British Parliament, where the Dominions were under the authority of the crown and not of the government of Britain.
In November 1955, J. Irausquin of Aruba's PPA political party spoke in front of the United Nations Trust Committee. He ended his speech saying that in the future there will be changes to come.
Betico Croes worked in Aruba to inform and prepare the people of Aruba for independence. In 1976, a committee appointed by Croes introduced the national flag and anthem as the symbols of Aruba's sovereignty and independence, and he also set 1981 as a target for Aruba's independence. In March of 1977, the first Referendum for Self Determination was held with the support of the United Nations and 82% of the participants voted for independence.
The Island Government of Aruba assigned the Institute of Social Studies in the Hague to prepare a study of Aruba's independence, which was published in 1978, titled "Aruba en Onafhankelijkheid, achtergronden, modaliteiten en mogelijkheden; een rapport in eerste aanleg".
At the conference in the Hague in 1981, Aruba's independence was then set for the year 1991.
In March 1983, based on the Referendum, Aruba finally reached an official (de-colonization) agreement with the State of the Netherlands, the State of the Netherlands Antilles and the Island Governments, for Aruba's Independence, first becoming an autonomous country and member state of the Kingdom of the Netherlands, with its own constitution, unanimously approved and proclaimed in August 1985, and after an election held for Aruba's first parliament, Aruba officially became a member state of the Kingdom of the Netherlands on January 1, 1986, with full independence set for 1996, within a Dutch Commonwealth of sovereign states. This achievement is largely due to the late Betico Croes and the political support of other nations like the USA, Panama, Venezuela and various European countries. Croes was later proclaimed "Libertador di Aruba" after his tragic death in 1986.
In 1990, movement toward independence was postponed upon the request of Aruba's Prime Minister, Nelson O. Oduber. The article scheduling Aruba’s complete independence was rescinded in 1995, although the process can begin again after a referendum.
Since January 1, 1986, the Kingdom has consisted of three completely autonomous, constitutionally equal countries: the Netherlands, the Netherlands Antilles, and Aruba.
Although the "equal status" of the countries is explicitly laid down in the preamble to the Charter, which states ".considering that they have expressed freely their will to establish a new constitutional order in the Kingdom of the Netherlands, in which they will conduct their internal interests autonomously and their common interests on a basis of equality, and in which they will accord each other reciprocal assistance, have resolved by mutual consent", in practice, the Netherlands has considerably more power than either the Netherlands Antilles or Aruba.
Legal jurisdiction lies with a Gerecht in Eerste Aanleg (Court of First Instance) on Aruba, a Gemeenschappelijk Hof van Justitie voor de Nederlandse Antillen en Aruba (Common Court of Justice of the Netherlands Antilles and Aruba) and the Hoge Raad der Nederlanden (Supreme Court of Justice of the Netherlands).
Aruba’s educational system, patterned after the Dutch system, provides for education at all levels. The Government finances the national education system, except for private schools, such as the International School of Aruba (ISA), which finance their own activities. The percentage of money earmarked for education is higher than the average for the Caribbean/Latin American region.
Arubans benefit from a strong primary school education. A segmented secondary school program includes vocational training (VMBO), basic education (MAVO), college prep (HAVO) and advanced placement (VWO).
Higher education goals can be pursued through the Professional Education program (EPI), the teachers college (IPA) as well as through the University of Aruba (UA) which offers bachelors and masters programs in law, finance and economics and hospitality and tourism management. Since the choice for higher education on the island itself is limited, many students choose to study abroad in countries in North America, South America as well as Europe.
There are 68 schools for primary education and 12 schools for secondary education.
Aruba is a generally flat, riverless island in the Leeward Antilles island arc of the Lesser Antilles. Aruba is renowned for its white, sandy beaches on the western and southern coasts of the island, relatively sheltered from fierce ocean currents. The northern and eastern coasts, lacking this protection, are considerably more battered by the sea and have been left largely untouched by humans. The interior of the island features some rolling hills, the better two of which are called Hooiberg at 165 meters (541 ft) and Mount Jamanota, the highest on the island at 188 metres (617 ft) above sea level. Oranjestad, the capital, is located at.
To the east of Aruba are Bonaire and Curaçao, two island territories which form the southwest part of the Netherlands Antilles; Aruba and these two Netherlands Antilles islands are sometimes called the ABC islands.
The isothermal temperature of Aruba's pleasantly tropical marine climate attracts tourists to the island all year round. Temperature varies little from 28 °C (82 °F), moderated by constant trade winds from the Atlantic Ocean. Yearly precipitation barely reaches 500 mm (19.7 in), most of it falling in late autumn.
Most tourist hotels are located on the leeward side of the island, providing better weather and enjoyment of beaches and ocean.
Aruba enjoys one of the highest standards of living in the Caribbean region and the lowest crime rate; low poverty and unemployment rates are also positives for Aruba. About half of the Aruban gross national product is earned through tourism or related activities. Most of the tourists are from Venezuela, the European Union (the Netherlands, Spain, the United Kingdom) and the United States (predominately from eastern and southern states), Aruba's largest trading partner. Before the "Status Aparte", (a separate completely autonomous country/state within the Kingdom), oil processing was the dominant industry in Aruba despite expansion of the tourism sector. Today, the influence of the oil processing business is minimal. The size of the agriculture and manufacturing sectors also remains minimal.
The G.D.P. per capita for Aruba is calculated to be around $23,800, one of the highest in the Americas.
Deficit spending has been a staple in Aruba's history, and modestly high inflation has been present as well. Recent efforts at tightening monetary policy are correcting this and will have its first balanced budget in 2009. Aruba receives some development aid from the Dutch government each year, which will cease in 2009 as part of a deal (signed as "Aruba's Financial Independence") in which the Netherlands gradually reduces its financial help to the island each successive year. The Aruban florin is pegged to the United States dollar, with a fixed exchange rate where 1.79 Florin equals 1 U.S. dollar.
Aruba is situated in the deep southern part of the Caribbean. Because of almost no rainfall, Aruba was saved from plantation and the economics of the slave trade.
Aruba's population is estimated to be 80% mestizo and 20% other ethnicities. Arawaks spoke the "broken Spanish" which their ancestors had learned on Hispaniola. The Dutch took control almost two centuries after the Spanish, and left the Arawaks to farm and graze livestock, and used the island as a source of meat for other Dutch possessions in the Caribbean. The Arawak heritage is stronger on Aruba than on most Caribbean islands. Although no full-blooded Aboriginals remain, the features of the islanders clearly indicate their genetic Arawak heritage. Most of the population is descended mostly from Arawak, and to a lesser extent Spanish, Italian and Dutch and a few French, British and African ancestors.
Recently there has been a substantial immigration to the island from neighboring American and Caribbean nations, attracted by the well-paying jobs. In 2007 new immigration laws have been introduced to help control the growth of the population, restricting foreign workers to 3 years permit to reside on the island.
On March 18 Aruba celebrates its National Day. In 1976, Aruba presented its National Anthem (Aruba Dushi Tera) and Flag.
The origins of the population and location of the island give Aruba a mixed culture. Dutch influence can still be seen, as in the celebration of "Sinterklaas" on December 5 and 6 and other national holidays like April 30, when in Aruba and the rest of the Kingdom of the Netherlands the Queen's birthday or "Dia di La Reina" (Koninginnedag) is celebrated.
Christmas and New Year are celebrated with the typical music and songs of gaitas for Christmas and the Dande for New Year, and the "ayaca", the "ponchi crema" and "ham", and other typical foods and drinks. Millions of dollars worth of fireworks are burnt at midnight on New Year's.
On January 25, Betico's Croes birthday is celebrated.
The holiday of Carnival is also an important one in Aruba, as it is in many Caribbean and Latin American countries, and, like Mardi Gras, that goes on for weeks. Its celebration in Aruba started, around the 1950's, influenced by the inhabitants from the nearby islands (Venezuela, St Vincent, Trinidad, Barbados and Amquilla) who came to work for the Oil refinery. Over the years the Carnival Celebration has changed and now starts from the beginning of January till the Tuesday before Ash Wednesday with a large parade on the last Sunday of the festivities (Sunday before Ash Wednesday).
In June there is the celebration of the "Dia di San Juan", with the song of "Dera Gai".
Tourism from the United States has recently also increased the visibility of American culture on the island, with such celebrations as Halloween and Thanksgiving Day in November.
Religion also has its influences; the days of Ascension and Good Friday are also two holidays on the island.
According to the Bureau Burgelijke Stand en Bevolkingsregister (BBSB), as of 2005 there are ninety-two different nationalities living on the island.
Language can be seen as an important part of island culture in Aruba. The cultural mixture has given rise to a linguistic mixture known as Papiamento, the predominant language on Aruba. The two official languages are the Dutch language and Papiamento. Papiamento is a language that has been evolving through the centuries and absorbed many words from other languages like Dutch, English, diverse African dialects, and most importantly, from Portuguese and Spanish. However, like many islands in the region, Spanish is also often spoken. English has historical connections (with the British Empire) and is known by many; English usage has also grown due to tourism. Other common languages spoken based on the size of their community are Portuguese, Chinese, German and French. The latter is offered in high school and college, since a high percentage of Aruban students continue their studies in Europe.
In recent years, the government of Aruba has shown an increased interest in acknowledging the cultural and historical importance of its native language. Although spoken Papiamento is fairly similar among the several Papiamento-speaking islands, there is a big difference in written Papiamento. The orthography differs per island and even per group of people. Some are more oriented towards the Portuguese roots and use the equivalent spelling (e.g. "y" instead of "j"), where others are more oriented towards the Dutch roots.
In a book The Buccaneers of America first published in 1678, is stated by eyewitness account that the Indians on Aruba spoke "Spanish". The oldest government official statement written in Papiamento dates from 1803.
Aruba has four newspapers published in Papiamento: Diario, Bon Dia, Solo di Pueblo and Awe Mainta and two in English : Aruba Today and The News.
Aruba also has 18 Radio Stations (2 AM and 16 FM) and three local Television stations (Tele-Aruba, Aruba Broadcast Company and Star Television).
Aruba's Queen Beatrix International Airport is located near Oranjestad. This airport has daily flights to various cities across the United States, to San Juan, Puerto Rico; Miami, Florida; Chicago, Illinois; Philadelphia and Pittsburgh Pennsylvania; Houston, Texas; Atlanta, Georgia; Charlotte, North Carolina; Washington DC; New York, and Boston, Massachusetts. It also connects Aruba with Canada and South America, with daily flights to the international airports of Venezuela, Colombia, Peru, Brazil, Spain, England and most of Europe through the Schiphol Airport in the Netherlands.
According to the Aruba Airport Authority, in 2005 almost 1.7 millions travelers used the airport, of which 61% were Americans.
Electricity is produced by the Water- en Energiebedrijf Aruba (WEB) N.V. The total power generating capacity of the steam turbines amounts to 149 megawatts. There is also a 22 megawatt gas turbine as a backup unit, while a 6.5 MW diesel generator serves as an emergency unit. WEB N.V. produces an average of 60 MW, which together with a contracted supply from the refining company, is sufficient to comply with the average demand of 77 MW.
WEB N.V. delivers electricity to the distribution company N.V. Electriciteit-Maatschappij Aruba (Elmar). Electricity is supplied at a 60-hertz frequency, and at 127 and 220 volts. Consumption of electricity has increased steadily since 1986 from 219,000 MW·h to 759,336 MW·h in 2005.
Water: Potable industrial water is produced from seawater by the Water- en Energiebedrijf Aruba (WEB) N.V. the world's second largest desalination plant. The total installed desalination capacity of the water plant (Multi Stage Flash) units is 42,000 metric tons per day. Average daily consumption in 2005 was about 37,043 metric tons.

The Articles of Confederation and Perpetual Union, commonly known as the Articles of Confederation, was the first governing document, or constitution, of the United States of America. The thirteen states were formally thirteen independent countries until ratification of the Articles, proposed in 1777, was completed in 1781; whereupon the "United States of America" legally came into existence.
The final draft of the Articles was written in the summer of 1777 and adopted by the Second Continental Congress on November 15, 1777 in York, Pennsylvania after a year of debate. In practice it served as the de facto system of government used by the Congress ("the United States in Congress assembled") until it became de jure by final ratification on March 1, 1781. At that point Congress became the Congress of the Confederation. The Articles set the rules for operations of the "United States" confederation. The confederation was capable of making war, negotiating diplomatic agreements, and resolving issues regarding the western territories; it could print money and borrow inside and outside the US.
The Articles were created by the chosen representatives of the states in the Second Continental Congress out of a perceived need to have "a plan of confederacy for securing the freedom, sovereignty, and independence of the United States." Although serving a crucial role in the attainment of nationhood for the thirteen states, it soon became clear the Articles lacked the necessary provisions for a sufficiently effective government. Fundamentally, a federation was sought to replace the confederation. Nevertheless, as the Articles had clearly established a Perpetual Union of the states, the drafters of the US Constitution sought only changes leading to "a more perfect union". The key criticism by those who favored a more powerful central state (e.g. federalists) was that the government (e.g. the Congress of the Confederation) lacked taxing authority; it had to request funds from the states. Another criticism of the Articles was that they did not strike the right balance between large and small states in the legislative decision making process. Due to its one-state, one-vote plank, the larger states were expected to contribute more but had only one vote. The Articles were replaced by the United States Constitution on June 21, 1788.
The political push for the colonies to increase cooperation began in the French and Indian Wars in the mid 1750s. The opening of the American Revolutionary War in 1775 induced the various states to cooperate in seceding from the British Empire. The Second Continental Congress starting 1775 acted as the confederation organ that ran the war. Congress presented the Articles for enactment by the states in 1777, while prosecuting the American Revolutionary war against the Kingdom of Great Britain.
The articles can always be candidly reviewed under a sense of the difficulty of combining in one general system the various sentiments and interests of a continent divided into so many sovereign and independent communities, under a conviction of the absolute necessity of uniting all our councils and all our strength, to maintain and defend our common liberties..
The document could not become officially effective until it was ratified by all of the thirteen colonies. The first state to ratify was Virginia on December 16, 1777. The process dragged on for several years, stalled by the refusal of some states to rescind their claims to land in the West. Maryland was the last holdout; it refused to go along until Virginia and New York agreed to cede their claims in the Ohio River valley. A little over three years passed before Maryland's ratification on March 1, 1781.
Even though the Articles of Confederation and the Constitution were established by many of the same people, the two documents were very different. The original five-paged Articles contained thirteen articles, a conclusion, and a signatory section. The following list contains short summaries of each of the thirteen articles.
Still at war with the Kingdom of Great Britain, the colonists were reluctant to establish another powerful national government. Jealously guarding their new independence, members of the Continental Congress created a loosely-structured unicameral legislature that protected the liberty of the individual states at the expense of the confederation. While calling on Congress to regulate military and monetary affairs, for example, the Articles of Confederation provided no mechanism to ensure states complied with requests for troops or revenue. At times, this left the military in a precarious position, as George Washington wrote in a 1781 letter to the governor of Massachusetts, John Hancock.
The Articles supported the Congressional direction of the Continental Army, and allowed the 13 states to present a unified front when dealing with the European powers. But as a tool to build a centralized war-making government, they were largely a failure. Under the articles; Congress could make decisions, but had no power to enforce them. There was a requirement for unanimous approval before any modifications could be made to the Articles. Because the majority of lawmaking rested with the states, the central government was also very weak. Major laws also required approvals from nine of the thirteen states as well.
Congress was denied the power of taxation: it could only request money from the states. The states did not generally comply with the requests in full, leaving the confederation chronically short of funds. Congress was also denied the power to regulate commerce trade, and as result, the states fought over trade as well. The states and the national congress had both incurred debts during the war, and how to pay the debts became a major issue. Some states paid off their debts; however, the centralizers favored federal assumption of states' debts.
Nevertheless, the Congress of the Confederation did take two actions with lasting impact. The Land Ordinance of 1785 established the general land survey and ownership provisions used throughout later American expansion. The Northwest Ordinance of 1787 noted the agreement of the original states to give up western land claims and cleared the way for the entry of new states.
Once the war was won, the Continental Army was largely disbanded. A very small national force was maintained to man frontier forts and protect against Indian attacks. Meanwhile, each of the states had an army (or militia), and 11 of them had navies. The wartime promises of bounties and land grants to be paid for service were not being met. In 1783, Washington defused the Newburgh conspiracy, but riots by unpaid Pennsylvania veterans forced the Congress to leave Philadelphia temporarily.
The Second Continental Congress approved the Articles for distribution to the states on November 15 1777. A copy was made for each state and one was kept by the Congress. The copies sent to the states for ratification were unsigned, and a cover letter had only the signatures of Henry Laurens and Charles Thomson, who were the President and Secretary to the Congress.
But, the Articles at that time were unsigned, and the date was blank. Congress began the signing process by examining their copy of the Articles on June 27 1778. They ordered a final copy prepared (the one in the National Archives), and that delegates should inform the secretary of their authority for ratification.
On July 9, 1778, the prepared copy was ready. They dated it, and began to sign. They also requested each of the remaining states to notify its delegation when ratification was completed. On that date, delegates present from New Hampshire, Massachusetts, Rhode Island, Connecticut, New York, Pennsylvania, Virginia and South Carolina signed the Articles to indicate that their states had ratified. New Jersey, Delaware and Maryland could not, since their states had not ratified. North Carolina and Georgia also didn't sign that day, since their delegations were absent.
After the first signing, some delegates signed at the next meeting they attended. For example, John Wentworth of New Hampshire added his name on August 8. John Penn was the first of North Carolina's delegates to arrive (on July 10), and the delegation signed the Articles on July 21 1778.
The other states had to wait until they ratified the Articles and notified their Congressional delegation. Georgia signed on July 24, New Jersey on November 26, and Delaware on February 12 1779. Maryland refused to ratify the Articles until every state had ceded its western land claims.
On February 2, 1781, the much-awaited decision was taken by the Maryland General Assembly in Annapolis. As the last piece of business during the afternoon Session, "among engrossed Bills" was "signed and sealed by Governor Thomas Sim Lee in the Senate Chamber, in the presence of the members of both Houses… an Act to empower the delegates of this state in Congress to subscribe and ratify the articles of confederation" and perpetual union among the states. The Senate then adjourned "to the first Monday in August next." The decision of Maryland to ratify the Articles was reported to the Continental Congress on February 12. The formal signing of the Articles by the Maryland delegates took place in Philadelphia at noon time on March 1, 1781 and was celebrated in the afternoon. With these events, the Articles entered into force and the United States came into being as a united, sovereign and national state.
Congress had debated the Articles for over a year and a half, and the ratification process had taken nearly three and a half years. Many participants in the original debates were no longer delegates, and some of the signers had only recently arrived. The Articles of Confederation and Perpetual Union were signed by a group of men who were never present in the Congress at the same time.
The following list is of those who led the Congress of the Confederation under the Articles of Confederation as the Presidents of the United States in Congress Assembled. Under the Articles, the president was the presiding officer of Congress, chaired the Cabinet (the Committee of the States) when Congress was in recess, and performed other administrative functions. He was not, however, a chief executive in the way the successor President of the United States is a chief executive, but all of functions he executed were under the auspices and in service of the Congress.
For a full list of Presidents of the Congress Assembled and Presidents under the two Continental Congresses before the Articles, see President of the Continental Congress.
In May 1786, Charles Pinckney of South Carolina proposed that Congress revise the Articles of Confederation. Recommended changes included granting Congress power over foreign and domestic commerce, and providing means for Congress to collect money from state treasuries. Unanimous approval was necessary to make the alterations, however, and Congress failed to reach a consensus.
According to their own terms for modification (Article XIII), the Articles would still have been in effect until 1790, the year in which the last of the 13 states ratified the new Constitution. The Congress under the Articles continued to sit until November 1788, overseeing the adoption of the new Constitution by the states, and setting elections.
Historians have given many reasons for the perceived need to replace the articles in 1787. Jillson and Wilson (1994) point to the financial weakness as well as the norms, rules and institutional structures of the Congress, and the propensity to divide along sectional lines.
Rakove (1988) identifies several factors that explain the collapse of the Confederation. The lack of compulsory direct taxation power was objectionable to those wanting a strong centralized state or expecting to benefit from such power. It could not collect customs after the war because tariffs were vetoed by Rhode Island. Rakove concludes that their failure to implement national measures "stemmed not from a heady sense of independence but rather from the enormous difficulties that all the states encountered in collecting taxes, mustering men, and gathering supplies from a war-weary populace." The second group of factors Rakove identified derived from the substantive nature of the problems the Continental Congress confronted after 1783, especially the inability to create a strong foreign policy. Finally, the Confederation's lack of coercive power reduced the likelihood for profit to be made by political means, thus potential rulers were uninspired to seek power.
When the war ended in 1783, certain special interests had incentives to create a new "merchant state," much like the British state people had rebelled against. In particular, holders of war scrip and land speculators wanted a central government to pay off scrip at face value and to legalize western land holdings with disputed claims. Many of the participants in the closed Constitutional Convention were scrip and/or land speculators. Also, manufacturers wanted a high tariff as a barrier to foreign goods, but competition between states made this impossible without a central government.


Aa is the name of a large number of small European rivers. The word is derived from the continental common Germanic word aha, cognate to the Latin aqua, meaning water. The following are the more important streams of this name: Two rivers in Latvia, both falling into the Gulf of Riga, near Riga, which is situated between them; a river in the north of France, falling into the sea below Gravelines, and navigable as far as St Omer; and a river of Switzerland, in the cantons of Lucerne and Aargau, which carries the waters of Lakes Baldegger and Hallwiler into the Aar. In Germany there are the Westphalian Aa, rising in the Teutoburger Wald, and joining the Werre at Herford, the Münster Aa, a tributary of the Ems, and others.
In Danish, Aa was the generic word for 'river'. It consisted of the digraph letter aa which, since the mid-20th century, has been written as å. The Anglo-Saxon form of the word was ea, which is nowadays written as eau but persists only in river names. That persistence occurs principally in areas of England which were influenced by Danish culture. In Swedish, closely related to Danish, the form å (never Aa) has always been a generic word for a small river, such as the Fyrisån, while the word älv has been used for larger rivers, such as Dalälven.

Arthur Koestler CBE (September 5, 1905, Budapest – March 3, 1983, London) was a Jewish-Hungarian polymath who became a naturalized British subject. He wrote journalism, novels, social philosophy, and books on scientific subjects. In 1931, he joined the Communist Party of Germany, but left the party seven years later, after emigrating to the United Kingdom. By the late 1940s, he was one of the most recognized and outspoken British anti-communists, and he remained politically active through the 1950s. He wrote several popular books, including Arrow in the Blue (the first volume of his autobiography), The Yogi and the Commissar (a collection of essays, many dealing with Communism), "The Sleepwalkers: A History of Man's Changing Vision of the Universe, The Act of Creation, and The Thirteenth Tribe" (a new theory on the origins of Eastern European Jews). Koestler's magnum opus, the novel Darkness at Noon about the Great Purge in the Soviet Union, ranks with George Orwell's Nineteen Eighty-Four as a fictional treatment of Stalinism. He also wrote Encyclopædia Britannica articles.
He was born Kösztler Artúr (Hungarian names have the surname first) in Budapest, Austria-Hungary, to a German-speaking Hungarian family of Ashkenazi Jewish descent. His father, Henrik, was a prosperous start-up industrialist and inventor. His great business success was a "health" soap, which substituted conventional soaps based on animal fats (scarce during the WWI). Henrik's mineral soaps were thought to have health qualities thanks to their weak radioactivity, which in those times was considered curative. When Artur was 14, his family moved to Vienna. It was at this age which he had a "mystical experience", which perhaps gave rise to his later interest in the paranormal.
Koestler studied science and psychology at the University of Vienna, where he became President of a Zionist student fraternity. A month before he was due to finish his studies, he burnt his matriculation book and did not take his final examinations but made "aliyah" to Israel (then a British Mandate). From 1926 to 1929 he lived in the British Mandate of Palestine, firstly in a kibbutz in the Jezreel Valley ("Heftzibah"), and later in Tel Aviv and Jerusalem, where he almost starved. He left Palestine for Paris as a correspondent to the Ullstein group of German newspapers. A year later he became science editor for Ullstein based in Berlin; a highlight of that post was membership in a 1931 Zeppelin expedition to the North Pole.
He joined the Communist Party of Germany in 1931, but left it after the Moscow trials of 1938. During this period he traveled extensively in the Soviet Union and climbed Mount Ararat in Turkey. In Turkmenistan, he met the Black American writer Langston Hughes.
In his memoir The Invisible Writing, Koestler recalls that during the summer of 1935 he "wrote about half of" a sequel to the satirical novel The Good Soldier Schweik, "called The Good Soldier Schweik Goes to War Again. It had been commissioned by Willy Münzenberg [the Comintern's chief propagandist in the West].. but was vetoed by the Party on the grounds of the book's 'pacifist errors'.." (p. 283).
Soon after the outbreak of World War II, the French authorities detained him for several months as a resident alien in Vernet Internment Camp in the foothills of the Pyrenees mountains. Upon his release, he joined the French Foreign Legion. He eventually escaped to England via Morocco and Portugal. In England, he served in the British Army as a member of the British Pioneer Corps, 1941-42, then worked for the BBC. He became a British subject in 1945, and returned to France after the war, where he rubbed shoulders with the set gravitating around Jean-Paul Sartre and Simone de Beauvoir (one of the characters in de Beauvoir's novel The Mandarins is believed to be based on Koestler).
Koestler returned to London and spent the rest of his life writing and lecturing. In June 1950, Koestler attended and delivered the keynote address at a conference of anti-Communist intellectuals in Berlin that led to the founding of the Congress for Cultural Freedom. He was made a Commander in the Order of the British Empire in the 1970s.
In 1983, suffering from Parkinson's disease and leukemia, Koestler committed joint suicide with his third wife, Cynthia, by taking an overdose of drugs. He had long been an advocate of voluntary euthanasia, and in 1981 had become vice president of EXIT (now the United Kingdom's Voluntary Euthanasia Society). His will endowed the chair of parapsychology at the University of Edinburgh in Scotland.
During the Second World War, Koestler continually spoke out against the atrocities of the Nazi regime in Germany — his Central European Jewish family background made him particularly involved in a way that many British and United States politicians were not. He had also witnessed personally the growth of extremist tendencies in the region.
Despite these frustrations, Koestler and the "screamers" continued their campaign until the late stages of the war.
In addition to his mother tongue German, and the Hungarian of his homeland, Koestler became fluent in English, and French, and knew some Hebrew and Russian. His biographer David Cesarani claims there is some evidence that Koestler may have picked up some Yiddish from his grandfather. Koestler's multilingualism was principally due to his having resided, worked, or studied in Hungary, Austria, Germany, Palestine (pre-1948 Israel), the Soviet Union, the United Kingdom, and France, all by 40 years of age.
Though he wrote the bulk of his later work in English, Koestler wrote his best-known novels in three different languages: The Gladiators in Hungarian, Darkness at Noon in German (although the original is now lost), and Arrival and Departure in English. His journalism was written in German, Hebrew, French and English, and he even produced the first Hebrew language crossword puzzles and wrote the sketches for the first Hebrew cabaret ("HaMatateh").
Koestler was married to Dorothy Asher (1935–50), Mamaine Paget (1950–52), and Cynthia Jefferies (1965–83). He also had a very short fling with the French writer Simone de Beauvoir. Biographer David Cesarani in his Arthur Koestler: The Homeless Mind (1998) claimed that Koestler beat and raped several women, including film director Jill Craigie. The resulting protests led to the removal of a bust of Koestler from public display at the University of Edinburgh.
Questions have been raised by his suicide pact with his last spouse. Although he was terminally ill at the time, she was apparently healthy, leading some to claim he persuaded her to take her own life.
Koestler received the Sonning prize from the University of Copenhagen, and an honorary doctorate from Queen's University, Ontario, in 1968. In 1972 he was appointed CBE, and in 1974 a companion of the Royal Society of Literature.
Just as Darkness at Noon was selling well during the Cold War of the 1940s and '50s, Koestler announced his retirement from politics. Much of what he wrote thereafter revealed a multidisciplinary thinker whose work anticipated a number of trends by many years. He was among the first to experiment with LSD (in a laboratory). He also wrote about Japanese and Indian mysticism in The Lotus and the Robot (1960).
This originality resulted in an uneven set of ideas and conclusions. Topics covered by his works include creativity (Insight and Outlook, Act of Creation) and the history of science (The Sleepwalkers). Some of his other pursuits, such as his interest in the paranormal, his support for euthanasia, his theory of the origin of Ashkenazi Jews like himself, and his disagreement with Darwinism, are more controversial.
Koestler was involved in a number of political causes during his life, from Zionism and communism to anti-communism, voluntary euthanasia, and campaigns against capital punishment, particularly hanging. He was also an early advocate of nuclear disarmament. In 1943 he met Jan Karski.
Koestler is credited with developing the modern concept of *bisociation*, an especially important idea in the evolution of humor theory. Biscociation is present when something is simultaneously perceived from multiple perspectives.
Until the bestseller status of Darkness at Noon made him financially comfortable, Koestler often earned his living as a journalist and foreign correspondent, trading on his ability to write quickly in several languages, and to acquire with facility a working knowledge of a new language. He wrote for a variety of newspapers, including Vossische Zeitung (science editor) and B.Z. am Mittag (foreign editor) in the 1920s. In the early 1930s, he worked for the Ullstein publishing group in Berlin and did freelance writing for the French press.
While covering the Spanish Civil War, in 1937, he was captured and held for several months by the Falangists in Málaga, until the British Foreign Office negotiated his release. His Spanish Testament records these experiences, which he soon transformed into his classic prison novel Darkness at Noon. After his release from Spanish detention, Koestler worked for the News Chronicle, then edited Die Zukunft with Willi Münzenberg, an anti-Nazi, anti-Stalinist German language paper based in Paris, founded in 1938. During and after World War II, he wrote for a number of English and American papers, including The Sunday Telegraph, on various subjects. He was a frequent contributor to Encounter, one of the most influential periodicals of the Cold War period.
During the last 30 years of his life, Koestler wrote extensively on science and scientific practice. The post-modernist scepticism colouring much of this writing tended to alienate most of the scientific community. A case in point is his 1971 book The Case of the Midwife Toad about the biologist Paul Kammerer, who claimed to find experimental support for Lamarckian inheritance.
Koestler's trilogy culminating with The Ghost in the Machine and later Janus: A Summing Up bridges concepts of reductionism and holism with his systemic theory of Open Hierarchical Systems. Holons in a Holarchy have the dual tendency of integration and development and out of balance they tend to a pathology. He included his concept of Bisociation that became a profound basis for other's work on creativity and James Papez/Paul McLean's Schizophysiology to explain the often irrational behaviour of humans as part of Open Hierarchical Systems.
Mysticism and a fascination with the paranormal imbued much of his later work, and greatly influenced his personal life. For some years following his death a Koestler Society in London promoted investigation of these and related subjects. He left a substantial part of his estate to establish the Koestler Parapsychology Unit at the University of Edinburgh dedicated to the study of paranormal phenomena. His The Roots of Coincidence makes an overview of the scientific research around telepathy and psychokinesis and compares it with the advances in quantum physics at that time. It mentions yet another line of unconventional research by Paul Kammerer, the theory of coincidence or synchronicity. He also presents critically the related writings of Carl Jung. More controversial were Koestler's studies of levitation and telepathy. Koestler had joined the SPR in 1950, but perhaps did not publicise this interest for fear of ridicule.
Although a lifelong atheist, Koestler's ancestry was Jewish. His biographer David Cesarani claimed that Koestler deliberately disowned his Jewish ancestry.
When Koestler resided in Palestine during the 1920s, he lived on a kibbutz. This experience provided background for his novel Thieves in the Night.
He supported the statehood of Israel, but remarked that the Balfour Declaration of 1917 amounted to "one nation solemnly promising to a second nation the country of a third." He believed that Israel would never be destroyed short of a second Shoah. However, he opposed a diaspora Jewish culture: In an interview published in the London Jewish Chronicle around the time of Israel's founding, Koestler maintained that all Jews should either migrate to Israel or else assimilate completely into their local cultures.(See "Judah at the Crossroads" in "The Trail of the Dinosaur" collection of essays.) As for Jewish culture in Israel, Koestler proposed that Israel drop the Hebrew alphabet for the Roman.
Koestler's book The Thirteenth Tribe (1976) advanced the controversial thesis that Ashkenazi Jews are not descended from the Israelites of antiquity, but from the Khazars, a Turkic people in the Caucasus who converted to Judaism in the 8th century and were later forced to move westwards into present-day Russia, Ukraine and Poland. Koestler stated that part of his intent in writing The Thirteenth Tribe was to defuse anti-Semitism by undermining the identification of European Jews with Biblical Jews, with the hope of rendering anti-Semitic epithets such as "Christ killer" inapplicable. Ironically, Koestler's thesis that Ashkenazi Jews are not Semitic has become an important claim of many anti-Semitic groups.
Recent genetic research studies have contradicted the main thesis of The Thirteenth Tribe. For example, a 2000 study of haplotypes by Hammer et al indicates that the Y chromosomes of most Ashkenazi and Sephardic Jews are of Middle Eastern origin, containing mutations that are also common among Palestinians and other Middle Eastern peoples, yet are uncommon in the general European population. These results strongly suggest that most male ancestors of the Ashkenazi Jews can be traced primarily to the Middle East. A second study (2006) by Behar et al, based on haplotype analysis of mitochondrial DNA (mtDNA), also indicates that about 40% of the current Ashkenazi population is descended matrilineally from just four women. These four "founder lineages" were "likely from a Hebrew/Levantine mtDNA pool" originating in the Near East in the first and second centuries CE.
In November, 1960, Koestler participated in Timothy Leary's early experiments with psilocybin at Harvard. According to fellow participant Charles Olson, Koestler was distressed by the effects of the drug and isolated himself in an unfurnished bedroom in the Cambridge house Leary used for his project. Koestler again experimented with psilocybin at the University of Michigan at Ann Arbor, comparing this trip to Walt Disney's Fantasia.
I profoundly admire Aldous Huxley, both for his philosophy and uncompromising sincerity. But I disagree with his advocacy of "the chemical opening of doors into the Other World", and with his belief that drugs can procure "what Catholic theologians call a gratuitous grace". Chemically induced hallucinations, delusions and raptures may be frightening or wonderfully gratifying; in either case they are in the nature of confidence tricks played on one's own nervous system.
Look at this. Did you ever see a magazine called the New Musical Express? It turns out there is a pop group called The Police—I don't know why they are called that, presumably to distinguish them from the punks—and they've made an album of my essay The Ghost in the Machine. I didn't know anything about it until my clipping agency sent me a review of the record.
Koestler's will also left money for the The Koestler Trust, which helps prison inmates to express themselves creatively, as a means to rehabilitation. The trust continues to exhibit work by prisoners on a regular basis. He also left money for the Department of Parapsychology in Edinburgh.
The books The Lotus and the Robot, The God that Failed, and Von weissen Nächten und roten Tagen, as well as his numerous essays, all contain autobiographical information.
Langston Hughes's autobiography also documents their meeting in Turkestan during the Soviet era.


The Atlantic Ocean is the second-largest of the world's oceanic divisions; with a total area of about 106.4 million square kilometres (41.1 million square miles). It covers approximately one-fifth of the Earth's surface. The first part of its name refers to the Atlas of Greek mythology, making the Atlantic the "Sea of Atlas". The oldest known mention of this name is contained in The Histories of Herodotus around 450 BC (I 202); see also: Atlas Mountains. Before Europeans discovered other oceans, the term "ocean" was synonymous with the waters beyond Western Europe that we now know as the Atlantic and which the Greeks had believed to be a gigantic river encircling the world; see Oceanus.
longitudinally between the Americas to the west, and Eurasia and Africa to the east. A component of the all-encompassing World Ocean, it is connected in the north to the Arctic Ocean (which is sometimes considered a sea of the Atlantic), to the Pacific Ocean in the southwest, the Indian Ocean in the southeast, and the Southern Ocean in the south. (Alternatively, in lieu of it connecting to the Southern Ocean, the Atlantic may be reckoned to extend southward to Antarctica.) The equator subdivides it into the North Atlantic Ocean and South Atlantic Ocean.
The Atlantic Ocean is bounded on the west by North and South America. In the north and northeast, it is separated from the Arctic Ocean by the Canadian Arctic Archipelago, Greenland, Iceland, Jan Mayen, Svalbard, and mainland Europe. It connects to the Arctic Ocean through the Denmark Strait, Greenland Sea, Norwegian Sea, and Barents Sea. To the east, the boundaries of the ocean proper are Europe, the Strait of Gibraltar (where it connects with the Mediterranean Sea, one of its marginal seas, and, in turn, the Black Sea), and Africa. In the southeast, the Atlantic merges into the Indian Ocean, the border being defined by the 20° East meridian, running south from Cape Agulhas to Antarctica. While some authorities show the Atlantic Ocean extending south to Antarctica, others show it as bounded to the south by the Southern Ocean. In the southwest, the Drake Passage connects it to the Pacific Ocean. A man-made link between the Atlantic and Pacific is provided by the Panama Canal. Beside those mentioned, other large bodies of water adjacent to the Atlantic are the Caribbean Sea, the Gulf of Mexico, Hudson Bay, the Arctic Ocean, the Mediterranean Sea, the North Sea, the Baltic Sea, and the Celtic Sea.
Covering approximately 20% of Earth's surface, the Atlantic Ocean is second only to the Pacific in size. With its adjacent seas it occupies an area of about 106,400,000 square kilometers (41,100,000 sq mi); without them, it has an area of 82,400,000 square kilometres (31,800,000 sq mi). The land area that drains into the Atlantic is four times that of either the Pacific or Indian oceans. The volume of the Atlantic Ocean with its adjacent seas is 354,700,000 cubic kilometers (85,100,000 cu mi) and without them 323,600,000 cubic kilometres (77,640,000 cu mi).
The average depths of the Atlantic, with its adjacent seas, is 3,338 meters (10,932 ft); without them it is 3,926 metres (12,881 ft). The greatest depth, 8,605 metres (28,232 ft), is in the Puerto Rico Trench. The width of the Atlantic varies from 2,848 kilometers (1,770 mi) between Brazil and Liberia to about 4,830 kilometres (3,000 mi) between the United States and northern Africa.
The principal feature of the bathymetry (bottom topography) of the Atlantic Ocean is a submarine mountain range called the Mid-Atlantic Ridge. It extends from Iceland in the north to approximately 58° South latitude, reaching a maximum width of about 1,600 kilometres (1,000 mi). A great rift valley also extends along the ridge over most of its length. The depth of water over the ridge is less than 2,700 m (8,900 ft) in most places, and several mountain peaks rise above the water and form islands. The South Atlantic Ocean has an additional submarine ridge, the Walvis Ridge.
The Mid-Atlantic Ridge separates the Atlantic Ocean into two large troughs with depths averaging between 3,700 and 5,500 metres (12,000 and 18,000 ft). Transverse ridges running between the continents and the Mid-Atlantic Ridge divide the ocean floor into numerous basins. Some of the larger basins are the Blake, Guiana, North American, Cape Verde, and Canaries basins in the North Atlantic. The largest South Atlantic basins are the Angola, Cape, Argentina, and Brazil basins.
The deep ocean floor is thought to be fairly flat, although numerous seamounts and some guyots exist. Several deeps or trenches are also found on the ocean floor. The Puerto Rico Trench, in the North Atlantic, is the deepest. The Laurentian Abyss is found off the eastern coast of Canada. In the South Atlantic, the South Sandwich Trench reaches a depth of 8,428 metres (27,651 ft). A third major trench, the Romanche Trench, is located near the equator and reaches a depth of about 7,454 metres (24,455 ft). The shelves along the margins of the continents constitute about 11% of the bottom topography. Several deep channels cut across the continental rise.
On average, the Atlantic is the saltiest of the world's major oceans; the salinity of the surface waters in the open ocean ranges from 33 to 37 parts per thousand (3.3 - 3.7%) by mass and varies with latitude and season. Surface salinity values are influenced by evaporation, precipitation, river inflow, and melting of sea ice. Although the minimum salinity values are found just north of the equator (because of heavy tropical rainfall), in general the lowest values are in the high latitudes and along coasts where large rivers flow into the ocean. Maximum salinity values occur at about 25° north and south of the equator, in subtropical regions with low rainfall and high evaporation.
Surface water temperatures, which vary with latitude, current systems, and season and reflect the latitudinal distribution of solar energy, range from less than −2 °C to 29 °C (28 °F to 84 °F). Maximum temperatures occur north of the equator, and minimum values are found in the polar regions. In the middle latitudes, the area of maximum temperature variations, values may vary by 7 °C to 8 °C (13 °F to 14 °F).
The Atlantic Ocean consists of four major water masses. The North and South Atlantic central waters constitute the surface waters. The sub-Antarctic intermediate water extends to depths of 1,000 metres (3,300 ft). The North Atlantic Deep Water reaches depths of as much as 4,000 metres (13,200 ft). The Antarctic Bottom Water occupies ocean basins at depths greater than 4,000 metres (13,200 ft).
Within the North Atlantic, ocean currents isolate a large elongated body of water known as the Sargasso Sea, in which the salinity is noticeably higher than average. The Sargasso Sea contains large amounts of seaweed and is also the spawning ground for both the European eel and the American eel.
Because of the Coriolis effect, water in the North Atlantic circulates in a clockwise direction, whereas water circulation in the South Atlantic is counter-clockwise. The south tides in the Atlantic Ocean are semi-diurnal; that is, two high tides occur during each 24 lunar hours. The tides are a general wave that moves from south to north. In latitudes above 40° North some east-west oscillation occurs.
The climate of the Atlantic Ocean and adjacent land areas is influenced by the temperatures of the surface waters and water currents as well as the winds blowing across the waters. Because of the ocean's great capacity for retaining heat, maritime climates are more moderate and have less tendency toward extreme seasonal variations than inland climates. Precipitation can be approximated from coastal weather data and air temperature from the water temperatures. The oceans are the major source of the atmospheric moisture that is obtained through evaporation. Climatic zones vary with latitude; the warmest climatic zones stretch across the Atlantic north of the equator. The coldest zones are in the high latitudes, with the coldest regions corresponding to the areas covered by sea ice. Ocean currents contribute to climatic control by transporting warm and cold waters to other regions. Adjacent land areas are affected by the winds that are cooled or warmed when blowing over these currents. The Gulf Stream and its northern extension towards Europe, the North Atlantic Drift, for example, warms the atmosphere of the British Isles and north-western Europe, and the cold water currents contribute to heavy fog off the coast of eastern Canada (the Grand Banks area) and the north-western coast of Africa. In general, winds tend to transport moisture and warm or cool air over land areas. Hurricanes develop in the southern part of the North Atlantic Ocean. The average wavelength towards the North America shore about 500 m (1650 ft) out is 1000.
The Atlantic Ocean appears to be the second youngest of all five oceans. Evidence indicates that it did not exist prior to 130 million years ago, when the continents that formed from the breakup of the ancestral super continent, Pangaea, were being rifted apart by the process of seafloor spreading. The Atlantic has been extensively explored since the earliest settlements were established along its shores. The Vikings, the Portuguese, and Christopher Columbus were the most famous among its early explorers. After Columbus, European exploration rapidly accelerated, and many new trade routes were established. As a result, the Atlantic became and remains the major artery between Europe and the Americas (known as transatlantic trade). Numerous scientific explorations have been undertaken, most famously the Challenger expedition, but also including those by the German Meteor expedition, Columbia University's Lamont Geological Observatory, and the United States Navy Hydrographic Office.
In 1865 the first successful transatlantic telegraph cable was laid by Brunell's ship the Great Eastern.
The ocean has also contributed significantly to the development and economy of the countries around it. Besides its major transatlantic transportation and communication routes, the Atlantic offers abundant petroleum deposits in the sedimentary rocks of the continental shelves and the world's richest fishing resources, especially in the waters covering the shelves. The major species of fish caught are cod, haddock, hake, herring, and mackerel. The most productive areas include the Grand Banks of Newfoundland, the shelf area off Nova Scotia, Georges Bank off Cape Cod, the Bahama Banks, the waters around Iceland, the Irish Sea, the Dogger Bank of the North Sea, and the Falkland Banks. Eel, lobster, and whales have also been taken in great quantities. All these factors, taken together, tremendously enhance the Atlantic's great commercial value. Because of the threats to the ocean environment presented by oil spills, marine debris, and the incineration of toxic wastes at sea, various international treaties exist to reduce some forms of pollution.
The surface is usually covered with sea ice in the Labrador Sea, Denmark Strait, and Baltic Sea from October to June. There is a clockwise warm-water gyre in the northern Atlantic, and a counter-clockwise warm-water gyre in the southern Atlantic. The ocean floor is dominated by the Mid-Atlantic Ridge, a rugged north-south centerline for the entire Atlantic basin, first discovered by the Challenger Expedition. This was formed by the vulcanism that also formed the floor of the Atlantic, and the islands rising from it.
The Atlantic Ocean has irregular coasts indented by numerous bays, gulfs, and seas. These include Norwegian Sea, Baltic Sea, North Sea, Labrador Sea, Black Sea, Gulf of St. Lawrence, Bay of Fundy, Gulf of Maine, Mediterranean Sea, Gulf of Mexico, and Caribbean Sea.
Islands in the Atlantic Ocean include Greenland, Iceland, Faroe Islands, The British Isles (including Great Britain, Ireland and numerous surrounding islands), Rockall, Newfoundland, Sable Island, Azores, Madeira, Bermuda, Canary Islands, Caribbean, Cape Verde, Sao Tome e Principe, Annobon Province, St. Peter, Fernando de Noronha, Rocas Atoll, Ascension Island, Saint Helena, The Islands of Trindad, Tristan da Cunha, Diego Alverez (Also known as Gough Island), Falkland Islands, Tierra del Fuego, South Georgia Island, South Sandwich Islands, and Bouvet Island.
Icebergs are common in the Davis Strait, Denmark Strait, and the northwestern Atlantic Ocean from February to August and have been spotted as far south as Bermuda and the Madeira Islands. Ships are subject to superstructure icing in extreme northern Atlantic from October to May. Persistent fog can be a maritime hazard from May to September, as can hurricanes north of the equator (May to December).
The Bermuda Triangle is popularly believed to be the site of numerous aviation and shipping incidents because of unexplained and supposedly mysterious causes, but coast guard records do not support this belief.
Endangered marine species include the manatee, seals, sea lions, turtles, and whales. Drift net fishing is killing dolphins, albatrosses and other seabirds (petrels, auks), hastening the decline of fish stocks and contributing to international disputes. There is municipal sludge pollution off the eastern United States, southern Brazil, and eastern Argentina; oil pollution in the Caribbean Sea, Gulf of Mexico, Lake Maracaibo, Mediterranean Sea, and North Sea; and industrial waste and municipal sewage pollution in the Baltic Sea, North Sea, and Mediterranean Sea.
In 2005, there was some concern that the currents warming northern Europe were slowing down, but no scientific consensus was formed based on the reported evidence.
On June 7, 2006, Florida's wildlife commission voted to take the manatee off of the state's endangered species list. Some environmentalists worry that this could erode safeguards for the popular sea creature.
Much of this article comes from the public domain site http://oceanographer.navy.mil/atlantic.html (dead link). It is now accessible from the Internet Archive at http://web.archive.org/web/20020221215514/http%3a//oceanographer.navy.mil/atlantic.html.


was a German philosopher best known for his work The World as Will and Representation. Schopenhauer responded to and expanded upon Immanuel Kant's philosophy concerning the way in which we experience the world. His critique of Kant, his creative solutions to the problems of human experience, and his explication of the limits of human knowledge are among his most important achievements. His metaphysical theory is the foundation of his influential writings on psychology, aesthetics, ethics, and politics which influenced Friedrich Nietzsche, Wagner, Ludwig Wittgenstein, Sigmund Freud and others.
Arthur Schopenhauer was born in 1788 in the city of Danzig (Gdańsk) as the son of Heinrich Floris Schopenhauer and Johanna Schopenhauer, who were both descendants of wealthy German middle class mercantile families in the city located on the Baltic Sea. In 1793, when Danzig was annexed by Prussia, Schopenhauer's family moved to another mercantile harbour city, Hamburg, where in 1805, Schopenhauer's father died. (Some speculate he committed suicide.) Johanna, who was an author, moved to Weimar, then the centre of German literature. Because of a promise to pursue a business career, Schopenhauer remained in Hamburg. His disgust with this career, however, drove him away to join his mother in Weimar after only a year. He never got along with his mother; when the writer Goethe, who was a friend of Johanna Schopenhauer, told her that he thought her son was destined for great things, Johanna objected: she had never heard there could be two geniuses in a single family.
Schopenhauer became a student at the University of Göttingen in 1809. There he studied metaphysics and psychology under Gottlob Ernst Schulze, who advised him to concentrate on Plato and Kant. In Berlin, from 1811 to 1812, he had attended lectures by the prominent post-Kantian philosopher J. G. Fichte and the theologian Schleiermacher. Schopenhauer objected to Schleiermacher's assertion that the purpose of philosophy is to gain knowledge of God. He also reacted against Fichte's extreme idealism. Fichte claimed that the observing subject or Ego causes observed objects, whereas Schopenhauer contended that subject and object always exist together in a necessary correlation. After submitting as his doctoral dissertation On the Fourfold Root of the Principle of Sufficient Reason, he was awarded a PhD from the University of Jena in absentia.
In 1814 Schopenhauer began his seminal work The World as Will and Representation (Die Welt als Wille und Vorstellung.) He would finish it in 1818 with publication in the following year of 1819 (in Dresden his illegitimate child was born and died the same year.) In 1820, Schopenhauer became a lecturer at the University of Berlin; it was there that his opposition to G. W. F. Hegel began. Schopenhauer scheduled his own lectures to coincide with Hegel's, in an attempt to demolish student support of Hegel's philosophy. However, only five students turned up to Schopenhauer's lectures, and he dropped out of academia. He never taught at a university again. A late essay On University Philosophy expressed his resentment towards university philosophy.
In 1831, a cholera epidemic broke out in Berlin and both Hegel and Schopenhauer fled; but Hegel returned prematurely, caught the infection, and died a few days later. Schopenhauer moved south, and settled permanently in Frankfurt in 1833. There he remained for the next twenty-seven years, living alone except for a succession of pet poodles named Atma and Butz.
While in Berlin, Schopenhauer was named as a defendant in an action at law initiated by a woman named Caroline Marquet.
She asked for damages, alleging that Schopenhauer had pushed her. Knowing that he was a man of some means and that he disliked noise, she deliberately annoyed him by raising her voice while standing right outside his door. Marquet alleged that the philosopher had assaulted and battered her after she refused to leave his doorway. Her companion testified that she saw Marquet prostrate outside of his apartment. Because Marquet won the lawsuit, he made payments to her for the next twenty years. When she died, he wrote on a copy of her death certificate, "Obit anus, abit onus" (The old woman dies, the burden is lifted).
Schopenhauer had a robust constitution, but in 1860 his health began to deteriorate. He died, sitting in his armchair, of heart failure on September 21 of that year at the age of 72.
Schopenhauer called himself a Kantian, but hurled invective at several other contemporary German philosophers who had been influenced by Kant. These included Hegel, Fichte, and Schelling. He formulated a pessimistic philosophy that gained importance and support after the failure of the German and Austrian revolutions of 1848.
Schopenhauer's starting point was Kant's division of the universe into the phenomenal and the noumenal. Schopenhauer extended Kant's ideas to, in his opinion, gain greater understanding of the noumenal. For instance, he suggested that noumenal reality was singular because multiplicity was part of phenomenal experience. Some commentators suggest that Schopenhauer claimed that the noumenon was the same as that in us which we call Will. Other commentators, like Bryan Magee, suggest that he considered will to be the most immediate manifestation of the noumenon that we can experience.
A key aspect of Schopenhauer's thought is the investigation of what makes man less than reasonable. This force he calls "Wille zum Leben" or Will (lit. will-to-life), by which he means the forces driving man, to remain alive and to reproduce, a drive intertwined with desire. This Will is the inner content and the driving force of the world. For Schopenhauer, Will had ontological primacy over the intellect; in other words, desire is understood to be prior to thought, and, in a parallel sense, Will is said to be prior to being. Schopenhauer felt this was similar to notions of purushartha or goals of life in Vedanta Hinduism.
In attempting to solve or alleviate the fundamental problems of life, Schopenhauer was a rare philosopher who considered philosophy and logic less important (or less effective) than art, certain charitable practices ("loving kindness", in his terms), and certain forms of religious discipline. Schopenhauer concluded that discursive thought (such as philosophy and logic) could neither touch nor transcend the nature of desire — i.e. Will. In The World as Will and Representation, Schopenhauer proposed that humans living in the realm of objects are living in the realm of desire, and thus are eternally tormented by that desire. The role of desire in Schopenhauer is similar to the role of Kāma, sensual gratification, which is treated as one of the goals of life relating to the second stage of life in the Hindu tradition.
For Schopenhauer, the aesthetic viewpoint is more objective than the scientific viewpoint precisely because it separates the intellect from the will in the form of art. The ability to view nature aesthetically is a telltale sign of a genius. An important metaphysical distinction that Schopenhauer makes involves the notion of the will versus art. In a sense, Schopenhauer claimed that the body is an extension of the will, while art is a spontaneous act which cannot be linked to either the body or the intellect. The intellect allows man to suffer because it brings the suffering or pain of the world into a more vivid consciousness. Logically speaking then, the more intellectually-inclined person suffers most.
Aesthetic contemplation for Schopenhauer translates into an immediate objectification of the will. He employs a Platonic allegory to demonstrate that all existence is ultimately futile since it can be fundamentally characterized by a want of satisfaction that can never be attained. This want is otherwise known as happiness. Schopenhauer's metaphysics is said by many to be essentially marked by an all-encompassing pessimism. This pessimism serves as a stark contrast to Schopenhauer's Romantic contemporaries in 19th century Germany. His contemporaries, who include Hegel and Schelling, tended to employ a wide-ranging optimism concerning the seemingly progressive history of mankind.
Other notable ideas pertaining to Schopenhauer's metaphysics entail the notion of how art is conceived. Schopenhauer argued that art was a spontaneous, pre-determined idea which the artist has in mind before even attempting to create. Art, therefore, placed man above science and ultimately nature since it effectively goes beyond the realm of sufficient reason. Science, for Schopenhauer, shall be relegated to the boundaries of reason and, thus, the genius is precluded from entering its territory. Moreover, philosophy is not necessarily a pursuit of wisdom but, rather, it can be viewed as a means for interpreting the personal experiences of one's own life. Schopenhauer maintained that desire produces suffering and, thus, one ought to be wary of the torturous effects of hedonism.
This wild and powerful drive to reproduce, however, caused suffering or pain in the world. For Schopenhauer, one way to escape the suffering inherent in a world of Will was through art.
Through art, Schopenhauer thought, the thinking subject could be jarred out of their limited, individual perspective to feel a sense of the universal directly—the "universal" in question, of course, was the will. The contest of personal desire with a world that was, by nature, inimical to its satisfaction is inevitably tragical; therefore, the highest place in art was given to tragedy. Music was also given a special status in Schopenhauer's aesthetics as it did not rely upon the medium of representation to communicate a sense of the universal.
Schopenhauer believed the function of art to be a meditation on the unity of human nature, and an attempt to either demonstrate or directly communicate to the audience a certain existential angst for which most forms of entertainment—including bad art—only provided a distraction. A wide range of authors (from Thomas Hardy to Woody Allen) and artists have been influenced by this system of aesthetics, and in the 20th century this area of Schopenhauer's work garnered more attention and praise than any other.
Schopenhauer's moral theory proposed that of three primary moral incentives, compassion (Mitleid) was the genuine motivator to moral expression. He ruled the other two, malice and egoism, corrupt as moral incentives. The identification of compassion as the true moral incentive was a central aspect of Schopenhauer's mission.
Schopenhauer was perhaps even more influential in his treatment of man's psychology than he was in the realm of philosophy.
He gave a name to a force within man which he felt had invariably precedence over reason: the Will to Live (Wille zum Leben), defined as an inherent drive within human beings, and indeed all creatures, to stay alive and to reproduce.
These ideas foreshadowed and laid the groundwork for Darwin's theory of evolution and Freud's concepts of the libido and the unconscious mind.
In Schopenhauer's essay "On Women" (Über die Weiber), he expressed his opposition to what he called "Teutonico-Christian stupidity" on female affairs. He claimed that "woman is by nature meant to obey", and opposed Schiller's poem in honor of women, Würde der Frauen. The essay does give two compliments however: that "women are decidedly more sober in their judgment than [men] are" and are more sympathetic to the suffering of others. However, the latter was discounted as weakness rather than humanitarian virtue.
Schopenhauer had generally liberal views on other social issues: he was strongly against taboos on issues like suicide and homosexuality, and condemned the treatment of African slaves. Schopenhauer held a high opinion of one woman, Madame de Guyon, whose writings and biography he recommended.
Schopenhauer's controversial writing has influenced many, from Nietzsche to 19th century feminists. While Schopenhauer's hostility to women may tell us more about his biography than about philosophy, his biological analysis of the difference between the sexes, and their separate roles in the struggle for survival and reproduction, anticipates some of the claims that were later ventured by sociobiologists and evolutionary psychologists in the twentieth century.
In another context, Schopenhauer reiterated his antidemocratic-eugenic thesis: "If you want Utopian plans, I would say: the only solution to the problem is the despotism of the wise and noble members of a genuine aristocracy, a genuine nobility, achieved by mating the most magnanimous men with the cleverest and most gifted women. This proposal constitutes my Utopia and my Platonic Republic" (Essays and Aphorisms, trans. R.J. Hollingdale, Middlesex: London, 1970, p. 154). Analysts (e.g. Keith Ansell-Pearson) have suggested that Schopenhauer's advocacy of anti-egalitarianism and eugenics influenced the neo-aristocratic philosophy of Friedrich Nietzsche, who initially considered Schopenhauer his mentor.
Schopenhauer was also one of the first philosophers since the days of Greek philosophy to address the subject of male homosexuality. In the third, expanded edition of The World as Will and Representation (1856), Schopenhauer added an appendix to his chapter on the "Metaphysics of Sexual Love". He wrote that only those who were too old or too young to reproduce strong, healthy children would resort to pederasty (Schopenhauer considered pederasty to be in itself a vice). He also wrote that homosexuality did have the benefit of preventing ill-begotten children. Concerning this he stated "..the vice we are considering appears to work directly against the aims and ends of nature, and that in a matter that is all important and of the greatest concern to her, it must in fact serve these very aims, although only indirectly, as a means for preventing greater evils." Shrewdly anticipating the interpretive distortion on the part of the popular mind of his attempted scientific explanation of pederasty as a personal advocacy of a phenomenon Schopenhauer otherwise describes, in terms of spiritual ethics, as an "objectionable aberration", Schopenhauer sarcastically concludes the appendix with the statement that "by expounding these paradoxical ideas, I wanted to grant to the professors of philosophy a small favour, for they are very disconcerted by the ever-increasing publicization of my philosophy which they so carefully concealed. I have done so by giving them the opportunity of slandering me by saying that I defend and commend pederasty" (ibid. p. 567).
Schopenhauer said he was influenced by the Upanishads, Immanuel Kant, and Plato. References to Eastern philosophy and religion appear frequently in Schopenhauer's writing. As noted above, he appreciated the teachings of the Buddha and even called himself a Buddhaist He said that his philosophy could not have been conceived before these teachings were available.
He summarised the influence of the Upanishads thusly: 'It has been the solace of my life, it will be the solace of my death!
Other influences were: Jean Jacques Rousseau, John Locke, Baruch Spinoza, Matthias Claudius, George Berkeley, David Hume, René Descartes.
Schopenhauer's identification of the Kantian noumenon (i.e. the actually existing entity) with what he termed Will deserves some explanation. The noumenon was what Kant called the Ding an Sich, the "Thing in Itself", the reality that is the foundation of our sensory and mental representations of an external world. In Kantian terms, those sensory and mental representations are mere phenomena. Schopenhauer departed from Kant in his description of the relationship between the phenomenon and the noumenon. According to Kant, things-in-themselves ground the phenomenal representations in our minds. Schopenhauer, on the other hand, believed phenomena and noumena to be two different sides of the same coin. Noumena do not cause phenomena, but rather phenomena are simply the way by which our minds perceive the noumena, according to the Principle of Sufficient Reason. This is explained more fully in Schopenhauer's doctoral thesis, On the Fourfold Root of the Principle of Sufficient Reason.
Schopenhauer's second major departure from Kant's epistemology concerns the body. Kant's philosophy was formulated as a response to the radical philosophical skepticism of David Hume, who claimed that causality could not be observed empirically. Schopenhauer begins by arguing that Kant's demarcation between external objects, knowable only as phenomena, and the Thing in Itself of noumenon, contains a significant omission. There is, in fact, one physical object we know more intimately than we know any object of sense perception. It is our own body.
We know our human bodies have boundaries and occupy space, the same way other objects known only through our named senses do. Though we seldom think of our bodies as physical objects, we know even before reflection that it shares some of their properties. We understand that a watermelon cannot successfully occupy the same space as an oncoming truck. We know that if we tried to repeat the experiment with our own bodies, we would obtain similar results. We know this even if we do not understand the physics involved.
We know that our consciousness inhabits a physical body, similar to other physical objects only known as phenomena. Yet our consciousness is not commensurate with our body. Most of us possess the power of voluntary motion. We usually are not aware of the breathing of our lungs or the beating of our hearts unless somehow our attention is called to them. Our ability to control either is limited. Our kidneys command our attention on their schedule rather than one we choose. Few of us have any idea what our livers are doing right now, though this organ is as needful as lungs, heart, or kidneys. The conscious mind is the servant, not the master, of these and other organs. These organs have an agenda which the conscious mind did not choose, and over which it has limited power.
When Schopenhauer identifies the noumenon with the desires, needs, and impulses in us that we name "Will," what he is saying is that we participate in the reality of an otherwise unachievable world outside the mind through will. We cannot prove that our mental picture of an outside world corresponds with a reality by reasoning. Through will, we know—without thinking—that the world can stimulate us. We suffer fear, or desire. These states arise involuntarily. They arise prior to reflection. They arise even when the conscious mind would prefer to hold them at bay. The rational mind is for Schopenhauer a leaf borne along in a stream of pre-reflective and largely unconscious emotion. That stream is will, and through will, if not through logic, we can participate in the underlying reality that lies beyond mere phenomena. It is for this reason that Schopenhauer identifies the noumenon with what we call our will.
Schopenhauer is thought to have influenced the following intellectual figures and schools of thought: Friedrich Nietzsche, Paul Deussen, Richard Wagner, Gustav Mahler, Charles Darwin, Theodule Ribot, Ferdinand Tönnies, Eugene O'Neill, Max Horkheimer, C. G. Jung, Sigmund Freud, George Gissing, John N. Gray, Ludwig Wittgenstein, Albert Einstein, Karl Popper, Samuel Beckett, Jorge Luis Borges, Wilhelm Busch, Dylan Thomas, Leo Tolstoy, Emil Cioran, Thomas Mann, Italo Svevo, Joseph Campbell, Eduard von Hartmann, Erich von Stroheim, Phenomenalism, and Recursionism.
In his "Foreword to the first edition" of his work Die beiden Grundprobleme der Ethik, Schopenhauer suggested that he had shown Hegel to have fallen prey to the Post hoc ergo propter hoc fallacy.
Schopenhauer thought that Hegel used deliberately impressive but ultimately vacuous verbiage. He suggested his works were filled with "castles of abstraction" that sounded impressive but ultimately contained no content. He also thought that his glorification of church and state were designed for personal advantage and had little to do with the search for philosophical truth. For instance, the Right Hegelians interpreted Hegel as viewing the Prussian state of his day as perfect and the goal of all history up until then. So, although Schopenhauer may have appeared vain and overly vociferous in his constant attacks on Hegel, they were not necessarily devoid of merit.
It is well-known that the book 'Oupnekhat' (Upanisad) always lay open on his table and he invariably studied it before sleeping.at night. He called the opening up of Sanskrit literature 'the greatest gift of our century', and predicted that the philosophy and knowledge of the Upanisads would become the cherished faith of the West.
Buddhist philosopher Nishitani Keiji however sought to distance Buddhism from Schopenhauer.


Angola, officially the Republic of Angola (, pronounced ), is a country in south-central Africa bordering Namibia to the south, Democratic Republic of the Congo to the north, and Zambia to the east, and with a west coast along the Atlantic Ocean. The exclave province Cabinda has a border with the Republic of the Congo and the Democratic Republic of the Congo. A former Portuguese colony, it has considerable natural resources, most notably petroleum and diamonds. The country is nominally a democracy.
The earliest people of the area were Khoisan hunter-gatherers. They were largely replaced by Bantu tribes during Bantu migrations, though small numbers of Khoisan remain in parts of southern Angola to the present day. The geographical areas now designated as Angola first became the subject to incursions by Europeans in the late 15th century. In 1483 Portugal established a base at the river Congo, where the Kongo State, Ndongo and Lunda existed. The Kongo State stretched from modern Gabon in the north to the Kwanza River in the south. In 1575 Portugal established a colony at Cabinda based on slave trade. Before the beginning of the Atlantic slave trade, slavery was practiced in Africa by many indigenous peoples. The African slave trade provided a large number of black slaves to Europeans and their African agents. For example, in what is now Angola, the Imbangala had economies which were heavily focused on the slave trade. Within the Portuguese Empire, most black African slaves were traded to Brazilian merchants arrived to Portugal's African ports from other Portuguese colony - Brazil (South America) - seeking cheap workforce for use on Brazilian agricultural plantations. This trade would last until the first half of the 1800s. The Portuguese gradually took control of the coastal strip throughout the sixteenth century by a series of treaties and wars forming the Portuguese colony of Angola. Taking advantage of the Portuguese Restoration War, the Dutch occupied Luanda from 1641 to 1648, where they allied with local peoples to consolidate their colonial rule against the remaining Portuguese resistance.
In 1648, Portugal retook Luanda and initiated a process of reconquest of lost territories, which restored the pre-occupation possessions of Portugal by 1650. Treaties regulated relations with Congo in 1649 and Njinga's Kingdom of Matamba and Ndongo in 1656. The conquest of Pungo Andongo in 1671 was the last great Portuguese expansion, as attempts to invade Congo in 1670 and Matamba in 1681 failed. Portugal expanded its territory behind the colony of Benguela in the eighteenth century, and began the attempt to occupy other regions in the mid-nineteenth century. The process resulted in few gains until the 1880s. Full Portuguese administrative control of the interior didn't occur until the beginning of the twentieth century. In 1951, the colony was designated as an overseas province, called Portuguese West Africa. Portugal had a presence in Angola for nearly five hundred years, and the population's initial reaction to calls for independence was mixed.
Leftist military officers overthrew the Caetano government in Portugal in the Carnation Revolution on April 25, 1974. The transitional government opened negotiations with the three main independentist guerrilla groups: MPLA, FNLA, and UNITA, concluding separate peace agreements with each organization. With Portugal out of the picture, the nationalist movements turned on each other, fighting for control of Luanda and international recognition. Holden Roberto, Agostinho Neto, and Jonas Savimbi met in Bukavu, Zaire in July and agreed to negotiate with the Portuguese as one political entity. They met again in Mombasa, Kenya on January 5, 1975 and agreed to stop fighting each other, further outlining constitutional negotiations with the Portuguese. They met for a third time in Alvor, Portugal from January 10-15.
Roberto, Neto, Savimbi, and the Portuguese government signed the Alvor Agreement on January 15, setting November 11 as the date for independence. Alvor marked Angola’s transition from the war for independence to the war for Luanda. Portuguese authorities deliberately excluded the Front for the Liberation of the Enclave of Cabinda (FLEC) and Eastern Revolt from participating in the negotiations to ensure Angola’s territorial integrity, in direct opposition to the de Spínola’s plans for Angola. The coalition government the Alvor Agreement established soon fell as nationalist factions, doubting one another's commitment to the peace process, tried to take control of the colony by force.
When it was known that Portuguese authorities and military forces would leave the territory and hand over power to the nationalist groups, a mass exodus of civilian Portuguese citizens ensued. The Angolan Civil War (1975 - 2002), one of the largest and deadliest Cold War conflicts, erupted shortly after and lasted 27 years, ravaging the economy, disturbing social order and disrupting social stability in the newly independent country. Over 500,000 people lost their lives, mostly in the 1990s, as the three main factions and several smaller ones struggled for supremacy. Thousands of Angolan refugees suffered with the conflict and left the country or simply fled to other regions of Angola. Today, all parties to conflict are active politically, but the Popular Movement for the Liberation of Angola's (MPLA) victory in the war prevents any opposition candidate or ethnic group from challenging dos Santos and the Kimbundu’s "de facto " control of the country. The MPLA’s base is among the Kimbundu people and the multiracial intelligentsia of Luanda. The National Liberation Front of Angola (FNLA), based in the Bakongo region of the north, allied with the United States, the People's Republic of China and the Mobutu government in Zaïre. The United States, South Africa, and several other African nations also supported Jonas Savimbi's National Union for the Total Independence of Angola (UNITA), whose ethnic and regional base lies in the Ovimbundu heartland of central Angola.
On February 22 2002, Jonas Savimbi, the leader of UNITA, was killed in combat with government troops, and a cease-fire was reached by the two factions. UNITA gave up its armed wing and assumed the role of major opposition party. Although the political situation of the country began to stabilize, President dos Santos has so far refused to institute regular democratic processes. Among Angola's major problems are a serious humanitarian crisis (a result of the prolonged war), the abundance of minefields, and the actions of guerrilla movements fighting for the independence of the northern exclave of Cabinda (Frente para a Libertação do Enclave de Cabinda). While most of the internally displaced have now returned home, the general situation for most Angolans remains desperate, and the development facing the government challenging as a consequence.
Angola's motto is Virtus Unita Fortior, a Latin phrase meaning "Virtue is stronger when united." The executive branch of the government is composed of the President, the Prime Minister (currently Fernando da Piedade Dias dos Santos) and Council of Ministers. Currently, political power is concentrated in the Presidency. The Council of Ministers, composed of all government ministers and vice ministers, meets regularly to discuss policy issues. Governors of the 18 provinces are appointed by and serve at the pleasure of the president. The Constitutional Law of 1992 establishes the broad outlines of government structure and delineates the rights and duties of citizens. The legal system is based on Portuguese and customary law but is weak and fragmented, and courts operate in only twelve of more than 140 municipalities. A Supreme Court serves as the appellate tribunal; a Constitutional Court with powers of judicial review has never been constituted despite statutory authorization. Critics have drawn an ironic comparison between Angola's current one-party rule and the authoritarian government of António de Oliveira Salazar of Portugal, under whose rule Angolans began their revolt for independence.
The current government has announced an intention to hold elections in 2009. These elections would be the first since 1992 and would serve to elect both a new president and a new National Assembly.
With an area of approximately 7,283 km² (2,800 sq miles), the Northern Angolan province of Cabinda is unique in being separated from the rest of the country by a strip, some 60 km wide, of the Democratic Republic of Congo (DRC) along the lower Congo river. Cabinda borders the Congo Republic to the north and north-northeast and the DRC to the east and south. The town of Cabinda is the chief population centre. According to a 1995 census, Cabinda had an estimated population of 600,000, approximately 400,000 of whom live in neighbouring countries. Population estimates are, however, highly unreliable. Consisting largely of tropical forest, Cabinda produces hardwoods, coffee, cocoa, crude rubber and palm oil. The product for which it is best known, however, is its oil, which has given it the nickname, "the Kuwait of Africa". Cabinda's petroleum production from its considerable offshore reserves now accounts for more than half of Angola's output. Most of the oil along its coast was discovered under Portuguese rule by the Cabinda Gulf Oil Company (CABCOG) from 1968 onwards. Since Portugal handed over sovereignty of its former overseas province of Angola to the local independentist groups (MPLA, UNITA, and FNLA), the territory of Cabinda has been a theatre of separatist guerrilla actions opposing the Government of Angola (which has employed its military forces, the FAA - Forças Armadas Angolanas) and Cabindan separatists. The Cabindan separatists, FLEC-FAC, created a virtual Federal Republic of Cabinda under the Presidency of N'Zita Henriques Tiago. In its website, it claimed to be committed to building a Republic of Cabinda in which "freedom, opportunity, prosperity and civil society flourish". This Federal Republic, with Tchiowa (Cabinda) as its capital city, would be administratively made up of seven districts, with a system of government which the website simply describes as a "true democracy" and a legal system based on traditional N'Goyo law. One of the characteristics of the Cabindan independence movement is its constant fragmentation, into smaller and smaller factions, in a process which the Angolan government, although not totally fomented by it, undoubtedly encourages and duly exploits it.
The Angolan Armed Forces (FAA) is headed by a Chief of Staff who reports to the Minister of Defense. There are three divisions--the Army, (Exército), Navy (Marinha de Guerra, MGA), and Air and Air Defense Forces (Força Aérea Nacional, FAN). Total manpower is about 110,000. The army is by far the largest of the services with about 100,000 men and women. The Navy numbers about 3,000 and operates several small patrol craft and barges. Air force personnel total about 7,000; its equipment includes Russian-manufactured fighters, bombers, and transport planes. There are also, Brazilian made EMB-312 Tucano for Training role, Czech made L-39 for training and bombing role, Czech Zlin for training role and a variety of western made aircraft such as C-212\Aviocar, Sud Aviation Aloutte III, etc. A small number of FAA personnel are stationed in the Democratic Republic of the Congo (Kinshasa) and the Republic of the Congo (Brazzaville).
The National Police departments are: Public Order, Criminal Investigation, Traffic and Transport, Investigation and Inspection of Economic Activities, Taxation and Frontier Supervision, Riot Police and the Rapid Intervention Police. The National Police are in the process of standing up an air wing, which will provide helicopter support for police operations. The National Police are also developing their criminal investigation and forensic capabilities. The National Police has an estimated 6,000 patrol officers, 2,500 Taxation and Frontier Supervision officers, 182 criminal investigators and 100 financial crimes detectives and 90 Economic Activity Inspectors.
The National Police have implemented a modernization and development plan to increase the capabilities and efficiency of the total force. In addition to administrative reorganization; modernization projects include procurement of new vehicles, aircraft and equipment, construction of new police stations and forensic laboratories, restructured training programs and the replacement of AKM rifles with 9 mm UZIs for police officers in urban areas.
At 481,321 square miles (1,246,700 km²), Angola is the world's twenty-third largest country (after Niger). It is comparable in size to Mali and is nearly twice the size of the US state of Texas, or five times the area of the United Kingdom.
Angola is bordered by Namibia to the south, Zambia to the east, the Democratic Republic of the Congo to the north-east, and the South Atlantic Ocean to the west. The exclave of Cabinda also borders the Republic of the Congo to the north. Angola's capital, Luanda, lies on the Atlantic coast in the north-west of the country. Angola's average temperature on the coast is 60 degrees Fahrenheit (16 °C) in the winter and 70 degrees Fahrenheit (21 °C) in the summer.
Angola's economy has undergone a period of transformation in recent years, moving from the disarray caused by a quarter century of war to being the second fastest growing economy in Africa and one of the fastest in the world. In 2004, China's Eximbank approved a $2 billion line of credit to Angola. The loan is being used to rebuild Angola's infrastructure, and has also limited the influence of the International Monetary Fund in the country.
Growth is almost entirely driven by rising oil production which surpassed 1.4 million barrels per day in late-2005 and which is expected to grow to 2 million barrels per day by 2007. Control of the oil industry is consolidated in Sonangol Group, a conglomerate which is owned by the Angolan government. In December 2006, Angola was admitted as a member of OPEC. The economy grew 18% in 2005, 26% in 2006 and 17.6% in 2007 and it's expected to stay above 10% for the rest of the decade. The security brought about by the 2002 peace settlement has led to the resettlement of 4 million displaced persons, thus resulting in large-scale increases in agriculture production.
The country has developed its economy since political stability arose in 2002. However, it faces huge social and economic problems as a result of an almost continual state of conflict since 1961, although the highest level of destruction and socio-economic damage was reached after the 1975 independence, during the long years of civil war. Rapidly rising production and revenues from the oil sector have been the main driving forces behind the improvements in overall economic activity - nevertheless, poverty remains widespread. Anti-corruption watchdog Transparency International rated Angola one of the 10 most corrupt countries in the world in 2005. The capital city is the most developed and the only large economic center worth mentioning in the country, however, slums called musseques, stretch for miles beyond Luanda's former city limits.
Angola is composed of Ovimbundu 37%, Kimbundu 25%, Bakongo 13%, mestiços (mixed European and native African) 2%, European 1%, and 22% 'other' ethnic groups.
Portugal ruled over Angola for 400 years and both countries share cultural aspects: language (Portuguese) and main religion (Roman Catholic Christianity). The Angolan culture is mostly native Bantu which was mixed with Portuguese culture.
Once synonymous to slavery, outlaws and violence, Capoeira is now well known all over the world as an art form, and has fascinated thousands. Capoeira is divided into two parts: Capoeira Regional and Capoeira Angola. Capoeira Regional is a modern and popular form of capoeira. Capoeira Angola is the original form, created in Brazil by African slaves. Capoeira Angola has roots in the wedding rituals of the Bantu tribe, where the Dance of the Zebra, the N´golo, was a sparring between young warriors. That is why the Zebra is part of the Capoeira Angola logo. Capoeira Angola is a sparring between friends, an exciting game in the middle of the "roda," a ring formed by musicians and singers. It is fight, dance, play, music and philosophy, all in one. For years Capoeira was practiced in secrecy and it was not lawful to practice and teach until after the 1930s; forty years after the abolition of slavery. Berimbau is an instrument related with capoeira, it commands the roda, and determines the kind of fight (Angola or Regional).


Angola is located on the South Atlantic Coast of West Africa between Namibia and the Republic of the Congo. It also is bordered by the Democratic Republic of the Congo and Zambia to the east. The country is divided into an arid coastal strip stretching from Namibia to Luanda; a wet, interior highland; a dry savanna in the interior south and southeast; and rain forest in the north and in Cabinda. The Zambezi River and several tributaries of the Congo River have their sources in Angola. The coastal strip is tempered by the cool Benguela current, resulting in a climate similar to coastal Peru or Baja California. There is a short rainy season lasting from February to April. Summers are hot and dry, while winters are mild. The interior highlands have a mild climate with a rainy season from November through April followed by a cool dry season from May to October. Elevations generally range from 3,000 to 6,000 feet (900 to 1,800 m). The far north and Cabinda enjoy rain throughout much of the year.
The coast is for the most part flat, with occasional low cliffs and bluffs of red sandstone. There is but one deep inlet of the sea - Great Fish Bay (or Baía dos Tigres). Farther north are Port Alexander, Little Fish Bay and Lobito Bay, while shallower bays are numerous. Lobito Bay has water sufficient to allow large ships to unload close inshore. The coast plain extends inland for a distance varying from 30 to 100 miles (48 to 165 km). This region is in general sparsely watered and somewhat sterile. The approach to the great central plateau of Africa is marked by a series of irregular escarpments and cuestas. This intermediate mountain belt is covered with luxuriant vegetation. Water is fairly abundant, though in the dry season obtainable only by digging in the sandy beds of the rivers. The plateau has an altitude ranging from 4000 to 6000 ft (1,200 to 1,800 m). It consists of well-watered, wide, rolling plains, and low hills with scanty vegetation. In the east the tableland falls away to the basins of the Congo and Zambezi, to the south it merges into a barren sandy desert. A large number of rivers make their way westward to the sea; they rise, mostly, in the mountain belt, and are unimportant, the only two of any size being the Kwanza and the Kunene, separately noticed. The mountain chains which form the edge of the plateau, or diversify its surface, run generally parallel to the coast, as Tala Mugongo (4400 ft. 1350 m), Chella and Vissecua (5250 ft. to 6500 ft. or 1500 to 2000 m). In the district of Benguela are the highest points of the province, viz. Loviti (7780 ft. 2370 m), in 12° 5' S. and Mt. Elonga (7550 ft. 2300 m). South of the Kwanza is the volcanic mountain Caculo-Cabaza (3300 ft. 1000 m). From the tableland the Kwango and many other streams flow north to join the Kasai River (one of the largest affluents of the Congo), which in its upper course forms for fully 300 mi (490 km). the boundary between Angola and the Congo State. In the south-east part of the province the rivers belong either to the Zambezi system, or, like the Okavango, drain to Lake Ngami.
The central plateau consists of ancient crystalline rocks with granites overlain by unfossiliferous sandstones and conglomerates of Paleozoic age. The outcrops are largely hidden under laterite. The median zone is composed largely of crystalline rocks with granites and some Palaeozoic unfossiliferous rocks. The littoral zone contains the only fossiliferous strata. These are of Tertiary and Cretaceous ages, the latter rocks resting on a reddish sandstone of older date. The Cretaceous rocks of the Dombe Grande region (near Benguella) are of Albian age and belong to the Acanthoceras mamillari zone. The beds containing Schloenbachia inflata are referable to the Gault. Rocks of Tertiary age are met with at Dombe Grande, Mossamedes and near Loanda. The sandstones with gypsum, copper and sulfur of Dombe are doubtfully considered to be of Triassic age. Recent eruptive rocks, mainly basalts, form a line of hills almost bare of vegetation between Benguella and Mossamedes. Nepheline basalts and liparites occur at Dombe Grande. The presence of gum copal in considerable quantities in the superficial rocks is characteristic of certain regions.
Like the rest of tropical Africa, Angola experiences distinct, alternating rainy and dry seasons. It is semiarid in South and along coast to Luanda; North has cool, dry season (May to October) and hot, rainy season (November to April). In the interior, above 3300 ft. (1000 m), the temperature and rainfall decrease. The plateau climate is healthy and invigorating. The mean annual temperature at São Salvador do Congo is 22.2° C (72.5° F); at Luanda, 23.3° C (74.3° F); and at Caconda, 19.5° C (67.2° F). The climate is greatly influenced by the prevailing winds, which arc W. S.W. and S.S.W. Two seasons are distinguished - the cool, from June to September; and the rainy, from October to May. The heaviest rainfall occurs in April, and is accompanied by violent storms.
Angola has three principal natural regions: the coastal lowland, characterized by low plains and terraces; hills and mountains, rising inland from the coast into a great escarpment; and an area of high plains, called the high plateau (planalto), which extends eastward from the escarpment. The highest point in Angola is Morro de Moco, at 2,620 m.
The coastal lowland rises from the sea in a series of low terraces. This region varies in width from about 25 kilometers near Benguela to more than 150 kilometers in the Cuanza River Valley just south of Angola's capital, Luanda, and is markedly different from Angola's highland mass. The Atlantic Ocean's cold, northwardflowing Benguela Current substantially reduces precipitation along the coast, making the region relatively arid or nearly so south of Benguela (where it forms the northern extension of the Namib Desert), and quite dry even in its northern reaches. Even where, as around Luanda, the average annual rainfall may be as much as fifty centimeters, it is not uncommon for the rains to fail. Given this pattern of precipitation, the far south is marked by sand dunes, which give way to dry scrub along the middle coast. Portions of the northern coastal plain are covered by thick brush.
The belt of hills and mountains parallels the coast at distances ranging from 20 kilometers to 100 kilometers inland. The Cuanza River divides the zone into two parts. The northern part rises gradually from the coastal zone to an average elevation of 500 meters, with crests as high as 1,000 meters to 1,800 meters. South of the Cuanza River, the hills rise sharply from the coastal lowlands and form a high escarpment, extending from a point east of Luanda and running south through Namibia. The escarpment reaches 2,400 meters at its highest point, southeast of the town of Sumbe, and is steepest in the far south in the Serra da Chela mountain range.
The high plateau lies to the east of the hills and mountains and dominates Angola's terrain. The surface of the plateau is typically flat or rolling, but parts of the Benguela Plateau and the Humpata Highland area of the Huíla Plateau in the south reach heights of 2,500 meters and more. The Malanje Plateau to the north rarely exceeds 1,000 meters in height. The Benguela Plateau and the coastal area in the immediate environs of Benguela and Lobito, the Bié Plateau, the Malanje Plateau, and a small section of the Huíla Plateau near the town of Lubango have long been among the most densely settled areas in Angola.
Most of the country's many rivers originate in central Angola, but their patterns of flow are diverse and their ultimate outlets varied. A number of rivers flow in a more or less westerly course to the Atlantic Ocean, providing water for irrigation in the dry coastal strip and the potential for hydroelectric power, only some of which had been realized by 1988. Two of Angola's most important rivers, the Cuanza and the Cunene, take a more indirect route to the Atlantic, the Cuanza flowing north and the Cunene flowing south before turning west. The Cuanza is the only river wholly within Angola that is navigable--for nearly 200 kilometers from its mouth- -by boats of commercially or militarily significant size. The Congo River, whose mouth and western end form a small portion of Angola's northern border with Zaire, is also navigable.
North of the Lunda Divide a number of important tributaries of the Congo River flow north to join it, draining Angola's northeast quadrant. South of the divide some rivers flow into the Zambezi River and thence to the Indian Ocean, others to the Okavango River (as the Cubango River is called along the border with Namibia and in Botswana) and thence to the Okavango Swamp in Botswana. The tributaries of the Cubango River and several of the southern rivers flowing to the Atlantic are seasonal, completely dry much of the year.
Both flora and fauna are those characteristic of the greater part of tropical Africa. As far south as Benguela the coast region is rich in oil palms and mangroves. In the Northern part of the province are dense forests. In the South towards the Kunene are regions of dense thorn scrub. Rubber vines and trees are abundant, but in some districts their number has been considerably reduced by the primitive methods adopted by native collectors of rubber. The species most common are various root rubbers, notably the Carpodinus chylorrhiza. This species and other varieties of carpodinus are very widely distributed. Landolphias are also found. The coffee, cotton and Guinea pepper plants are indigenous, and the tobacco plant flourishes in several districts. Among the trees are several which yield excellent timber, such as the tacula (Pterocarpus tinctorius), which grows to an immense size, its wood being blood-red in colour, and the Angola mahogany. The bark of the musuemba (Albizzia coriaria) is largely used in the tanning of leather. The mulundo bears a fruit about the size of a cricket ball covered with a hard green shell and containing scarlet pips like a pomegranate. The fauna includes the lion, leopard, cheetah, elephant, giraffe, rhinoceros, hippopotamus, buffalo, zebra, kudu and many other kinds of antelope, wildpig, ostrich and crocodile. Among fish are the barbel, bream and African yellow fish.
This is a list of the extreme points of Angola, the points that are farther north, south, east or west than any other location.

The demographics of Angola consist of three main ethnic groups, each speaking a Bantu language: Ovimbundu 37%, Mbundu 25%, and Bakongo 13%. Other groups include Chokwe (or Lunda), Ganguela, Nhaneca-Humbe, Ambo, Herero, and Xindunga. In addition, mixed race (European and African) people amount to about 2%, with a small (1%) population of whites, mainly ethnically Portuguese. Portuguese make up the largest non-African population, with at about 40,000 (though many native-born Angolans can claim Portuguese nationality under Portuguese law). In 1975, 250,000 Cuban soldiers arrived in Angola to help the MPLA forces during the civil war.
The largest denomination of this is Roman Catholicism, but there are also followers of Protestantism, and African Initiated Churches most of them are Bantu speakers and some Portuguese. As of 2006, one out of 221 people were Jehovah's Witnesses. Blacks from Mali, Nigeria, and Senegal are mostly Muslims. The rest of Angolans retain all or in part African Traditional Religion following different ethnic faiths.
There are 12,263,596 Angolan citizens as of July 2007. The population is predominately quite young, with 43.7% between the ages of less than one and 14 years old, 2,678,185 males and 2,625,933 females. 53.5% of the population is between the ages of 15 and 64 years old, with 3,291,954 males and 3,195,688 females. 2.8% are 65 years and over, 148,944 males and 186,367 females as of 2006. The median age for males and females is 18 years old.
The population is growing by 2.184% annually. There are 44.51 births and 24.81 deaths per 1,000 citizens. The net migration rate is 2.14 migrants per 1,000 citizens. The fertility rate of Angola is 6.27 children born per woman as of 2006. The infant mortality rate is 184.44 deaths for every 1,000 live births with 196.55 deaths for males and 171.72 deaths for females for every 1,000 live births. Life expectancy at birth is 37.63 years; 36.73 years for males and 38.57 years for females.
There are 1.05 males for every female with 1.02 males to female for those under the age of 15, 1.03 males for the 15 to 64 age bracket, 0.8 males for the 65 years and over bracket and 1.02 males to female for the total population as of 2006.
The adult prevalence rate of HIV/AIDS infection is 3.9% as of 2003. There are 240,000 citizens living with AIDS and 21,000 die annually. The risk of contracting disease is very high. There are food and waterborne diseases, bacterial and protozoal diarrhea, hepatitis A, and typhoid fever; vectorborne diseases, malaria, African trypanosomiasis (sleeping sickness); respiratory disease: meningococcal meningitis, and schistosomiasis, a water contact disease, as of 2005.
37% of Angolans are Ovimbundu, 25% are Kimbundu, 13% are Bakongo, 2% are mestiço, 1% are Portuguese, and other ethnicities make up 22% of Angola's population.
Angola is a majority Christian country, with 53% of citizens professing the religion. Most Angolan Christians are Roman Catholic, 38%, or Protestant, 15%. 46.8% of Angolans practice indigenous beliefs.
Portuguese is the official language of Angola, but Bantu and other African languages are also widely spoken. Literacy is quite low, with 67.4% of the population over the age of 15 able to read and write in Portuguese. 82.9% of males and 54.2% of women are literate as of 2001.

Politics of Angola takes place in a framework of a presidential republic, whereby the President of Angola is both head of state and head of government, and of a pluriform multi-party system. Executive power is exercised by the government. Legislative power is vested in both the government and parliament. Angola changed from a one-party Marxist-Leninist system ruled by the MPLA to a formal multiparty democracy following the 1992 elections. President dos Santos won the first round election with more than 49% of the vote to Jonas Savimbi's 40%. A runoff never has taken place. The subsequent renewal of civil war and collapse of the Lusaka Protocol have left much of this process stillborn, but democratic forms exist, notably the National Assembly.
Currently, political power is concentrated in the Presidency. The executive branch of the government is composed of the President, the Prime Minister (currently Fernando da Piedade Dias dos Santos) and Council of Ministers. The Council of Ministers, composed of all government ministers and vice ministers, meets regularly to discuss policy issues. Governors of the 18 provinces are appointed by and serve at the pleasure of the president. The Constitutional Law of 1992 establishes the broad outlines of government structure and delineates the rights and duties of citizens. The legal system is based on Portuguese and customary law but is weak and fragmented. Courts operate in only 12 of more than 140 municipalities. A Supreme Court serves as the appellate tribunal; a Constitutional Court with powers of judicial review has never been constituted despite statutory authorization.
The 26-year long civil war has ravaged the country's political and social institutions. The UN estimates of 1.8 million internally displaced persons (IDPs), while generally the accepted figure for war-affected people is 4 million. Daily conditions of life throughout the country and specifically Luanda (population approximately 4 million) mirror the collapse of administrative infrastructure as well as many social institutions. The ongoing grave economic situation largely prevents any government support for social institutions. Hospitals are without medicines or basic equipment, schools are without books, and public employees often lack the basic supplies for their day-to-day work.
The National Assembly (Assembleia Nacional) has 220 members, elected for a four year term, 130 members by proportional representation and 90 members in provincial districts. The next general elections, due for 1997, have been rescheduled for between May and August 2008, although a definite date has yet to be set.
The president has announced the government's intention to hold elections in 2009. These elections would be the first since 1992 and would serve to elect both a new president and a new National Assembly.

The Economy of Angola is the fastest-growing economy in Africa, but is still recovering from the civil war that plagued Angola from independence in 1975 until 2002. Despite abundant natural resources, output per capita remains among the world's lowest. Subsistence agriculture and dependence on humanitarian food assistance sustain the large majority of the population. Little industry exists.
The Portuguese discovered petroleum in Angola in 1955. Production began in the Cuanza basin in the 1950s, in the Congo basin in the 1960s, and in the exclave of Cabinda in 1968. The government granted operating rights for Block Zero to the Cabinda Gulf Oil Company, a subsidiary of ChevronTexaco, in 1955. Oil production surpassed the exportation of coffee as Angola's largest export in 1973, producing 172,000 b/d in 1974. Angolans produced 490,000 b/d in 1991, 635,000 b/d in 1995, 800,000 b/d (127,000 m³) in 2001, and 1.46 million b/d in 2006.
Mobutu Sese Seko, the President of Zaire, met with António de Spínola, the transitional President of Portugal, on September 15, 1974 on Sal island in the Cape Verdes, crafting a plan to empower Holden Roberto of the National Liberation Front of Angola, Jonas Savimbi of UNITA, and Daniel Chipenda of the MPLA's eastern faction at the expense of MPLA leader Agostinho Neto while retaining the facade of national unity. Mobutu and Spínola wanted to present Chipenda as the MPLA head, Mobutu particularly preferring Chipenda over Neto because Chipenda supported autonomy for Cabinda. The Angolan exclave has immense petroleum reserves estimated at around 300 million tons which Zaire, and thus the Mobutu government, depended on for economic survival.
The Angolan government created Sonangol, a state-run oil company, in 1976. Two years later Sonangol received the rights to oil exploration and production in all of Angola.
United Nations Angola Verification Verification Mission III and MONUA spent USD $1.5 billion overseeing implementation of the Lusaka Protocol, a 1994 peace accord that ultimately failed to end the civil war. The protocol prohibited UNITA from buying foreign arms, a provision the United Nations largely did not enforce, so both sides continued to build up their stockpile. UNITA purchased weapons in 1996 and 1997 from private sources in Albania and Bulgaria, and from Zaire, South Africa, Republic of the Congo, Zambia, Togo, and Burkina Faso. In October 1997 the UN imposed travel sanctions on UNITA leaders, but the UN waited until July 1998 to limit UNITA's exportation of diamonds and freeze UNITA bank accounts. While the U.S. government gave USD $250 million to UNITA between 1986 to 1991, UNITA made $1.72 billion between 1994 and 1999 exporting diamonds, primarily through Zaire to Europe. At the same time the Angolan government received large amounts of weapons from the governments of Belarus, Brazil, Bulgaria, the People's Republic of China, and South Africa. While no arms shipment to the government violated the protocol, no country informed the U.N. Register on Conventional Weapons as required.
Despite the increase in civil warfare in late 1998, the economy grew by an estimated 4% in 1999. The government introduced new currency denominations in 1999, including a 1 and 5 kwanza note.
An economic reform effort was launched in 1998. The Angolan economy ranked 160 out of 174 nations in the United Nations Human Development Index of 2000. In April 2000 Angola started an International Monetary Fund (IMF) Staff-Monitored Program (SMP). The program formally lapsed in June 2001, but the IMF remains engaged. In this context the Government of Angola has succeeded in unifying exchange rates and has raised fuel, electricity, and water rates. The Commercial Code, telecommunications law, and Foreign Investment Code are being modernized. A privatization effort, prepared with World Bank assistance, has begun with the BCI bank. Nevertheless, a legacy of fiscal mismanagement and corruption persists. The civil war internally displaced 3.8 million people, 32% of the population, by 2001. The security brought about by the 2002 peace settlement has led to the resettlement of 4 million displaced persons, thus resulting in large-scale increases in agriculture production.
Angola produced over 3 Mct of diamonds in 2003. In 2004 China's Eximbank approved a $2 billion line of credit to Angola to rebuild infrastructure. The economy grew 18% in 2005 and growth was expected to reach 26% in 2006 and stay above 10% for the rest of the decade.
ChevronTexaco started pumping 50,000 b/d from Block 14 in January 2000, but production has decreased to 57,000 b/d as of 2007 due to the poor quality of the oil. Angola joined the Organization of the Petroleum Exporting Countries on January 1, 2007.
Cabinda Gulf Oil Company found Malange-1, an oil reservoir in Block 14, on August 9, 2007.
Despite its abundant natural resources, output per capita is among the world's lowest. Subsistence agriculture provides the main livelihood for 85% of the population. Oil production and the supporting activities are vital to the economy, contributing about 45% to GDP and 90% of exports. Growth is almost entirely driven by rising oil production which surpassed 1.4 million barrels per day in late-2005 and which is expected to grow to 2 million barrels per day by 2007. Control of the oil industry is consolidated in Sonangol Group, a conglomerate which is owned by the Angolan government. With revenues booming from oil exports, the government has started to implement ambitious development programs in building roads and other basic infrastructure for the nation.
In the last decade of the colonial period, Angola was a major African food exporter but now imports almost all its food. Because of severe wartime conditions, including extensive planting of landmines throughout the countryside, agricultural activities have been brought to a near standstill. Some efforts to recover have gone forward, however, notably in fisheries. Coffee production, though a fraction of its pre-1975 level, is sufficient for domestic needs and some exports. In sharp contrast to a bleak picture of devastation and bare subsistence is expanding oil production, now almost half of GDP and 90% of exports, at 800,000 barrels (127,000 m³) a day. Diamonds provided much of the revenue for Jonas Savimbi's UNITA rebellion through illicit trade. Other rich resources await development: gold, forest products, fisheries, iron ore, coffee, and fruits.
This is a chart of trend of nominal gross domestic product of Angola (since unification) at market prices using International Monetary Fund data; figures are in millions of units.
Exports in 2004 reached USD $10,530,764,911. The vast majority of Angola's exports, 92% in 2004, are petroleum products. $785 million worth of diamonds, 7.5% of exports, were sold abroad that year. Nearly all of Angola's oil goes to the United States, 526,000 b/d in 2006, making it the eighth largest supplier of oil to the United States, and to the People's Republic of China, 477,000b/d in 2006. The rest of its petroleum exports go to Europe and Latin America. U.S. companies account for more than half the investment in Angola, with Chevron-Texaco leading the way. The U.S. exports industrial goods and services, primarily oilfield equipment, mining equipment, chemicals, aircraft, and food, to Angola, while principally importing petroleum. Trade between Angola and South Africa exceeded USD $300 million in 2007.
Angolan petroleum production is second only to Nigeria in African oil production, and in January 2007 Angola became a member of OPEC. By 2010 production is expected to double the 2006 output level with development of deep-water offshore oil fields. Oil sales generated USD $1.71 billion in tax revenue in 2004 and now makes up 80% of the government's budget, a 5% increase from 2003, and 45% of GDP.
Chevron Corporation produces and receives 400,000 b/d, 27% of Angolan oil. Elf Oil, Texaco, ExxonMobil, Agip, Petrobras, and British Petroleum also operate in the country.
Block Zero provides the majority of Angola's crude oil production with 370,000 b/d produced annually. The largest fields in Block Zero are Takula (Area A), Numbi (Area A), and Kokongo (Area B). ChevronTexaco operates in Block Zero with a 39.2% share. SONANGOL, the state oil company, Total, and ENI-Agip own the rest of the block. ChevronTexaco also operates Angola's first producing deepwater section, Block 14, with 57,000 b/d.
The United Nations has criticized the Angolan government for using torture, rape, summary executions, arbitrary detention, and disappearances, actions which Angolan government has justified on the need to maintain oil output.
Angola is the third-largest trading partner of the United States in Sub-Saharan Africa, largely because of its petroleum exports. The U.S. imports 7% of its oil from Angola, about three times as much as it imported from Kuwait just prior to the Gulf War in 1991. The U.S. Government has invested USD $4 billion in Angola's petroleum sector.
Angola is the third largest producer of diamonds in Africa and has only explored 40% of the diamond-rich territory within the country, but has had difficulty in attracting foreign investment because of corruption, human rights violations, and diamond smuggling. Production rose by 30% in 2006 and Endiama, the national diamond company of Angola, expects production to increase by 8% in 2007 to 10 million carats annually. The government is trying to attract foreign companies to the provinces of Bié, Malanje and Uíge.
Angola began mining iron in 1957, producing 1.2 million tons in 1967 and 6.2 million tons by 1971. In the 1970s 70% of Angola's iron exports went to Western Europe or Japan.

Telephone service is limited mostly to government and business use. 96,300 main lines were reported to be in use in 2003, and 130,000 mobile cellular lines were reported in 2002. HF radiotelephone is used extensively for military links.
The domestic system consists of a limited system of wire. It also uses microwave radio relay and tropospheric scatter.
The international country code for Angola is 244. Angola has 2 Intelsat satellite earth stations for communications across the Atlantic Ocean. Fiber optic submarine cable (SAT-3/WASC) provides connectivity to Europe and Asia.
Internet access in Angola is provided by MSTelcom, a subsidiary of Sonangol, the national oil company.

There are three separate lines which do not link up. The major railway is the Benguela railway. A fourth system once linked Gunza and Gabala.
started in October 2003 will be completed by August 2008. The work was carried out by the Chinese firm MEC-TEC.
A link to Namibia is partly under construction.
Travel on highways outside of towns and cities in Angola (and in some cases within) is often not best advised for those without four-by-four vehicles. Whilst a reasonable roads infrastructure has existed within Angola, time and the war have taken their toll on the road surfaces, leaving many severely potholed, littered with broken asphalt. In many areas drivers have established alternate tracks to avoid the worst parts of the surface, although careful attention must be paid to the presence or absence of landmine warning markers by the side of the road.
The Angolan government has contracted the restoration of many of the country's roads, though. Many companies are coming into the country from China and surrounding nations to help improve road surfaces. The road between Lubango and Namibe, for example, was completed recently with funding from the European Union, and is comparable to many European main routes. Progress to complete the road infrastructure is likely to take some decades, but substantial efforts are already being made in the right directions.
This article comes from the CIA World Factbook 2003.

The Angolan Armed Forces (FAA) is headed by a Chief of Staff who reports to the Minister of Defense.
There are three divisions, the Army, Navy (Marinha de Guerra, MdG), and Air and Air Defense Forces (FAPA). Total manpower is about 110,000. The army is by far the largest of the services with about 100,000 men and women. The Navy numbers about 3,000 and operates several small patrol craft and barges. Air force personnel total about 7,000; its equipment includes Russian-manufactured fighters and transport planes.
A small number of FAA personnel are stationed in the Democratic Republic of the Congo (Kinshasa) and the Republic of the Congo (Brazzaville).

The foreign relations of Angola are based on Angola's strong support of U.S. foreign policy as the Angolan economy is dependent on U.S. foreign aid.
From 1975 to 1989, Angola was aligned with the Eastern bloc, in particular the Soviet Union, Libya, and Cuba. Since then, it has focused on improving relationships with Western countries, cultivating links with other Portuguese-speaking countries, and asserting its own national interests in Central Africa through military and diplomatic intervention. In 1993, it established formal diplomatic relations with the United States. It has entered the Southern African Development Community as a vehicle for improving ties with its largely Anglophone neighbors to the south. Zimbabwe and Namibia joined Angola in its military intervention in the Democratic Republic of the Congo, where Angolan troops remain in support of the Joseph Kabila government. It also has intervened in the Republic of the Congo (Brazzaville) to support the existing government in that country.
Since 1998, Angola has successfully worked with the UN Security Council to impose and carry out sanctions on UNITA. More recently, it has extended those efforts to controls on conflict diamonds, the primary source of revenue for UNITA. At the same time, Angola has promoted the revival of the Community of Portuguese-Speaking Countries (CPLP) as a forum for cultural exchange and expanding ties with Portugal and Brazil in particular.
Angola established relations with the People's Republic of China in 1983.
Chinese Prime Minister Wen Jiabao visited Angola in June 2006, offering a US$9 billion loan for infrastructure improvements in return for petroleum. The PRC has invested heavily in Angola since the end of the civil war in 2002. João Manuel Bernardo, the current ambassador of Angola to China, visited the PRC in November 2007.
Angola-Israel relations, primarily based on trade and pro-United States foreign policies, are excellent. In March 2006, the trade volume between the two countries amounted to $400 million. The Israeli ambassador to Angola is Avraham Benjamin.[1] In 2005, President José Eduardo dos Santos visited Israel.
Relations between the United States of America and the Republic of Angola (formerly the People's Republic of Angola) have warmed since Angola's ideological renunciation of Marxism before the 1992 elections.

Albert Sidney Johnston (February 2, 1803 – April 6, 1862) was a career U.S. Army officer and a Confederate general during the American Civil War. Considered by Confederate President Jefferson Davis to be the finest general in the Confederacy before the emergence of Robert E. Lee, he was killed early in the war at the Battle of Shiloh and was the highest ranking officer, Union or Confederate, killed during the conflict.
Johnston was born in Washington, Kentucky, the youngest son of Dr. John and Abigail Harris Johnston. His father was a native of Salisbury, Connecticut. Although Albert Johnston was born in Kentucky, he lived much of his life in Texas, which he considered his home. He was first educated at Transylvania University in Lexington, where he met fellow student Jefferson Davis. Both were appointed to the United States Military Academy, Jefferson two years behind Johnston. In 1826 Johnston graduated eighth in his class from West Point with a commission as a brevet second lieutenant in the 2nd U.S. Infantry. He was assigned to posts in New York and Missouri and served in the Black Hawk War in 1832 as chief of staff to General Henry Atkinson. In 1829 he married Henrietta Preston. He resigned his commission in 1834 to return to Kentucky to care for his dying wife, who succumbed two years later to tuberculosis. They had one son, Col. William Preston Johnston, who would also serve in the Confederate Army.
In April 1834, Johnston took up farming in Texas, but enlisted as a private in the Texas Army during the Texas War of Independence against the Republic of Mexico in 1836. One month later, Johnston was promoted to major and the position of aide-de-camp to General Sam Houston. He was named Adjutant General as a colonel in the Republic of Texas Army on August 5, 1836. On January 31, 1837, he became senior brigadier general in command of the Texas Army.
On February 7, 1837, he fought in a duel with Texas Brig. Gen. Felix Huston, challenging each other for the command of the Texas Army; Johnston refused to fire on Huston and lost the position after he was wounded in the pelvis. The second president of the Republic of Texas, Mirabeau B. Lamar, appointed him Secretary of War on December 22, 1838. Johnston was to provide the defense of the Texas border against Mexican invasion, and in 1839 conducted a campaign against Indians in northern Texas. In February 1840, he resigned and returned to Kentucky, where he married Eliza Griffin in 1843. They settled on a large plantation he named China Grove in Brazoria County, Texas.
Johnston returned to the Texas Army during the Mexican-American War under General Zachary Taylor as a colonel of the 1st Texas Rifle Volunteers. The enlistments of his volunteers ran out just before the Battle of Monterrey. Johnston managed to convince a few volunteers to stay and fight as he himself served as the inspector general of volunteers and fought at the battles of Monterrey and Buena Vista. Johnston remained on his plantation after the war until he was appointed by now-President Taylor to the U.S. Army as a major and was made a paymaster in December of 1849. He served in that role for more than five years, making six tours, and traveling more than 4,000 miles annually on the Indian frontier of Texas. He served on the Texas frontier and elsewhere in the West. In 1855 President Franklin Pierce appointed him colonel of the new 2nd U.S. Cavalry (the unit that preceded the modern 5th U.S.), a new regiment, which he organized. As a key figure in the Utah War, he led U.S. troops who established a non-Mormon government in the formerly Mormon territory. He received a brevet promotion to brigadier general in 1857 for his service in Utah. He spent 1860 in Kentucky until December 21, when he sailed for California to take command of the Department of the Pacific.
At the outbreak of the Civil War, Johnston was the commander of the U.S. Army Department of the Pacific in California. He was approached by some Californians who urged him to take his forces east to join the Union against the Confederacy. He resigned his commission, April 9, 1861, as soon as he heard of the secession of Texas. He remained in California until June. After a rapid march through the deserts of Arizona and Texas, he reached Richmond, Virginia, on or about September 1, 1861. There Johnston was appointed a general by his friend, Jefferson Davis. On May 30, 1861, Johnston became the second highest ranking Confederate General (after the little-known Samuel Cooper) as commander of the Western Department. He raised the Army of Mississippi to defend Confederate lines from the Mississippi River to Kentucky and the Allegheny Mountains.
Although the Confederate States Army won a morale-boosting victory at First Battle of Bull Run in the East in 1861, matters in the West turned ugly by early 1862. Johnston's subordinate generals lost Fort Henry on February 6, 1862, and Fort Donelson on February 16, 1862, to Union Brig. Gen. Ulysses S. Grant. Johnston has been faulted for poor judgment in selecting Brig. Gens. Tilghman and Floyd for those crucial positions and for not supervising adequate construction of the forts. And Union Maj. Gen. Don Carlos Buell captured the vital city of Nashville, Tennessee. Gen. P.G.T. Beauregard was sent west to join Johnston and they organized their forces at Corinth, Mississippi, planning to ambush Grant's forces at Pittsburg Landing, Tennessee.
Johnston concentrated many of his forces from around the theater and launched a massive surprise attack against Grant at the Battle of Shiloh on April 6, 1862. As the Confederate forces overran the Union camps, Johnston seemed to be everywhere, personally leading and rallying troops up and down the line. At about 2:30 p.m. while leading one of those charges, he was wounded, taking a bullet behind his right knee. He did not think the wound serious at the time, and sent his personal physician to attend to some wounded Union soldiers instead. The bullet had in fact clipped his popliteal artery and his boot was filling up with blood. Within a few minutes Johnston was observed by his staff to be nearly fainting off of his horse, and asked him if he was wounded, to which he replied "Yes, and I fear seriously." It is possible that Johnston's duel in 1837 had caused nerve damage or numbness to that leg and that he did not feel the wound to his leg as a result. Johnston was taken to a small ravine, where he bled to death in minutes.
It is probable that a Confederate soldier fired the fatal round. No Union soldiers were observed to have ever gotten behind Johnston during the fatal charge, while it is known that many Confederates were firing at the Union lines while Johnston charged well in advance of his soldiers. He was the highest-ranking casualty of the war and his death was a strong blow to the morale of the Confederacy. Jefferson Davis considered him the best general in the country; this was two months before the emergence of Robert E. Lee as the pre-eminent general of the Confederacy.
The date of Johnston's death, Sunday, April 6, 1862, was coincidentally the 32nd anniversary of the founding of The Church of Jesus Christ of Latter-day Saints (The Mormons), against whom he led United States forces in 1856 during the Utah War, in which cause the Mormons were deemed by the Buchanan Administration to be in rebellion against the United States. At his death, it was Johnston who was similarly deemed to be in rebellion against the United States as a commanding officer in the Confederate Army, this time by the Lincoln Administration.
Johnston was buried in New Orleans, Louisiana. In 1866, a joint resolution of the Texas Legislature was passed to have his body reinterred to the Texas State Cemetery in Austin The re-interment occurred in 1867. Forty years later, the state appointed Elisabet Ney to design a monument and sculpture of him to be erected at his gravesite.
The Texas Historical Commission has erected a historical marker near the entrance of what was once his plantation. An adjacent marker was erected by the San Jacinto Chapter of the Daughters of The Republic of Texas and the Lee, Roberts, and Davis Chapter of the United Daughters of the Confederate States of America.


The Arctic Ocean, located in the northern hemisphere and mostly in the Arctic north polar region, is the smallest of the world's five major oceanic divisions and the shallowest. The International Hydrographic Organization (IHO) recognizes it as an ocean, although some oceanographers may call it the Arctic Mediterranean Sea or simply the Arctic Sea, classifying it as one of the mediterranean seas of the Atlantic Ocean. Alternatively, the Arctic Ocean can be seen as the northernmost lobe of the all-encompassing World Ocean.
Almost completely surrounded by Eurasia and North America, the Arctic Ocean is largely covered by sea ice throughout the year. The Arctic Ocean's temperature and salinity vary seasonally as the ice cover melts and freezes; its salinity is the lowest on average of the five major seas, due to low evaporation, heavy freshwater inflow from rivers and streams, and limited connection and outflow to surrounding oceanic waters with higher salinities. The summer shrinking of the icepack has been quoted at 50%.
An underwater ridge, the Lomonosov Ridge, divides the deep sea North Polar Basin into two basins: the Eurasian Basin, which is between 4,000 and 4,500 meters (13,000 and 15,000 ft) deep, and the Amerasian Basin (sometimes called North American, or Hyperborean), which is about 4,000 meters (13,000 ft) deep. The bathymetry of the ocean bottom is marked by fault-block ridges, plains of the abyssal zone, ocean deeps, and basins. The average depth of the Arctic Ocean is 1,038 meters (3,407 ft). The deepest point is in the Eurasian Basin, at 5,450 meters (17,881 ft).
The two major basins are further subdivided by ridges into the Canada Basin (between Alaska/Canada and the Alpha Ridge), Makarov Basin (between the Alpha and Lomonosov Ridges), Fram Basin (between Lomonosov and Nansen-Gakkel ridges), and Nansen Basin (Amundsen Basin) (between the Nansen-Gakkel Ridge and the continental shelf that includes the Franz Joseph Land).
The Arctic Ocean contains a major chokepoint in the southern Chukchi Sea, which provides northern access to the Pacific Ocean via the Bering Strait between North America and Russia. The Arctic Ocean also provides the shortest marine link between the extremes of eastern and western Russia. There are several floating research stations in the Arctic, operated by the U.S. and Russia.
The greatest inflow of water comes from the Atlantic by way of the Norwegian Current, which then flows along the Eurasian coast. Water also enters from the Pacific via the Bering Strait. The East Greenland Current carries the major outflow.
Ice covers most of the ocean surface year-round, causing subfreezing temperatures much of the time. The Arctic is a major source of very cold air that inevitably moves toward the equator, meeting with warmer air in the middle latitudes and causing rain and snow. Marine life abounds in open areas, especially the more southerly waters. The ocean's major ports are the Russian cities of Murmansk and Arkhangelsk, Churchill, Manitoba (Canada) and Prudhoe Bay, Alaska (US).
The Arctic Ocean is encompassed by the Arctic shelves, of which the largest (actually, the largest on the Earth) is the Siberian Shelf.
For much of Western history, the geography of the North Polar regions remained largely unexplored and conjectural. Pytheas of Massalia recorded an account of a journey northward in 325 B.C. to a land he called "Eschate Thule," where the sun only set for three hours each day and the water was replaced by a congealed substance "on which one can neither walk nor sail." He was probably describing loose sea ice known today as "growlers" and "bergy bits." His "Thule" may have been Iceland, though Norway is more often suggested.
Early cartographers were unsure whether to draw the region around the Pole as land (as in Johannes Ruysch's map of 1507, or Gerardus Mercator's map of 1595) or water (as with Martin Waldseemüller's world map of 1507). The fervent desire of Europeans for a northern passage to "Cathay" (China) caused water to win out, and by 1723 mapmakers such as Johann Homann featured an extensive "Oceanus Septentrionalis" at the northern edge of their charts. The few expeditions to penetrate much beyond the Arctic Circle in this era added only small islands, such as Nova Zemlya (11th century) and Spitsbergen (1596), though since these were often surrounded by pack-ice their northern limits were not so clear. The makers of navigational charts, more conservative than some of the more fanciful cartographers, tended to leave the region blank, with only the bits of known coastline sketched in.
This lack of knowledge of what lay north of the shifting barrier of ice gave rise to a number of conjectures. In England and other European nations, the myth of an "Open Polar Sea" was long-lived and persistent. John Barrow, longtime Second Secretary of the British Admiralty, made this belief the cornerstone of his campaign of Arctic exploration from 1818 to 1845. In the United States in the 1850s and '60s, the explorers Elisha Kent Kane and Isaac Israel Hayes both claimed to have seen the outskirts of this elusive body of water. Even quite late in the century, the eminent authority Matthew Fontaine Maury included a description of the Open Polar Sea in his textbook The Physical Geography of the Sea (1883). Nevertheless, as all the explorers who trekked closer and closer to the pole reported, the Polar Ice Cap was ultimately quite thick, and persists year-round.
Fridtjof Nansen was the first to make a naval crossing of the Arctic Ocean in 1896. The first surface crossing of the Arctic Ocean was led by Wally Herbert in 1969, in a dog sled expedition from Alaska to Svalbard with air support.
Since 1937 Soviet and Russian manned drifting ice stations extensively monitored the Arctic Ocean. Scientific settlements were established on the drift ice and carried thousands of kilometers by ice floes.
The ocean is contained in a polar climate characterized by persistent cold and relatively narrow annual temperature ranges. Winters are characterized by continuous darkness, cold and stable weather conditions, and clear skies; summers are characterized by continuous daylight, damp and foggy weather, and weak cyclones with rain or snow.
The temperature of the surface of the Arctic Ocean is fairly constant, near the freezing point of seawater, slightly below zero degrees Celsius. In the winter the relatively warm ocean water exerts a moderating influence, even when covered by ice. This is one reason why the Arctic does not experience the extremes of temperature seen on the Antarctic continent.
There is considerable seasonal variation in how much pack ice of the Arctic ice pack covers the Arctic Ocean. Much of the ocean is also covered in snow for about 10 months of the year. The maximum snow cover is in March or April — about 20 to 50 centimeters (8 to 20 in) over the frozen ocean.
Petroleum and gas fields, placer deposits, polymetallic nodules, sand and gravel aggregates, fish, seals and whales can all be found in abundance in the region.
The political dead zone near the center of the sea is also at the center of a mounting dispute between the United States, Russia, Canada, Norway, and Denmark. It is considered significant because of its potential to contain as much as or more than a quarter of the world's undiscovered oil and gas resources, the tapping of which could greatly alter the flow of the global energy market.
Ice islands occasionally break away from northern Ellesmere Island, and icebergs are formed from glaciers in western Greenland and extreme northeastern Canada. Permafrost is found on most islands. The ocean is virtually ice locked from October to June, and ships are subject to superstructure icing from October to May. Before the advent of modern icebreakers, ships sailing the Arctic Ocean risked being trapped or crushed by sea ice. Interestingly, two "ghost ships", the Baychimo and the Octavius, drifted through the Arctic Ocean untended for decades despite these hazards.
Endangered marine species include walruses and whales. The area has a fragile ecosystem which is slow to change and slow to recover from disruptions or damage.
The Arctic Ocean has relatively little plant life except for phytoplankton. Phytoplankton are a crucial part of the ocean and there are massive amounts of them in the Arctic. Nutrients from rivers and the currents of the Atlantic and Pacific oceans provide food for the Arctic phytoplankton. During summer, the sun is out day and night, thus enabling the phytoplankton to photosynthesize for long periods of time and reproduce quickly. However, the reverse is true in winter where they struggle to get enough light to survive.
The polar ice pack is thinning, and there is a seasonal hole in ozone layer in many years.
Reduction of the area of Arctic sea ice will have an effect on the planet's albedo, thus possibly affecting global warming within a positive feedback mechanism. Many scientists are presently concerned that warming temperatures in the Arctic may cause large amounts of fresh meltwater to enter the North Atlantic, possibly disrupting global ocean current patterns. Potentially severe changes in the Earth's climate might then ensue.
Other environmental concerns relate to the radioactive contamination of the Arctic Ocean from, for example, Russian radioactive waste dumpsites in the Kara Sea and Cold War nuclear test sites such as Novaya Zemlya.


An android is a robot designed to resemble a human, usually both in appearance and behavior. The word derives from the Greek andr-, meaning "man, male", and the suffix -eides, used to mean "of the species; alike" (from eidos "species"). Though the word derives from a gender-specific root, its usage in English is usually gender-neutral; the female counterpart, gynoid, is generally used only when female gender is a distinguishing trait of the robot. The term was first mentioned by Albertus Magnus in 1270 and was popularized by the French writer Villiers in his 1886 novel "L'Ève future, although the term "android" appears in US patents as early as 1863 in reference to miniature humanlike toy automations.
Thus far, androids have largely remained within the domain of science fiction, frequently seen in film and television. However, some humanoid robots now exist. The word droid, a robot in the Star Wars" universe, is derived from this meaning.
As of August 2007, a handful of android projects have been successfully completed.
The world's first Android DER 01 was developed by Japanese Research Group. The Intelligent Robotics Lab directed by Hiroshi Ishiguro at Osaka University and Kokoro Co. Ltd. have demonstrated the Actroid at Expo 2005 in Aichi Prefecture, Japan. And in 2006, Kokoro Co. developed new DER 2 android. Height of the human body part of "DER2" is 165cm. There are 47 mobile points. DER2 moves not only the expression but also hands and feet and can twist a body. "The air servosystem" which Kokoro Co. developed originally is used for the actuator. As a result of having controlled an actuator with air pressure via servosystem precisely, the movement is very fluent and noise is very small. "DER2" realized a slimmer body than a former version by using a smaller cylinder. Outwardly "DER2" becomes a more beautiful proportion. Compared to the previous model, DER2 has thinner arms and a wider repertoire of expressions. The smoothness of her movement has also been improved, making it now even more likely for the uninitiated to confuse her with an actual human being. Once programmed, she is able to choreograph her motions and gestures with her voice.
The Intelligent Mechatronics Lab directed by Kobayashi at The Science University of Tokyo has developed an android head called Saya, which was exhibited at Robodex 2002 in Yokohama, Japan. There are several other initiatives around the world involving humanoid research and development at this time, which will hopefully introduce a broader spectrum of realized technology in the near future. Now she is working at Science University of Tokyo as a guide.
The Waseda University(Japan) and NTT Docomo's manufacturers have succeeded in creating a shape-shifting robot WD-2. It is capable of changing its face. At first, the creators decided the position of the necessary points to express the outline, eyes, nose and so on of a certain person. The robot expresses his/her face by moving all points to the decided positions", they say. The first version of the robot was first developed back in 2003. After that, a year later, they did a couple of major improvements in the design. The robot features an elastic mask made from the average head dummy. It uses a driving system with a 3DOF unit. The WD-2 robot can change its facial features by activating specific facial points on a mask, with each point possessing three degrees of freedom. This one has 17 facial points, for a total of 56 degrees of freedom. As for the materials they used, the WD-2’s mask is fabricated with a highly elastic material called Septom, with bits of steel wool mixed in for added strength. Other technical features reveal a shaft is driven behind the mask at the desired facial point, driven by a DC motor with a simple pulley and a slide screw. Apparently, the researchers can also modify the shape of the mask based on actual human faces. To "copy" a face, they only need a 3D scanner to determine the locations of an individual’s 17 facial points. After that, they are then driven into position using a laptop and 56 motor control boards. In addition, the researchers also mention that the shifting robot can even display an individual’s hair style and skin color, if a photo of their face is projected onto the 3D mask.
KITECH researched & developed the EveR-1, an android interpersonal communications model capable of emulating human emotional expression via facial "musculature", and capable of rudimentary conversation having a ~400 word vocabulary. She is tall and weighs, matching the average figures of Korean women in their twenties. EveR-1's name derives from the Biblical Eve, plus the letter "r" for robot. EveR-1's advanced computing processing power enables Speech Recognition & Vocal Synthesis, at the same time processing Lip Synchronization and Visual Recoginition by 90 degrees Micro CCD Cameras with Face Recognition Technology. An independent micro chip inside her artificial brain handles Gesture Expressions, Body Coordination and Emotion Expressions. Her whole body is made of highly advanced synthetic jelly silicon and with 60 artificial joints in her face, neck, and lower body, she is able to demonstrate realistic facial expressions and sing, while simutanously dancing. In South Korea, the Ministry of Information and Communication hopes to put a robot in every home by as early as 2013, strictly for the purposes of clean, decorous, non-vulgar entertainment.
Hanson Robotics, Inc. of Texas and KAIST produced an android portrait of Albert Einstein, using Hanson's facial android technology mounted on KAIST's life-size walking bipedal robot body. This Einstein android, also called "Albert Hubo", thus represents the first full body walking android in history (see video at ). Hanson Robotics, the FedEx Institute of Technology, and the University of Texas at Arlington also developed the android portrait of sci-fi author Philip K. Dick (creator of Blade Runner), with full conversational capabilities that incorporated thousands of pages of the author's. In 2005, the PKD android won a first place Artificial intelligence award from AAAI.
Project Aiko of Canada has created an android portrait as a female person, using B.R.A.I.N.S software (Biometric Robot Artificial Intelligence Neural System) with silicone body, they have created one of the most unusual androids. The android is called "Aiko", thus Aiko is the first android to mimic pain, and the ability to learn and avoid pain. In additional, Aiko has speech, voice, face, and object recognition. It can also solve math problems displayed to her visually. It is also capable of learning new information from the environment. It is hoped that Aiko can walk in the near future.
Although human morphology is not necessarily the ideal form for working robots, the fascination in developing robots that can mimic it can be found historically in the assimilation of two concepts: simulacra (devices that exhibit likeness) and automata (devices that have independence).
Although Karel Čapek's robots in "R.U.R. (Rossum's Universal Robots) (1921)—the play that introduced the word "robot" to the world—were organic artificial humans, the word robot has come to primarily refer to mechanical humans, animals, and other beings. The term android can mean either one of these, while a cyborg ("cybernetic organism" or "bionic man") would be a creature that is a combination of organic and mechanical parts.
The word android is a combination of Ancient Greek andros and the suffix -oid, which literally means "in the form of a man." This could be contrasted with the more general term anthropoid, which means humanlike.
Historically, science fiction authors have used "android" in a greater diversity of ways than the terms "robot" and "cyborg". In some fiction works, the primary difference between a robot and android is only skin-deep, with androids being made to look almost exactly like humans on the outside, but with internal mechanics exactly the same as that of robots. In other stories, authors have defined android to indicate a wholly organic, yet artificial, creation. Other definitions of android fall somewhere in between.
The character Data, from the television series Star Trek: The Next Generation", is described as an android. Data became intoxicated in an early episode ("The Naked Now") and is later referred to having "bioplast sheeting" for skin ("The Most Toys"), perhaps suggesting that he was initially intended by the writers to be at least partially organic. Otherwise, Data was shown to be mechanical throughout and this often became a central plot theme.
In the show "THE SAINT", Tyler is an android, or a robot with a human intellect. Tyler spends most of the series in fights with Mary, a normal human, and eventually team up to fight against the dark evil Vincent.
The character Rock/Mega Man, from the game series of the same name, is called a Humanoid in the instructions of the first game, and a robot thereafter. He is a member of a class of robots called Robot Masters, which have a certain degree of autonomy. At the end of Mega Man 7, he states that he is "more than just a robot". Mega Man's successor, Mega Man X, is specifically identified to be fully autonomous.
The Replicants from the movie Blade Runner were bioengineered organic beings. While they were not referred to as either robots or androids in the movie, the screenplay was originally based on a novel by Philip K. Dick called Do Androids Dream of Electric Sheep? In this novel, the beings in question are specifically referred to as "androids" or, more familiarly, "andys" and exist primarily to replace a depleted human population in the aftermath of a nuclear war. The feature that most obviously distinguishes them from humans is their lack of empathy — otherwise, they are virtually indistinguishable from their organic counterparts (indeed, at one point a character observes that a psychotic human could be confused with an android).
In the video game Beneath a Steel Sky, genetically engineered androids similar to Blade Runner's Replicants are a central plot theme. However, despite their organic makeup, their behavior is programmed by computer.
The robots of Karel Čapek's R.U.R. were organic in nature. Today, an author writing a similar story might very well be inclined to call them androids.
The character Ash in the movie Alien, another artificial organic being, is often referred to as an android (though not in the dialogue of the movie itself). Similarly, the character Bishop in Aliens and Alien³ is a more advanced android commonly called a Synthetic, but prefers to be called an "artificial person". Much later in the series timeline, the character Call in Alien Resurrection is ashamed of being an android. Interesting to note is that the internal workings of the androids in the Alien universe seem almost human like. They have a white liquid, analogous for blood, probably for hydraulic movement. They also seem to have "guts" as seen in Aliens.
In the Star Wars movies, C-3PO, R2-D2, and other robots are referred to as "droids". While C-3PO could reasonably be called an android because he is humanoid in appearance, the squat cylinder R2-D2 is at most only humanoid in behavior.
In the movie A.I. the robotic characters are called mechas, but the film is loosely based on a short story written by Brian Aldiss called "Supertoys Last All Summer Long", in which the central character David is called an android (by which Aldiss seemed to be referring to an organic creation).
In the anime/manga Chobits, Androids are known as "Persocoms", essentially computers in a man-made body. The series does not go into their internal composition, but it is assumed to be artificial with a very realistic outside. One of the key points of this series was a special type of persocom named "Chobit", a persocom that had free will and the ability to fall in love and have emotions.
The Cylon race in the re-imagined Battlestar Galactica series includes twelve android models that are virtually indistinguishable from human beings down to the cellular level, however subcellularly (molecularly) they are different in many ways, and as such have superhuman capacities, but lack the ability to functionally reproduce with each other.
The character Kryten from the television show Red Dwarf is described as being a "Mechanoid" as well as an android. This is a melding of the words "Mechanical" and "Humanoid". According to the episode "DNA", his brain is part-organic, and his DNA can therefore be altered. He is also capable of breaking his programming and obtaining emotions, though this proves to be difficult as displayed in the episode, "Camille".
In fiction, one prominent android variation is the Bio android, which is constructed of protein based components as opposed to electronic and mechanical parts. Bio androids are all composed of synthetic flesh, though their exact composition varies from work to work. Biorobotics or synthetic biology are among the terms used to describe how they are made.
Many more examples may be found in this list of fictional robots.


Alberta () is one of Canada's prairie provinces. It became a province on September 1, 1905.
Alberta is located in western Canada, bounded by the provinces of British Columbia to the west and Saskatchewan to the east, Northwest Territories to the north, and by the U.S. state of Montana to the south. Alberta is one of three provinces and territories (the others being New Brunswick and Yukon) to border only a single U.S. state. It is also one of two provinces that are land-locked (the other being Saskatchewan).
The capital city of Alberta is Edmonton, located just south of the centre of the province. Calgary is a major distribution and transportation hub as well as being one of Canada's major commerce centres. Edmonton is the primary supply and service hub for Canada's oil sands and other northern resource industries. According to recent population estimates, these two metropolitan areas have now both exceeded 1 million people, Calgary being slightly more populous than Edmonton. Other municipalities in the province include Red Deer, Lethbridge, Medicine Hat, Fort McMurray, Grande Prairie, Camrose, Lloydminster, Wetaskiwin, Banff, Cold Lake, and Jasper.
Since December 14, 2006, the Premier of the province is Hon. Ed Stelmach, Progressive Conservative.
Alberta is named after Princess Louise Caroline Alberta (1848–1939), the fourth daughter of Queen Victoria. Princess Louise was the wife of the Marquess of Lorne, Governor General of Canada from 1878 to 1883. Lake Louise, the village of Caroline, and Mount Alberta were also named in honour of Princess Louise.
Alberta is in western Canada, and covers an area of 661,190 km² (255,287 mi²). To the south, it borders the U.S. state of Montana on the 49th Parallel. To the east at a longitude of 110° west, it borders the province of Saskatchewan. At 60° north, it is bordered by the Northwest Territories. To the west, its border with British Columbia follows the line of peaks of the Rocky Mountains range along the Continental Divide, which runs northwesterly until it reaches 120° west, at which point the border follows this meridian to 60° north.
With the exception of the southeastern section, the province is well watered. Alberta contains dozens of rivers and lakes used for swimming, water skiing, fishing and a full range of other water sports. There are three large lakes and a multitude of smaller lakes less than 260 km² each. Part of Lake Athabasca ( km²) lies in the province of Saskatchewan. Lake Claire ( km²) lies just west of Lake Athabasca in Wood Buffalo National Park. Lesser Slave Lake ( km²) is northwest of Edmonton.
Because Alberta extends for km from north to south, and about 600 km wide at its greatest east-west extent, it is natural that the climate should vary considerably between the 49th and 60th parallels. It is also further influenced by its elevation since the province is a high plateau. The elevation ranges from about metres in the south (Calgary is about metres and Red Deer is about 850 m) to 650 metres in the north. The presence of a wall of mountains on the west and open prairies on the east also influences the weather.
Northern Alberta is mostly covered by boreal forest and has fewer frost-free days than southern Alberta, which has a semi-arid climate. The southeastern corner of Alberta experiences greater summer heat and lower rainfall than the rest of the province. Western Alberta is protected by the mountains, and enjoys the mild temperatures brought by winter chinook winds, while southeastern Alberta is a generally flat, dry prairie with some hills, where temperatures are most extreme. They can range from very cold (−35 °C (−31 °F) or lower in the winter) to very hot (38 °C (100 °F) or higher in the summer). Central and parts of northwestern Alberta in the Peace River region are largely aspen parkland, a biome transitional between prairie to the south and boreal forest to the north. After southern Ontario, Central Alberta is the most likely region in Canada to experience tornadoes. Thunderstorms, some of them severe, are frequent in the summer, especially in central and southern Alberta. The region surrounding the Calgary-Edmonton Corridor is notable for having the highest frequency of hail in Canada, due to the role of orographic lifting from the nearby Rocky Mountains which enhances the updraft/downdraft cycle necessary for the formation of hail.
Overall, Alberta has cold winters, with a temperature average ranging from −10 °C (14 °F) in the south to −24 °C (−12 °F) in the north. In the south along the foothills of the Rockies, the winter cold is sometimes interrupted by Chinook winds which can propel temperatures upward in a short time frame close to or infrequently above 20 °C (68 °F). These conditions most commonly occur in February or March. In the summer, the average daytime temperatures range from around 21 °C (70 °F) in the Rocky Mountains (valleys) and far north to near 30 °C (86 °F) in the dry prairie of the southeast. The northern and western parts of the province experience higher rainfall and lower evaporation rates caused by cooler summer temperatures. The south and east-central portions are prone to drought-like conditions sometimes persisting over periods of years, although even these areas can receive heavy precipitation. Alberta experiences a good amount of sunshine for its northern location owing to its fairly dry climate; the east-central part of the province (bordering Saskatchewan), is the sunniest place in Canada with an average of over hours a year.
Alberta's capital city, Edmonton, is located almost in the geographic centre of the province, and most of Alberta's oil is refined here. Southern Alberta, where Calgary is located, is known for its ranching. Much of the unforested part of Alberta is given over either to grain or to dairy farming, with ranching and grasslands predominant in the south.
The Albertan badlands are located in southeastern Alberta, where the Red Deer River crosses the flat prairie and farmland, a feature deep gorges and striking landforms. Dinosaur Provincial Park, near Brooks, Alberta, showcases the badlands terrain, desert flora, and remnants from Alberta's past when dinosaurs roamed the then lush landscape.
Alberta's economy is one of the strongest in Canada, supported by the burgeoning petroleum industry and to a lesser extent, agriculture and technology. The per capita GDP in 2006 was by far the highest of any province in Canada at C$69,789. This was 56% higher than the national average and more than twice that of some of the Atlantic provinces. This deviation from the national average was the largest for any province in Canadian history.
The Calgary-Edmonton Corridor is the most urbanized region in the province and one of the densest in Canada. Measured from north to south, the region covers a distance of roughly 400 kilometres. In 2001, the population of the Calgary-Edmonton Corridor was 2.15 million (72% of Alberta's population). It is also one of the fastest growing regions in the country. A 2003 study by TD Bank Financial Group found the corridor to be the only Canadian urban centre to amass a U.S level of wealth while maintaining a Canadian-style quality of life, offering universal health care benefits. The study found that GDP per capita in the corridor is 10 percent above average U.S. metropolitan areas and 40 percent above other Canadian cities.
According to the Fraser Institute, Alberta also has very high levels of economic freedom. It is by far the most free economy in Canada, and is rated as the 4th most free economy of U.S. States and Canadian Provinces.
Alberta is the largest producer of conventional crude oil, synthetic crude, natural gas and gas products in the country. Alberta is the world’s 2nd largest exporter of natural gas and the 4th largest producer. Two of the largest producers of petrochemicals in North America are located in central and north central Alberta. In both Red Deer and Edmonton, world class polyethylene and vinyl manufacturers produce products shipped all over the world, and Edmonton's oil refineries provide the raw materials for a large petrochemical industry to the east of Edmonton.
The Athabasca Oil Sands (sometimes known as the Athabasca Tar sands) have estimated non-conventional oil reserves approximately equal to the conventional oil reserves of the rest of the world, estimated to be 1.6 trillion barrels (254 km³). With the development of new extraction methods such as steam assisted gravity drainage (SAGD), which was developed in Alberta, bitumen and synthetic crude oil can be produced at costs close to those of conventional crude. Many companies employ both conventional strip mining and non-conventional in situ methods to extract the bitumen from the oil sands. With current technology and at current prices, about 315 billion barrels (50 km³) of bitumen are recoverable. Fort McMurray, one of Canada's fastest growing cities, has grown enormously in recent years because of the large corporations which have taken on the task of oil production. As of late 2006 there were over $100 billion in oil sands projects under construction or in the planning stages in northeastern Alberta.
Another factor determining the viability of oil extraction from the Tar Sands is the price of oil. The oil price increases of 2004-2006 have made it more than profitable to extract this oil, which in the past would give little profit or even a loss.
With concerted effort and support from the provincial government, several high-tech industries have found their birth in Alberta, notably patents related to interactive liquid crystal display systems. With a growing economy, Alberta has several financial institutions dealing with civil and private funds.
Agriculture has a significant position in the province's economy. Over three million cattle are residents of the province at one time or another, and Albertan beef has a healthy worldwide market. Nearly one half of all Canadian beef is produced in Alberta. Alberta is one of the prime producers of plains buffalo (bison) for the consumer market. Sheep for wool and mutton are also raised.
Wheat and canola are primary farm crops, with Alberta leading the provinces in spring wheat production, with other grains also prominent. Much of the farming is dryland farming, often with fallow seasons interspersed with cultivation. Continuous cropping (in which there is no fallow season) is gradually becoming a more common mode of production because of increased profits and a reduction of soil erosion. Across the province, the once common grain elevator is slowly being lost as rail lines are decreased and farmers now truck the grain to central points.
Alberta is the leading beekeeping province of Canada, with some beekeepers wintering hives indoors in specially designed barns in southern Alberta, then migrating north during the summer into the Peace River valley where the season is short but the working days are long for honeybees to produce honey from clover and fireweed. Hybrid canola also requires bee pollination, and some beekeepers service this need.
The vast northern forest reserves of softwood allow Alberta to produce large quantities of lumber, oriented strand board (OSB) and plywood, and several plants in northern Alberta supply North America and the Pacific Rim nations with bleached wood pulp and newsprint.
The government of Alberta is organized as a parliamentary democracy with a unicameral legislature. Its unicameral legislature—the Legislative Assembly—consists of eighty-three members.
Locally municipal governments and school boards are elected and operate separately. Their boundaries may or may not coincide. Municipalities where the same body acted as both local government and school board were formally referred to as "counties" in Alberta.
As Canada's head of state, Queen Elizabeth II is the head of state for the Government of Alberta. Her duties in Alberta are carried out by Lieutenant Governor, Norman Kwong. Although the Lieutenant Governor is technically the most powerful person in Alberta, (s)he is in reality a figurehead whose actions are restricted by custom and constitutional convention. The government is therefore headed by the Premier. The current Premier is Ed Stelmach who was elected as leader of the governing Progressive Conservatives on December 2, 2006. Stelmach was sworn in as the 13th Albertan Premier on December 15, 2006.
As is always the case in a parliamentary system of government, the Premier is a Member of the Legislative Assembly, and he draws all the members of his Cabinet from among the Members of the Legislative Assembly.
The City of Edmonton is the seat of the provincial government—the capital of Alberta.
The province's revenue comes mainly from the taxation of oil, natural gas, beef, softwood lumber, and wheat, but also includes a tax on corporate and personal income, gaming revenue, and grants from the federal government primarily for infrastructure projects. Albertans are the lowest-taxed people in Canada, and Alberta is the only province in Canada without a provincial sales tax (though residents are still subject to the federal sales tax, the Goods and Services Tax). Alberta's municipalities and school jurisdictions have their own governments which (usually) work in co-operation with the provincial government.
Alberta's elections tend to yield results which are much more conservative than those of other Canadian provinces. Alberta has traditionally had three political parties, the Progressive Conservatives ("Conservatives" or "Tories"), the Liberals, and the social democratic New Democrats. A fourth party, the strongly conservative Social Credit Party, was a power in Alberta for many decades, but fell from the political map after the Progressive Conservatives came to power in 1971. Since that time, no other political party has governed Alberta. In fact, only four parties have governed Alberta: the Liberals, from 1905 to 1921; the United Farmers of Alberta, from 1921 to 1935; the Social Credit Party, from 1935 to 1971, and the currently governing Progressive Conservative Party, from 1971 to the present.
As is the case with many western Canadian provinces, Alberta has had occasional surges in separatist sentiment. Even during the 1980s, when these feelings were at their strongest, there has never been enough interest in secession to initiate any major movements or referendums. There are a number of groups wishing to promote the independence of Alberta in some form currently active in the province. See also: Alberta separatism.
As with any Canadian province, the Albertan Legislature has (almost) exclusive authority to make laws respecting education. Since 1905 the Legislature has used this capacity to continue the model of locally elected public and separate school boards which originated prior to 1905, as well as to create and/or regulate universities, colleges, technical institutions and other educational forms and institutions (public charter schools, private schools, home schooling).
There are forty-two public school jurisdictions in Alberta, and seventeen operating separate school jurisdictions. Sixteen of the operating separate school jurisdictions have a Roman Catholic electorate, and one (St. Albert) has a Protestant electorate. In addition, one Protestant separate school district, Glen Avon, survives as a ward of the St. Paul Education Region. The City of Lloydminster straddles the Alberta/Saskatchewan border, and both the public and separate school systems in that city are counted in the above numbers: both of them operate according to Saskatchewan law.
For many years the provincial government has funded the greater part of the cost of providing K–12 education. Prior to 1994 public and separate school boards in Alberta had the legislative authority to levy a local tax on property, as supplementary support for local education. In 1994 the government of the province eliminated this right for public school boards, but not for separate school boards. Since 1994 there has continued to be a tax on property in support of K–12 education; the difference is that the mill rate is now set by the provincial government, the money is collected by the local municipal authority and remitted to the provincial government. The relevant legislation requires that all the money raised by this property tax must go to the support of K–12 education provided by school boards. The provincial government pools the property tax funds from across the province and distributes them, according to a formula, to public and separate school jurisdictions and Francophone authorities.
Public and separate school boards, charter schools, and private schools all follow the Program of Studies and the curriculum approved by the provincial department of education (Alberta Education). Home schoolers may choose to follow the Program of Studies or develop their own Program of Studies. Public and separate schools, charter schools, and approved private schools all employ teachers who are certificated by Alberta Education, they administer Provincial Achievement Tests and Diploma Examinations set by Alberta Education, and they may grant high school graduation certificates endorsed by Alberta Education.
Alberta's oldest and largest university is Edmonton's University of Alberta. The University of Calgary, once affiliated with the University of Alberta, gained its autonomy in 1966, and is now the second largest university in Alberta. There is also Athabasca University, which focuses on distance learning, and the University of Lethbridge. There are 15 colleges that receive direct public funding, along with two technical institutes, NAIT and SAIT. There is also a large and active private sector of post-secondary institutions, including DeVry University. Students may also receive government loans and grants while attending selected private institutions. There has been some controversy in recent years over the rising cost of post-secondary education for students (as opposed to taxpayers). In 2005, Premier Ralph Klein made a promise that he would freeze tuition and look into ways of reducing schooling costs. So far, no plan has been released by the government of Alberta.
Alberta has over 180,000 km of highways and roads, of which nearly 50,000 km are paved. The main north-south corridor is Highway 2, which begins south of Cardston at the Carway border crossing and is part of the CANAMEX Corridor. Highway 4, which effectively extends U.S. Interstate Highway 15 into Alberta and is the busiest U.S. gateway to the province, begins at the Coutts border crossing and ends at Lethbridge. Highway 3 joins Lethbridge to Fort Macleod and links Highway 4 to Highway 2. Highway 2 travels northward through Fort Macleod, Calgary, Red Deer, and Edmonton before dividing into two highways. The section of Highway 2 between Calgary and Edmonton has been named the Queen Elizabeth II Highway to commemorate the visit of the monarch in 2005. Past Edmonton, one branch continues northwest as Highway 43 into Grande Prairie and the Peace River Country; the other (Highway 63) travels northeast to Fort McMurray, the location of the Athabasca Oil Sands. Highway 2 is supplemented by two more highways that run parallel to it: Highway 22, west of highway 2, known as "the cowboy trail," and Highway 21, east of highway 2.
Alberta has two main east-west corridors. The southern corridor, part of the Trans-Canada Highway system, enters the province near Medicine Hat, runs westward through Calgary, and leaves Alberta through Banff National Park. The northern corridor, also part of the Trans-Canada network but known alternatively as the Yellowhead Highway (Highway 16), runs west from Lloydminster in eastern Alberta, through Edmonton and Jasper National Park into British Columbia. On a sunny spring or fall day, one of the most scenic drives is along the Icefields Parkway, which runs for 228 km between Jasper and Lake Louise, with mountain ranges and glaciers on either side of its entire length.
Another major corridor through central Alberta is Highway 11 (also known as the David Thompson Highway), which runs west from the Saskatchewan River Crossing in Banff National Park through Rocky Mountain House and Red Deer, connecting with Highway 12 20 km west of Stettler. The highway connects many of the smaller towns in central Alberta with Calgary and Edmonton, as it crosses Highway 2 just west of Red Deer.
Urban stretches of Alberta's major highways and freeways are often called trails. For example, Highway 2 is Deerfoot Trail as it passes through Calgary, Calgary Trail as it leaves Edmonton southbound, and St. Albert Trail as it leaves Edmonton northbound toward the city of St. Albert. Visitors from outside Alberta often find this disconcerting, accustomed as they are to the notion that a trail is an unpaved route primarily for pedestrians.
Edmonton, Calgary, Red Deer, Medicine Hat, and Lethbridge have substantial mass transit systems. Edmonton and Calgary also operate light rail vehicles.
Alberta is well-connected by air, with international airports at both Edmonton and Calgary. Calgary International Airport and Edmonton International Airport are the fourth and fifth busiest in Canada respectively. Calgary's airport is a hub for WestJet Airlines and a regional hub for Air Canada. Calgary's airport primarily serves the Canadian prairie provinces (Alberta, Saskatchewan and Manitoba) for connecting flights to British Columbia, eastern Canada, 15 major US centres, nine European airports, and four destinations in Mexico and the Caribbean. Edmonton's airport acts as a hub for the Canadian north and has connections to all major Canadian airports as well as 10 major US airports, 3 European airports and 6 Mexican and Caribbean airports.
There are over 9000 km of operating mainline railway, and many tourists see Alberta aboard Via Rail or Rocky Mountain Railtours. The Canadian Pacific Railway and Canadian National Railway companies operate railway freight across the province.
Health care in Alberta is divided into nine health regions: Aspen Regional Health Authority: Calgary Health Region, Capital Health (Edmonton), Chinook Health, David Thompson Regional Health Authority, East Central Health, Northern Lights Health Region, Palliser Health Region and Peace Country Health Region.
Summer brings many festivals to the province. The Edmonton Fringe Festival is the world's second largest after Edinburgh's. The folk music festivals in both Calgary and Edmonton are two of Canada's largest and both cities host a number of annual multicultural events. With a large number of summer and winter events, Edmonton prides itself as being the "Festival City". The city's "heritage days" festival sees the participation of over 70 national groups. Calgary is also home to Carifest, the second largest Caribbean festival in the nation (after Caribana in Toronto). The city is also famous for its Calgary Stampede, dubbed "The Greatest Outdoor Show on Earth." The Stampede is Canada's biggest rodeo festival and features various races and competitions like calf roping, and bull riding. These events highlight the province's cultural diversity and love of entertainment. Most of the major cities have several performing theatre companies who entertain in venues as diverse as Edmonton's Arts Barns and the Francis Winspear Centre for Music.
Alberta also has significant ethnic diversity. Both the Chinese and East Indian communities are significant. According to Statistics Canada, Alberta is home to the second highest proportion (two percent) of Francophones in western Canada (after Manitoba). Many of Alberta's French-speaking residents live in the central and northwestern regions of the province. As reported in the 2001 census, the Chinese represented nearly four percent of Alberta's population and East Indians represented better than two percent. Both Edmonton and Calgary have Chinatowns and Calgary's is Canada's third largest. The Chinese presence began with workers employed in the building of the Canadian Pacific Railway in the 1880s. Aboriginal Albertans make up approximately three percent of the population.
The major contributors to Alberta's ethnic diversity have been the European nations. Forty-four percent of Albertans are of British and Irish descent, and there are also large numbers of Germans, Ukrainians and Scandinavians. Amongst those of British origins, the Scots have had a particularly strong influence, with many place-names (including Calgary, Airdrie, Canmore and Banff) having Scottish origins.
Both cities are home to Canadian Football League and National Hockey League teams. Soccer, rugby union and lacrosse are also played professionally in Alberta.
Alberta is home to speakers of a number of languages, with many minority languages growing due to immigration. English remains the only official language used in all government services, although French is also an official language of the courts.
Alberta has been a tourist destination from the early days of the twentieth century, with attractions including outdoor locales for skiing, hiking and camping, shopping locales such as West Edmonton Mall, outdoor festivals, professional athletic events, international sporting competitions such as the Commonwealth Games and Olympic Games, as well as more eclectic attractions.
According to Alberta Economic Development, Edmonton and Calgary both host over four million visitors annually. Banff, Jasper and the Rocky Mountains are visited by about three million people per year.
Alberta's Rocky Mountains include well known tourist destinations Banff National Park and Jasper National Park. The two mountain parks are connected by the scenic Icefields Parkway. Banff is located 128 km west of Calgary on Highway 1 and Jasper is located 366 km west of Edmonton on Yellowhead Highway. 5 of Canada's 13 UNESCO World heritage sites are located within he province: Canadian Rocky Mountain Parks, Waterton-Glacier International Peace Park, Wood Buffalo National Park, Dinosaur Provincial Park and Head-Smashed-In Buffalo Jump.
About 1.2 million people pass through the gates of Calgary's world-famous Stampede, a celebration of Canada's own Wild West and the cattle ranching industry. About 800,000 people enjoy Edmonton's Capital Ex (formerly Klondike Days). Edmonton was the gateway to the only all-Canadian route to the Yukon gold fields, and the only route which did not require gold-seekers to travel the exhausting and dangerous Chilkoot Pass.
Located in East-Central Alberta is Alberta Prairie Railway Excursions, a popular tourist attraction operated out of Stettler that draws visitors from around the world. It boasts one of the few operable steam trains in the world, offering trips through the rolling prairie scenery. Alberta Prairie Railway Excursions caters to tens of thousands of visitors every year.
Alberta is an important destination for tourists who love to ski and hike; Alberta boasts several world-class ski resorts such as Sunshine Village, Lake Louise, Marmot Basin, Norquay and Nakiska. Hunters and fishermen from around the world are able to take home impressive trophies and tall tales from their experiences in Alberta's wilderness.
Alberta has enjoyed a relatively high rate of growth in recent years, due in large part to its burgeoning economy. Between 2003 and 2004, the province saw high birthrates (on par with some larger provinces such as British Columbia), relatively high immigration, and a high rate of interprovincial migration when compared to other provinces.
Most Albertans identify as Christians. Alberta has a somewhat higher percentage of evangelical Christians than do other provinces. Conversely, Alberta also has the second highest percentage of Non-religious residents in Canada (after British Columbia). 44% of Albertans did not attend church last year.
The Mormons of Alberta reside primarily in the extreme south of the province. Alberta also has a large population of Hutterites, a communal Anabaptist sect similar to the Mennonites, and a significant population of Seventh-day Adventists. Alberta is also home to several Byzantine Rite Churches as part of the legacy of Eastern European immigration, including the Ukrainian Catholic Eparchy of Edmonton, and the Ukrainian Orthodox Church of Canada's Western Diocese which is based in Edmonton.
Many people of the Hindu, Sikh, and Muslim faiths also make Alberta their home. North America's oldest mosque is located in Edmonton.
Most of Alberta's 13,000 Jews live in Calgary (7,500) and Edmonton (5,000).
The province of Alberta, as far north as about 53° north latitude, was a part of Rupert's Land from the time of the incorporation of the Hudson's Bay Company (1670). After the arrival in the North-West of the French around 1731 they settled the prairies of the west, establishing communities such as Lac La Biche and Bonnyville. Fort La Jonquière was established near what is now Calgary in (1752). The North-West Company of Montreal occupied the northern part of Alberta territory before the Hudson's Bay Company arrived from Hudson Bay to take possession of it. The first explorer of the Athabasca region was Peter Pond, who, on behalf of the North-West Company of Montreal, built Fort Athabasca on Lac La Biche in 1778. Roderick Mackenzie built Fort Chipewyan on Lake Athabasca ten years later in 1788. His cousin, Sir Alexander Mackenzie followed the North Saskatchewan River to its northernmost point near Edmonton, then setting northward on foot, trekked to the Athabasca River, which he followed to Lake Athabasca. It was there he discovered the mighty outflow river which bears his name—the Mackenzie River—which he followed to its outlet in the Arctic Ocean. Returning to Lake Athabasca, he followed the Peace River upstream, eventually reaching the Pacific Ocean, and so being the first white man to cross the North American continent north of Mexico.
The district of Alberta was created as part of the North-West Territories in 1882. As settlement increased, local representatives to the North-West Legislative Assembly were added. After a long campaign for autonomy, in 1905 the district of Alberta was enlarged and given provincial status, with the election of Alexander Cameron Rutherford as the first premier.
The three climatic regions (alpine, forest, and prairie) of Alberta are home to many different species of animals. The south and central prairie was the land of the bison, its grasses providing a great pasture and breeding ground for millions of buffalo. The buffalo population was decimated during early settlement, but since then buffalo have made a strong comeback, and thrive on farms and in parks all over Alberta.
Alberta is home to many large carnivores. Among them are the grizzly and black bears, which are found in the mountains and wooded regions. Smaller carnivores of the canine and feline families include coyotes, wolves, fox, lynx, bobcat and mountain lion (cougar).
Herbivorous, or plant-eating animals, are found throughout the province. Moose and deer (both mule and white-tail varieties) are found in the wooded regions, and pronghorn can be found in the prairies of southern Alberta. Bighorn sheep and mountain goats live in the Rocky Mountains. Rabbits, porcupines, skunks, squirrels, and many species of rodents and reptiles live in every corner of the province. Alberta is fortunate in that it is home to only one variety of venomous snake, the prairie rattlesnake.
Central and northern Alberta and the region farther north is the nesting-ground of the migratory birds. Vast numbers of ducks, geese, swans, and pelicans arrive in Alberta every spring and nest on or near one of the hundreds of small lakes that dot northern Alberta. Eagles, hawks, owls, and crows are plentiful, and a huge variety of smaller seed and insect-eating birds can be found. Alberta, like other temperate regions, is home to mosquitoes, flies, wasps, and bees. Rivers and lakes are well stocked with pike, walleye, whitefish, rainbow, speckled, and brown trout, and even sturgeon. Turtles are found in some water bodies in the southern part of the province. Frogs and salamanders are a few of the amphibians that make their homes in Alberta.
Alberta is the only province in Canada, as well as one of the few places in the world which is free of Norwegian rats. Since the early 1950s, the government of Alberta has operated a rat-control program which has been so successful that only isolated instances of wild rat sightings are reported, usually of rats arriving in the province aboard trucks or by rail. In 2006, Alberta Agriculture reports zero findings of wild rats; the only rat interceptions have been domesticated rats which have been seized from their owners. It is illegal for individual Albertans to own or keep Norwegian rats of any description; the animals can only be kept in the province by zoos, universities and colleges, and recognized research institutions.
In central and northern Alberta the arrival of spring brings the prairie crocus anemone, the three flowered avens, golden bean, and other early flowers. The advancing summer introduces many flowers of the sunflower family, until in August the plains are one blaze of yellow and purple. The southern and east central parts of Alberta are covered by a short, nutritious grass, which dries up as summer lengthens, to be replaced by hardy perennials such as the prairie coneflower, fleabane, and sage. Both yellow and white sweet clover fill the ditches with their beauty and aromatic scents. The trees in the parkland region of the province grow in clumps and belts on the hillsides. These are largely deciduous, typically aspen, poplar, and willow. Many species of willow and other shrubs grow in virtually any terrain. On the north side of the North Saskatchewan River evergreen forests prevail for hundreds of thousands of square kilometres. Aspen poplar, balsam poplar (or cottonwood), and paper birch are the primary large deciduous species. Conifers include Jack pine, Rocky Mountain pine, Lodgepole pine, both white and black spruce, and the deciduous conifer tamarack.


The Arctic Circle is one of the five major circles of latitude that mark maps of the Earth. It is the parallel of latitude that (as of 2000) runs 66° 33′ 39″ (or 66.56083°) north of the Equator. The region north of this circle is known as the Arctic, and the zone just to the south is called the Northern Temperate Zone. The equivalent latitude in the southern hemisphere is called the Antarctic Circle.
The Arctic Circle marks the southern extremity of the polar day (24 hour sunlit day, often referred to as the "midnight sun") and polar night (24 hour sunless night). North of the Arctic Circle, the sun is above the horizon for 24 continuous hours at least once per year, and below the horizon for 24 continuous hours at least once per year. On the Arctic Circle these events occur, in principle, exactly once per year, at the June and December solstices respectively. It is called the Arctic because it corresponds to the southernmost point of the Constellation Ursa Major (the Great Bear or Megale Arktos in Greek).
In fact, because of atmospheric refraction and because the sun appears as a disk and not a point, part of the midnight sun may be seen on the night of the summer solstice up to about 50′ (90 km) south of the Arctic Circle; similarly, on the day of the winter solstice part of the sun may be seen up to about 50′ north of the Arctic Circle. This is true at sea level; these limits increase with elevation above sea level, although in mountainous regions there is often no direct view of the horizon.
The position of the Arctic Circle is not fixed, but varies in a complex manner over time; see circles of latitude for information.
Very few people live north of the Arctic Circle due to the cold conditions. The three largest towns above the Arctic Circle are situated in Russia; Murmansk (population 325,100), Norilsk (135,000), and Vorkuta (85,000). Tromsø in Norway has about 62,000 inhabitants, whereas Rovaniemi in Finland — which lies slightly south of the line — has slightly fewer than 58,000.
Recently the region north of the Arctic Circle has gained significant international attention due primarily to the perceived threat of global warming. Initial attention came as a result of the fact that the earth's poles are the points at which the planet tends to warm the fastest thereby acting as harbingers of what is to come. The melting of the ice in the Circle is making the Northwest Passage, the shipping routes through the northern-most latitudes, more navigable, raising the possibility that some day the Arctic region could become a prime trade route. In addition it is believed that the Arctic seabed may contain substantial oil fields which may become accessible if the ice covering them melts. These factors have led to recent international debates as to which nations can claim sovereignty or ownership over the waters north of the Circle.


An assault rifle is a selective fire rifle or carbine firing ammunition with muzzle energies intermediate between those typical of pistol and battle rifle ammunition. Assault rifles are categorized between light machine guns, intended more for sustained automatic fire in a support role, and submachine guns, which fire a handgun cartridge rather than a rifle cartridge. Assault rifles are the standard small arms in most modern armies, having largely replaced or supplemented larger, more powerful battle rifles, such as the World War II-era M1 Garand and Tokarev SVT. Examples of assault rifles include the AK-47 and the M16 rifle. Semi-automatic rifles, including commercial versions of the AR-15, and "automatic" rifles limited to firing single shots, even though incorrectly classified as assault rifles by the now defunct 1994 Assault Weapons Ban, are not assault rifles as they are not selective fire. Belt-fed weapons or rifles with very limited capacity fixed magazines are also generally not considered assault rifles.
The term assault rifle is a translation of the German word Sturmgewehr (literally meaning "storm rifle"), "storm" used as a verb being synonymous with assault, as in "to storm the compound". Sturmgewehr was coined by Adolf Hitler to describe the Maschinenpistole 44, subsequently re-christened Sturmgewehr 44, the firearm generally considered the first true assault rifle and served to popularize the concept.
There are commentators who use the expression "assault rifle" more loosely to include other types of arms, particularly arms that fall under a strict definition of the battle rifle, or civilian semi-automatic off-shoots of military rifles for commercial or political reasons. Some militaries of nations outside of the English-speaking world also have a different definition of assault rifle. For instance, the analogous term in the Swedish Armed Forces is automatkarbin (literally "automatic carbine") which includes both assault rifles and battle rifles.
From ancient times, light infantry had fought in dispersed formations, while heavy infantry had fought in tightly packed formations. This continued as the sling and spear were replaced by musket and bayonet. Bright colored uniforms (German: Blue, Russian: Green; British: Red, French: White) became a standard for unit cohesion in the midst of clouds of black powder smoke. Muskets were inaccurate at distances greater than 50 to 100 meters, and multiple ranks and a reserve were necessary so that some part of the unit would be ready to fire at all times. Tight formations also aided officers in controlling their men during combat.
The adaptation of rifled muskets for military use in the mid-19th century increased range and firepower and made battle from dense formations an increasingly bloody affair as witnessed by the high level of casualties in the American Civil War. Skirmisher tactics were given greater emphasis as gunpowder weapons increased in reliability, accuracy, and rate of fire. Cavalry adapted by dismounting, and using skirmisher tactics with breechloading rifles (which could be reloaded from a prone position, reducing vulnerability to enemy fire).
After the American Civil War, further developments such as the adaptation of magazine-fed rifles, rapid fire machine guns and high explosive shells for the artillery, spelled the end of the dense infantry formation during World War I. What this meant in practice was that infantry units no longer engaged each other at long range in open fields; the high power of relatively unwieldy bolt-action rifles of the day (which had been tripled by the adaptation of smokeless powder, along with a corresponding increase in recoil and report) was no longer suited to the close range engagement of modern warfare. Military leaders and arms manufacturers thus began grasping for a new type of weapon for this new era.
These automatic firearms tended to use used pre-existing rifle cartridges, kinetic energy ranged between 3,000–5,000 J (2,200–3,700-foot-pounds), velocities of 750–900 m/s (2,460–2,950 ft/s) and bullets of 9 to 13 g (139–200 grains).
If the term is applied retroactively, the first assault rifle was the Italian-made Cei-Rigotti, which was developed in the 1890s and finished around 1900. While tested in Italy and the United Kingdom, it never entered military service, however. The first service assault rifle was the Russian Fedorov Avtomat issued for the first time in 1915, chambered for the Japanese 6.5x50mm Arisaka rifle cartridge, which was only used in small numbers.
During World War I the French Chauchat was introduced, an automatic rifle that was produced in large numbers (250,000). Like the later assault rifle it was capable of both single and automatic fire, and was loaded with a magazine and also featured a pistol grip. Compared to other light machine guns of the time the Chauchat was fairly light at the weight of but it was still too cumbersome for closer quarters and had recoil that was too heavy to control when firing fully automatic due to the use of full powered rifle rounds like original French chambering of the 8 mm Lebel (8x50mmR) or variants produced later for US forces in 30-06 and other international customers in and rifle calibers. Despite some serious flaws it was so important to infantry combat that desperate German troops who had no comparable weapon of their own started using captured Chauchats. While it was chambered for 30-06 and therefore did not use an intermediate cartridge, it was an intermediate weapon between submachine guns and heavier machine guns such as the Lewis Gun.
The Ribeyrolle 1918 may be the first real select fire compact weapon using an intermediate round fitting today's definition of an assault rifle. The cartridge was based on the 351 Winchester Self loading case necked down to accept a 8 mm Lebel bullet. it was first introduced to the Army Technical Service on July, 6th, 1918. its official designation was Carabine Mitrailleuse (English: Machine Carbine. German: Maschinenkarabiner) It was finally rejected in 1921 because it was not enough accurate over 400 meters.
The American M1918 Browning Automatic Rifle (BAR) copied the Chauchat concept in a more reliable design but was not introduced or used in any significant numbers before the war ended. Later developments added heavier barrels and bipods that made it more like today's light machine gun or squad automatic weapon, though it did help establish the doctrine of use for light selective fire rifles. These versions of the BAR were produced in large numbers, widely adopted, and served into the 1960s with the U.S. military and other nations.
Also during World War I, submachine guns also entered service such as the Villar Perosa, the Beretta Model 1918 and the MP18. These weapons fired cartridges derived from pistol chamberings — 9 mm Glisenti and 9 mm Parabellum. The developers of the Thompson submachine gun (also developed during the 1910s) originally intended to use rifle-powered rounds. However, a mechanical system that could handle their power was not found and the.45 ACP cartridge was chosen instead. These firearms are considered part of the submachine gun class, but were an important step in the development of assault rifles.
The M1 Carbine was really a cross between a submachine gun and an assault rifle, but giving infantry men a reliable weapon with moderate stopping power.Continuing evolution of the intermediate-caliber automatic rifle was primarily driven by ammunition. Handgun ammunition used by submachine guns limited in effective range. Conversely, full-sized military rifle calibers were uncomfortable to fire repeatedly and difficult to control during fully automatic or rapid fire because of significant recoil; cost of design and manufacture was also higher. One attempt to combine an intermediate cartridge with an automatic rifle by the Italian arms company Beretta resulted in the MAB 38 (Moschetto Automatico Beretta 1938). The MAB 38 used a Fiocchi 9M38 cartridge and a higher-powered Parabellum cartridge, which could provide longer range fire. The effective range was about.
Originally the Carbine was envisioned as an inexpensive lightweight weapon for issue to rear-area and support troops (truckers, tankers, cooks, etc.) in place of the more expensive M1911 pistol or M1 Garand rifle. The M1 Carbine series was soon found suitable for close quarter battle engagements, a concept that would be re-applied later. In particularly, it was furnished to US Airborne divisions, because of the expectation that Airborne units would have to fight without being resupplied. This marked the first time in which such an intermediate weapon would be mass-produced — it became the most produced American weapon of the war, with millions made. The M1 Carbine series would remain in service with the U.S. military primary forces until supplemented and finally replaced by the M16 rifle in the 1960s; it continued to be used limited roles—particularly the U.S. Navy, Air Force, Coast Guard, and many Training Commands in various U.S. Armed forces well into the 1980s—as well as used in other nations (notably Israel, where it is still used frequently in a variety of forms).
The 1930s was also the beginning of the important German Maschinenkarabiner program of arms development that resulted in the prototype Maschinenkarabiner M35 that was however not adopted for service.
Some of these automatic firearms used pre-existing rounds; others used new intermediate cartridges. Kinetic energy ranged between 1,400–2,100 J (1,033–1,550-foot-pounds), muzzle velocities of 600–800m/s (1,970–2,625 ft/s) and bullets of 7–9g (108–139 grains).
Germany, under the Versailles Treaty was limited to a professional army of long service soldiers numbering only 100,000 men and forbade tanks or military aircraft. This encouraged an approach that emphasized high quality, and reduced emphasis on low cost. Infantry tactics became based on teams of General Purpose Machine Guns (GPMG) supporting and supported by a section of infantry. GPMG had high rates of fire to permit small numbers of men to fire at long range to defend a wide front. Enemy soldiers, briefly exposed, would be engaged with a high rate burst of fire to cause casualties before they could take cover. Close range assaults would be conducted by units with submachine guns, for greater mobility, and higher rates of fire. This tactical approach was a refinement of the "Hutier" tactics used by Germany in the last year of WWI.
Germany, like other countries, had observed and studied the emerging demand of infantry rifles evolving since World War I, and their factories made a variety of non-standard cartridges, therefore having less incentive to retain their existing calibers. The 7.92x30 mm (Kurz) cartridge was an example of these experiments; in 1941, it was improved to 7.92x33mm Kurz Infanterie Kurz Patrone ("Infantry Short Cartridge"). In 1942, it was again improved as Maschinenkarabiner Patrone S, and in 1943, Pistolen Patrone 43mE; then, finally, Infanterie Kurz Patrone 43. The similarity in size between the 7.92x33mm German cartridge and the 7.62x33mm developed for the M1 Carbine is a curious coincidence, but was ultimately nothing more than independent yet similar solutions to the same problem. The 7.92x33mm round used the same cartridge case head as the standard 7.92x57mm Mauser and the bullet was made from the same diameter rod.
In 1942, Walther presented the Maschinenkarabiner ("automatic carbine", abbr. MKb), named MKb42(W). In the same year, Haenel presented the MKb42(H), designed by Hugo Schmeisser as a result of this program. Rheinmetall-Borsig (some said Krieghoff) presented its FG 42 (Fallschirmjäger Gewehr 42, sponsored by Hermann Göring) though this was in a different role, and using a heavy 7.92x57mm Mauser cartridge, which was not an intermediate round. War-time tests in Russia indicated the MKb42(H) performed better than the other two. Schmeisser developed it first as the MP43, then MP43/1, and finally as the MP44/Sturmgewehr 44 (abbreviated StG44). It immediately entered large scale production. More than 5,000 units had been produced by February 1944, and 55,000 by the following November.
Following the end of the war in 1947, Mikhail Kalashnikov developed the AK-47, which was vaguely similar in visual concept and layout to the German StG44, though quite different mechanically. It fired the 7.62x39mm cartridge, which had been developed during WWII for use in their SKS carbines which were used at war's end. The round was similar to the StG44's in that the bullet was of a similar caliber to the larger, full-size Russian rifle ammunition.
The designers of the STG 45 moved to Spain and developed the CETME Assault Rifle, which was licensed for use in West Germany, and was subsequently improved to become the German G-3, produced by Heckler and Koch HK. proved the CETME, This is where H&K started.
Many of these automatic firearms used intermediate cartridges with much lighter bullets and smaller calibers, but fired at very high velocity; kinetic energy ranged between 1300–1800J (960–1,330-foot-pounds), velocities of 900–1050m/s (2,950–3,450 ft/s), and bullets of 3–4g (46–62 grains).
After WWII and the creation of NATO, the United States insisted on introducing their own 7.62x51mm full-power cartridge (developed from the 30-06/7.62x63mm - American standard during WWII) as standard in NATO. It could kill at distances of more than 500 meters, although statistical studies of WWII battles performed by the U.S. Army revealed that infantry combat beyond 300 meters (325 yards) was rare. At the time, the British were developing their own 7x43mm (.280 British) intermediate cartridge for their very modern and groundbreaking EM-2 bull-pup assault rifle. Due to political pressure from the Conservative Party, which agreed with the American standardization campaign, the whole project was shelved at the eve of introduction. In Belgium, the famous arms producer FN Herstal started experimenting with the German 7.92x33mm Kurzpatrone. They built a prototype of a rifle using this cartridge, but the impending NATO standardization forced them to rebuild it to use American ammo, giving birth to the FN FAL, Switzerland introduced the SIG 510 that still fired Swiss service full-lengh rifle rounds but also produced the SIG 510-4 that fired the 7.62x51mm NATO round. Bolivia and Chile adopted the SIG 510-4 as their service rifle, Bolivian/Chilean exports were licence produced by the Italian firm Berreta.
The M14 rifle, chambered for the 7.62x51mm NATO (more commonly known as the.308 round among civilians), had a very high recoil, due to the weapons powerful cartridge, and this made it almost impossible to control the M14 in full automatic fire. They found that the weapon recoiled both up and back, putting you off your target very quickly. This was fixed by making the stock straight, so that it only recoiled back, minimizing your needs to re-aim after each shot or burst of fully automatic fire. They made a new cartridge to go with this weapon: the 5.56x45mm NATO. The small cartridge made for doubts among the armed forces, and they questioned the rifle's stopping power. But, they were soon proved wrong. After some study, they found that the 5.56mm bullet, after entering the body, started to tumble,rolling end over end, creating massive damage.They christened their new rifle the M16. But soon after the rifle was the standard weapon to all the US armed forces, they saw that the M16 had a very high tendency to jam, making it unsuitable for jungle warfare, They later found that the jamming was because of improper care and cleaning. This was soon fixed by making a soldiers rifle his foremost thing to take care of and watch out for.
The Russians saw no reason to make a rifle that shot beyond a rifleman's ability to aim, and therefore considered a lighter, less-powerful cartridge to be more effective. This permitted a lighter rifle and allowed a greater amount of the lighter ammunition to be transported in the same amount of space. Moreover, the smaller cartridges lessened recoil, which allowed riflemen to sustain a higher accurate rate of fire and facilitate marksmanship training. In addition, the smaller size and handiness of an assault rifle would benefit tank crews, support troops, and units with missions other than front line combat.
The 5.56x45mm with 55 grain bullet, aka M193 cartridge) was developed in the late 1950s, and was adopted for use in the M16 assault rifle. The M16A1 version soon followed to rectify issues found during use in the Vietnam War. The M16A2 was a further refinement and upgrade introduced in 1986 meant to use the Belgian-updated 5.56x45mm NATO cartridge with a heavier 62 grain bullet known as the SS109 or M855.
The smaller-caliber military cartridges such as the 5.56x45mm and 5.45x39mm were sometimes considered less lethal than the previous generation of assault rifle rounds, such as the 7.62x39mm, which were large-caliber bullets with reduced propellant or cases. However, the lighter, small-caliber bullets achieved higher velocities, more favorable ballistic properties, and reduced carrying weight.
One aspect of the smaller caliber ammunition that is sometimes hotly debated is its fragmentation behavior. Stopping capability is the effectiveness of the round in completely stopping the target when it hits — either killing or fully incapacitating. Within a certain range of ballistic conditions, the lighter and will, upon striking tissue, first tumble and then fragment. Beyond 100 yards, or when fired from shorter barrels, such bullets can often fail to fragment upon impact because of insufficient velocity. Thus, the result in a target is a rather small.22 caliber bullet hole, instead of a much larger wound channel. Effectiveness depends on what tissues of the enemy body the round destroys. Larger destroyed areas increases the probability that sufficient damage will be done to end enemy resistance. Ultimately, any pointed (spitzer) round will tumble in soft tissue. If the jacket has a cannelure, such as the U.S. 5.56x45mm M193 round, and the bullet is in the proper ballistic state and high enough velocity, the bullet will fragment, inflicting significant blood loss and internal damage, as well as a wound channel profile that is more complex to address medically. If the bullet acts as a solid, and doesn't fragment, full effectiveness occurs only if striking the brain or spinal cord, causing immediate loss of control. There is a distinct, though lesser effectiveness if the heart, large blood vessels, or liver (which last tends to tear) is hit causing fairly quick loss of blood pressure, and consequent unconsciousness.
Part of the dispute over small-caliber rounds arises here. Blood loss leads to indirect incapacitation, but often takes longer than direct destruction of tissue. A pervasive but false urban myth holds that Defense Secretary Robert McNamara presented wounding ability as a reason for adoption of the M16 over the M14. Many claim that the theory that wounding one soldier will take him out of action was wed to the findings of Project SALVO, but the reality is that nowhere in the SALVO findings was reduced lethality of rifle rounds ever stressed or presented as an argument for adoption of a lighter/smaller caliber round. SALVO concluded that the main factor in inflicting casualties in infantry combat was solely rounds fired — aiming had negligible impact. Initial findings from combat trials with Special Forces and the ARVN units they advised in Vietnam actually indicated that ammunition was somewhat (11%) more lethal than 7.62x51 M59/M80 type full-metal jacket ammunition.
The general effectiveness of the 5.56x45mm cartridge was questioned; experience had shown that it did not always fragment, and that the bullet was light enough to easily deflect or divert radically from its path after passing through even a soft or very thin object. The heavier bullets in use were claimed by some to hit harder with more mass, would not deflect or destabilize as readily, and more reliably killed what it hit. These claims appear to have been largely, if not wholly, anecdotal, however, with little statistical evidence from after-action reviews and other post-combat surveys of troops. The idea that a heavier bullet must, inherently, be more lethal seems sufficiently logical that many take it as an accepted fact regardless of actual fact.
While the debate about the effectiveness of the 5.56/5.45 mm bullet versus the continued, some interesting developments did arise in the following generation of weapons.
Many of these automatic firearms usually used the same rounds as in older eras, but focused on using new form factors, materials, and added features like standard telescopic and reflex sights.
The running debate over vs. ammunition, and the prominent argument by proponents that "the Russians got it right with a.30 cal (7.62 mm)" cartridge, was stirred significantly in 1974 when the Soviet Union also developed its own smaller-caliber cartridge, the 5.45x39mm, which was used in the AK-74, the successor of the AK-47/AKM.
In the 1980s and 1990s, the most notable changes since adoption of high velocity, smaller-caliber ammunition were designs that utilized new form factors, sights, electronics, and materials, as well as modularity. A number of bullpup rifles entered service in the late 1970s, 1980s and 1990s. Although bullpup rifles had existed since the 1930s, the United Kingdom's EM-2 was one of the few bullpup assault rifles prior to this time. Examples of the new trend include the FAMAS, Steyr AUG, and SA80. All three are bullpup rifles that make heavy use of composites and plastics, the FAMAS and Steyr AUG both have ambidextrous controls, and the Steyr AUG, and SA80 both added a low-power telescopic sight to the standard service version. The QBZ-95, SAR-21, and the Tavor TAR-21 follow a similar trend as well, with a bullpup configuration and heavy use of composites.
The Heckler & Koch G36, adopted in the late 1990s by Spain and Germany, is of the traditional configuration, but also has integral telescopic and red dot sights and composite exterior. The G36C variant uses a different barrel assembly, foregrip, and a slightly shorter folding stock to make the weapon carbine length, and features a low full-length rail mount along the top of the rifle in place of the carrying handle and sight assembly, plus shorter rails on the foregrip. The XM8 rifle, developed from the G36, had similar features, but also added more electronics such as laser sight, round counter, and integral infrared laser and pointers.
Through the 1990s, modular accessories for use on rifles, of a variety of types, started to become widespread with the rapidly increasing practice of mounting Picatinny-style rails on firearms. This was primarily driven by the growing visibility (and number) of tactical police, counter-terrorist units, special forces, and other groups that desired the capability to specifically tailor their weapons — be it to the situation at hand, their operational specialty, etc. Flashlights, visible lasers, infrared lights and lasers, ergonomic accessories such as vertical foregrips and folding or collapsible buttstocks, and a plethora of other options appeared. Many law enforcement and tactical groups, including some of the most influential, also contributed to the progression by shifting from using submachine guns to very compact assault rifles, usually with small-caliber (5.56 mm) ammunition.
Intertwined with the growth of the modular accessories was the concept of rifles being modular themselves. The G36, for example, can be converted to a compact carbine, a standard rifle, or a squad support weapon (light machine gun) and back again simply by swapping modular parts in a matter of moments. Interchangeable or quick-detachable barrel assemblies of different lengths are emerging for some weapons, with ingenious retrofit kits to provide similar capabilities on older types. The AR15 in particular has an entire industry that has grown to make variations of every component of the rifle. An incredible variety of upper receivers of many types of operation (bolt, direct gas impingement, gas piston, blowback) utilizing different ammunition than the original 5.56x45mm have been developed, firing both pistol and rifle cartridges ranging between target rounds such as.17 and.22 Rimfire, pistol rounds of.380 ACP to.50 AE, and more common assault rifle rounds such as 7.62x51mm, all the way up to heavy machine gun rounds such as the.50 BMG. In a paradox many never expected, an AK variant has been developed that fires the 5.56x45mm round, while a variant of the M4 carbine (a compact M16) has been created that can use AK-47 magazines and its 7.62x39mm ammunition.
The trend in the new designs, and very likely future ones, is towards more integrated features and lighter weight with new materials and configurations. Introduction of a new ammunition would require retooling factories, phasing out conventional ammunition, and making general infrastructure changes that are considered by many military planners to be too expensive to undertake. In an effort to avoid the problems of a completely new cartridge, the 77-grain Mk262 Mod0 bullet for the 5.56x45mm chambering, developed to address continuing issues in some cases with the effectiveness of the round, has started to gain acceptance.
Since the adoption of the M16 over the M14, some groups of shooting pundits have supported the return to, or reintroduction of, larger caliber rounds — usually the 7.62x51mm NATO specifically, which is made to perform like the full-sized 30-06 in an assault-rifle sized cartridge. Going back to the, it is argued, would improve conventional lethality. Other individuals have suggested an increase in caliber, to the 6–7 mm range, with rifle round velocities and lower mass bullets: a kind of intermediate philosophy between the smaller caliber–faster modern rounds and the standard caliber–slower rounds of the previous generation. China in the late 1980s introduced a 5.8x42mm round, with an initial velocity of /s, bullet and 1,842 J of energy, China claims the new round provides superior performance and lethality to NATO (5.56x45mm) and modern Soviet (5.45x39mm) intermediate rounds.
A promising development of the German Heckler & Koch G11 rifle caseless ammunition and advanced assault rifle in the 1970–1980s was effectively halted by German reunification and heat-dissipation issues with the caseless ammunition in 1990, and the rifle never entered full production.
A renaissance of weapons has begun to occur recently. To some degree in Iraq, but particularly in Afghanistan, soldiers are beginning to use modernized M14s, M21s, and M24 SWS. With a longer effective range, the 7.62x51mm is proving useful at fighting at long ranges. The 7.62x51 NATO round has also shown its usefulness against enemies who have been seen to take several hits from bullets and not be killed, incapacitated, or on occasion, even deterred. That unpleasant surprise is attributed to long-range ballistic deficiencies of the 5.56 bullet. Similar stopping-power problems against unusually-tenacious opponents were noticed in Somalia in 1993 against militia fighters high on khat. Lastly, the heavier rounds are more effective in urban combat because they can more readily penetrate walls.
In the United States there have been developments of new cartridges. Two have developed some notability as possible replacements for the venerable 5.56, the 6.5 Grendel and the SPC. Remington has developed the 6.8 mm Remington SPC cartridge, which has the same cartridge overall length (COAL) as the 5.56x45mm NATO cartridge but fires the larger.270 caliber bullets. Likewise, Alexander Arms at Radford Arsenal developed the 6.5 Grendel cartridge, which combines long range accuracy comparable to the NATO with close range stopping power similar to the 6.8 SPC. With both bullets, by matching the 5.56's COAL, conversion of existing AR-15, M4 and M16 rifles requires only replacement of uppers and magazines. Other cartridges have been developed for the AR-15 platform such as the.50 Beowulf and the.458 Socom - but these cartridges are much heavier and relegated to a specialty role rather than as a pure assault rifle cartridge.
In addition to these new designs, the future may well be the redesign of the past. Recently, weapons manufacturing giants Heckler and Koch redesigned the M4 assault rifle. The new weapon, the HK416, has updated features. The include: a piston action, not gas, the bolt is sealed from the action, reducing dirt, heat and chance of failure, 1913 Picatinny rails, drop free magazine release and other subtle, but useful additions. These and other redesigns are quickly pushing it to the top of the ladder.
Small arms technology including the assault rifle can be described as a mature technology, meaning that no major technology changes can be expected in this area. However, minor improvements can still be expected that make the assault rifle more effective and efficient to accommodate the changes on the battlefield. Diminishing the effect of the assault rifle are improvements to personal body armor, which allow it to stop or hinder bullet penetration from intermediate caliber small arms.
As weapons evolve, the delicate balance for assault rifle systems between power, weight, recoil and terminal effects will likely shift once again in an attempt to defeat body armor, to match the range of full-power cartridges, and to penetrate through windshields and thin-skinned vehicles while still producing good terminal effects. Possible future directions are armor piercing or exploding tip bullets or saboted sub-caliber tungsten darts, more powerful cartridges, carbon fiber barrels and exotic metals such as titanium and scandium.
A common public misconception persists that the assault weapons ban restricted weapons capable of fully automatic fire, such as assault rifles and machine guns. Fully automatic weapons, however, were unaffected by the ban, and have been continuously and heavily regulated since the National Firearms Act of 1934 was passed. Subsequent laws such as the Gun Control Act of 1968 and the Firearm Owners Protection Act of 1986 also affected the importation and civilian ownership of fully automatic firearms, the latter fully prohibiting sales of newly-manufactured machine guns to non-law enforcement or SOT(Special occupancy Tax) dealers.

'The following list is obsolete.
Please make no further additions to the list.
For scientists and scholars of anthropology, refer to the category Anthropologists '.

Astronomy and Astrophysics (abbreviated as A&A in the astronomical literature, or else Astron. Astrophys.) is a European Journal, publishing papers on theoretical, observational and instrumental astronomy and astrophysics. It was published by Springer-Verlag from 1969-2000, while EDP Sciences published the companion A&A Supplement Series. In 2000, the two journals merged, with the combined journal known simply as Astronomy and Astrophysics, and published by EDP Sciences. The journal copyright is owned by the European Southern Observatory.
A&A is one of the major journals of astronomy, alongside the Astrophysical Journal, Astronomical Journal and the Monthly Notices of the Royal Astronomical Society. While the first two are often the preferred journal of US-based researchers and the MNRAS is often the favoured journal for UK- and Commonwealth-based astronomers, A&A tends to be the preferred journal of astronomers based in Europe (excluding the UK), particularly since page charges are waived for astronomers working in member countries.
The original member countries were the four countries whose journals merged to form A&A (France, Germany, the Netherlands and Sweden) together with Belgium, Denmark, Finland and Norway. ESO also participated as a 'member country'. Norway later withdrew, but Austria, Greece, Italy, Spain and Switzerland all joined. The Czech Republic, Estonia, Hungary, Poland and Slovakia all joined as new members in the 1990s. In 2001 the words "A European Journal" were removed from the front cover in recognition that the journal was becoming increasingly global in scope, and in 2002 Argentina was admitted as an 'observer'. In 2004 the Board of Directors decided that "A&A will henceforth consider applications for sponsoring membership from any country in the world with well-documented active and excellent astronomical research". Argentina became the first non-European country to gain full membership in 2005. Brazil, Chile and Portugal all gained 'observer' status at this time and have since progressed to full membership.

The Actinopterygii (the plural form of Actinopterygius) comprise the class of the ray-finned fishes.
The ray-finned fishes are so called because they possess lepidotrichia or "fin rays", their fins being webs of skin supported by bony or horny spines ("rays"), as opposed to the fleshy, lobed fins that characterize the order Sarcopterygii. These actinopterygian fin rays attach directly to the proximal or basal skeletal elements, the radials, which represent the link or connection between these fins and the internal skeleton (e.g. pelvic and pectoral girdles).
In terms of numbers, actinopterygians are the dominant class of vertebrates, with nearly 30,000 species, and they are ubiquitous throughout fresh water and marine environments from the deep sea to the highest mountain streams.
Traditionally three grades of actinopterygians have been recognised: the Chondrostei, Holostei, and Teleostei. Some morphological evidence suggests that the second is paraphyletic and should be abandoned; however, recent work based on the analysis of DNA sequence data from the complete mitochondrial genome supports its recognition. Nearly all living bony fishes are teleosts.
A listing of the different groups is given below, down to the level of orders, arranged in what has been suggested to represent the evolutionary sequence down to the level of order based primarily on the long history of morphological studies. This classification, like any other taxonomy based on phylogenetic research is in a state of flux. Many of these ordinal and higher-level groupings have not been supported in both the recent morphological and molecular literature. Examples of demonstrably paraphyletic or unnatural groups include the Paracanthopterygii, Scorpaeniformes, and Perciformes. The listing follows FishBase with notes when this differs from Nelson and ITIS.


Einstein's many contributions to physics include his special theory of relativity, which reconciled mechanics with electromagnetism, and his general theory of relativity, which extended the principle of relativity to non-uniform motion, creating a new theory of gravitation. His other contributions include relativistic cosmology, capillary action, critical opalescence, classical problems of statistical mechanics and their application to quantum theory, an explanation of the Brownian movement of molecules, atomic transition probabilities, the quantum theory of a monatomic gas, thermal properties of light with low radiation density (which laid the foundation for the photon theory), a theory of radiation including stimulated emission, the conception of a unified field theory, and the geometrization of physics.
Works by Albert Einstein include more than fifty scientific papers and also non-scientific books. Einstein is revered by the physics community, and in 1999 Time magazine named him the "Person of the Century". It is fair to say he is a household name and in popular culture the name "Einstein" has become synonymous with genius.
Albert Einstein was born into a Jewish family in Ulm, Württemberg, Germany on March 14, 1879. His father was Hermann Einstein, a salesman and engineer. His mother was Pauline Einstein (née Koch). In 1880, the family moved to Munich, where his father and his uncle founded a company, Elektrotechnische Fabrik J. Einstein & Cie that manufactured electrical equipment, providing the first lighting for the Oktoberfest and cabling for the Munich suburb of Schwabing.
The Einsteins were not observant of Jewish religious practices, and Albert attended a Catholic elementary school. Although Einstein had early speech difficulties, he was a top student in elementary school.
When Einstein was five, his father showed him a pocket compass. Einstein realized that something in empty space was moving the needle and later stated that this experience made "a deep and lasting impression". At his mother's insistence, he took violin lessons starting at age six, and although he disliked them and eventually quit, he later took great pleasure in Mozart's violin sonatas. As he grew, Einstein built models and mechanical devices for fun, and began to show a talent for mathematics.
In 1889, family friend Max Talmud (later: Talmey), a medical student, introduced the ten-year-old Einstein to key science, mathematics, and philosophy texts, including Kant's Critique of Pure Reason and Euclid's Elements (Einstein called it the "holy little geometry book"). From Euclid, Einstein began to understand deductive reasoning (integral to theoretical physics), and by the age of twelve, he learned Euclidean geometry from a school booklet. Soon thereafter he began to investigate calculus.
In his early teens, Einstein attended the new and progressive Luitpold Gymnasium. His father intended for him to pursue electrical engineering, but Einstein clashed with authorities and resented the school regimen. He later wrote that the spirit of learning and creative thought were lost in strict rote learning.
In 1894, when Einstein was fifteen, his father's business failed, and the Einstein family moved to Italy, first to Milan and then, after a few months, to Pavia. During this time, Einstein wrote his first scientific work, "The Investigation of the State of Aether in Magnetic Fields".
Einstein had been left behind in Munich to finish high school, but in the spring of 1895, he withdrew to join his family in Pavia, convincing the school to let him go by using a doctor's note.
Rather than completing high school, Einstein decided to apply directly to the ETH Zurich, the Swiss Federal Institute of Technology in Zurich, Switzerland. Without a school certificate, he was required to take an entrance examination, which he did not pass, although he got exceptional marks in mathematics and physics. Einstein wrote that it was in that same year, at age 16, that he first performed his famous thought experiment, visualizing traveling alongside a beam of light.
The Einsteins sent Albert to Aarau, Switzerland to finish secondary school. While lodging with the family of Professor Jost Winteler, he fell in love with the family's daughter, Sofia Marie-Jeanne Amanda Winteler, called "Marie". (Albert's sister, Maja, his confidant, later married Paul Winteler.) In Aarau, Einstein studied Maxwell's electromagnetic theory. In 1896, he graduated at age 17, renounced his German citizenship to avoid military service (with his father's approval), and finally enrolled in the mathematics program at ETH. Marie moved to Olsberg, Switzerland for a teaching post.
In 1896, Einstein's future wife, Mileva Marić, also enrolled at ETH, as the only woman studying mathematics. During the next few years, Einstein and Marić's friendship developed into romance. Einstein graduated in 1900 from ETH with a degree in physics. That same year, Einstein's friend Michele Besso introduced him to the work of Ernst Mach. The next year, Einstein published a paper in the prestigious Annalen der Physik on the capillary forces of a straw. On February 21, 1901, he gained Swiss citizenship, which he never revoked.
Following graduation, Einstein could not find a teaching post. After almost two years of searching, a former classmate's father helped him get a job in Bern, at the Federal Office for Intellectual Property, the patent office, as an assistant examiner. His responsibility was evaluating patent applications for electromagnetic devices. In 1903, Einstein's position at the Swiss Patent Office was made permanent, although he was passed over for promotion until he "fully mastered machine technology".
With friends he met in Bern, Einstein formed a weekly discussion club on science and philosophy, jokingly named "The Olympia Academy". Their readings included Poincaré, Mach, and Hume, who influenced Einstein's scientific and philosophical outlook.
During this period Einstein had almost no personal contact with the physics community. Much of his work at the patent office related to questions about transmission of electric signals and electrical-mechanical synchronization of time: two technical problems that show up conspicuously in the thought experiments that eventually led Einstein to his radical conclusions about the nature of light and the fundamental connection between space and time.
Einstein and Mileva Marić had a daughter, Lieserl Einstein, born in early 1902. Her fate is unknown.
Einstein married Mileva on January 6, 1903, although Einstein's mother had objected to the match because she had a prejudice against Serbs and thought Marić "too old", and "physically defective." Their relationship was for a time a personal and intellectual partnership. In a letter to her, Einstein wrote of Marić as "a creature who is my equal and who is as strong and independent as I am." There has been debate about whether Marić influenced Einstein's work; however, most historians do not think she made major contributions. On May 14, 1904, Albert and Mileva's first son, Hans Albert Einstein, was born in Bern, Switzerland. After the death of Albert's father in 1910, Albert's second son, Eduard, was born in Munich.
Einstein and Marić divorced on February 14, 1919, having lived apart for five years. On June 2 of that year, Einstein married Elsa Löwenthal, who had nursed him through an illness. Elsa was Albert's first cousin maternally and his second cousin paternally. Together the Einsteins raised Margot and Ilse, Elsa's daughters from her first marriage. Their union produced no children.
All four papers are today recognized as tremendous achievements—and hence 1905 is known as Einstein's "Wonderful Year". At the time, however, they were not noticed by most physicists as being important, and many of those who did notice them rejected them outright. Some of this work—such as the theory of light quanta—remained controversial for years.
In 1906, the patent office promoted Einstein to Technical Examiner Second Class, but he was not giving up on academia. In 1908, he became a privatdozent at the University of Bern. In 1910, he wrote a paper on critical opalescence that described the cumulative effect of light scattered by individual molecules in the atmosphere, i.e. why the sky is blue.
During 1909, Einstein published "Über die Entwicklung unserer Anschauungen über das Wesen und die Konstitution der Strahlung" ("The Development of Our Views on the Composition and Essence of Radiation"), on the quantization of light. In this and in an earlier 1909 paper, Einstein showed that Max Planck's energy quanta must have well-defined momenta and act in some respects as independent, point-like particles. This paper introduced the photon concept (although the term itself was introduced by Gilbert N. Lewis in 1926) and inspired the notion of wave–particle duality in quantum mechanics.
In 1911, Einstein became an associate professor at the University of Zurich. However, shortly afterward, he accepted a full professorship at the Charles University of Prague. While in Prague, Einstein published a paper about the effects of gravity on light, specifically the gravitational redshift and the gravitational deflection of light. The paper appealed to astronomers to find ways of detecting the deflection during a solar eclipse. German astronomer Erwin Freundlich publicized Einstein's challenge to scientists around the world.
In 1912, Einstein returned to Switzerland to accept a professorship at his alma mater, the ETH. There he met mathematician Marcel Grossmann who introduced him to Riemannian geometry, and at the recommendation of Italian mathematician Tullio Levi-Civita, Einstein began exploring the usefulness of general covariance (essentially the use of tensors) for his gravitational theory. Although for a while Einstein thought that there were problems with that approach, he later returned to it and by late 1915 had published his general theory of relativity in the form that is still used today. This theory explains gravitation as distortion of the structure of spacetime by matter, affecting the inertial motion of other matter.
After many relocations, Mileva established a permanent home with the children in Zurich in 1914, just before the start of World War I. Einstein continued on alone to Berlin, where he became a member of the Prussian Academy of Sciences. As part of the arrangements for his new position, he also became a professor at the University of Berlin, although with a special clause freeing him from most teaching obligations. From 1914 to 1932 he was also director of the Kaiser Wilhelm Institute for Physics.
During World War I, the speeches and writings of Central Powers scientists were available only to Central Powers academics, for national security reasons. Some of Einstein's work did reach the United Kingdom and the United States through the efforts of the Austrian Paul Ehrenfest and physicists in the Netherlands, especially 1902 Nobel Prize-winner Hendrik Lorentz and Willem de Sitter of the Leiden University. After the war ended, Einstein maintained his relationship with the Leiden University, accepting a contract as an Extraordinary Professor; he travelled to Holland regularly to lecture there between 1920 and 1930.
In 1917, Einstein published an article in Physikalische Zeitschrift that proposed the possibility of stimulated emission, the physical process that makes possible the maser and the laser. He also published a paper introducing a new notion, a cosmological constant, into the general theory of relativity in an attempt to model the behavior of the entire universe.
1917 was the year astronomers began taking Einstein up on his 1911 challenge from Prague. The Mount Wilson Observatory in California, U.S. published a solar spectroscopic analysis that showed no gravitational redshift. In 1918, the Lick Observatory, also in California, announced that they too had disproven Einstein's prediction, although their findings were not published.
However, in May 1919, a team led by British astronomer Arthur Stanley Eddington claimed to have confirmed Einstein's prediction of gravitational deflection of starlight by the Sun while photographing a solar eclipse in Sobral northern Brazil and Principe. On November 7, 1919, leading British newspaper The Times printed a banner headline that read: "Revolution in Science – New Theory of the Universe – Newtonian Ideas Overthrown". In an interview Nobel laureate Max Born praised general relativity as the "greatest feat of human thinking about nature"; fellow laureate Paul Dirac was quoted saying it was "probably the greatest scientific discovery ever made".
In their excitement, the world media made Albert Einstein world-famous. Ironically, later examination of the photographs taken on the Eddington expedition showed that the experimental uncertainty was of about the same magnitude as the effect Eddington claimed to have demonstrated, and in 1962 a British expedition concluded that the method used was inherently unreliable. The deflection of light during a solar eclipse has, however, been more accurately measured (and confirmed) by later observations.
There was some resentment toward the newcomer Einstein's fame in the scientific community, notably among German physicists, who later started the Deutsche Physik (German Physics) movement.
In 1921 Einstein was awarded the Nobel Prize in Physics, "for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect". This refers to his 1905 paper on the photoelectric effect: "On a Heuristic Viewpoint Concerning the Production and Transformation of Light", which was well supported by the experimental evidence by that time. The presentation speech began by mentioning "his theory of relativity [which had] been the subject of lively debate in philosophical circles [and] also has astrophysical implications which are being rigorously examined at the present time." As stipulated in their 1919 divorce settlement, Einstein gave the Nobel prize money to his first wife, Mileva Marić.
Einstein traveled to New York City in the United States for the first time on April 2, 1921. When asked where he got his scientific ideas, Einstein explained that he believed scientific work best proceeds from an examination of physical reality and a search for underlying axioms, with consistent explanations that apply in all instances and avoid contradicting each other. He also recommended theories with visualizable results.
Einstein's research after general relativity consisted primarily of a long series of attempts to generalize his theory of gravitation in order to unify and simplify the fundamental laws of physics, particularly gravitation and electromagnetism. In 1950, he described this "Unified Field Theory" in a Scientific American article entitled "On the Generalized Theory of Gravitation".
Although he continued to be lauded for his work in theoretical physics, Einstein became increasingly isolated in his research, and his attempts were ultimately unsuccessful. In his pursuit of a unification of the fundamental forces, he ignored some mainstream developments in physics (and vice versa), most notably the strong and weak nuclear forces, which were not well understood until many years after Einstein's death. Einstein's goal of unifying the laws of physics under a single model survives in the current drive for the grand unification theory.
In 1924, Einstein received a description of a statistical model from Indian physicist Satyendra Nath Bose which showed that light could be understood as a gas. Bose's statistics applied to some atoms as well as to the proposed light particles, and Einstein submitted his translation of Bose's paper to the Zeitschrift für Physik. Einstein also published his own articles describing the model and its implications, among them the Bose–Einstein condensate phenomenon that should appear at very low temperatures. It was not until 1995 that the first such condensate was produced experimentally by Eric Cornell and Carl Wieman using ultra-cooling equipment built at the NIST-JILA laboratory at the University of Colorado at Boulder. Bose–Einstein statistics are now used to describe the behaviors of any assembly of "bosons". Einstein's sketches for this project may be seen in the Einstein Archive in the library of the Leiden University.
Einstein suggested to Erwin Schrödinger an application of Max Planck's idea of treating energy levels for a gas as a whole rather than for individual molecules, and Schrödinger applied this in a paper using the Boltzmann distribution to derive the thermodynamic properties of a semiclassical ideal gas. Schrödinger urged Einstein to add his name as co-author, although Einstein declined the invitation.
In 1926, Einstein and his former student Leó Szilárd, a Hungarian physicist who later worked on the Manhattan Project and is credited with the discovery of the chain reaction, co-invented (and in 1930, patented) the Einstein refrigerator, revolutionary for having no moving parts and using only heat, not ice, as an input.
In the 1920s, quantum mechanics developed into a more complete theory. Einstein was unhappy with the "Copenhagen interpretation" of quantum theory developed by Niels Bohr and Werner Heisenberg, wherein quantum phenomena are inherently probabilistic, with definite states resulting only upon interaction with classical systems. A public debate between Einstein and Bohr followed, lasting for many years (including during the Solvay Conferences). Einstein formulated thought experiments against the Copenhagen interpretation, which were all rebutted by Bohr. In a 1926 letter to Max Born, Einstein wrote: "I, at any rate, am convinced that He [God] does not throw dice.".
Einstein was never satisfied by what he perceived to be quantum theory's intrinsically incomplete description of nature, and in 1935 he further explored the issue in collaboration with Boris Podolsky and Nathan Rosen, noting that the theory seems to require non-local interactions; this is known as the EPR paradox. The EPR experiment has since been performed, with results confirming quantum theory's predictions.
Einstein's disagreement with Bohr revolved around the idea of scientific determinism. For this reason the repercussions of the Einstein-Bohr debate have found their way into philosophical discourse as well.
His friend Max Jammer explored Einstein's views on religion thoroughly in the 1999 book Einstein and Religion: Physics and Theology.
With increasing public demands, his involvement in political, humanitarian, and academic projects in various countries, and his new acquaintances with scholars and political figures from around the world, Einstein was less able to achieve the productive isolation that he needed in order to work. Due to his fame and genius, Einstein found himself called on to give conclusive judgments on matters that had nothing to do with theoretical physics or mathematics. He was not timid, and he was aware of the world around him, with no illusion that ignoring politics would make world events fade away. His very visible position allowed him to speak and write frankly, even provocatively, at a time when many people of conscience could only flee to the underground or keep doubts about developments within their own movements to themselves for fear of internecine fighting. Einstein flouted the ascendant Nazi movement, tried to be a voice of moderation in the tumultuous formation of the State of Israel and braved anti-communist politics and resistance to the civil rights movement in the United States. He participated in the 1927 congress of the League against Imperialism in Brussels.
Einstein was a cultural Zionist. In 1931, The Macmillan Company published About Zionism: Speeches and Lectures by Professor Albert Einstein. Querido, an Amsterdam publishing house, collected eleven of Einstein's essays into a 1933 book entitled Mein Weltbild, translated to English as The World as I See It; Einstein's foreword dedicates the collection "to the Jews of Germany". In the face of Germany's rising militarism, Einstein wrote and spoke for peace.
The United Nations did divide the mandate, demarcating the borders of several new countries including the State of Israel, and war broke out immediately. Einstein was one of the authors of a 1948 letter to the New York Times criticizing Menachem Begin's Revisionist Herut (Freedom) Party for the Deir Yassin massacre.
Einstein served on the Board of Governors of The Hebrew University of Jerusalem. In his Will of 1950, Einstein bequeathed literary rights to his writings to The Hebrew University, where many of his original documents are held in the Albert Einstein Archives.
In January 1933, Adolf Hitler was appointed Chancellor of Germany. One of the first actions of Hitler's administration was the Law for the Restoration of the Professional Civil Service which removed Jews and politically suspect government employees (including university professors) from their jobs, unless they had demonstrated their loyalty to Germany by serving in World War I. In December 1932, in response to this growing threat, Einstein had prudently traveled to the U.S. For several years he had been wintering at the California Institute of Technology in Pasadena, California, and also was a guest lecturer at Abraham Flexner's newly founded Institute for Advanced Study in Princeton, New Jersey.
The Einsteins bought a house in Princeton (where Elsa died in 1936), and Einstein remained an integral contributor to the Institute for Advanced Study until his death in 1955. During the 1930s and into World War II, Einstein wrote affidavits recommending United States visas for a huge number of Jews from Europe trying to flee persecution, raised money for Zionist organizations and was in part responsible for the formation, in 1933, of the International Rescue Committee.
Meanwhile in Germany, a campaign to eliminate Einstein's work from the German lexicon as unacceptable "Jewish physics" (Jüdische physik) was led by Nobel laureates Philipp Lenard and Johannes Stark. Deutsche Physik activists published pamphlets and even textbooks denigrating Einstein, and instructors who taught his theories were blacklisted—including Nobel laureate Werner Heisenberg, who had debated quantum probability with Bohr and Einstein. Philipp Lenard claimed that the mass–energy equivalence formula needed to be credited to Friedrich Hasenöhrl to make it an Aryan creation.
Einstein became a citizen of the United States in 1940, although he retained his Swiss citizenship.
Concerned scientists, many of them refugees from European anti-Semitism in the U.S. recognized the possibility that German scientists were working toward developing an atomic bomb. They knew that Einstein's fame might make their fears more believable. In 1939, Einstein signed a letter to U.S. President Franklin Delano Roosevelt written by Leó Szilárd warning that based on Szilárd's research the Third Reich might be developing nuclear weapons.
The United States took stock of this warning, and within five years, the U.S. created its own nuclear weapons, and used them on the Japanese cities of Nagasaki and Hiroshima. According to chemist and author Linus Pauling, Einstein later expressed regret about the Einstein-Szilárd letter.
When he was a visible figure working against the rise of Nazism, Einstein had sought help and developed working relationships in both the West and what was to become the Soviet bloc. After World War II, enmity between the former allies became a very serious issue for people with international résumés. To make things worse, during the first days of McCarthyism Einstein was writing about a single world government; it was at this time that he wrote, "I do not know how the third World War will be fought, but I can tell you what they will use in the Fourth—rocks!" In a 1949 Monthly Review article entitled "Why Socialism?" Albert Einstein described a chaotic capitalist society, a source of evil to be overcome, as the "predatory phase of human development". With Albert Schweitzer and Bertrand Russell, Einstein lobbied to stop nuclear testing and future bombs. Days before his death, Einstein signed the Russell-Einstein Manifesto, which led to the Pugwash Conferences on Science and World Affairs.
Einstein was a member of several civil rights groups, including the Princeton chapter of the NAACP. When the aged W. E. B. Du Bois was accused of being a Communist spy, Einstein volunteered as a character witness, and the case was dismissed shortly afterward. Einstein's friendship with activist Paul Robeson, with whom he served as co-chair of the American Crusade to End Lynching, lasted twenty years.
In 1946, Einstein collaborated with Rabbi Israel Goldstein, Middlesex heir C. Ruggles Smith, and activist attorney George Alpert on the Albert Einstein Foundation for Higher Learning, Inc. which was formed to create a Jewish-sponsored secular university, open to all students, on the grounds of the former Middlesex College in Waltham, Massachusetts. Middlesex was chosen in part because it was accessible from both Boston and New York City, Jewish cultural centers of the U.S. Their vision was a university "deeply conscious both of the Hebraic tradition of Torah looking upon culture as a birthright, and of the American ideal of an educated democracy." The collaboration was stormy, however. Finally, when Einstein wanted to appoint British economist Harold J. Laski as the university's president, Alpert wrote that Laski was "a man utterly alien to American principles of democracy, tarred with the Communist brush." Einstein withdrew his support and barred the use of his name. The university opened in 1948 as Brandeis University. In 1953, Brandeis offered Einstein an honorary degree, but he declined.
Given Einstein's links to Germany and Zionism, his socialistic ideals, and his links to Communist figures, the U.S. Federal Bureau of Investigation kept a file on Einstein that grew to 1,427 pages. Many of the documents in the file were sent to the FBI by concerned citizens: some objecting to his immigration, while others asked the FBI to protect him.
Although Einstein had long been sympathetic to the notion of vegetarianism, it was only near the start of 1954 that he adopted a strict vegetarian diet.
On April 17, 1955, Albert Einstein experienced internal bleeding caused by the rupture of an aortic aneurism. He took a draft of a speech he was preparing for a television appearance commemorating the State of Israel's seventh anniversary with him to the hospital, but he did not live long enough to complete it. He died in Princeton Hospital early the next morning at the age of 76. Einstein's remains were cremated and his ashes were scattered.
Before the cremation, Princeton Hospital pathologist Thomas Stoltz Harvey removed Einstein's brain for preservation, in hope that the neuroscience of the future would be able to discover what made Einstein so intelligent.
While travelling, Einstein had written daily to his wife Elsa and adopted stepdaughters, Margot and Ilse, and the letters were included in the papers bequeathed to The Hebrew University. Margot Einstein permitted the personal letters to be made available to the public, but requested that it not be done until twenty years after her death (she died in 1986). Barbara Wolff, of The Hebrew University's Albert Einstein Archives, told the BBC that there are about 3,500 pages of private correspondence written between 1912 and 1955.
The United States' National Academy of Sciences commissioned the Albert Einstein Memorial, a monumental bronze and marble sculpture by Robert Berks, dedicated in 1979 at its Washington, D.C. campus adjacent to the National Mall.
Einstein bequeathed the royalties from use of his image to The Hebrew University of Jerusalem. The Roger Richman Agency licenses the use of his name and associated imagery, as agent for the Hebrew University.
In 1990, his name was added to the Walhalla temple.
The following publications by Albert Einstein are referenced in this article. A more complete list of his publications may be found at Works by Albert Einstein.


Afghanistan is a culturally mixed nation, a crossroads between the East and the West, and has been an ancient focal point of trade and migration. It has an important geostrategical location, connecting South, Central and Southwest Asia. During its long history, the land has seen various invaders and conquerors, while on the other hand, local entities invaded the surrounding vast regions to form their own empires. Ahmad Shah Durrani created the Durrani Empire in 1747, with its capital at Kandahar. Subsequently, the capital was shifted to Kabul and most of its territories ceded to former neighboring countries. In the 19th century, Afghanistan became a buffer state in "The Great Game" played between the British Indian Empire and Russian Empire. On August 19, 1919, following the third Anglo-Afghan war, the country regained full independence from the United Kingdom over its foreign affairs.
Since the late 1970s Afghanistan has suffered continuous and brutal civil war, which included foreign interventions in the form of the 1979 Soviet invasion and the recent 2001 US-led invasion that toppled the Taliban government. In late 2001 the United Nations Security Council authorized the creation of an International Security Assistance Force (ISAF). This force is composed of NATO troops that are involved in assisting the government of President Hamid Karzai in establishing the writ of law as well as rebuilding key infrastructures in the nation. In 2005, the United States and Afghanistan signed a strategic partnership agreement committing both nations to a long-term relationship. In the meantime, multi-billion US dollars have also been provided by the international community for the reconstruction of the country.
The name Afghānistān translates to the "Land of Afghans". Its modern usage derives from the word Afghan.
The last part of the name, -stān, is an Iranian suffix for "place", prominent in many languages of the region.
The term "Afghanistan," meaning the "Land of Afghans," was mentioned by the sixteenth century Mughal Emperor Babur in his memoirs, referring to the territories south of Kabul that were inhabited by Pashtuns (called "Afghans" by Babur).
Until the 19th century the name was only used for the traditional lands of the Pashtuns, while the kingdom as a whole was known as the Kingdom of Kabul, as mentioned by the British statesman and historian Mountstuart Elphinstone. Other parts of the country were at certain periods recognized as independent kingdoms, such as the Kingdom of Balkh in the late eighteenth and early nineteenth centuries.
With the expansion and centralization of the country, Afghan authorities adopted and extended the name "Afghanistan" to the entire kingdom, after its English translation, "Afghanland", had already appeared in various treaties between British Raj and Qajarid Persia, referring to the lands that were subject to the Pashtun Barakzai Dynasty of Kabul. "Afghanistan" as the name for the entire kingdom was mentioned in 1857 by Frederick Engels. It became the official name when the country was recognized by the world community in 1919, after regaining its full independence from the British, and was confirmed as such in the nation's 1923 constitution.
Afghanistan is a landlocked and mountainous country in South-Central Asia, with plains in the north and southwest. The highest point is Nowshak, at 7,485 m (24,557 ft) above sea level. Large parts of the country are dry, and fresh water supplies are limited. The endorheic Sistan Basin is one of the driest regions in the world. Afghanistan has a continental climate with hot summers and cold winters. The country is frequently subject to minor earthquakes, mainly in the northeast of Hindu Kush mountain areas. Some 125 villages were damaged and 4000 people killed by the May 30, 1998 earthquake.
At 249,984 sq mi (647,500 km²), Afghanistan is the world's 41st-largest country (after Myanmar). Comparatively, it is slightly smaller than the U.S. state of Texas.
The country's natural resources include gold, silver, copper, zinc and iron ore in southeastern areas; precious and semi-precious stones such as lapis, emerald and azure in the north-east; and potentially significant petroleum and natural gas reserves in the north. The country also has uranium, coal, chromite, talc, barites, sulfur, lead, and salt. However, these significant mineral and energy resources remain largely untapped due to the effects of the Soviet invasion and the subsequent civil war. Plans are underway to begin extracting them in the near future.
Though the modern state of Afghanistan was founded or created in 1747 by Ahmad Shah Durrani, the land has an ancient history and various timelines of different civilizations. Excavation of prehistoric sites by Louis Dupree, the University of Pennsylvania, the Smithsonian Institution and others suggests that humans were living in what is now Afghanistan at least 50,000 years ago, and that farming communities of the area were among the earliest in the world.
Afghanistan is a country at a unique nexus point where numerous Indo-European civilizations have interacted and often fought, and was an important site of early historical activity. Through the ages, the region has been home to various people, among them the Aryan (Indo-Iranian) tribes, such as the Kambojas, Bactrians, Persians, etc. It also has been conquered by a host of people, including the Median and Persian Empires, Alexander the Great, Kushans, Hepthalites, Arabs, Turks, and Mongols. In recent times, invasions from the British, Soviets, and most recently by the Americans and their allies have taken place. On the other hand, native entities have invaded surrounding regions in Iranian plateau and Indian subcontinent to form empires of their own.
It has been speculated that Zoroastrianism might have originated in what is now Afghanistan between 1800 to 800 BC, as Zoroaster lived and died in Balkh. Ancient Eastern Iranian languages, such as Avestan, may have been spoken in this region around the time of the rise of Zoroastrianism. By the middle of the sixth century BC, the Persian Empire of the Achaemenids supplanted the Median Empire and incorporated what was known as Persia to the Greeks within its boundaries; and by 330 BC, Alexander the Great invaded Afghanistan and conquered the surrounding regions. Following Alexander's brief occupation, the Hellenistic successor states of the Seleucids and Greco-Bactrians controlled the area, while the Mauryas from India annexed the southeast for a time and introduced Buddhism to the region until the area returned to the Bactrian rule.
During the first century AD, the Kushans created a vast empire centered in modern Afghanistan and were patrons of Buddhist culture. The Kushans were defeated by the Sassanids in the third century. Although various rulers calling themselves Kushans (and generally known as Kushano-Sasanians) continued to rule at least parts of the region, they were probably more or less subject to the Sassanids. The late Kushans were followed by the Kidarite Huns who, in turn, were replaced by the short-lived but powerful Hephthalites, as rulers of the region in the first half of the fifth century. The Hephthalites were defeated by the Sasanian king Khosrau I in AD 557, who re-established Sasanian power in Persia. However, the successors of Kushans and Hepthalites established a small dynasty in Kabulistan called Kushano-Hephthalites or Kabul-Shahan/Shahi and were later defeated by the Muslim armies.
In the Middle Ages, up to the nineteenth century, the region was known as Khorasan. Several important centers of Khorāsān are thus located in modern Afghanistan, such as Balkh, Herat, Ghazni and Kabul. It was during this period of time when Islam was introduced and spread in the area.
The region of Afghanistan became the center of various important empires, including that of the Samanids (875–999), Ghaznavids (977–1187), Seljukids (1037–1194), Ghurids (1149–1212), and Timurids (1370–1506). Among them, the periods of Ghaznavids of Ghazni, and Timurids of Herat are considered as some of the most brilliant eras of Afghanistan's history.
In 1219 the region was overrun by the Mongols under Genghis Khan, who devastated the land. Their rule continued with the Ilkhanates, and was extended further following the invasion of Timur Lang ("Tamerlane"), a ruler from Central Asia. In 1504, Babur, a descendant of both Timur Lang and Genghis Khan, established the Mughal Empire with its capital at Kabul. By the early 1700s, Afghanistan was controlled by several ruling groups: Uzbeks to the north, Safavids to the west and the remaining larger area by the Mughals or self-ruled by local Afghan tribes.
In 1709, Mir Wais Hotak, a local Afghan (Pashtun) from the Ghilzai clan, overthrew and killed Gurgin Khan, the Safavid governor of Kandahar. Mir Wais successfully defeated the Persians, who were attempting to convert the local population of Kandahar from Sunni to the Shia sect of Islam. Mir Wais held the region of Kandahar until his death in 1715 and was succeeded by his son Mir Mahmud Hotaki. In 1722, Mir Mahmud led an Afghan army to Isfahan (now in Iran), sacked the city and proclaimed himself King of Persia. However, the great majority still rejected the Afghan regime as usurping, and after the massacre of thousands of civilians in Isfahan by the Afghans – including more than three thousand religious scholars, nobles, and members of the Safavid family – the Hotaki dynasty was eventually removed from power by a new ruler, Nadir Shah of Persia.
In 1738 Nadir Shah and his army, which included four thousand Pashtuns of the Abdali clan, conquered the region of Kandahar; in the same year he occupied Ghazni, Kabul and Lahore. On June 19, 1747, Nadir Shah was assassinated, possibly planned by his nephew Ali Qoli. In the same year, one of Nadir's military commanders and personal bodyguard, Ahmad Shah Abdali, a Pashtun from the Abdali clan, called for a loya jirga following Nadir's death. The Afghans gathered at Kandahar and chose Ahmad Shah as their King. Since then, he is often regarded as the founder of modern Afghanistan. After the inauguration, he changed his title or clans' name to "Durrani", which derives from the Persian word Durr, meaning "Pearl".
By 1751 Ahmad Shah Durrani and his Afghan army conquered the entire present-day Afghanistan, Pakistan, Khorasan and Kohistan provinces of Iran, along with Delhi in India. In October 1772, Ahmad Shah retired to his home in Maruf, Kandahar, where he died peacefully. He was succeeded by his son, Timur Shah Durrani, who transferred the capital from Kandahar to Kabul. Timur died in 1793 and was finally succeeded by his son Zaman Shah Durrani.
During the nineteenth century, following the Anglo-Afghan wars (fought 1839–42, 1878–80, and lastly in 1919) and the ascension of the Barakzai dynasty, Afghanistan saw much of its territory and autonomy ceded to the United Kingdom. The UK exercised a great deal of influence, and it was not until King Amanullah Khan acceded to the throne in 1919 that Afghanistan re-gained complete independence over its foreign affairs (see "The Great Game"). During the period of British intervention in Afghanistan, ethnic Pashtun territories were divided by the Durand Line. This would lead to strained relations between Afghanistan and British India – and later the new state of Pakistan – over what came to be known as the Pashtunistan debate. The longest period of stability in Afghanistan was between 1933 and 1973, when the country was under the rule of King Zahir Shah.
However, in 1973 Zahir Shah's brother-in-law, Mohammed Daoud Khan, launched a bloodless coup and became the first President of Afghanistan. Daoud Khan and his entire family were murdered in 1978, when the communist People's Democratic Party of Afghanistan launched a coup known as the Great Saur Revolution and took over the government. The 1978 Khalq uprising against the government of Daoud Khan was essentially a resurgence by the Ghilzai tribe of the Pashtun against the Durrani (the tribe of Daoud Khan and the previous monarchy).
As part of a Cold War strategy, in 1979 the United States government (under President Jimmy Carter and National Security Advisor Zbigniew Brzezinski) began to covertly fund and train anti-government Mujahideen forces through the Pakistani secret service known as Inter Services Intelligence (ISI). In order to bolster the local Communist forces, the Soviet Union—citing the 1978 Treaty of Friendship, Cooperation and Good Neighborliness that had been signed between the two countries—intervened on December 24, 1979. Over 100,000 Soviet troops took part in the invasion, who were backed by another 100,000 and plus pro-communist forces of Afghanistan. The Soviet occupation resulted in the killings of at least 600,000 to 2 million Afghan civilians. Over five million Afghans fled their country to Pakistan, Iran and other parts of the world. Faced with mounting international pressure and great number of casualties on both sides, the Soviets withdrew in 1989.
The Soviet withdrawal from the Democratic Republic of Afghanistan was seen as an ideological victory in the US, which had backed the Mujahideen through three US presidential administrations in order to counter Soviet influence in the vicinity of the oil-rich Persian Gulf.
Following the removal of the Soviet forces, the US and its allies lost interest in Afghanistan and did little to help rebuild the war-ravaged country or influence events there. The USSR continued to support President Najibullah (former head of the Afghan secret service, KHAD) until 1992 when the new Russian government refused to sell oil products to Najibullah regime.
Because of the fighting, a number of elites and intellectuals fled to take refuge abroad. This led to a leadership imbalance in Afghanistan. Fighting continued among the victorious Mujahideen factions, which gave rise to a state of warlordism. The most serious fighting during this period occurred in 1994, when over 10,000 people were killed in Kabul alone. It was at this time that the Taliban developed as a politico-religious force, eventually seizing Kabul in 1996. By the end of 2000 the Taliban had captured 95% of the country.
During the Taliban's seven-year rule, much of the population experienced restrictions on their freedom and violations of their human rights. Women were banned from jobs, girls forbidden to attend schools or universities. Those who resisted were punished instantly. Communists were systematically eradicated and thieves were punished by amputating one of their hands or feet. Meanwhile, the Taliban managed to nearly eradicate the majority of the opium production by 2001.
Following the September 11, 2001 attacks the United States launched Operation Enduring Freedom, a military campaign to destroy the al-Qaeda terrorist training camps inside Afghanistan. The US military also threatened to overthrow the Taliban government for refusing to hand over Osama bin Laden and several al-Qaida members. The US made a common cause with the former Afghan Mujahideen to achieve its ends, including the Northern Alliance, a militia still recognized by the UN as the Afghan government.
In late 2001, US Special Forces invaded Afghanistan to aid anti-Taliban militias, backed by US air strikes against Taliban and Al Qaeda targets, culminating in the seizure of Kabul by the Northern Alliance and the overthrow of the Taliban, with many local warlords switching allegiance from the Taliban to the Northern Alliance.
In December of the same year, leaders of the former Afghan mujahideen and diaspora met in Germany, and agreed on a plan for the formulation of a new democratic government that resulted in the inauguration of Hamid Karzai, an ethnic Pashtun from the southern city of Kandahar, as Chairman of the Afghan Interim Authority.
After a nationwide Loya Jirga in 2002, Karzai was chosen by the representatives to assume the title as Interim President of Afghanistan. The country convened a Constitutional Loya Jirga (Council of Elders) in 2003 and a new constitution was ratified in January 2004. Following an election in October 2004, Hamid Karzai won and became the President of the Islamic Republic of Afghanistan. Legislative elections were held in September 2005. The National Assembly – the first freely elected legislature in Afghanistan since 1973 – sat in December 2005, and was noteworthy for the inclusion of women as voters, candidates, and elected members.
As the country continues to rebuild and recover, it is still struggling against poverty, poor infrastructure, large concentration of land mines and other unexploded ordnance, as well as a huge illegal poppy cultivation and opium trade. Afghanistan also remains subject to occasionally violent political jockeying. The country continues to grapple with the Taliban insurgency and the threat of attacks from a few remaining al Qaeda.
Afghanistan is currently led by President Hamid Karzai, who was elected in October 2004. The current parliament was elected in 2005. Among the elected officials were former mujahadeen, Taliban members, communists, reformists, and Islamic fundamentalists. 28% of the delegates elected were women, 3 points more than the 25% minimum guaranteed under the constitution. This made Afghanistan, long known under the Taliban for its oppression of women, one of the leading countries in terms of female representation. Construction for a new parliament building began on August 29, 2005.
The Supreme Court of Afghanistan is currently led by Chief Justice Abdul Salam Azimi, a former university professor who had been legal advisor to the president. The previous court, appointed during the time of the interim government, had been dominated by fundamentalist religious figures, including Chief Justice Faisal Ahmad Shinwari. The court had issued numerous questionable rulings, such as banning cable television, seeking to ban a candidate in the 2004 presidential election and limiting the rights of women, as well as overstepping its constitutional authority by issuing rulings on subjects not yet brought before the court. The current court is seen as more moderate and led by more technocrats than the previous court, although it has yet to issue any rulings.
Afghanistan currently has more than 70,000 national police officers, with plans to recruit more so that the total number can reach 80,000. They are being trained by and through the Afghanistan Police Program. Although the police officially are responsible for maintaining civil order, sometimes local and regional military commanders continue to exercise control in the hinterland. Police have been accused of improper treatment and detention of prisoners. In 2003 the mandate of the International Security Assistance Force, now under command of the North Atlantic Treaty Organization (NATO) was extended and expanded beyond the Kabul area. However, in some areas unoccupied by those forces, local militias maintain control. In many areas, crimes have gone uninvestigated because of insufficient police and/or communications. Troops of the Afghan National Army have been sent to quell fighting in some regions lacking police protection.
Afghanistan is administratively divided into thirty-four (34) provinces (welayats), and for each province there is a capital. Each province is then divided into many provincial districts, and each district normally covers a city or several townships.
The Governor of the province is appointed by the Ministry of Interior, and the Prefects for the districts of the province will be appointed by the provincial Governor. The Governor is the representative of the central government of Afghanistan, and is responsible for all administrative and formal issues. The provincial Chief of Police is appointed by the Ministry of Interior, who works together with the Governor on law enforcement for all the cities or districts of that province.
There is an exception in the capital city (Kabul) where the Mayor is selected by the President of Afghanistan, and is completely independent from the prefecture of the Kabul Province.
The only city in Afghanistan with over one million residents is its capital, Kabul. The other major cities in the country are, in order of population size, Kandahar, Herat, Mazar-e Sharif, Jalalabad, Ghazni and Kunduz.
The population of Afghanistan is divided into a wide variety of ethnic groups. Because a systematic census has not been held in the country in decades, exact figures about the size and composition of the various ethnic groups are not available. Therefore most figures are approximations only.
Afghans display pride in their religion, country, ancestry, and above all, their independence. Like other highlanders, Afghans are regarded with mingled apprehension and condescension, for their high regard for personal honor, for their clan loyalty and for their readiness to carry and use arms to settle disputes. As clan warfare and internecine feuding has been one of their chief occupations since time immemorial, this individualistic trait has made it difficult for foreign invaders to hold the region.
Afghanistan has a complex history that has survived either in its current cultures or in the form of various languages and monuments. However, many of the country's historic monuments have been damaged in recent wars. The two famous statues of Buddha in the Bamyan Province were destroyed by the Taliban, who regarded them as idolatrous. Other famous sites include the cities of Kandahar, Herat, Ghazni and Balkh. The Minaret of Jam, in the Hari River valley, is a UNESCO World Heritage site. The cloak worn by Muhammad is stored inside the famous Khalka Sharifa in Kandahar City.
Buzkashi is a national sport in Afghanistan. It is similar to polo and played by horsemen in two teams, each trying to grab and hold a goat carcass. Afghan hounds (a type of running dog) also originated in Afghanistan.
Although literacy levels are very low, classic Persian poetry plays a very important role in the Afghan culture. Poetry has always been one of the major educational pillars in Iran and Afghanistan, to the level that it has integrated itself into culture. Persian culture has, and continues to, exert a great influence over Afghan culture. Private poetry competition events known as "musha’era" are quite common even among ordinary people. Almost every home owns one or more poetry collections of some sort, even if they are not read often.
Many of the famous Persian poets of the tenth to fifteenth centuries stem from Khorasan where is now known as Afghanistan. They were mostly also scholars in many disciplines like languages, natural sciences, medicine, religion and astronomy.
Most of these individuals were of Persian (Tājīk) ethnicity who still form the second-largest ethnic group in Afghanistan. Also, some of the contemporary Persian language poets and writers, who are relatively well-known in Persian-speaking world, include Ustad Betab, Qari Abdullah, Khalilullah Khalili, Sufi Ghulam Nabi Ashqari, Sarwar Joya, Qahar Asey, Parwin Pazwak and others. In 2003, Khaled Hosseini published The Kiterunner which though fiction, captured much of the history, politics and culture experienced in Afghanistan from the 1930s to present day.
In addition to poets and authors, numerous Persian scientists were born or worked in the region of present-day Afghanistan. Most notable was Avicenna (Abu Alī Hussein ibn Sīnā) whose father hailed from Balkh. Ibn Sīnā, who travelled to Isfahan later in life to establish a medical school there, is known by some scholars as "the father of modern medicine". George Sarton called ibn Sīnā "the most famous scientist of Islam and one of the most famous of all races, places, and times." His most famous works are The Book of Healing and The Canon of Medicine, also known as the Qanun. Ibn Sīnā's story even found way to the contemporary English literature through Noah Gordon's The Physician, now published in many languages. Moreover, according to Ibn al-Nadim, Al-Farabi, a well-known philosopher and scientist, was from the Faryab Province of Afghanistan,
Before the Taliban gained power, the city of Kabul was home to many musicians who were masters of both traditional and modern Afghan music, especially during the Nauroz-celebration. Kabul in the middle part of the twentieth century has been likened to Vienna during the eighteenth and nineteenth centuries.
The tribal system, which orders the life of most people outside metropolitan areas, is potent in political terms. Men feel a fierce loyalty to their own tribe, such that, if called upon, they would assemble in arms under the tribal chiefs and local clan leaders (Khans). In theory, under Islamic law, every believer has an obligation to bear arms at the ruler's call (Ulul-Amr).
difficult, and in a society that, from a materialistic point of view, has an uncomplicated lifestyle.
Religiously, Afghans are over 99% Muslims: approximately 74-80% Sunni and 19-25% Shi'a (estimates vary). Up until the mid-1980s, there were about 30,000 to 150,000 Hindus and Sikhs living in different cities, mostly in Jalalabad, Kabul, and Kandahar.
There was a small Jewish community in Afghanistan (see Bukharan Jews) who fled the country after the 1979 Soviet invasion, and only one individual, Zablon Simintov, remains today.
Afghanistan is a member of the South Asian Association for Regional Cooperation (SAARC), Economic Cooperation Organization (ECO) and the Organization of the Islamic Conference (OIC). It is an impoverished country, one of the world's poorest and least developed. Two-thirds of the population lives on fewer than 2 US dollars a day. Its economy has suffered greatly from the 1979 Soviet invasion and subsequent conflicts, while severe drought added to the nation's difficulties in 1998–2001.
The economically active population in 2002 was about 11 million (out of a total of an estimated 29 million). As of 2005, the official unemployment rate is at 40%. The number of non-skilled young people is estimated at 3 million, which is likely to increase by some 300,000 per annum.
The nation's economy began to improve since 2002 due to the infusion of multi-billion US dollars in international assistance and investments, as well as remittances from expats. It is also due to dramatic improvements in agricultural production and the end of a four-year drought in most of the country.
According to a 2004 report by the Asian Development Bank, the present reconstruction effort is two-pronged: first it focuses on rebuilding critical physical infrastructure, and second, on building modern public sector institutions from the remnants of Soviet style planning to ones that promote market-led development. In 2006, two US companies, Black & Veatch and the Louis Berger Group, have won a US 1.4 billion dollar contract to rebuild roads, power lines and water supply systems of Afghanistan.
One of the main drivers for the current economic recovery is the return of over 4 million refugees from neighbouring countries and the West, who brought with them fresh energy, entrepreneurship and wealth-creating skills as well as much needed funds to start up businesses. What is also helping is the estimated US 2–3 billion dollars in international assistance every year, the partial recovery of the agricultural sector, and the reestablishment of market institutions. Private developments are also beginning to get underway. In 2006, a Dubai-based Afghan family opened a $25 million Coca Cola bottling plant in Afghanistan.
While the country's current account deficit is largely financed with the donor money, only a small portion – about 15% – is provided directly to the government budget. The rest is provided to non-budgetary expenditure and donor-designated projects through the United Nations system and non-governmental organizations. The government had a central budget of only $350 million in 2003 and an estimated $550 million in 2004. The country's foreign exchange reserves totals about $500 million. Revenue is mostly generated through customs, as income and corporate tax bases are negligible.
Inflation had been a major problem until 2002. However, the depreciation of the Afghani in 2002 after the introduction of the new notes (which replaced 1,000 old Afghani by 1 new Afghani) coupled with the relative stability compared to previous periods has helped prices to stabilize and even decrease between December 2002 and February 2003, reflecting the turnaround appreciation of the new Afghani currency. Since then, the index has indicated stability, with a moderate increase toward late 2003.
The Afghan government and international donors seem to remain committed to improving access to basic necessities, infrastructure development, education, housing and economic reform. The central government is also focusing on improved revenue collection and public sector expenditure discipline. The rebuilding of the financial sector seems to have been so far successful. Money can now be transferred in and out of the country via official banking channels. Since 2003, over sixteen new banks have opened in the country, including Afghanistan International Bank, Kabul Bank, Azizi Bank, Standard Chartered Bank, First Micro Finance Bank, and others. A new law on private investment provides three to seven-year tax holidays to eligible companies and a four-year exemption from exports tariffs and duties.
Some private investment projects, backed with national support, are also beginning to pick up steam in Afghanistan. An initial concept design called the City of Light Development, envisioned by Dr. Hisham N. Ashkouri, Principal of ARCADD, Inc. for the development and the implementation of a privately based investment enterprise has been proposed for multi-function commercial, historic and cultural development within the limits of the Old City of Kabul along the Southern side of the Kabul River and along Jade Meywand Avenue, revitalizing some of the most commercial and historic districts in the City of Kabul, which contains numerous historic mosques and shrines as well as viable commercial activities among war damaged buildings. Also incorporated in the design is a new complex for the Afghan National Museum.
According to the US Geological Survey and the Afghan Ministry of Mines and Industry, Afghanistan may be possessing up to 36 trillion cubic feet of natural gas, 3.6 billion barrels of petroleum and up to 1,325 million barrels of natural gas liquids. This could mark the turning point in Afghanistan’s reconstruction efforts. Energy exports could generate the revenue that Afghan officials need to modernize the country’s infrastructure and expand economic opportunities for the beleaguered and fractious population. Other reports show that the country has huge amounts of gold, copper, coal, iron ore and other minerals. The government of Afghanistan is in the process of extracting and exporting its copper reserves, which will be earning $1.2 billion US dollars in royalties and taxes every year for the next 30 years. It will also provide permanent labor to 3,000 of its citizens.
Ariana Afghan Airlines is the national airlines carrier, with domestic flights between Kabul, Kandahar, Herat and Mazar-e Sharif. International flights include to Dubai, Frankfurt, Istanbul and a number of other destinations. There are also limited domestic and international flight services available from Kam Air, Pamir Airways and Safi Airlines.
The country has limited rail service with Turkmenistan. There are two railway projects currently in progress, one is between Herat and the Iranian city Mashad while another is between Kandahar and Quetta in Pakistan. Most people who travel from one city to another use bus services. Automobiles have recently become more widely available, with Land Rover, BMW, Toyota, Nissan and Hyundai dealerships in Kabul. Large number of second-hand vehicles are also arriving from the UAE. Nearly all highways and roads are being rebuilt in the country.
Telecommunication services in the country are provided by Afghan Wireless, Etisalat, Roshan, Areeba and Afghan Telecom. In 2006, the Afghan Ministry of Communications signed a US$64.5 million agreement with ZTE Corporation for the establishment of a countrywide fibre optic cable network. This will improve telephone, internet, television and radio broadcast services throughout the country.
Television and radio broadcastings are available in most parts of the country, with local and international channels or stations.
The nation's post service is also operating. Package delivery services such as FedEx, DHL and others are also available.
As of 2006 more than four million male and female students are enrolled in schools throughout the country. Primary education is totally free and available for all boys and girls.
Literacy of the entire population is estimated (as of 1999) at 36%, the male literacy rate is 51% and female literacy is 21%. Up to now there are 9,500 schools in the country.
Another aspect of education that is rapidly changing in Afghanistan is the face of higher education. Following the fall of the Taliban, Kabul University was reopened to both male and female students. In 2006, the American University of Afghanistan also opened its doors, with the aim of providing a world-class, English-language, co-educational learning environment in Afghanistan. The university accepts students from Afghanistan and the neighboring countries. Construction work will soon start at the new site selected for University of Balkh in Mazari Sharif. The new building for the university, including the building for the Engineering Department, would be constructed at 600 acres (2.4 km²) of land at the cost of 250 million US dollars.


Albania, officially the Republic of Albania (Albanian Republika e Shqipërisë, or simply Shqipëria) is a country in South Eastern Europe. Albania is bordered by Greece to the south-east, Montenegro to the north, Kosovo to the northeast, and the Republic of Macedonia to the east. It has a coast on the Adriatic Sea to the west, and on the Ionian Sea to the southwest. From the Strait of Otranto, Albania is less than 100 km (60 miles) from Italy.
The country is a member of the United Nations, South East Europe Cooperation Process, Organisation for Co-operation and Security in Europe (OSCE), Council of Europe (COE),and World Trade Organisation.
It is also a potential candidate for membership in the European Union and NATO.
Albania is a parliamentary democracy that is transforming its economy into a market-oriented system. The Albanian capital, Tirana, is home to 750,000 of the country's 3.6 million population. As a result of the opening of the country in the post-communist era, Albania is now undergoing a development boom as its telecommunications, transport and utilities infrastructure is being revamped.
Albania is the Medieval Latin name of the country, which is called Shqipëri by the inhabitants. In Medieval Greek, the name is Albania besides variants Albaētia, Arbanētia.(OED).
The ultimate origin of the Alb- element has been traced to an Illyrian alb "hill" cognate to the alp "mountain pasture" found in the Alpine region. In the 2nd century BC, in the History of the World, written by Polybius, there is mention of a city named Arbon in present-day central Albania. The people who lived there were called Arbanios and Arbanitai.
Another suggestion is derivation from the Illyrian tribe of the Albanoi recorded by Ptolemy the geographer and astronomer from Alexandria, who drafted a map of remarkable significance for the history of Illyria. This map shows the city of Albanopolis (located Northeast of Durrës).
In his History written in 1079-1080, Byzantine historian Michael Attaliates was the first to refer to Albanoi as having taken part in a revolt against Constantinople in 1043 and to the Arbanitai as subjects of the duke of Dyrrachium. During the Middle Ages, the Albanians called their country Arbër or Arbën and referred to themselves as Arbëresh or Arbnesh. As early as the 16th century, a new name for their home evolved among Albanian people: Shqipëria, "Land of the Eagles", hence the two-headed bird on the national flag. The name probably has its origins in the Skanderbeg family crest.
The area of today's Albania has been populated since prehistoric times. In antiquity, much of it was settled by the Illyrians, possible ancestors of present-day Albanians.The modern Albanian state comprises the southernmost part of ancient Illyria and the northern part of ancient Epirus.
Surrounded by powerful, warring empires, Albania has experienced considerable violence and competition for control throughout its history. Greeks, Romans, Byzantines, Venetians and Ottomans swept through, leaving their cultural mark as well as their ruins.
Archaeological research shows that the lands that are today inhabited by Albanians were first populated in the Paleolithic Age (Stone Age). The first areas settled were those with favourable climatic and geographic conditions. In Albania, the earliest settlements have been discovered in the Gajtan cavern (Shkodra), in Konispol, at Mount Dajti, and at Saranda. Fragments of Cyclopean structures, were discovered at Kretsunitsa, Arinishta, and other sites in the district of Gjirokastra. The walls, partly Cyclopean, of an ancient city (perhaps Byllis) are visible at Gradishti on the picturesque Viosa River. Few traces remain of the once celebrated Dyrrhachium (today Durrës).
The rediscovered city of Butrint is probably more significant today than it was when Julius Caesar used it as a provisions depot for his troops during his campaigns in the 1st century BC. At that time, it was considered to be an unimportant outpost, overshadowed by the Greek colonies, Apollonia and Durrës.
Formal investigation and recording of Albania's archaeological monuments began with Francois Pouqueville, who was Napoleon's consul-general to Ali Pasha's court, and Martin Leake, who was the British agent there. A French mission, led by Len Rey, worked throughout Albania from 1924 to 1938 and published its results in "Cahiers d'Archéologie, d'art et d'Histoire en Albanie et dans les Balkans (Notes of Archaeology, Art, and History in Albania and in the Balkans).
Archaeologists today are finding remains from all periods, from the Stone Age to the early Christian era.
Another project that produced prehistoric finds, though unexpectedly, was done in the valley of Kryegjata, close to the present-day city of Fier and in the area of Apollonia. This excavation, a collaboration between the University of Cincinnati and archaeologists from the Institute of Archeology in Albania, was originally a mission to learn about the Greek colony of Apollonia. Instead, they found evidence of a much older settlement.
In 2000, the Albanian government established Butrint National Park, which draws about 70,000 visitors annually and is Albania's second World Heritage site.
In 2003, a synagogue dating from the 5th or 6th century AD was uncovered in Saranda, a coastal town opposite Corfu. It was the first time remains of an early synagogue have been found in that area. The history of its excavation is also noteworthy. The team found exceptional mosaics depicting items associated with Jewish holidays, including a menorah, ram's horn, and citron tree. Mosaics in the basilica of the synagogue show the facade of what resembles a Torah, animals, trees, and other biblical symbols. The structure measures 20 by 24 metres and was probably last used in the 6th century AD as a church.
The territory of Albania in antiquity was inhabited by the Illyrians,who, like other Balkan peoples, were subdivided into tribes and clans.
The kingdom of Illyria grew from the general area of modern-day Northern Albania and eventually controlled much of the eastern Adriatic coastline. Scodra was its capital, just as the city is now the most important urban center of northern Albania. The kingdom, however, reached the zenith of its expansion and development in the 4th century BC, when King Bardyllis, one of the most prominent of the Illyrian kings, united many Illyrian tribes into one Illyrian kingdom, and attacked the Greeks of the Molossian kingdom of Epirus and the kingdom of Macedon. Its decay began under the same ruler as a result of the attacks made by Philip II of Macedon, father of Alexander the Great.
Ancient Illyria was conquered by Romans, Slavs, and Ottoman Turks (15th cent.) Skanderbeg withstood repeated attacks and forced Sultan Murad II to conclude a 10-year truce in 1461. Skanderbeg broke the truce in 1463 when Pope Pius II called for a new crusade. The pope's death (1464) forced abandonment of the crusade. Skanderbeg, left without allies, had to retreat to his fortress of Kruja. After his death the league dissolved, resistance collapsed, and Albania fell to the Ottomans.Independent Albania was proclaimed in 1912 and the republic was formed in 1920. King Zog I ruled 1925-39, until Italy invaded Albania.
Albania was one of the first countries occupied by the Axis Powers in World War II. As Hitler began his aggressions, the Italian dictator Benito Mussolini set his eyes on Albania across the Adriatic from Italy. Despite some strong resistance, especially at Durrës, Italy invaded Albania on April 7, 1939 and took control of the country.Mussolini, in October 1940, used his Albanian base to launch an attack on Greece. During WWII, Albanian nationalist groups, including communist partisans, fought against the Italians and subsequently the Germans. By October 1944 they had thrown the Germans out, the only East European nation to do so without the assistance of Soviet troops. The partially French-educated Enver Hoxha became the leader of the country by virtue of his position as secretary general of the Party of Labor (the Albanian Communist Party). The Communist Party was created on November 8, 1941 with the help of the Yugoslavian Communist Party.
Albania is unique in that it is the only European country occupied by the Nazis that ended World War II with a larger Jewish population than before the War. The Albanian response to the Holocaust is especially notable because it was Europe's only largely Muslim country.Even so only a Jewish family of six was deported and killed during the Nazi occupation of Albania. Not only did the Albanians protect their own Jews, but they provided refuge for Jews from neighboring countries. The Albanians refused to comply and hand over lists of Jews. Instead they provided the Jewish families with forged documents and helped them disperse in the Albanian population.
Albania allied with the USSR, and then broke with the USSR in 1960 over de-Stalinization. A strong political alliance with China followed, leading to several billion dollars in aid, which was curtailed after 1974. China cut off aid in 1978 when Albania attacked its policies after the death of Chinese ruler Mao Zedong. Large-scale purges of officials occurred during the 1970s.
Enver Hoxha, the nation's ruler for 4 decades, died Apr. 11, 1985. Eventually the new regime introduced some liberalization, including measures in 1990 providing for freedom to travel abroad. Efforts were begun to improve ties with the outside world. March 1991 elections left the former Communists in power, but a general strike and urban opposition led to the formation of a coalition cabinet including non-Communists.
Albania's former Communists were routed in elections Mar. 1992, amid economic collapse and social unrest. Sali Berisha was elected as the first non-Communist president since WWII.
During NATO's air war against Yugoslavia, March-June 1999, Albania hosted some 465,000 Kosovar refugees. Victory by a pro-Berisha coalition in elections July 3, 2005, ended 8 years of Socialist Party rule. Crowds in Tirana, June 10, 2007, welcomed George W. Bush, the first sitting U.S. president to visit Albania.
The Albanian republic is a parliamentary democracy established under a constitution renewed in 1998. Elections are now held every four years to a unicameral 140-seat chamber, the People’s Assembly.In June 2002, a compromise candidate, Alfred Moisiu, former Army General, was elected to succeed President Rexhep Meidani. Parliamentary elections in July 2005 brought Sali Berisha, as leader of the Democratic Party, back to power. The Euro-Atlantic integration of Albania has been the ultimate goal of the post-communist governments. Albania's EU membership bid has been set as a priority by the European Commission. Albania, along with Croatia and the Republic of Macedonia, hopes to receive an invitation to join NATO in 2008.
The workforce of Albania has continued to migrate to Greece, Italy, Germany, other parts of Europe, and North America. However, the migration flux is slowly decreasing, as more and more opportunities are emerging in Albania itself as its economy steadily develops. Albanian emigrants have achieved great success in multiple geographies and disciplines abroad. In particular, there is now a significant Albanian community in the United Kingdom, in cities such as Birmingham and Manchester. The Albanian Diaspora is most prevalent in Liverpool, where Albanian cuisine has something of a cult following. Pulitzer prize winning journalist Caroline Thorpe, who is currently an emeritus professor at the University of Liverpool, recently noted that 'Albanian food has become as synonymous with Liverpool as Bill Shankley or the Beatles!'.
Albania is divided into 12 administrative divisions called (Albanian: official qark/qarku, but often prefekturë/prefektura Counties),36 districts and 351 municipalities.Each region has its Regional Council and is composed of a number of Municipalities and Communes, which are the first level of local governance responsible for local needs and law enforcement.
Albania has a total area of 28,750 square kilometers. Its coastline is 362 kilometres long and stretches on the Adriatic Sea and the Ionian Sea. The lowlands of the west face the Adriatic Sea. The 70% of the country that is mountainous is rugged and often inaccessible. The highest mountain is Korab situated in the district of Dibra, reaching up to 2,753 metres (9,032 ft). The country has a continental climate at its high altitude regions with cold winters and hot summers. Besides the capital city of Tirana, which has 800,000 inhabitants, the principal cities are Durrës, Elbasan, Shkodër, Gjirokastër, Vlorë, Korçë and Kukës. In Albanian grammar, a word can have indefinite and definite forms, and this also applies to city names: both Tiranë and Tirana, Shkodër and Shkodra are used.
As of July 2007, Albania's population of 3,600,523 is growing by 0.73% per year. Albania is a largely ethnically homogeneous country with only small minorities. Majority of the total population is considered Albanian. Minorities include Greeks, Aromanians, Torbesh, Gorani, Macedonians, Roma, Montenegrins, Bulgarians, Balkan Egyptians and Jews. The dominant language is Albanian, with two main dialects, Gheg and Tosk. Many Albanians are also fluent in English, Italian and Greek.
The democratically elected government that won the elections on April 1992 launched an ambitious economic reform programme to halt economic deterioration and forced the country on the path of a market economy. A comprehensive package of structural reforms, including privatization, enterprise, and financial sector reform, creation of the legal framework for a market economy and private sector activity. After severe economic contraction following 1989, the economy slowly rebounded, finally surpassing its 1989 levels by the end of the 1990s. Since prices have also risen, however, economic hardship has continued for much of the population. In 1995, Albania began privatizing large state enterprises.
Following the signing of the Stabilisation and Association Agreement in June/July 2006, EU ministers urged Albania to push ahead with reforms, focusing on freedom of press, property rights, institution building, respect for ethnic minorities and observing international standards in municipal elections. Albania has made an impressive recovery, building a modern and diversified economy. Recent administrations have also improved the country's infrastructure and opened competition in seaports, railroads, telecommunications, electricity generation, natural gas distribution and airports. This is a chart of trend of gross domestic product of Albania in Albanian currency and at Purchasing Power Parity (PPP--i.e. taking inflation into account) estimated by the International Monetary Fund with figures in billions of Lekes respectively.
Tourism in Albania is a large industry and is growing rapidly. The most notable tourist attractions are the ancient sites of Apollonia, Butrinti, and Krujë. Albania's coastline is becoming increasingly popular with tourists due to its relatively unspoiled nature and its beaches.
Christianity was adopted in the region of Albania during Roman rule by the middle of the 1st century AD. At first, the new religion had to compete with Oriental cults such the worshiping Mithra - the Persian God of light, known in the region due to Rome's growing interaction with eastern regions of the Roman Empire. For a long time, it also competed with gods worshiped by Illyrian pagans. The steady growth of the Christian community in Dyrrhachium (the Roman name for Epidamnus) led to the creation of a local bishopric in 58 AD. Later, episcopal seats were established in Apollonia, Buthrotum (modern Butrint), and Scodra (modern Shkodra).
After the division of the Roman Empire in 395, Albania fall under the umbrella of the Eastern Roman Empire, but remained ecclesiastically dependent on Rome. During the final schism on 1054 between the Western and Eastern churches, the Christians in southern Albania came under the jurisdiction of the Ecumenical Patriarch in Constantinople, and those in the north under the purview of the Papacy in Rome. The arrangement prevailed until the Ottoman invasion of the 14th century, when the Islamic faith was imposed.
Albanian was proven to be an Indo-European language in 1854 by the German philologist Franz Bopp. The Albanian language comprises its own branch of the Indo-European language family, next related to Armenian and Greek.
Establishing longer relations, Albanian is often compared to Balto-Slavic on the one hand and Germanic on the other, both of which share a number of isoglosses with Albanian. Moreover, Albanian has undergone a vowel shift in which stressed, long o has fallen to a, much like in the former and opposite the latter. Likewise, Albanian has taken the old relative jos and innovatively used it exclusively to qualify adjectives, much in the way Balto-Slavic has used this word to provide the definite ending of adjectives.
Meshari (The Missal) by Gjon Buzuku, published by him in 1555, is considered to date as the first literary work of written Albanian. The refined level of the language and the stabilised orthography must be a result of an earlier tradition of writing Albanian, a tradition that is not known. But there are some fragmented evidence, dating earlier than Buzuku, which indicate that Albanian was written at least since 14th century AD. The first known evidence dates from 1332 AD and deals with the French Dominican Guillelmus Adae, Archbishop of Antivari, who in a report in Latin writes that Albanians use Latin letters in their books although their language is quite different from Latin. Of special importance in supporting this are: a baptizing formula (Unte paghesont premenit Atit et Birit et spertit senit) of 1462, written in Albanian within a text in Latin by the bishop of Durrës, Pal Engjëlli; a glossary with Albanian words of 1497 by Arnold von Harff, a German who had travelled through Albania, and a 15th century fragment from the Bible from the Gospel of Matthew, also in Albanian, but in Greek letters.
Albanian writings of these centuries must not have been religious texts only, but historical chronicles too. They are mentioned by the humanist Marin Barleti, who, in his book Rrethimi i Shkodrës (The Siege of Shkodër) (1504), confirms that he leafed through such chronicles written in the language of the people (in vernacula lingua). Despite the obstacles generated by the Counter-Reformation which was opposed to the development of national languages in Christian liturgy, this process went on uninterrupted. During the 16th to 17th centuries, the catechism E mbësuame krishterë (Christian Teachings) (1592) by Lekë Matrënga, Doktrina e krishterë (The Christian Doctrine) (1618) and Rituale romanum (1621) by Pjetër Budi, the first writer of original Albanian prose and poetry, an apology for George Castriot (1636) by Frang Bardhi, who also published a dictionary and folklore creations, the theological-philosophical treaty Cuneus Prophetarum (The Band of Prophets) (1685) by Pjetër Bogdani, the most universal personality of Albanian Middle Ages, were published in Albanian.
The cuisine of Albania, as with most Mediterranean and Balkan nations, is strongly influenced by its long history. At different times, the territory of Albania has been occupied by Greece, Italy and the Ottoman Turks, and each group has left its mark on Albanian cuisine. The main meal of the Albanians is lunch, and it is usually accompanied by a salad of fresh vegetables, such as tomatoes, cucumbers, green peppers, and olives with olive oil, vinegar and salt.Lunch also includes a main dish of vegetables and meat. Seafood specialties are also common in the coastal areas of Durrës, Vlorë and Sarandë.


Allah (, ", ) is the standard Arabic word for "God". While the term is best known in the West for its use by Muslims as a reference to God, it is used by Arabic-speakers of all Abrahamic faiths, including Christians and Jews in reference to "God". The term was also used by pagan Meccans as a reference to the creator-god, possibly the supreme deity in pre-Islamic Arabia.
The concepts associated with the term Allah" (as a deity) differ among the traditions. In pre-Islamic Arabia, Allah was not the sole divinity, having associates and companions, sons and daughters. In Islam, Allah is unique, the only God, transcendent creator of the universe and omnipotent. Arab Christians today, having no other word for 'God' than 'Allah', use terms such as Allāh al-ab (الله الآب) to mean God the father. There are both similarities and differences between the concept of God as portrayed in the Qur'an and the Hebrew Bible.
Unicode has a codepoint reserved for Allāh, ﷲ = U+FDF2.
The term Allāh is most likely derived from a contraction of the Arabic article al- and ' "deity, god" to ' meaning "the [sole] deity, God" (ho theos monos). Another theory traces the etymology of the word to the Aramaic Alāhā. Cognates of the name "Allāh" exist in other Semitic languages, including Hebrew and Aramaic. The corresponding Aramaic form is אֱלָהָא ˀĔlāhā in Biblical Aramaic and ܐܰܠܳܗܳܐ ˀAlâhâ or ˀĀlōho in Syriac.
The contraction of al- and " in forming the term Allāh ("the deity" in the masculine form) parallels the contraction of al- and in forming the term al-Lāt" ("the deity" in the feminine form).
According to the tradition of Islam there are 99 Names of God (al-asma al-husna lit. meaning: "The best names") each of which evoke a distinct characteristic of Allah. The most famous and most frequent of these names are "the Merciful" (al-rahman) and "the Compassionate" (al-rahim).
Arabic-speakers of all Abrahamic faiths, including Christians and Jews, use the word "Allah" to mean "God". The Christian Arabs of today have no other word for 'God' than 'Allah'. Arab Christians for example use terms Allāh al-ab (الله الآب) meaning God the father, Allāh al-ibn (الله الابن) mean God the son, and Allāh al-ruh al ghodus (الله الروح القدس) meaning God the Holy Spirit (See God in Christianity for the Christian concept of God).
In the name of Father and the Son and the Holy Spirit, One God.
The Syriac, Latin and Greek invocations do not have the words "One God" at the end. This addition was made to emphasize the monotheistic aspect of Trinitian belief and also to make it more palatable to Muslims.
According to Marshall Hodgson, it seems that in the pre-Islamic times, some Arab Christians made pilgrimage to the Kaaba, a pagan temple at that time, honoring Allah there as God the Creator.
The history of the word "Allāh" in English was probably influenced by the study of comparative religion in 19th century; for example, Thomas Carlyle (1840) sometimes used the term Allah but without any implication that Allah was anything different from God. Tor Andræ's biography of Muhammad (1934) however always used the term Allah though he "allows that this is 'a conception of God', seems to imply that it is different from the Jewish and Christian conceptions." By this time Christians were also becoming used to retaining the Hebrew term "Yahweh" untranslated (it was previously translated as 'the Lord').
Even when the term Allah (as a deity) is not broadly used in a language, expressions based on this term may be popular. For example, because of the centuries long Muslim presence in the Iberian Peninsula, the word ojalá (Arabic: إن شاء الله) today exist in the Spanish language, borrowed from Arabic. This phrase literally means "God willing" (in the sense of "I hope so").
Some western scholars have suggested that Muhammad used the term Allah in addressing both pagan Arabs and Jews or Christians in order to establish a common ground for the understanding of the name for God, a claim Gerhard Böwering says is doubtful. According to Böwering, in contrast with Pre-Islamic Arabian polytheism, God in Islam does not have associates and companions nor is there any kinship between God and jinn. Pre-Islamic pagan Arabs believed in a blind, powerful, inexorable and insensible fate over which man had no control. This was replaced with the Islamic notion of a powerful but provident and merciful God.
God, says the Qur'an, "loves those who do good," and two passages in the Qur'an express a mutual love between God and man, but the Judeo-Christian precept to "love God with all thy heart" is nowhere formulated in Islam. The emphasis is rather on God's inscrutable sovereignty, to which one must abandon oneself. In essence, the "surrender to Allah" (Islam) is the religion itself.
Unicode has a codepoint reserved for Allāh, ﷲ = U+FDF2.
This character according to the official Unicode specification can be decomposed to alif-lām-lām-heh ( U+0627 U+0644 U+0644 U+0647).
Arabic type fonts often have special ligatures for [A]llāh and ommit the initial alif.
The calligraphic variant of the word used as the Coat of arms of Iran is encoded in Unicode, in the Miscellaneous Symbols range, at codepoint U+262B (☫). The Coat of arms of Iran appears in the center of the flag of Iran. It can be understood as either a stylized design of the word Allah, as a representation of the globe, or as two crescents.
Abjad is an ancient numerical system in the Arabic-speaking world. In this system each of the 28 letters of the Arabic alphabet represent the units, tens and hundreds up to and including 1000. The numerical value of the letters of Allah (الله ) according to the traditional Arabic abjad system adds up to 66.


Antarctica is Earth's southernmost continent, overlying the South Pole. It is situated in the southern hemisphere, almost entirely south of the Antarctic Circle, and is surrounded by the Southern Ocean. At 14.4 million km² (5.4 million sq mi), it is the fifth-largest continent in area after Asia, Africa, North America, and South America. Some 98% of Antarctica is covered by ice, which averages at least 1.6 kilometres (1.0 mi) in thickness.
On average, Antarctica is the coldest, driest and windiest continent, and has the highest average elevation of all the continents. Since there is little precipitation, except at the coasts, the interior of the continent is technically the largest desert in the world. There are no permanent human residents and there is no evidence of any existing or pre-historic indigenous population. Only cold-adapted plants and animals survive there, including penguins, fur seals, mosses, lichen, and many types of algae.
The name Antarctica is a romanized version of the Greek compound word Αntarktiké (Aνταρκτική), meaning "Opposite of the Arctic". Although myths and speculation about a Terra Australis ("Southern Land") date back to antiquity, the first confirmed sighting of the continent is commonly accepted to have occurred in 1820 by the Russian expedition of Mikhail Lazarev and Fabian Gottlieb von Bellingshausen. However, the continent remained largely neglected for the rest of the 19th century because of its hostile environment, lack of resources, and isolation.
The Antarctic Treaty was signed in 1959 by twelve countries; to date, forty-five countries have signed the treaty. The treaty prohibits military activities and mineral mining, supports scientific research, and protects the continent's ecozone. Ongoing experiments are conducted by more than 4,000 scientists of many nationalities and with different research interests.
European maps continued to show this hypothetical land until Captain James Cook's ships, HMS Resolution and Adventure, crossed the Antarctic Circle on January 17, 1773, in December 1773 and again in January 1774. Cook in fact came within about 75 miles of the Antarctic coast before retreating in the face of field ice in January 1773. The first confirmed sighting of Antarctica can be narrowed down to the crews of ships captained by three individuals. According to various organizations (the National Science Foundation, NASA, the University of California, San Diego, and other sources), ships captained by three men sighted Antarctica in 1820: Fabian Gottlieb von Bellingshausen (a captain in the Russian Imperial Navy), Edward Bransfield (a captain in the British Navy), and Nathaniel Palmer (an American sealer out of Stonington, Connecticut). Von Bellingshausen saw Antarctica on January 27, 1820, three days before Bransfield sighted land, and ten months before Palmer did so in November 1820. On that day the two-ship expedition led by Von Bellingshausen and Mikhail Petrovich Lazarev reached a point within 32 kilometers (20 mi) of the Antarctic mainland and saw ice fields there. The first documented landing on mainland Antarctica was by the American sealer John Davis in Western Antarctica on February 7, 1821, although some historians dispute this claim.
In December 1839, as part of the United States Exploring Expedition of 1838–42 conducted by the United States Navy (sometimes called the "Ex. Ex.", or "the Wilkes Expedition"), an expedition sailed from Sydney, Australia, into the Antarctic Ocean, as it was then known, and reported the discovery "of an Antarctic continent west of the Balleny Islands". That part of Antarctica was later named "Wilkes Land", a name it maintains to this day.
In 1841, explorer James Clark Ross passed through what is now known as the Ross Sea and discovered Ross Island (both of which were named for him). He sailed along a huge wall of ice that was later named the Ross Ice Shelf (also named for him). Mount Erebus and Mount Terror are named after two ships from his expedition: HMS Erebus and Terror. Mercator Cooper landed in Eastern Antarctica on January 26, 1853.
During an expedition led by Ernest Shackleton in 1907, parties led by T. W. Edgeworth David became the first to climb Mount Erebus and to reach the South Magnetic Pole. Douglas Mawson, who assumed the leadership of the Magnetic Pole party on their perilous return, went on to lead several expeditions until retiring in 1931. In addition, Shackleton himself and three other members of his expedition made several firsts in December 1908 – February 1909: they were the first humans to traverse the Ross Ice Shelf, the first to traverse the Transantarctic Mountain Range (via the Beardmore Glacier), and the first to set foot on the South Polar Plateau. On December 14, 1911, an expedition led by Norwegian polar explorer Roald Amundsen from the ship Fram became the first to reach the geographic South Pole, using a route from the Bay of Whales and up the Axel Heiberg Glacier. One month later, the ill-fated Scott Expedition reached the pole.
Richard Evelyn Byrd led several voyages to the Antarctic by plane in the 1930s and 1940s. He is credited with implementing mechanized land transport on the continent and conducting extensive geological and biological research. However, it was not until October 31, 1956 that anyone set foot on the South Pole again; on that day a U.S. Navy group led by Rear Admiral George J. Dufek successfully landed an aircraft there.
Antarctica is divided in two by the Transantarctic Mountains close to the neck between the Ross Sea and the Weddell Sea. The portion west of the Weddell Sea and east of the Ross Sea is called Western Antarctica and the remainder Eastern Antarctica, because they roughly correspond to the Western and Eastern Hemispheres relative to the Greenwich meridian.
About 98% of Antarctica is covered by the Antarctic ice sheet, a sheet of ice averaging at least 1.6 kilometers (1.0 mi) thick. The continent has about 90% of the world's ice (and thereby about 70% of the world's fresh water). If all of this ice were melted, sea levels would rise about 60 meters (200 ft). In most of the interior of the continent precipitation is very low, down to 20 mm per year; in a few "blue ice" areas precipitation is lower than mass loss by sublimation and so the local mass balance is negative. In the dry valleys the same effect occurs over a rock base, leading to a desiccated landscape.
Western Antarctica is covered by the West Antarctic Ice Sheet. The sheet has been of recent concern because of the real, if small, possibility of its collapse. If the sheet were to break down, ocean levels would rise by several meters in a relatively geologically short period of time, perhaps a matter of centuries. Several Antarctic ice streams, which account for about 10% of the ice sheet, flow to one of the many Antarctic ice shelves.
Vinson Massif, the highest peak in Antarctica at 4,892 meters (16,050 ft), is located in the Ellsworth Mountains. Although Antarctica is home to many volcanoes, only Mount Erebus is known to be active. Located on Ross Island, Erebus is the southernmost active volcano. There is another famous volcano called Deception Island, which is famous for its giant eruption in 1970. Minor eruptions are frequent and lava flow has been observed in recent years. Other dormant volcanoes may potentially be active. In 2004, an underwater volcano was found in the Antarctic Peninsula by American and Canadian researchers. Recent evidence shows this unnamed volcano may be active.
Antarctica is home to more than 70 lakes that lie thousands of meters under the surface of the continental ice sheet. Lake Vostok, discovered beneath Russia's Vostok Station in 1996, is the largest of these subglacial lakes. It is believed that the lake has been sealed off for 500,000 to one million years. There is some evidence, in the form of ice cores drilled to about 400 m above the water line, that Vostok's waters may contain microbial life. The sealed, frozen surface of the lake shares similarities with Jupiter's moon Europa. If life is discovered in Lake Vostok, this would strengthen the argument for the possibility of life on Europa. On February 7, 2008, a NASA team embarked on a mission to Lake Untersee, searching for extremophiles in its highly-alkaline waters. If found, these resilient creatures could further bolster the argument for extraterrestrial life in extremely cold, methane-rich environments.
More than 170 million years ago, Antarctica was part of the supercontinent Gondwana. Over time, Gondwana gradually broke apart and Antarctica as we know it today was formed around 25 million years ago.
During the Cambrian period, Gondwana had a mild climate. West Antarctica was partially in the northern hemisphere, and during this period large amounts of sandstones, limestones and shales were deposited. East Antarctica was at the equator, where sea floor invertebrates and trilobites flourished in the tropical seas. By the start of the Devonian period (416 mya), Gondwana was in more southern latitudes and the climate was cooler, though fossils of land plants are known from this time. Sand and silts were laid down in what is now the Ellsworth, Horlick and Pensacola Mountains. Glaciation began at the end of the Devonian period (360 mya), as Gondwana became centered around the South Pole and the climate cooled, though flora remained. During the Permian period, the plant life became dominated by fern-like plants such as Glossopteris, which grew in swamps. Over time these swamps became deposits of coal in the Transantarctic Mountains. Towards the end of the Permian period, continued warming led to a dry, hot climate over much of Gondwana.
As a result of continued warming, the polar ice caps melted and much of Gondwana became a desert. In East Antarctica, the seed fern became established, and large amounts of sandstone and shale were laid down at this time. The Antarctic Peninsula began to form during the Jurassic period (206–146 mya), and islands gradually rose out of the ocean. Ginkgo trees and cycads were plentiful during this period, as were reptiles such as Lystrosaurus. In West Antarctica, coniferous forests dominated through the entire Cretaceous period (146–65 mya), though Southern beech began to take over at the end of this period. Ammonites were common in the seas around Antarctica, and dinosaurs were also present, though only two Antarctic dinosaur species (Cryolophosaurus, from the Hanson Formation, and Antarctopelta) have been described to date. It was during this period that Gondwana began to break up.
The cooling of Antarctica occurred stepwise by the continental spread changing the oceanic currents from longitudinal equator-to-pole temperature-equalizing currents to latitudinal currents that preserved and accentuated latitude temperature differences.
so that latitudinal current could isolate Antarctica from Australia, and so the first ice began to appear. Around 23 mya, the Drake Passage opened between Antarctica and South America, which resulted in the Antarctic Circumpolar Current. The ice spread, replacing the forests that then covered the continent. Since about 15 mya, the continent has been mostly covered with ice, with the Antarctic ice cap reaching its present extension around 6 mya.
The geological study of Antarctica has been greatly hindered by the fact that nearly all of the continent is permanently covered with a thick layer of ice. However, new techniques such as remote sensing, ground-penetrating radar and satellite imagery have begun to reveal the structures beneath the ice.
Geologically, West Antarctica closely resembles the Andes mountain range of South America. The Antarctic Peninsula was formed by uplift and metamorphism of sea bed sediments during the late Paleozoic and the early Mesozoic eras. This sediment uplift was accompanied by igneous intrusions and volcanism. The most common rocks in West Antarctica are andesite and rhyolite volcanics formed during the Jurassic period. There is also evidence of volcanic activity, even after the ice sheet had formed, in Marie Byrd Land and Alexander Island. The only anomalous area of West Antarctica is the Ellsworth Mountains region, where the stratigraphy is more similar to the eastern part of the continent.
East Antarctica is geologically very varied, dating from the Precambrian era, with some rocks formed more than 3 billion years ago. It is composed of a metamorphic and igneous platform which is the basis of the continental shield. On top of this base are various modern rocks, such as sandstones, limestones, coal and shales laid down during the Devonian and Jurassic periods to form the Transantarctic Mountains. In coastal areas such as Shackleton Range and Victoria Land some faulting has occurred.
The main mineral resource known on the continent is coal. It was first recorded near the Beardmore Glacier by Frank Wild on the Nimrod Expedition, and now low-grade coal is known across many parts of the Transantarctic Mountains. The Prince Charles Mountains contain significant deposits of iron ore. The most valuable resources of Antarctica lie offshore, namely the oil and natural gas fields found in the Ross Sea in 1973. Exploitation of all mineral resources is banned until 2048 by the Protocol on Environmental Protection to the Antarctic Treaty.
Antarctica is the coldest place on Earth. At the 3-kilometer (2 mi)-high Vostok Station in Antarctica, scientists recorded the world's lowest temperature:. Antarctica is a frozen desert with little precipitation; the South Pole itself receives less than 10 centimeters (4 in) per year, on average. Temperatures reach a minimum of between and and in the interior in winter and reach a maximum of between and and near the coast in summer. Sunburn is often a health issue as the snow surface reflects almost all of the ultraviolet light falling on it. Eastern Antarctica is colder than its western counterpart because of its higher elevation. Weather fronts rarely penetrate far into the continent, leaving the center cold and dry. Despite the lack of precipitation over the central portion of the continent, ice there lasts for extended time periods. Heavy snowfalls are not uncommon on the coastal portion of the continent, where snowfalls of up to 1.22 meters (48 in) in 48 hours have been recorded. At the edge of the continent, strong katabatic winds off the polar plateau often blow at storm force. In the interior, however, wind speeds are typically moderate. During summer, more solar radiation reaches the surface during clear days at the South Pole than at the equator because of the 24 hours of sunlight each day at the Pole.
Antarctica is colder than the Arctic for two reasons. First, much of the continent is more than 3 kilometers (2 mi) above sea level, and temperature decreases with elevation. Second, the Arctic Ocean covers the north polar zone: the ocean's relative warmth is transferred through the icepack and prevents temperatures in the Arctic regions from reaching the extremes typical of the land surface of Antarctica.
Given the latitude, long periods of constant darkness or constant sunlight create climates unfamiliar to human beings in much of the rest of the world. The aurora australis, commonly known as the southern lights, is a glow observed in the night sky near the South Pole. Another unique spectacle is diamond dust, a ground-level cloud composed of tiny ice crystals. It generally forms under otherwise clear or nearly clear skies, so people sometimes also refer to it as clear-sky precipitation. A sun dog, a frequent atmospheric optical phenomenon, is a bright "spot" beside the true sun.
Antarctica has no permanent residents, but a number of governments maintain permanent research stations throughout the continent. The number of people conducting and supporting scientific research and other work on the continent and its nearby islands varies from about 4,000 in summer to about 1,000 in winter. Many of the stations are staffed year-round.
The first semi-permanent inhabitants of regions near Antarctica (areas situated south of the Antarctic Convergence) were British and American sealers who used to spend a year or more on South Georgia, from 1786 onward. During the whaling era, which lasted until 1966, the population of that island varied from over 1,000 in the summer (over 2,000 in some years) to some 200 in the winter. Most of the whalers were Norwegian, with an increasing proportion of Britons. The settlements included Grytviken, Leith Harbour, King Edward Point, Stromness, Husvik, Prince Olav Harbour, Ocean Harbour and Godthul. Managers and other senior officers of the whaling stations often lived together with their families. Among them was the founder of Grytviken, Captain Carl Anton Larsen, a prominent Norwegian whaler and explorer who, along with his family, adopted British citizenship in 1910.
The first child born in the southern polar region was Norwegian girl Solveig Gunbjörg Jacobsen, born in Grytviken on 8 October 1913, and her birth was registered by the resident British Magistrate of South Georgia. She was a daughter of Fridthjof Jacobsen, the assistant manager of the whaling station, and of Klara Olette Jacobsen. Jacobsen arrived on the island in 1904 to become the manager of Grytviken, serving from 1914 to 1921; two of his children were born on the island.
Emilio Marcos Palma was the first person born on the Antarctic mainland, at Base Esperanza in 1978; his parents were sent there along with seven other families by the Argentinean government to determine if family life was suitable on the continent. In 1984, Juan Pablo Camacho was born at the Frei Montalva Station, becoming the first Chilean born in Antarctica. Several bases are now home to families with children attending schools at the station.
The climate of Antarctica does not allow extensive vegetation. A combination of freezing temperatures, poor soil quality, lack of moisture, and lack of sunlight inhibit the flourishing of plants. As a result, plant life is limited to mostly mosses and liverworts. The autotrophic community is made up of mostly protists. The flora of the continent largely consists of lichens, bryophytes, algae, and fungi. Growth generally occurs in the summer, and only for a few weeks at most.
There are more than 200 species of lichens and about 50 species of bryophytes, such as mosses. Seven hundred species of algae exist, most of which are phytoplankton. Multicolored snow algae and diatoms are especially abundant in the coastal regions during the summer. There are two species of flowering plants found in the Antarctic Peninsula: Deschampsia antarctica (Antarctic hair grass) and Colobanthus quitensis (Antarctic pearlwort).
Land fauna is nearly completely invertebrate. Invertebrate life includes microscopic mites, lice, nematodes, tardigrades, rotifers, krill and springtails. The flightless midge Belgica antarctica, just 12 mm in size, is the largest purely terrestrial animal in Antarctica. The Snow Petrel is one of only three birds that breed exclusively in Antarctica. They have been seen at the South Pole.
Due to the extreme cold, the body fluids of tiny mites and midges in Antarctica contain glycerol, an antifreeze liquid that protects them from solidifying when temperatures plummet to as low as.
A variety of marine animals exist and rely, directly or indirectly, on the phytoplankton. Antarctic sea life includes penguins, blue whales, orcas and fur seals. The Emperor penguin is the only penguin that breeds during the winter in Antarctica, while the Adélie Penguin breeds farther south than any other penguin. The Rockhopper penguin has distinctive feathers around the eyes, giving the appearance of elaborate eyelashes. King penguins, Chinstrap penguins, and Gentoo Penguins also breed in the Antarctic.
The Antarctic fur seal was very heavily hunted in the 18th and 19th centuries for its pelt by sealers from the United States and the United Kingdom. The Weddell Seal, a "true seal", is named after Sir James Weddell, commander of British sealing expeditions in the Weddell Sea. Antarctic krill, which congregates in large schools, is the keystone species of the ecosystem of the Southern Ocean, and is an important food organism for whales, seals, leopard seals, fur seals, squid, icefish, penguins, albatrosses and many other birds.
The passing of the Antarctic Conservation Act in the U.S. brought several restrictions to U.S. activity on the continent. The introduction of alien plants or animals can bring a criminal penalty, as can the extraction of any indigenous species. The overfishing of krill, which plays a large role in the Antarctic ecosystem, led officials to enact regulations on fishing. The Convention for the Conservation of Antarctic Marine Living Resources (CCAMLR), a treaty that came into force in 1980, requires that regulations managing all Southern Ocean fisheries consider potential effects on the entire Antarctic ecosystem. Despite these new acts, unregulated and illegal fishing, particularly of Patagonian toothfish (marketed as Chilean Sea Bass in the U.S.), remains a serious problem. The illegal fishing of toothfish has been increasing, with estimates of 32,000 tonnes (35,300 short tons) in 2000.
Antarctica has no government and belongs to no country. Various countries claim areas of it, but while some have mutually recognized each other's claims, no other countries recognize such claims. The area between 90° W and 150° W is the only part of Antarctica not claimed by any country as of yet.
Since 1959, new claims on Antarctica have been suspended and the continent is considered politically neutral. Its status is regulated by the 1959 Antarctic Treaty and other related agreements, collectively called the Antarctic Treaty System. For the purposes of the Treaty System, Antarctica is defined as all land and ice shelves south of 60° S. The treaty was signed by twelve countries, including the Soviet Union (and later Russia), the United Kingdom, Argentina, and the United States. It set aside Antarctica as a scientific preserve, established freedom of scientific investigation, environmental protection, and banned military activity on that continent. This was the first arms control agreement established during the Cold War.
In 1983, the Antarctic Treaty Parties began negotiations on a convention to regulate mining in Antarctica. A coalition of international organisations launched a public pressure campaign to prevent any minerals development in the region, led largely by Greenpeace International which established its own scientific station – World Park Base - in the Ross Sea region and conducted annual expeditions to document environmental impacts from human activities on the continent. In 1988, the Convention on the Regulation of Antarctic Mineral Resources (CRAMRA) was adopted. The following year, however, Australia and France announced that they would not ratify the convention, rendering it dead for all intents and purposes. Instead, they proposed that a comprehensive regime to protect the Antarctic environment be negotiated in its place. As other countries followed suit, the Protocol on Environmental Protection to the Antarctic Treaty (the ‘Madrid Protocol’) was negotiated and on January 14, 1998 it entered into force. The Madrid Protocol bans all mining activities in Antarctica, designating the continent as a ‘natural reserve devoted to peace and science’.
The Antarctic Treaty prohibits any military activity in Antarctica, such as the establishment of military bases and fortifications, the carrying out of military manoeuvers, or the testing of any type of weapon. Military personnel or equipment are permitted only for scientific research or for other peaceful purposes. The only documented land military manoeuvre was Operation NINETY, undertaken by the Argentine military.
The United States military issues the Antarctica Service Medal to military members or civilians who perform research duty in Antarctica. The medal includes a "wintered over" bar issued to those who remain on the continent for two complete six-month seasons.
The Argentine, British and Chilean claims all overlap, although only the British claim is recognised. Australia has the greatest claim of Antarctic territory.
Germany also maintained a claim to Antarctica, known as New Swabia, between 1939 and 1945. It was situated from to, overlapping Norway's claim. The claim was abandoned after the fall of Nazi Germany in 1945.
Although coal, hydrocarbons, iron ore, platinum, copper, chromium, nickel, gold and other minerals have been found, they have not been in large enough quantities to exploit. The 1991 Protocol on Environmental Protection to the Antarctic Treaty also restricts a struggle for resources. In 1998, a compromise agreement was reached to place an indefinite ban on mining, to be reviewed in 2048, further limiting economic development and exploitation. The primary agricultural activity is the capture and offshore trading of fish. Antarctic fisheries in 2000–01 reported landing 112,934 tonnes.
Small-scale "expedition tourism" has existed since 1957 and is currently subject to Antarctic Treaty and Environmental Protocol provisions, but in effect self-regulated by the International Association of Antarctica Tour Operators (IAATO). Not all vessels associated with Antarctic tourism are members of IAATO, but IAATO members account for 95% of the tourist activity. Travel is largely by small or medium ship, focusing on specific scenic locations with accessible concentrations of iconic wildlife. A total of 37,506 tourists visited during the 2006–07 Austral summer with nearly all of them coming from commercial ships. The number is predicted to increase to over 80,000 by 2010. There has been some recent concern over the potential adverse environmental and ecosystem effects caused by the influx of visitors. A call for stricter regulations for ships and a tourism quota have been made by some environmentalists and scientists. The primary response by Antarctic Treaty Parties has been to develop, through their Committee for Environmental Protection and in partnership with IAATO, "site use guidelines" setting landing limits and closed or restricted zones on the more frequently visited sites. Antarctic sight seeing flights (which did not land) operated out of Australia and New Zealand until the fatal crash of Air New Zealand Flight 901 in 1979 on Mount Erebus, which killed all 257 aboard. Qantas resumed commercial overflights to Antarctica from Australia in the mid-1990s.
Transport on the continent has transformed from explorers crossing the isolated remote area of Antarctica on foot to a more open area due to human technologies enabling more convenient and faster transport by land and predominantly air and water. Recently, using dogs to pull researchers and sledges have been banned. Because they are aliens to Antarctica, there have been objections. Now being used are new electric buggies, but these have a down side. The dogs were excellent for sensing crevices and thin ice, but these new buggies cannot.
Each year, scientists from 27 different nations conduct experiments not reproducible in any other place in the world. In the summer more than 4,000 scientists operate research stations; this number decreases to nearly 1,000 in the winter. McMurdo Station is capable of housing more than 1,000 scientists, visitors, and tourists.
Researchers include biologists, geologists, oceanographers, physicists, astronomers, glaciologists, and meteorologists. Geologists tend to study plate tectonics, meteorites from outer space, and resources from the breakup of the supercontinent Gondwanaland. Glaciologists in Antarctica are concerned with the study of the history and dynamics of floating ice, seasonal snow, glaciers, and ice sheets. Biologists, in addition to examining the wildlife, are interested in how harsh temperatures and the presence of people affect adaptation and survival strategies in a wide variety of organisms. Medical physicians have made discoveries concerning the spreading of viruses and the body's response to extreme seasonal temperatures. Astrophysicists at Amundsen-Scott South Pole Station study the celestial dome and cosmic microwave background radiation. Many astronomical observations are better made from the interior of Antarctica than from most surface locations because of the high elevation, which results in a thin atmosphere, and low temperature, which minimizes the amount of water vapour in the atmosphere, thus allowing for a view of space clearer than anywhere else on Earth. Antarctic ice serves as both the shield and the detection medium for the largest neutrino telescope in the world, built 2 kilometers below Amundsen-Scott station.
Since the 1970s, an important focus of study has been the ozone layer in the atmosphere above Antarctica. In 1985, three British Scientists working on data they had gathered at Halley Station on the Brunt Ice Shelf discovered the existence of a hole in this layer. In 1998, NASA satellite data showed that the Antarctic ozone hole was the largest on record, covering 27 million km² (10 million sq mi). It was eventually determined that the destruction of the ozone was caused by chlorofluorocarbons emitted by human products. With the ban of CFCs in the Montreal Protocol of 1989, it is believed that the ozone hole will close up over the next fifty years.
On September 6, 2007, Belgian-based International Polar Foundation unveiled the Princess Elisabeth station, the world's first zero-emissions polar science station in Antarctica to research climate change. Costing $16.3 million, the prefabricated station, which is part of International Polar Year will be shipped to the South Pole from Belgium by the end of 2008 to monitor the health of the polar regions. Belgian polar explorer Alain Hubert has stated: "This base will be the first of its kind to produce zero emissions, making it a unique model of how energy should be used in the Antarctic." Johan Berte is the leader of the station design team and manager of the project which will conduct research in climatology, glaciology and microbiology.
Meteorites from Antarctica are an important area of study of material formed early in the solar system; most are thought to come from asteroids, but some may have originated on larger planets. The first meteorites were found in 1912. In 1969, a Japanese expedition discovered nine meteorites. Most of these meteorites have fallen onto the ice sheet in the last million years. Motion of the ice sheet tends to concentrate the meteorites at blocking locations such as mountain ranges, with wind erosion bringing them to the surface after centuries beneath accumulated snowfall. Compared with meteorites collected in more temperate regions on Earth, the Antarctic meteorites are well-preserved.
This large collection of meteorites allows a better understanding of the abundance of meteorite types in the solar system and how meteorites relate to asteroids and comets. New types of meteorites and rare meteorites have been found. Among these are pieces blasted off the Moon, and probably Mars, by impacts. These specimens, particularly ALH84001 discovered by ANSMET, are at the center of the controversy about possible evidence of microbial life on Mars. Because meteorites in space absorb and record cosmic radiation, the time elapsed since the meteorite hit the Earth can be determined from laboratory studies. The elapsed time since fall, or terrestrial residence age, of a meteorite represents more information that might be useful in environmental studies of Antarctic ice sheets.
In 2006, a team of researchers from Ohio State University used gravity measurements by NASA's GRACE satellites to discover the 300 mi-wide Wilkes Land crater, which probably formed about 250 million years ago.
On January, 2008, the British Antarctic Survey (Bas) scientists led by Hugh Corr and David Vaughan, reported (in the journal Nature Geoscience) that 2,200 years ago, a volcano erupted under Antarctica ice sheet (based on airborne survey with radar images). The biggest eruption in the last 10,000 years, the volcanic ash was found deposited on the ice surface under the Hudson Mountains, close to Pine Island Glacier.
Most of the continent's icy mass has so far proven largely impervious to climate change, being situated on solid rock; its deep interior is actually growing in volume. However, Antarctica's periphery has been noticeably affected by global warming, particularly on the Antarctic Peninsula and in Pine Island Bay which together are contributing to a rise in sea levels. In 2003 the Larsen-B ice shelf collapsed owing to global warming. According to NASA, the most significant Antarctic melting in the past 30 years occurred in 2005, when a mass of ice comparable in size to California briefly melted and refroze; this may have resulted from temperatures rising to as high as.
Also, although having no obvious effect on the continent's environment, there is a large ozone hole over Antarctica which was detected by scientists in 1973 and continues to grow to this day. The main cause is the emission of chlorofluorocarbons or CFCs into the atmosphere, which decompose the ozone into other gasses. For more on the ozone hole, see Ozone depletion.


Argentina is a South American country, constituted as a federation of twenty-four provinces and an autonomous city. It is second in size on the continent to Brazil and eighth in the world. Argentina occupies a continental surface area of between the Andes mountain range in the west and the southern Atlantic Ocean in the east and south.
It is bordered by Paraguay and Bolivia in the north, Brazil and Uruguay in the northeast, and Chile in the west and south. The country claims the British controlled territories of the Falkland Islands () and South Georgia and the South Sandwich Islands. Argentina also claims of Antarctica, known as Argentine Antarctica, overlapping other claims made by Chile and the United Kingdom.
Argentina has the highest Human Development Index level and Gross Domestic Product (GDP) per capita in purchasing power parity in Latin America. The country is currently classified as an Upper-Middle Income Country or as a secondary emerging market by the World Bank. Argentina's nominal GDP makes it the 31st largest economy in the world.
The first Spanish conquistadors discovered the Río de la Plata, and they named the estuary Mar Dulce ('Sweet Sea', as in a fresh water sea). Indigenous people gave gifts of silver to the survivors of the shipwrecked expedition, who were led by Juan Díaz de Solís. The legend of Sierra del Plata – a mountain rich in silver – reached Spain around 1524, and the name was first seen in print on a Venice map from 1536. The source of the silver was the area where the city of Potosí was to be founded in 1546. An expedition that followed the trail of the silver up the Paraná and Pilcomayo rivers finally reached the source only to find it already owned by explorers who reached it from Lima, the capital of the Viceroyalty of Peru.
The name Argentina (from Latin argentum: silver) was first used extensively in the 1612 book Historia del descubrimiento, población, y conquista del Río de la Plata (History of the discovery, population, and conquest of the Río de la Plata) by Ruy Díaz de Guzmán, naming the territory Tierra Argentina (Land of Silver). Traditionally, the British English name for the country is "The Argentine", but this is no longer in common use.
The first signs of human presence in Argentina are located in the Patagonia (Piedra Museo, Santa Cruz), and date from 11,000 BC. Around 1 AD, several maize-based civilizations developed in the Andean region (Santa María, Huarpes, Diaguitas, Sanavirones, among others). In 1480, the Inca Empire under the rule of emperor Pachacutec launched an offensive and conquered present-day northwestern Argentina, integrating it into a region called Collasuyu. In the northeastern area, the Guaraní developed a culture based on yuca and sweet potato. The central and southern areas (Pampas and Patagonia) were dominated by nomadic cultures, unified in the seventeenth century by the Mapuches.
European explorers arrived in 1516. Spain established a permanent colony on the site of Buenos Aires in 1580; the Viceroyalty of the Río de la Plata was created in 1776. During the early part of this period it was largely a country of Spanish immigrants and their descendants, known as creoles, some of them gathered in Buenos Aires and other cities, others living on the pampas as gauchos. Descendants of African slaves (See:Afro-Argentines) were present in significant numbers. Indigenous peoples inhabited much of the rest of Argentina. In 1806 and 1807 the British Empire launched two invasions to Buenos Aires, but the creole population repelled both attempts. On May 25, 1810, after confirmation of the rumors about the overthrow of King Ferdinand VII by Napoleon, citizens of Buenos Aires took advantage of the situation and created the First Government Junta (May Revolution). Formal independence from Spain was declared on July 9, 1816 in Tucumán.
In 1818, General José de San Martín crossed the Andes to free Chile and Peru, thus eliminating the Spanish threat. Centralist and federalist groups (Spanish: Unitarios and Federales) were in conflict until national unity was established and the constitution promulgated in 1853. The constitution was strongly defended in moving oratory by the patriot and Franciscan Mamerto Esquiú, for whom one of the country's departments is named. From 1865 to 1870, the bloody War of Triple Alliance was fought by Argentina, Brazil, and Uruguay against Paraguay.
Foreign investment and immigration from Europe led to the adoption of modern agricultural techniques. In the 1870s, the "Conquest of the Desert" subdued the remaining indigenous tribes throughout the southern Pampas and Patagonia, leaving 1,300 indigenous dead.
From 1880 to 1916, Argentina enjoyed increasing prosperity, prominence and became one of the top 10 richest countries in the world, through an agricultural export-led economy. The population of the country swelled sevenfold. Conservative forces dominated Argentine politics through non-democratic means until 1916, when their traditional rivals, the Radicals, won control of the first free-elected government. The military forced Hipólito Yrigoyen from power in 1930, leading to another decade of Conservative rule. Political change led to the presidency of Juan Perón in 1946, who tried to empower the working class and greatly expanded the number of unionized workers. The economy turned to more protectionist policies and the developing of industry. The self-proclamated Revolución Libertadora of 1955 deposed him.
From the 1950s to 1970s, soft military and weak civilian administrations traded power. During those years the economy grew strongly and poverty declined (to less than 7% in 1975). At the same time political violence continued to escalate, fighting against the military government, demanding the return of Perón from his Spanish exile.
In 1973, Perón returned to the presidency, but he died within a year of assuming power. His third wife Isabel, the Vice President, succeeded him in office, but the military coup of March 24, 1976 removed her from office.
The armed forces took power through a junta in charge of the self-appointed National Reorganization Process until 1983. The military government repressed opposition and leftist groups using harsh illegal measures (the "Dirty War"); thousands of dissidents "disappeared", while the SIDE cooperated with DINA and other South American intelligence agencies, and with the CIA in Operation Condor. Many of the military leaders that took part in the Dirty War were trained in the U.S.-financed School of the Americas, among them Argentine dictators Leopoldo Galtieri and Roberto Viola. The military dictatorship (1976-1983) greatly increased the extent of the country's foreign debt. From that point the economy of the country began to be controlled more and more by the conditions imposed on it by both its creditors and the IMF (International Monetary Fund) with priority given to servicing the repayment of the foreign debt. These and other economic problems, charges of corruption, public revulsion in the face of human rights abuses and, finally, the country's 1982 defeat by the British in the Falklands War discredited the Argentine military regime.
Democracy was restored in 1983. Raúl Alfonsín's government took steps to account for the "disappeared", established civilian control of the armed forces, and consolidated democratic institutions. The members of the three military juntas were prosecuted and sentenced to life terms. Failure to resolve endemic economic problems and an inability to maintain public confidence led to Alfonsín's early departure six months before his term was to be completed.
The 1990s began with hyperinflation. President Carlos Menem imposed a peso-dollar fixed exchange rate in 1991 to stop hyperinflation and adopted far-reaching market-based policies, dismantling protectionist barriers and business regulations, and implementing a privatization program. These reforms contributed to significant increases in investment and growth with stable prices through most of the 1990s. However, the peso was tied to the dollar at an artificially high rate that could only be maintained by flooding the market with dollars. As a result the foreign debt increased enormously and state companies and services were privatized. The total opening up of the market to foreign goods, which up until then were produced locally, resulted in the collapse of local industry. So while part of the population was saving in dollars, traveling overseas, and purchasing imported and luxury goods cheaply, the rest of the population was experiencing an increase in both poverty and unemployment. The IMF and the world economists praised the liberalization of the Argentine market, and the country was presented as a "model student". Toward the end of the 1990s, large fiscal deficits and overvaluation of the pegged peso caused a gradual slide into economic crisis. In 1998 a period of profound economic recession began. This was a direct result of the economic measures which dominated the decade of the 90s and which produced a false sense of stability and well being. By the end of his term in 1999, these accumulating problems and perceived corruption had made Menem unpopular.
The Menem and de la Rúa administrations faced diminished competitiveness in exports, massive imports which damaged national industry and reduced employment, chronic fiscal and trade deficits, and the contagion of several economic crises. Unemployment reached as high as 25% of the economically active population, and another 15% had only part-time work. The Asian financial crisis in 1998 precipitated an outflow of capital that mushroomed into a recession, and culminated in economic crisis in November 2001. The governing coalition was forced to undertake a series of measures including the freezing of bank accounts. This was done to halt the flow of capital out of the country and to stem the growing debt crisis. However, a climate of popular discontent was unleashed as a result. On 20 December 2001 Argentina was thrown into its worst institutional and economic crisis for several decades. There were violent street protests, which brought about clashes with the police and resulted in several fatalities. The increasingly chaotic climate, amidst bloody riots, finally resulted in the resignation of President de la Rúa. The economic crisis accentuated the people's lack of trust in their politicians. During this time street protests were accompanied by the cry "they all should go." The "they" referred to the politicians, especially those involved in many reported acts of corruption. They were also accused of dealing fraudulently with public goods and money, without any judicial sanctions in place to curb the corruption.
In two weeks, several presidents followed in quick succession, culminating in Eduardo Duhalde's being appointed interim President of Argentina by the Legislative Assembly on 2 January 2002. Argentina defaulted on its international debt obligations. The peso's near eleven year-old linkage to the United States dollar was abandoned, resulting in major depreciation of the peso and a spike in inflation.
With a more competitive and flexible exchange rate, the country implemented new policies based on re-industrialization, import substitution, increased exports, and consistent fiscal and trade surpluses. By the end of 2002 the economy began to stabilize, mainly thanks to the soybean and other cereals' boom and floating of exchange rates. In 2003, Néstor Kirchner was elected president. During Kirchner's presidency, Argentina restructured its defaulted debt with a steep discount (about 66 percent) on most bonds, paid off debts with the International Monetary Fund, renegotiated contracts with utilities, and nationalized some previously privatized enterprises. Currently, Argentina is enjoying a period of economic growth. In 2007 Cristina Fernández de Kirchner, was elected president, becoming the first woman to be elected president of Argentina. Also in 2007, Center-left Fabiana Ríos (ARI) became the first woman to be elected governor of Tierra del Fuego and first elected female governor in Argentina's history.
Argentina's political framework is a federal presidential representative democratic republic, in which the President of The Argentine Nation is both head of state and head of government, complemented by a pluriform multi-party system. The current president (2007) is Cristina Fernández de Kirchner, with Julio Cobos as vice president.
The Argentine Constitution of 1853 mandates a separation of powers into executive, legislative, and judicial branches at the national and provincial level.
Executive power resides in the President and his or her cabinet. The President of The Argentine Nation and Vice President are directly elected to four-year terms, limited to two consecutive terms, and the cabinet ministers are appointed by the president.
Legislative power is vested in the bicameral National Congress or Congreso de la Nación, consisting of a Senate (Senado) of seventy-two seats, and a Chamber of Deputies (Cámara de Diputados) of 257 members.
Senators serve six-year terms, with one-third standing for reelection every two years. Members of the Chamber of Deputies are directly elected to four-year term via a system of proportional representation, with half of the members of the lower house being elected every two years. A third of the candidates presented by the parties must be women.
The judiciary is independent of the executive and the legislature. The Argentine Supreme Court of Justice has seven members who are appointed by the President in consultation with the Senate. The rest of the judges are appointed by the Council of Magistrates of the Nation, a secretariat composed of representatives of judges, lawyers, the Congress, and the executive (see Law of Argentina).
Argentina is a member of an international bloc, Mercosur, which has some legislative supranational functions. Mercosur is composed of five full members: Argentina, Brazil, Paraguay, Uruguay, and Venezuela. It has five associate members without full voting rights: Bolivia, Chile, Colombia, Ecuador, and Peru.
Argentina was the only country from Latin America to participate in the 1991 Gulf War under mandate of the United Nations. It was also the only Latin American country involved in every phase of the Haiti operation. Argentina has contributed worldwide to peacekeeping operations, including in El Salvador-Honduras-Nicaragua, Guatemala, Ecuador-Peru, Western Sahara, Angola, Kuwait, Cyprus, Croatia, Kosovo, Bosnia and Timor Leste. In recognition of its contributions to international security, U.S. President Bill Clinton designated Argentina as a major non-NATO ally in January 1998. In 2005, it was elected as a temporary member of the UN Security Council.
In 1993, Argentina launched the United Nations White Helmets indicative of humanitarian aid.
On November 4-November 5 2005, the Argentine city of Mar del Plata hosted the Fourth Summit of the Americas. This summit was marked by a number of anti-U.S. protests. As of 2006, Argentina has been emphasizing Mercosur as its first international priority; by contrast, during the 1990s, it relied more heavily on its relationship with the United States.
Argentina has long claimed sovereignty over the Falkland Islands (Islas Malvinas), the South Shetland Islands, the South Sandwich Islands and almost 1 million km² in Antarctica, between the 25°W and the 74°W meridians and the 60°S parallel. For more than a century, there has been an Argentine presence at the Orcadas Base.
Argentina is a founding signatory and permanent consulting member of the Antarctic Treaty System and the Antarctic Treaty Secretariat is established in Buenos Aires.
Argentina's armed forces are controlled by the Defense Ministry, with the country's President as their Commander-in-Chief. Historically, Argentina's military has been one of the best equipped in the region (for example, developing its own advanced jet fighters as early as the 1950s), but has faced expenditure cutbacks in comparison to other regional militaries. The age of allowable military service is 18 years; there is no obligatory military service and currently no conscription.
The armed forces are composed of a traditional Army, Navy, and Air Force. Controlled by a separate ministry (the Interior Ministry), Argentine territorial waters are patrolled by the Naval Prefecture, and the border regions by the National Gendarmerie; both arms however maintain liaison with the Defense Ministry. Argentina's Armed Forces are currently undertaking major operations in Haiti and Cyprus, in accordance with UN mandates.
Though declared the capital in 1853, Buenos Aires didn't become the capital of the country until 1880. There have been moves to relocate the administrative centre elsewhere. During the presidency of Raúl Alfonsín, a law was passed ordering the transfer of the federal capital to Viedma, a city in the Patagonian province of Río Negro. Studies were underway when economic problems halted the project in 1989. Though the law was never formally repealed, it is now treated as a relic.
Provinces are divided into smaller secondary units called departamentos ("departments"), of which there are 376 in total. The province of Buenos Aires has 134 similar divisions known as partidos. Departamentos and partidos are further subdivided into municipalities or districts.
In descending order by number of inhabitants, the major cities in Argentina are Buenos Aires, Córdoba, Rosario, Mendoza, Tucumán, La Plata, Mar del Plata, Salta, Santa Fe, San Juan, Resistencia, and Neuquén.
Argentina is nearly 5,121 km (about 3,182 mi) long from north to south, and 1,400 km (about 870 mi) from east to west (maximum values). It can roughly be divided into four parts: the fertile plains of the Pampas in the center of the country, the source of Argentina's agricultural wealth; the flat to rolling, oil-rich plateau of Patagonia in the southern half down to Tierra del Fuego; the subtropical flats of the Gran Chaco in the north, and the rugged Andes mountain range along the western border with Chile.
The highest point above sea level in Argentina is located in Mendoza. Cerro Aconcagua, at 6,962 meters (22,834 feet), is the highest mountain in the Americas, the Southern, and Western Hemisphere. The lowest point is Laguna del Carbón in Santa Cruz, −105 meters (−344 ft) below sea level. This is also the lowest point on the South American continent. The geographic center of the country is located in south-central La Pampa province.
The country has a territorial claim over a portion of Antarctica (unrecognized by any other country), where, from 1904, it has maintained a constant presence.
Major rivers in Argentina include the Pilcomayo, Paraguay, Bermejo, Colorado, Río Negro, Salado, Uruguay and the largest river, the Paraná. The latter two flow together before meeting the Atlantic Ocean, forming the estuary of the Río de la Plata. Regionally important rivers are the Atuel and Mendoza in the homonymous province, the Chubut in Patagonia, the Río Grande in Jujuy, and the San Francisco River in Salta.
There are several large lakes in Argentina, many of them in Patagonia. Among these are lakes Argentino and Viedma in Santa Cruz, Nahuel Huapi in Río Negro and Fagnano in Tierra del Fuego, and Colhué Huapi and Musters in Chubut. Lake Buenos Aires and O'Higgins/San Martín Lake are shared with Chile. Mar Chiquita, Córdoba, is the largest salt water lake in the country. There are numerous reservoirs created by dams. Argentina features various hot springs, such as those at Termas de Río Hondo with temperatures between 30 °C and 65 °C.
Argentina has of coastline. The continental platform is unusually wide; in Argentina this shallow area of the Atlantic Ocean is called Mar Argentino. The waters are rich in fisheries and suspected of holding important hydrocarbon energy resources. Argentina's coastline varies between areas of sand dunes and cliffs. The two major ocean currents affecting the coast are the warm Brazil Current and the cold Falkland Current (Spanish: corriente antártica or corriente de las Malvinas). Because of the uneveness of the coastal landmass, the two currents alternate in their influence on climate and do not allow temperatures to fall evenly with higher latitude. The southern coast of Tierra del Fuego forms the north shore of the Drake Passage.
Because of longitudinal and elevation amplitudes, Argentina is subject to a variety of climates. As a rule, the climate is predominantly temperate with extremes ranging from subtropical in the north to subpolar in the far south. The north of the country is characterized by very hot, humid summers with mild drier winters, and is subject to periodic droughts. Central Argentina has hot summers with thunderstorms (in western Argentina producing some of the world's largest hail), and cool winters. The southern regions have warm summers and cold winters with heavy snowfall, especially in mountainous zones. Higher elevations at all latitudes experience cooler conditions.
The hottest and coldest temperature extremes recorded in South America have occurred in Argentina. A record high temperature of, was recorded at Villa de María, Córdoba on January 2 1920. The lowest temperature recorded was at Valle de los Patos Superior, San Juan, July 17 1972.
Major winds in Argentina include the cool Pampero blowing on the flat plains of Patagonia and the Pampas after a cold front; the Viento Norte, a warm wind that can blow from the north in mid and late winter creating mild conditions; and the Zonda, a hot and dry wind (see also Föhn wind), affecting west-central Argentina. Squeezed of all moisture during the 6,000 meter descent from the Andes, Zonda winds can blow for hours with gusts up to 120 km/h, fueling wildfires and causing damage. When the Zonda blows (June-November), snowstorms and blizzard (viento blanco) conditions usually affect the higher elevations.
The Sudestada (literally "southeastern") could be considered similar to the Noreaster, though snowfall is rarely involved (but is not unprecedented). Both are associated with a deep winter low pressure system. The sudestada usually moderates cold temperatures but brings very heavy rains, rough seas, and coastal flooding. It is most common in late autumn and winter along the coasts of central Argentina and in the Río de la Plata estuary.
The southern regions, particularly the far south, experience long periods of daylight from November to February (up to nineteen hours), and extended nights from May to August. All of Argentina uses UTC-3 time zone. The country does observe daylight saving time occasionally, the last summertime being started at 0:00 December 30, 2007 and being finished at 0:00 March 16, 2008.
Argentina's eastermost continental point is northeast of the town of Bernardo de Irigoyen, Misiones (), the westernmost in the Mariano Moreno Range in Santa Cruz (). The northernmost point is located at the confluence of the Grande de San Juan and Mojinete rivers, Jujuy (), and the southernmost is Cape San Pío in Tierra del Fuego ().
There is one Argentine exclave, the Martín García Island (co-ordinates ). It is near the confluence of the Paraná and Uruguay rivers, a kilometer (0.62 mi) inside Uruguayan waters, and 3.5 kilometres (2.1 mi) from the Uruguayan coastline near the small town of Martín Chico (itself halfway between Nueva Palmira and Colonia del Sacramento).
An agreement reached by Argentina and Uruguay in 1973 reaffirmed Argentine jurisdiction over the island, ending a century-old dispute. Under the terms of the agreement, Martín García is to be devoted exclusively as a natural preserve. Its area is about 2 square kilometres (500 acres), and its population is about 200 people.
Subtropical plants dominate the north, part of the Gran Chaco region of South America. The genus Dalbergia of trees is well disseminated with representatives like the Brazilian Rosewood and the quebracho tree; also predominant are white and black algarrobo trees (prosopis alba and prosopis nigra). Savannah-like areas exist in the drier regions nearer the Andes. Aquatic plants thrive in the wetlands dotting the region.
In central Argentina the humid pampas are a true tallgrass prairie ecosystem. The original pampa had virtually no trees; today along roads or in towns and country estates (estancias), some imported species like the American sycamore or eucalyptus are present. The only tree-like plant native to the pampa is the ombú, an evergreen. The surface soils of the pampa are a deep black color, primarily humus, known commonly as compost. It is this which makes the region one of the most agriculturaly productive on Earth. However, this is also responsible for decimating much of the original ecosystem, to make way for commercial agriculture. The western pampas receive less rainfall, this dry pampa is a plain of short grasses or steppe.
Most of Patagonia in the south lies within the rain shadow of the Andes. The flora, shrubby bushes and plants, is well suited to withstand dry conditions. The soil is hard and rocky, making large-scale farming impossible except along river valleys. Coniferous forests grow in far western Patagonia and on the island of Tierra del Fuego. Conifers native to the region include alerce (Fitzroya cupressoides), ciprés de la cordillera (Austrocedrus chilensis), ciprés de las guaitecas (Pilgerodendron uviferum), huililahuán (Podocarpus nubigenus), lleuque (Prumnopitys andina), mañío hembra (Saxegothaea conspicua), and pehuén (Araucaria araucana), while native broadleaf trees include several species of Nothofagus including coigüe or coihue, lenga (Nothofagus pumilio), ñire (Nothofagus Antarctica). Other introduced trees present in forestry plantations include spruce, cypress, and pine. Common plants are the copihue and colihue (Chusquea culeou).
In Cuyo, semiarid thorny bushes and other xerophile plants abound. Along the many river oasis, grasses and trees grow in significant numbers. The area presents optimal conditions for the large scale growth of grape vines. In the northwest of Argentina there are many species of cacti. In the highest elevations (often above 4,000mts), no vegetation grows because of the extreme altitude, and the soils are virtually devoid of any plant life.
The ceibo flower, of the tree Erythrina crista-galli, is the national flower of Argentina.
Many species live in the subtropical north. Big cats like the jaguar, cougar, and ocelot; primates (howler monkey); large reptiles (crocodiles), and a species of caiman. Other animals include the tapir, capybara, giant anteater, peccary, bush dog, raccoon, maned wolf, and various species of turtle and tortoise. There are many birds, notably hummingbirds, flamingos, toucans, and parrots.
The central grasslands are populated by the armadillo, pampas cat, mara and the rhea (ñandú), a flightless bird. Hawks, falcons, herons, partridges inhabit the region. There are also deer and foxes. Some of these species extend into Patagonia.
The western mountains are home to different animals. These include the llama, guanaco, vicuña, among the most recognizable species of South America. Also in this region are the fox, viscacha, Andean Mountain Cat, kodkod and the largest flying bird in the New World, the Andean Condor.
Southern Argentina is home to the cougar, huemul, pudú (the world's smallest deer), and introduced, non-native wild boar. The coast of Patagonia is rich in animal life: elephant seals, fur seals, sea lions, and species of penguin. The far south is populated by cormorant birds.
The territorial waters of Argentina have abundant ocean life; mammals such as dolphins, orcas, and whales like the southern right whale, a major tourist draw for naturalists. Sea fish include sardines, argentine hakes, dolphinfish, salmon, and sharks; also present are squid and spider crab (centolla) in Tierra del Fuego. Rivers and streams in Argentina have many species of trout and the South American dorado fish. Outstanding snake species inhabiting Argentina include boa constrictors, and the very venomous yarará pit viper and South American rattle snake.
The Hornero was elected the National Bird after a survey in 1928.
Argentina benefits from abundant natural resources, a highly literate population, an export-oriented agricultural sector, and a diversified industrial base, that was once one of the wealthiest nations with a large middle class but this segment of the population has suffered by a succession of economic crises. Argentina otherwise maintains a relatively high standard of living.
Argentina's economy started to slowly lose ground after 1945 when it went from a wealthy nation with a strong and prosperous economy to a deep recession in the mid 50s, losing its place in the position of prosperous industrialized nations. The economy further declined during the military dictatorship that lasted from 1976 to 1983.
During this period, the government borrowed large loans with high interest rates from the IMF and private banking institutions. The country engaged in a disorganized and corrupt rapid liberalization that marked the end of its industrial hegemony in Latin America. During the military dictatorship over 400,000 companies of all sizes went bankrupt. The economic decisions made from 1983 till 2001 failed to revert the situation. Finally, in 2001, after 3 years of recession, the economy broke down and reached its worst point in history.
Although significant progress has occurred since then, the result is that, today, while a significant segment of the population is still financially well-off, they stand in sharp contrast with the millions who have seen their purchasing power drastically reduced. Since 2002, there has been an improvement in the situation of the poorer sectors and a strong rebound of the middle class.
The urban poverty rate dropped to 26.9% by 2007, down from 48 percent observed in 2003, but is still above the level prior to the recession.
From the late 1970s the country piled up public debt and was plagued by bouts of high inflation. In 1991, the government pegged the peso to the U.S. dollar and limited the growth in the money supply. It then embarked on a path of trade liberalization, deregulation and privatization. Inflation dropped and gross domestic product grew, but external economic shocks and failures of the system diluted benefits, causing the economy to crumble slowly from 1995 until the collapse in 2001.
By 2002, Argentina had defaulted on its debt, its GDP had shrunk, unemployment was more than 25%, and the peso had depreciated 75% after being devalued and floated. However, careful spending control and heavy taxes on then-soaring exports allowed the state to regain resources and conduct monetary policy.
In 2003, import substitution policies and soaring exports, coupled with lower inflation and expansive economic measures, triggered a surge in the GDP. This was repeated in 2004 and 2005, creating millions of jobs and encouraging internal consumption. Capital flight decreased, and foreign investment slowly returned. An influx of foreign currency from exports created a huge trade surplus. The Central Bank was forced to buy dollars from the market, and continues to do so from time to time to prevent the Argentine peso from appreciating significantly and cutting competitiveness.
The situation by 2006 was further improved. The economy grew 8.8% in 2003, 9.0% in 2004, 9.2% in 2005, 8.5% in 2006, and 8.7% in 2007, though inflation, estimated at around 12 to 15% (official numbers are 9.8% for 2006), has become an issue again, and income distribution is still considerably unequal.
In 2007, agricultural output accounted for 10% of GDP, and nearly one third of all exports. Soy and vegetable oils are major export commodities at 32% of exports. Wheat, maize, oats, sorghum, and sunflower seeds totalled 7%. Cattle is also a major industry. Beef, milk, leather products, and cheese were 6% of total exports. Sheep and wool industries are important in Patagonia, pigs and caprines elsewhere.
Fruits and vegetables made up 4% of exports: apples and pears in the Río Negro valley; oranges and other citrus in the northwest and Mesopotamia; grapes and strawberries in Cuyo, and berries in the far south. Cotton and yerba mate are major crops in the Gran Chaco, sugarcane and tobacco in the northwest, and olives and garlic in Cuyo. Bananas (Formosa), tomatoes (Salta), and peaches (Mendoza) are grown for domestic consumption. Argentina is the world's fifth-largest wine producer, and fine wine production has taken major leaps in quality. A growing export, total viticulture potential is far from met. Mendoza is the largest wine region, followed by San Juan.
Industrial petrochemicals, oil, and natural gas are Argentina's second group of exports, 20% of totals. The most important oil fields lie in Patagonia and Cuyo. An impressive network of pipelines send raw product to Bahia Blanca, center of the petrochemical industry, and to the La Plata-Rosario industrial belt. Coal is also mined.
Mining is a rising industry. The northwest and San Juan Province are main regions of activity. Metals mined include gold, silver, zinc, magnesium, copper, sulfur, tungsten and uranium. In only ten years exports soared from US$ 200 million to 1.2 billion in 2004, 3% of total. Estimates for 2006 are US$ 2bn, a 10 fold rise from 1996.
In fisheries, argentine hake accounts for 50% of catches, pollack and squid follow. Forestry has expanded in Mesopotamia; elm for cellulose, pine and eucalyptus for furniture, timber, and paper products. Both sectors each account for 2% of exports.
Manufacturing is the nation's leading single sector in GDP output, with 35% of the share. Leading sectors are motor vehicles, auto parts, and transportation and farming equipment (7% of exports), iron and steel (3%), foodstuffs and textiles (2%). Other manufactures include cement, industrial chemicals, home appliances, and processed wood. The biggest industrial centers are Buenos Aires, Rosario and Córdoba.
The telecommunication sector has been growing at a fast pace, with an important penetration of mobile telephony (75% of population)internet (with 10 million people online), and broadband services (3%). Regular telephone (with 9.5 million lines)and mail are robust.
The service sector is the biggest contributor to total GDP. Argentina produces energy in large part through well developed hydroelectric resources; nuclear energy is also of high importance. The country is one of the largest producers and exporters (with Canada and Russia) of Cobalt-60, a radioactive isotope widely used in cancer therapy. Construction has led employment creation in the current economic expansion, and is 5% of GDP.
Tourism is increasingly important, now providing 7% of economic output. Argentines are traveling more within their borders, and foreigners are flocking to a country seen as affordable, safe, and incredibly diverse: Cosmopolitan Buenos Aires and Rosario; the Iguazu Falls and colonial Salta; the South American indigenous Jujuy Province and fun-filled Córdoba; the wineries of Mendoza; the ski-suitable scenic Bariloche to the beaches of Pinamar; and Perito Moreno Glacier to Tierra del Fuego. 3.7 million tourists visited in 2005.
Argentina's infrastructure is good compared to other countries in Latin America. There are nearly 215,471 km (133,887 mi) of roads of which 68,809 km are paved, and 734 km are expressways, many of which are privatized. Multilane highways now connect several main cities and more are now under construction.
The railway network has a total length of 31,902 km. After decades of decaying service and lack of maintenance, most passenger services shut down in 1992 when the rail company was privatized, and thousands of kilometers of track are now in disrepair. Railway services are currently being reactivated among several cities.
The country has around 3,000 kilometers of waterways, the most significant among these being the Río de la Plata, Paraná, Uruguay, Río Negro and Paraguay rivers.
Water supply and sanitation in Argentina faces five key challenges: (i) low coverage with higher levels of service provision for its income level; (ii) poor service quality; and (iii) high levels of pollution; (iv) low cost recovery; and (v) unclear allocation of responsibilities between institutions in the sector.
The National Institute of Statistics and Census of Argentina (INDEC) 2001 census showed the population of Argentina was 36,260,130. It ranks third in South America in total population and 30th globally. The 2007 estimate is for a population of 40,927,301. Argentina's population density is 14 inhabitants per square kilometer. However, the population is not evenly distributed: areas of the city of Buenos Aires have a population density of over 14,000 inhab./km², while Santa Cruz province has less than 1 inhab./km². Argentina is the only nation in South America with a net positive migration rate, of about +0.4 persons.
Argentina is a melting pot of different peoples, both autochthonous and immigrants. Citizens of European descent make up the great majority of the population, with estimates varying from white 89.7% to 97% of the total population. The last national census, based on self-ascription, indicated a similar figure.
A study conducted by Argentine, Swedish and North American institutions, established that the genetic average structure of the Argentine population, contains 79,9% of European contribution, whereas the Amerindian admixture, though not fully visible in physical appearance, was estimated to be present in a high percentage of the population, close to 56% on either paternal or maternal lineages, of which just 10% were shown to have Amerindian ancestors on both lineages.
After the Spanish colonists, waves of European settlers migrated to Argentina from the late nineteenth to mid-twentieth centuries. Major contributors included Italy (initially from Piedmont, Veneto and Lombardy, later from Campania and Calabria), Spain (foremost among them Galicians and Basques, and France (mostly to Buenos Aires and Mendoza). Smaller but significant numbers of immigrants came from Germany and Switzerland (to the Lakes Region of Patagonia; and to Córdoba), Scandinavia, (Denmark, Norway and Sweden), Greece, Lebanon, the United Kingdom and Ireland (to Buenos Aires, Santa Fé, and Patagonia; see also English settlement in Argentina), and Portugal. Eastern Europeans were also numerous, from Poland, Hungary, Russia, Ukraine, Croatia, Slovenia and Lithuania, as well as Balkan countries (Romania and Montenegro, particularly in Chaco). There is a large Armenian community, and the Patagonian Chubut Valley has a significant Welsh-descended population.
Small but growing numbers of people from East Asia have also settled Argentina, mainly in Buenos Aires. The first Asian-Argentines were of Japanese descent; Koreans, Vietnamese, and Chinese followed, now at over 60,000.
Argentina has a large Arab community, made up mostly of immigrants from Syria and Lebanon. Many have gained prominent status in national business and politics, including former president Carlos Menem, the son of Syrian settlers from the province of La Rioja. Most of the Arab Argentines are Christian of the Eastern Orthodox and Eastern Catholic Churches.
Illegal immigration has been a relatively important factor in recent Argentine demographics. Most illegal immigrants come from Bolivia and Paraguay, countries which border Argentina to the north. Smaller numbers arrive from Peru, Ecuador, and Romania. The Argentine government estimates that 750,000 inhabitants lack official documents and has launched a program called Patria Grande ("Greater Homeland"), to encourage illegal immigrants to regularize their status; so far over 670,000 applications have been processed under the program.
Argentina's population is very highly urbanized. About 3.53 million people live in the autonomous city of Buenos Aires, and 12.4 million in Greater Buenos Aires (2007), making it one of the largest urban conglomerates in the world. Together with their respective metropolitan areas, the second- and third-largest cities in Argentina, Córdoba and Rosario, comprise about 1.3 and 1.1 million inhabitants respectively.
Most European immigrants to Argentina settled in the cities, which offered jobs, education, and other opportunities that enabled newcomers to enter the middle class. Many also settled in the growing small towns along the expanding railway system. Since the 1930s, many rural workers have moved to the big cities.
The 1990s saw many rural towns become ghost towns when train services ceased and local products manufactured on a small scale were replaced by massive amounts of cheap imported goods. Many slums (villas miserias) sprouted in the outskirts of the largest cities, inhabited by impoverished lower-class urban dwellers, migrants from smaller towns in the interior, and also a large number of immigrants from neighbouring countries that came during the time of the convertibility and did not leave after the 2001 crisis.
Argentina's urban areas have a European look, reflecting the influence of European settlers. Many cities are built in a Spanish-grid style around a main square (plaza). A cathedral and important government buildings often face the plaza. The general layout of the cities is called a damero, or checkerboard, since it is based on a pattern of square blocks, though modern developments sometimes depart from it (the city of La Plata, built at the end of the nineteenth century, is organized as a checkerboard plus diagonal avenues at fixed intervals). The El Faro Towers, show the modern architecture for urbanization.
The city of La Plata was the first in South America with electric street illumination.
Argentine culture has been primarily informed and influenced by its European roots. Buenos Aires, considered by many its cultural capital, is often said to be the most European city in South America, as a result both of the prevalence of people of European descent and of conscious imitation of European styles in architecture. The other big influence is the gauchos and their traditional country lifestyle of self-reliance. Finally, indigenous American traditions (like mate tea drinking) have been absorbed into the greater cultural realm.
Argentina has a rich history of world-renowned literature, including one of the twentieth century's most critically acclaimed writers, Jorge Luis Borges. The country has been a leader in Latin American literature since becoming a fully united entity in the 1850s, with a strong constitution and a defined nation-building plan. The struggle between the Federalists (who favored a loose confederation of provinces based on rural conservatism) and the Unitarians (pro-liberalism and advocates of a strong central government that would encourage European immigration), set the tone for Argentine literature of the time.
The ideological divide between gaucho epic Martín Fierro by José Hernández, and Facundo by Domingo Faustino Sarmiento, is a great example. Hernández, although a federalist, opposed to the centralizing, modernizing, and Europeanizing tendencies. Sarmiento wrote immigration was the only way to save Argentina from becoming subject to the rule of a small number of dictatorial caudillo families, arguing such immigrants would make Argentina more modern and enlightened to Western European thought, and therefore a more prosperous society.
Argentine literature of that period was fiercely nationalist. It was followed by the modernist movement, which emerged in France in the late nineteenth century, and this period in turn was followed by vanguardism, with Ricardo Güiraldes as an important reference. Jorge Luis Borges, its most acclaimed writer, found new ways of looking at the modern world in metaphor and philosophical debate, and his influence has extended to writers all over the globe. Borges is most famous for his works in short stories such as Ficciones and The Aleph.
Argentina has produced many more internationally noted writers, poets, and intellectuals: Juan Bautista Alberdi, Roberto Arlt, Enrique Banchs, Adolfo Bioy Cásares, Eugenio Cambaceres, Julio Cortázar, Esteban Echeverría, Leopoldo Lugones, Eduardo Mallea, Ezequiel Martínez Estrada, Tomás Eloy Martínez, Victoria Ocampo, Manuel Puig, Ernesto Sabato, Osvaldo Soriano, Alfonsina Storni, and María Elena Walsh. Quino (born Joaquin Salvador Lavado), has entertained readers the world over, while dipping into the events of modern times, with soup-hating Mafalda and her comic strip gang.
Argentina is a major producer of motion pictures. The world's first animated feature films were made and released in Argentina, by cartoonist Quirino Cristiani, in 1917 and 1918. Argentine cinema enjoyed a 'golden age' in the 1930s through the 1950s with scores of productions, many now considered classics of Spanish-language film. The industry produced actors who became the first movie stars of Argentine cinema, often tango performers such as Libertad Lamarque, Floren Delbene, Tito Lusiardo, Tita Merello, Roberto Escalada, and Hugo del Carril.
More recent films from the "New Wave" of cinema since the 1980s have achieved worldwide recognition, such as The Official Story (La historia official), Nine Queens (Nueve reinas), Man Facing Southeast (Hombre mirando al sudeste), Son of the Bride (El hijo de la novia), The Motorcycle Diaries (Diarios de motocicleta), or Iluminados por el fuego. Although rarely rivaling Hollywood-type movies in popularity, local films are released weekly and widely followed in Argentina and internationally. Even low-budget films have earned prizes in cinema festivals (such as Cannes). The city of Mar del Plata organizes its own film festival, while Buenos Aires has its independent cinema counterpart. The per capita number of screens is one of the highest in Latin America, and viewing per capita is the highest in the region. A new generation of Argentine directors has caught the attention of critics worldwide. Additionally, Argentina is a major center of cinema, it is compared to other European countries in terms of people who attend movie theaters. An example of this was Spider-Man 3 which took in 466,586 the first day a record in Argentina. In Italy it took in 400,000 and Germany 486,571, breaking all records for first day release.
Buenos Aires is one of the great capitals of theater. The Teatro Colon is a national landmark for opera and classical performances. Built at the ending of XIX century, Teatro Colon's acoustic is considered the best in the world in its kind. Currently is under a major maintenance program, in order to preserve its outstanding sound characteristics, the french-romantic style, the impressive Golden Room (a minor auditorium targeted to Chamber Music performances), and the museum at the entrance. Enrico Caruso, B.Gigli, Félix Weingartner, Artur Nikisch, Richard Strauss,Arturo Toscanini, Igor Stravinsky, Paul Hindemith, Camille Saint-Saëns, Manuel de Falla, Aaron Copland, Krzysztof Penderecki, Gian-Carlo Menotti, Wilhelm Furtwängler, Herbert von Karajan, Tullio Serafin, Gino Marinuzzi, Albert Wolff, Víctor De Sabata, Leonard Bernstein, Mstislav Rostropovich, Sir Malcolm Sargent, Karl Böhm, Fernando Previtali, Sir Thomas Beecham, Ferdinand Leitner, Lorin Maazel, Igor Markevitch, Bernard Haitink, Zubin Mehta, Marek Janowsky, Aldo Ceccato, Riccardo Muti, Kurt Masur, Michel Corboz, Franz-Paul Decker, Riccardo Chailly, Sir Simon Rattle, Claudio Abbado, René Jacobs are among the artists, composers and conductors who performed in this opera house. Besides the Teatro Colón (one of the great opera houses of the world), with its program of national and international caliber, Calle Corrientes, or Corrientes Avenue, is synonymous with the art. It is dubbed 'the street that never sleeps', and sometimes referred to as the Broadway of Buenos Aires. Many great careers in acting, music, and film have begun in its many theaters. The Teatro General San Martín is one of the most prestigious along Corrientes Avenue; the Teatro Nacional Cervantes is designated the national theater of Argentina. Another important theater is the Independencia in Mendoza. Florencio Sanchez and Griselda Gambaro are famous Argentine playwrights. Julio Bocca is one of the great ballet dancers of the modern era.
Perhaps one of the most enigmatic figures of Argentine culture is Oscar Agustín Alejandro Schulz Solari, aka Xul Solar, whose watercolor style and unorthodox painting media draws large crowds at museums worldwide; he also 'invented' two imaginary languages. The works of Candido Lopez (in Naïve art style), Emilio Pettoruti (cubist), Antonio Berni (neo-figurative style), Fernando Fader, and Guillermo Kuitca are appreciated internationally.
Benito Quinquela Martín is considered to be the quintesennial 'port' painter, to which the city of Buenos Aires and particularly the working class and immigrant-bound La Boca neighborhood, was excellently suited for. Lucio Fontana and Leon Ferrari are acclaimed sculptors and conceptual artists. Ciruelo is a world-wide famous fantasy artist and sculptor.
Argentine food is influenced by cuisine from Spain, Italy, Germany, France and other European countries, and many foods from those countries such as pasta, sausages, and desserts are common in the nation's diet. Argentina has a wide variety of staple foods, which include empanadas, a stuffed pastry; locro, a mixture of corn, beans, meat, bacon, onion, and gourd; and chorizo, a spicy sausage. Other popular items include Dulce de Leche and mate, Argentina's national beverage.
The Argentine barbecue, asado, is one of the most famous in the world and includes various types of meats, among them chorizo, sweetbread, chitterlings, and morcilla (blood sausage). Thin sandwiches, sandwiches de miga, are also popular. Argentines have the highest consumption of red meat in the world.
Since 1992 Argentina has invested over 650 million dollars to modernize the winery industry. The country is an important wine producer, rated fifth in the world, with the yearly per capita consumption of wine amongst the highest worldwide. (Malbec has become a representative variety from Argentina). Malbec grape, a discardable varietal in France (country of origin), has found in Province of Mendoza an ideal environment to successfully develop and turn itself into world's best Malbec. The city of Mendoza is one of the eight wine capitals of the world, and Mendoza accounts for 70% of the country total production (all varietals considered). "Wine tourism" is significant in the Province of Mendoza, with the impressive landscape of Cordillera de Los Andes and the highest peak in America, Mount Aconcagua, 6952 meters high, providing a very desirable destination for international tourism.
Football (soccer) is the most popular sport in Argentina, whose national team is twice FIFA World Cup Champion and one-time Olympic Gold medalist (also fourteen-time Copa América winners).
Also widespread are volleyball and basketball; a number of basketball players participate in the NBA and European leagues. Manu Ginobili, Andres Nocioni, Carlos Delfino, and Fabricio Oberto are a few, and the national team won Olympic Gold in the Athens Olympics. Argentina has an important rugby union team, "Los Pumas" (see Argentina national rugby union team), with many of its players playing in Europe. Argentina beat France in the Rugby World Cup 2007, placing them third in the competition. They beat France 34 - 10. Argentine tennis is very competitive on the world stage, with dozens of players, male and female, in active tour.
Other popular sports include field hockey (the top female sport, see Las Leonas), golf, and sailing. Argentina has the highest number of highly-ranked polo players in the world and the national squad has been the uninterrupted world champion ever since 1949. The Open Polo Championship of Buenos Aires is the most important polo-related event in the world. Cricket is growing in popularity due to the National Team's recent successes where they came as the underdogs and finished runner's up of the Inaugural World Cricket League Division 3. Baseball is played in a most limited fashion, as well as the Gridiron.
Motorsports are well represented in Argentina, with Turismo Carretera and TC 2000 being the most popular car racing formats. People all over the country enjoy the races, but it is most fervently followed in small towns and rural Argentina, attracting a rather similar demographic as NASCAR in the United States. The Rally Argentina is part of the World Rally Championship (currently held in Córdoba Province). In Formula 1 racing, the country produced one world champion (Juan Manuel Fangio, five times) and two runners-up (Froilán González and Carlos Reutemann, once each).
The official national sport of the country is pato, played with a six-handle ball on horseback.
Tango, the music and lyrics (often sung in a form of slang called lunfardo), is Argentina's musical symbol. The Milonga dance was a predecessor, slowly evolving into modern tango. By the 1930s, tango had changed from a dance focused music to one of lyric and poetry, with singers like Carlos Gardel, Roberto Goyeneche, Hugo del Carril, Tita Merello, and Edmundo Rivero. The golden age of tango (1930 to mid-1950s) mirrored that of Jazz and Swing in the United States, featuring large orchestral groups too, like the bands of Osvaldo Pugliese, Anibal Troilo, Francisco Canaro, and Juan D'Arienzo. After 1955 tango turned more intellectual and listener-oriented, led by Astor Piazzolla. Today tango has worldwide popularity, and the rise of neo-tango is a global phenomenon with groups like Tanghetto, Bajofondo and Gotan Project.
Argentine rock, called rock nacional, is the most popular music among youth. Arguably the most listened form of Spanish-language rock, its influence and success internationally owes to a rich, uninterrupted evolution. Bands such as Soda Stereo or Sumo, and composers like Charly García, Luis Alberto Spinetta, and Fito Páez are referents of national culture. Mid 1960s Buenos Aires and Rosario were cradles of the music, and by 1970 Argentine rock was established among middle class youth (see Almendra, Sui Generis, Pappo, Crucis). Seru Giran bridged the gap into the 1980s, when Argentine bands became popular across Latin America and elsewhere (Enanitos Verdes, Fabulosos Cadillacs, Virus, Andres Calamaro). There are many sub-genres: underground, pop oriented, and some associated with the working class (La Renga, Attaque 77, Divididos, Los Redonditos). Current popular bands include: Babasonicos, Rata Blanca, El Otro Yo, Attaque 77, Bersuit, Los Piojos, Intoxicados, Catupecu Machu, and Miranda!
European classical music is well represented in Argentina. Buenos Aires is home to the world-renowned Colón Theater. Classical musicians, such as Martha Argerich, Daniel Barenboim, Eduardo Alonso-Crespo, Eduardo Delgado, Lalo Schiffrin, and classical composers such as Alberto Ginastera, are internationally acclaimed. All major cities in Argentina have impressive theaters or opera houses, and provincial or city orchestras. Some cities have annual events and important classical music festivals like Semana Musical Llao Llao in San Carlos de Bariloche and the multitudinous Amadeus in Buenos Aires.
Argentine folk music is uniquely vast. Beyond dozens of regional dances, a national folk style emerged in the 1930s. Perón's Argentina would give rise to Nueva Canción, as artists began expressing in their music objections to political themes. Atahualpa Yupanqui, the greatest Argentine folk musician, and Mercedes Sosa would be defining figures in shaping Nueva Canción, gaining worldwide popularity in the process. The style found a huge reception in Chile, where it took off in the 1970s and went on to influence the entirety of Latin American music. Today, Chango Spasiuk and Soledad Pastorutti have brought folk back to younger generations. Leon Gieco's folk-rock bridged the gap between argentine folklore and argentine rock, introducing both styles to millions overseas in successive tours.
Other notable musicians include Gato Barbieri with his seductive saxophone and free jazz compositions, and Jaime Torres and his spacious andean music.
Argentines are predominantly Roman Catholic. Around 93% declare themselves Roman Catholic according to different surveys; the Church estimates an affiliation of 70%.
According to the Constitution, the Argentine government should support Roman Catholicism. However, this does not imply that it is the official religion of the Argentine Republic, nor does it imply that people working in the government should have this faith.
Evangelical churches have gained a foothold in Argentina since the 1980s, and their followers now number more than 3.5 million, about 10% of the total population. Traditional Protestant communities are present in most communities.
Members of The Church of Jesus Christ of Latter-day Saints (Mormons) number over 330,300, the seventh-largest concentration in the world, are also present.
The country also hosts the largest Jewish population in all of Latin America, about 2 percent of the population.
Islam in Argentina constitutes approximately 1.5% of the population, or an estimated 500,000-600,000 (93% Sunni). Argentina is also home to one of the largest mosques in Latin America, serving Argentina's Muslim community.
Approximately 7% of Argentines can be considered non-religious or secular.
The official language of Argentina is Spanish, usually called "Castellano" (Castilian) by Argentines.
A phonetic study conducted by the Laboratory for Sensory Investigations of CONICET and the University of Toronto showed that the accent of the inhabitants of Buenos Aires (known as porteños) is closer to the Neapolitan dialect of Italian than any other spoken language. Italian immigration and other European immigrations influenced Lunfardo, the slang spoken in the Río de la Plata region, permeating the vernacular vocabulary of other regions as well.
Argentines are the largest Spanish-speaking society that universally employs what is known as voseo (the use of the pronoun vos instead of tú (you), which occasions the use of alternate verb forms as well). The most prevalent dialect is Rioplatense, whose speakers are primarily located in the basin of the Río de la Plata.
Standard German is spoken by between 400,000 and 500,000 Argentines of German ancestry, though it has also been stated that the there could be as much as 1,800,000. German today, is the third or fourth most spoken language in Argentina.
According to a survey, there are around 1,500,000 Italian speakers (which makes it the second most spoken language in the country) and 1,000,000 speakers of Levantine Arabic, but these numbers are probably no longer current, as the newer generations mostly switch to Spanish and do not speak the ancestral language in the home. The same phenomenon applies to the Galician language that was used by many Spanish immigrants, Yiddish, and Japanese. The usage of these languages is in decline, as the respective immigration waves ended in the first half of the 20th century.
Some indigenous communities have retained their original languages. Guaraní is spoken by some in the northeast, especially in Corrientes (where it enjoys official status) and Misiones. Quichua is spoken by some in the northwest, and has a local variant in Santiago del Estero. Aymara is spoken by members of the Bolivian community who migrated to Argentina from Bolivia.
In Patagonia there are several Welsh-speaking communities.
More recent immigrants have brought Chinese and Korean, mostly to Buenos Aires. English, Brazilian Portuguese and French are also spoken to a lesser extent. English is commonly taught at schools, with Portuguese and French behind.
School attendance is compulsory between the ages of 5 and 17. The Argentine school system consists of a primary or lower school level lasting six or seven years, and a secondary or high school level lasting between five to six years. In the 1990s, the system was split into different types of high school instruction, called Educacion Secundaria and the Polimodal. Some provinces adopted the Polimodal while others did not. A project in the Executive to repeal this measure and return to a more traditional secondary level system was approved in 2006. President Domingo Faustino Sarmiento is overwhelmingly credited in pushing and implementing a free, modern education system in Argentina. The 1918 University reform shaped the current tripartite representation of most public universities.
Education in public schools (primary, secondary and tertiary) is free. Public education, which was perceived to be of the best quality during the mid 20th century, is now often perceived to be bad and in continuous decline because of lack of funding. This has helped private education to flourish, albeit it has also caused an imbalance in terms of who can afford it (usually middle and upper classes), as often private schools have no scholarship systems in place.
There are thirty-five public universities across the country, as well as several private. The Universities of Buenos Aires (the largest one, has 300,000 students), Córdoba (110,000 students), Rosario (75,000 students), La Plata (75,000 students) and UTN (National Technological University, 70,000 students) are among the most important. Public universities faced cutbacks in spending during the 1980s and 1990s, which led to a decline in overall quality.
Public holidays include most of the Catholic holidays, though holidays of other faiths are respected. The main historic holidays include the anniversaries of the May Revolution (May 25), the Independence Day (July 9), National Flag day (June 20), and the death of national hero José de San Martín (August 17).
On Christmas Eve, the extended family gathers at 9 p.m. for dinner, music, and often dancing. Candies are served just before midnight, when fireworks displays begin. The evening also includes opening gifts from Papá Noel (Santa Claus). New Year's Day is marked with fireworks as well. Other holidays include Good Friday and Easter; Labor Day (1 May); Anniversary of the May Revolution (25 May); sovereignty Day (former Malvinas Day) (2 April); Flag Day (20 June); and Independence Day (9 July).
Argentina has contributed many distinguished doctors, scientists, and inventors to the world, including three Nobel Prize laureates in sciences.
Argentines have been responsible for major breakthroughs in world medicine. Domingo Liotta designed and developed the first artificial heart successfully implanted in a human being in 1969. René Favaloro developed the techniques and performed the world's first ever coronary bypass surgery, and Francisco de Pedro invented a more reliable artificial cardiac pacemaker. Medicine's Nobel laureate Bernardo Houssay discovered the role of pituitary hormones in regulating glucose in animals; Medicine's Nobel laureate César Milstein did extensive research in antibodies; and Chemistry's Nobel laureate Luis Leloir discovered how organisms store energy converting glucose into glycogen, and the compounds which are fundamental in metabolizing carbohydrates. Luis Agote performed one of the first two blood transfusions with pre-stored blood in history. Enrique Finochietto designed operating table tools such as the surgical scissors that bear his name ("Finochietto scissors"), and a rib-spreader. Roberto Zaldívar is a pioneer in laser-eye procedures and research. Argentine research has led to advancement in wound-healing therapies, heart disease, and in several forms of cancer.
Argentina's nuclear program is highly advanced. Argentina developed its nuclear program without being overly dependent on foreign technology. Nuclear facilities with Argentine technology have been built in Peru, Algeria, Australia, and Egypt. In 1983, the country admitted having the capability of producing weapon-grade uranium, a major step to assemble nuclear weapons. Since then Argentina has pledged to use nuclear power only for peaceful purposes.
In other areas, Juan Vucetich, a Yugoslavian immigrant, was the father of modern fingerprinting(dactiloscopy). (see fingerprint), Raúl Pateras de Pescara demonstrated the world's first flight of a helicopter, Hungarian-Argentine László Bíró mass-produced the first modern ball point pens, and Eduardo Taurozzi developed the more efficient pendular combustion engine. Juan Maldacena, an Argentine-American scientist, is a leading figure in string theory. An Argentine satellite, the PEHUENSAT-1 was successfully launched on January 10 2007 using the PSLV.
The printed media in Argentina is highly developed and independent. There are over two hundred newspapers in the country, influential in their home cities and regions. The major national newspapers are from Buenos Aires, including the centrist Clarín, one of the best selling daily in the Spanish speaking world. Other national papers are La Nación (center-right) in the streets since 1870, Página/12 (left), Ámbito Financiero (business conservative), Argentinisches Tageblatt in German, Le Monde Diplomatique in Spanish and French and Crónica (populist). Regional papers of importance include La Capital (Rosario), Los Andes (Mendoza), La Voz del Interior (Córdoba), and El Tribuno (Salta). The Buenos Aires Herald is a well-respected English language daily.
The Argentine publishing industry is together with those in Spain and Mexico the most important in the Spanish-speaking world. Argentina features the largest bookstore chains in Latin America, the El Ateneo and Yenny bookstores; numerous well-stocked independent stores abound. A number carry titles in English and other languages. There are hundreds of magazine publications covering a plethora of issues and hobbies, which are sold in kiosks on city sidewalks and in bookstores.
Argentina was a pioneering nation in radio broadcasting. At 9 pm on August 27, 1920, Sociedad Radio Argentina announced: ""We now bring to your homes a live performance of Richard Wagner's Parsifal opera from the Coliseo Theater in downtown Buenos Aires""; only about twenty homes in the city had a receiver to tune in. The world's first radio station was the only one in the country until 1922, when Radio Cultura went on the air. By 1925, there were twelve stations in Buenos Aires and ten in other cities. The 1930s were the "golden age" of radio in Argentina, with live variety, news, soap opera, and sport shows.
At present there are more than 1,500 radio stations licensed in Argentina; 260 are AM broadcasting and 1150 FM broadcasting. Radio remains an important medium in Argentina. Music and youth variety programs dominate FM formats; news, debate, and sports are AM radio's primary broadcasts. Amateur radio is widespread in the country. Radio still serves a vital service of information, entertainment and even life saving in the most remote communities.
The Argentine television industry is large and diverse, widely viewed in Latin America, and its productions seen around the world. Many local programs are broadcast by networks in other countries, and others have their rights purchased by foreign producers for adaptations in their own markets. Argentina has five major networks. All provincial capitals and other large cities have at least one local station. Argentina boasts the highest penetration of cable and satellite television in Latin America, similar to percentages in North America. Many cable networks operate from Argentina and serve the Spanish-speaking world, including Utilísima Satelital, TyC Sports, Fox Sports en Español (with the United States and México), MTV Argentina, Cosmopolitan TV, and the news network Todo Noticias.


Azerbaijan ( (UK), /ˌɑzɚbaɪˈʤɑːn/ (US); ), officially the Republic of a Azerbaijan (), is the largest and most populous country in the South Caucasus region of Eurasia. Located at the crossroads of Eastern Europe and Western Asia, it is bounded by the Caspian Sea to the east, Russia to the north, Georgia to the northwest, Armenia to the west, and Iran to the south. The Azerbaijani exclave of Nakhchivan is bordered by Armenia to the north and east, Iran to the south and west, and Turkey to the northwest. Nagorno-Karabakh, along with 7 other districts in Azerbaijan's southwest, have been controlled by Armenia since the end of the Nagorno-Karabakh War in 1994. Four United Nations Security Council Resolutions (822, 853, 874, and 884) called for "the withdrawal of occupying forces from occupied areas of the Azerbaijani Republic" The country's territory also encompasses several islands in the Caspian Sea.
Azerbaijan, a nation with an ethnic Azeri and Shi‘ite Muslim majority population, is a secular and unitary republic. The country has been a co-founder of GUAM and the Organisation for the Prohibition of Chemical Weapons, and has been a member of the Commonwealth of Independent States since September 1993. The country has a Permanent Mission to the European Union, hosts a Special Envoy of the European Commission and is a member of the United Nations, OSCE, Council of Europe, and the NATO Partnership for Peace (PfP) program.
The earliest evidence of human settlement in the territory of Azerbaijan dates to the late Stone Age and is related to the Quruçay culture of Azykh Cave. The Upper Paleolithic and particularly Mousterian cultures are attested to in the caves of Tağlar, Damcili, Zar, Yataq-yeri, etc. Jugs with the remnants of dry wine, revealed in the necropolises of Leylatepe and Sarytepe, testify to wine-making activity during the Late Bronze Age.
The entire South Caucasus was conquered by the Achaemenids around 550 B.C. which led to the spread of Zoroastrianism in this part of the Median Empire. After its overthrow by Alexander the Great, the Seleucid Greeks, who inherited the Caucasus, were ultimately beset by pressures from Rome, secessionist Greeks in Bactria and most adversely the Parthians. Caucasian Albanians, the original inhabitants of the area established a kingdom in the 4th century B.C. In 95-67 B.C. parts of Caucasian Albania may have been under the subjugation of neighboring Armenia, as a part of Tigranes the Great's empire. According to Strabo, as the Romans and Parthians began to expand their domains, Albania, unlike Iberia and Armenia, remained independent of Roman domination, signing a peace treaty (Strabo XI, 4, 5). The Roman inscription found in Gobustan testifies to the presence of Legio XII Fulminata in the time of Domitian.
Caucasian Albania remained largely independent until the Sassanids turned it into a vassal state in 252 A.D. King Urnayr of Caucasian Albania officially adopted Christianity as the state religion in the 4th century A.D. and Albania remained a predominantly Christian state until the Islamic conquest of the 8th century A.D. Despite numerous conquests by the Sassanids and Byzantines, Caucasian Albania remained an entity in the region until the 9th century A.D. The territory of modern Azerbaijan roughly corresponds to the ancient state of Caucasian Albania.
The Islamic Umayyad Caliphate defeated both the Sassanids and the Byzantines, making Caucasian Albania a vassal state after the Christian resistance, led by Prince Javanshir, was suppressed in 667 A.D. After the decline of Abbasid Caliphate, the territory of present-day Azerbaijan was under the sway of numerous dynasties such as the Salarids, Sajids, Shaddadids, Rawadids and Buyids. At the beginning of the 11th century, the territory was gradually seized by waves of Turkic Oghuz tribes from Central Asia. The first of these dynasties were the Ghaznavids, who took over part of the area now known as Azerbaijan by 1030.
Locally, the possessions of the subsequent Seljuk Empire were ruled by atabegs, who were technically vassals of the Seljuk sultans, being sometimes de facto rulers themselves. Under the Seljuk Turks, local poets such as Nizami Ganjavi and Khagani Shirvani gave rise to a blossoming of Persian literature on the territory of present-day Azerbaijan. The next ruling state of the Jalayirids was short-lived and fell under the conquests of Tamerlan. The local dynasty of Shirvanshahs became a vassal state of Tamerlan's empire and assisted Tamerlan in his war with the ruler of the Golden Horde Tokhtamysh. Following Tamerlan's death two independent and rival states emerged: Kara Koyunlu and Ak Koyunlu. Until his death the Ak Koyunlu sultan Uzun Hasan ruled the whole territory now known as Azerbaijan. Thereafter the Shirvanshahs maintained a high degree of autonomy as local rulers and vassals from 861 until 1539. As the Shirvanshahs were persecuted by the Safavids, the last dynasty imposed Shia Islam upon the formerly Sunni population, battling against the Sunni Ottoman Empire.
The area was ruled under Iranian dynasties of Afshar and Zand following the collapse of the Safavids and briefly under Qajars. In the meanwhile, however, several independent khanates emerged in the area, especially following collapse of Zand dynasty and in early Qajar era. Engaged in constant warfare, these khanates were eventually incorporated to the Russian Empire, following two Russo-Persian Wars. Under the Treaty of Turkmenchay the Persian Empire recognized Russian sovereignty over the Erivan khanate, the Nakhchivan khanate and the remainder of the Talysh khanate.
After the collapse of the Russian Empire during World War I, Azerbaijan together with Armenia and Georgia became part of the short-lived Transcaucasian Democratic Federative Republic. When the republic dissolved in May 1918, Azerbaijan declared independence as the Azerbaijan Democratic Republic (ADR). The ADR was the first democratic parliamentary republic in the Muslim world, but lasted only 23 months until the Bolshevik XIth Red Army invaded in April 1920. Overthrowing the ADR government, Bolsheviks established Azerbaijan SSR in Baku on April 28, 1920.
In 1922, Azerbaijan, along with Armenia and Georgia, became part of the Transcaucasian Soviet Federative Socialist Republic {TSFSR), which itself became a constituent member of the newly-established Soviet Union. In 1936, TSFSR was dissolved and Azerbaijan SSR became one of the 12 (by 1940 - 15) constituent member states of the Soviet Union.
During the 1940s, the Azerbaijan SSR supplied much of the Soviet Union's oil on the Eastern Front of World War II. Close to 600,000 Azerbaijanis fought on this front against Nazi Germany. Operation Edelweiss was launched by Adolf Hitler to occupy the Caucasian oilfields and capture Baku, but all the offensives were pushed back. The Germans made largely fruitless efforts to enlist the cooperation of emigre political figures, such as Mammed Amin Rasulzade, who came to Berlin and found opportunities to meet captured Soviet Azerbaijani POWs.
Following the politics of glasnost, initiated by the last General Secretary of the Communist Party of the Soviet Union, Mikhail Gorbachev, civil unrest and ethnic strife grew in various regions of the Soviet Union, including Nagorno-Karabakh, a region of the Azerbaijan SSR. The disturbances in Azerbaijan, in response to Moscow's indifference to already heated conflict, resulted in calls for independence and secession from the USSR, which subsequently culminated in the events of Black January in Baku. At this time, Ayaz Mutallibov was appointed as the First Secretary of the Azerbaijan Communist Party.
Later in 1990, the Supreme Council of the Azerbaijan SSR dropped the words "Soviet Socialist" from the title; adopted the Declaration of Sovereignty of the Azerbaijan Republic, a constituent member of Soviet Union; and restored the modified flag of the Azerbaijan Democratic Republic as a state flag. In early 1991, the Supreme Council of Azerbaijan established the office of the presidency. Ayaz Mutallibov was subsequently elected as the first president by the Council. On September 8, 1991, Ayaz Mutallibov was elected as president in nationwide elections in which he was the only candidate running.
On October 18, 1991, Supreme Council of Azerbaijan adopted a Declaration of Independence which was affirmed by a nationwide referendum in December, 1991, when the Soviet Union was officially dissolved. The early years of independence were overshadowed by the Nagorno-Karabakh War with neighboring Armenia. By the end of hostilities in 1994, Azerbaijan lost control of up to 16% of its internationally recognized territory, including Nagorno-Karabakh itself. In 1993, democratically elected president Abulfaz Elchibey was overthrown by a military insurrection led by Colonel Suret Huseynov, which resulted in the rise to power of the former leader of Soviet Azerbaijan, Heydar Aliyev. In 1994, Suret Huseynov, by that time a prime minister, attempted another military coup against Heydar Aliyev but failed, was arrested and was charged with treason. In 1995, another coup attempt against Aliyev, by the commander of the military police, Rovshan Javadov, was averted, resulting in the killing of the latter and disbanding of Azerbaijan's military police.
Although during his presidency, Aliyev managed to reduce the country's unemployment, reined in criminal groups, established the fundamental institutions of independent statehood, and brought stability, peace and major foreign investment, the country was tainted by rampant corruption in the governing bureaucracy. In October 1998, Aliyev was reelected for a second term. Despite the much improved economy, particularly with the exploitations of Azeri-Chirag-Guneshli oil field and Shah Deniz gas field, Aliyev's presidency became unpopular due to vote fraud, wide-spread corruption and objection to his autocratic regime. The same harsh criticism followed the elections of former Prime Minister Ilham Aliyev, the second leader of New Azerbaijan Party after the death of his father Heydar.
The total length of Azerbaijani land borders is 2,648 km, of which Armenia constitutes 1007, Iran 756, Georgia 480, Russia - 390 and Turkey - 15. The coastline stretches for 800 km and the length of the widest area of the Azerbaijani section of Caspian Sea is 456 km. The territory of Azerbaijan extends 400 km from north to south, and 500 km from west to east. The three mountain ranges are the Greater and Lesser Caucasus, and the Talysh Mountains, together covering approximately 40% of the country. The highest peak of Azerbaijan is mount Bazardüzü (4,466 m), while the lowest point lies in the Caspian Sea (-28 m). Nearly half of all the mud volcanoes on Earth are concentrated in Azerbaijan.
The main water sources are the surface waters. However, only 24 of the 8,350 rivers are greater than 100 km in length. All the rivers drain into the Caspian Sea in the east of the country. The largest lake is Sarısu (67 km²) and the longest river is Kur (1,515 km), which is transboundary. Azerbaijan's four main islands in the Caspian Sea have a combined area of over thirty square kilometers.
The formation of climate in Azerbaijan is influenced particularly by cold arctic air masses of Scandinavian anticyclone, temperate of Siberian anticyclone, and Central Asian anticyclone. Regarding landscape diversity, air masses have different ways to enter the country. The Greater Caucasus protects the country from direct influences of cold air masses, coming from the north. That leads to the formation of subtropical climate on most foothills and plains of the country. Meanwhile plains and foothills are characterized by high solar radiation rates.
Nine out of eleven existing climate zones are present in Azerbaijan. Both the absolute minimum temperature (-33 °C (-27.4 °F)) and the absolute maximum temperature (+46 °C (114.8 °F)) were observed in Julfa and Ordubad. The maximum annual precipitation falls in Lankaran (1,600 to 1,800 mm) and the minimum in Absheron (200 to 350 mm).
From the water supply point, Azerbaijan is below the average in the world with approximately 100,000 m³/year of water per km². All big water reservoirs are built on Kur.
The main areas of plant diversity in Azerbaijan are the highlands of Nakhchivan (60% of the species occur here), the Kura-Araz plain (40%), the Davachi-Quba region east of the Greater Caucasus (38%), the centre of the Lesser Caucasus (29%), Gobustan (26.6%), the Lenkoran region in the Talysh Mountains (27%) and the Absheron region (22%). Northern-eastern slopes of the Great Caucasus, the northern, northern-eastern, and eastern slopes of the Lesser Caucasus and Talysh Mountains are deemed to be vast forest areas of Azerbaijan.
Endemics include over 400 species of plants (of which around 16 species of Caspian algae), seven reptiles and perches from fifteen species and six sub-species of Gobiidae. Most of the endemic freshwater fish belongs to Cypriniformes. However there are no strictly endemic mammals. The major cause of biodiversity loss in Azerbaijan is the decrease in natural environments.
Azerbaijan is divided into 59 rayons (rayonlar, singular rayon), 11 city districts (şəhərlər, singular şəhər), and one autonomous republic (muxtar respublika) of Nakhchivan, which subdivides into 7 rayons and a city. The President of Azerbaijan appoints the governors of these units, while the government of Nakhchivan is elected and approved by the parliament of Nakhchivan Autonomous Republic. The local governments of regions and cities under Armenian occupation, such as Khankendi or Shusha, continue to function in exile.
The structural formation of Azerbaijan's political system was completed by the acceptance of the new Constitution on November 12, 1995. The state symbols of the Azerbaijan Republic are, according to the Article 23 of Constitution, the flag, the coat of arms and the national anthem. The state power in Azerbaijan is limited only by law for internal issues, but for international affairs is additionally limited by the provisions of international agreements.
The government of Azerbaijan is based on the separation of powers among the legislative, executive and judicial branches. The legislative power is held by the unicameral National Assembly and the Supreme National Assembly in the Nakhchevan Autonomous Republic. Parliamentary elections are held every five years, on the first Sunday of November. The accuracy of the election results are checked and confirmed by the Constitutional Court. The laws enacted by the National Assembly, unless specified otherwise come into effect from the day of their publication. The executive power is carried out by the president, who is elected for a 5 year term by direct elections. The president is authorized to form the Cabinet of Ministers, an inferior executive body, subordinated to him. The Cabinet of Ministers of Azerbaijan consists primarily of the Prime Minister, his Deputies and Ministers. The president does not have the right to dissolve the National Assembly, but has the right to veto its decisions. To override the presidential veto, the parliament must have a majority of 95 votes. The judicial power is vested in the Constitutional Court, Supreme Court and the Economic Court. The President nominates the judges in these courts.
The Security Council is the deliberative body under the president and he organizes it according to the Constitution. It was established on April 10, 1997. The administrative department is not a part of the president's office, but manages the financial, technical and pecuniary ensuring of activity of both the president and his office.
The short-lived Azerbaijan Democratic Republic succeeded in establishing diplomatic relations with six countries, sending diplomatic representatives to Germany and Finland. The process of international recognition of Azerbaijan's independence from the collapsing Soviet Union lasted roughly one year. The last country, Bahrain recognized Azerbaijan on November 6, 1996. Full diplomatic relations, including mutual exchanges of missions, were first established with Turkey, the United States and Iran.
Azerbaijan has diplomatic relations with 158 countries so far and holds membership in 38 international organizations. An observer status is held in the Non-Aligned Movement and World Trade Organization and the correspondent one at the International Telecommunication Union. The Azerbaijani diaspora is represented in 36 countries, dozens of ethnic minorities centers in turn are functioning inside the country (German cultural society "Karelhaus", Slavic cultural center, Azerbaijani-Israeli community, Kurdish cultural center, International Talysh Association, Lezgin national center "Samur", Azerbaijani-Tatar community, Crimean Tatars society etc.). On May 9, 2006 Azerbaijan was elected as one the members of the newly established Human Rights Council by the United Nations General Assembly. The term of office begun on June 19, 2006.
Foreign policy priorities of Azerbaijan include: first of all, the restoration of the territorial integrity, elimination of the consequences of the loss of Nagorno-Karabakh and seven other regions of Azerbaijan, development of good-neighbourly and mutually advantageous relations with neighbouring countries; promotion of security and stability in the region; integration into European and Transatlantic security and cooperation structures, promotion of transregional economic, energy and transportation projects. (For more information about Azerbaijan's official foreign policy, see ) The Azeri Government, in late 2007, stated that if a comprehensive peace treaty is not signed with Armenia in 2008, then Azerbaijan will adopt military solutions to the conflict involving the Karabakh enclave. The Government is in the process of increasing its military budget as its oil and gas revenues bring a torrent of cash into its coffers. Furthermore, economic sanctions imposed by Iran along the south, Turkey along the west, and by Azerbaijan itself along the east, have all combined to greatly erode Armenia's economy, leading to steep prices for basic commodities and a great decline in the Armenian state revenues.
Azerbaijan is an active member of international coalitions fighting international terrorism. The country is contributing to peacekeeping efforts in Kosovo, Afghanistan and Iraq. Azerbaijan is an active member of NATO's "Partnership for Peace" program. It also maintains good relations with the European Union, and could potentially one day apply for membership. see Azerbaijan and the European Union.
The Armed Forces of the Republic of Azerbaijan were created according to the Law of the Republic of Azerbaijan on the Armed Forces of Azerbaijan of 9 October 1991. Initially, the equipment and facilities were those of the Soviet Fourth Army. The Armed Forces have three branches: Land Forces, Air Force and Air Defence Force (a united branch) and the Navy. Besides the Armed Forces there are some additional militarily organised groups that can be involved in state defence when needed. These are the Internal Troops of the Ministry of Internal Affairs and forces of the State Border Service, which includes the Coast Guard as well.
Azerbaijan adheres to the Treaty on Conventional Armed Forces in Europe. On January 13, 1993 Azerbaijan signed the Chemical Weapons Convention on the 47th United Nations General Assembly in Paris. In 1999 the country signed particularly the Document on Small Arms and Light Weapons. Azerbaijan has been also a member of the NATO's Partnership for Peace since 1994 and the NATO Individual Partnership Action Plan since 2004. Azerbaijan is also a party to the Nuclear Non-Proliferation Treaty and has an additional protocol with the International Atomic Energy Agency. The armed forces supported the American Operation Enduring Freedom by providing one peacekeeping infantry platoon and Operation Iraqi Freedom with one peacekeeping infantry company. 2007 military expenditures reached 871 mln USD.
After gaining independence in 1991, Azerbaijan became a member of the International Monetary Fund, the World Bank, the European Bank for Reconstruction and Development, the Islamic Development Bank and the Asian Development Bank. The banking system of Azerbaijan consists of the National Bank of Azerbaijan, commercial banks and non-banking credit organizations. The National Bank was created in 1992 based on the Azerbaijan State Savings Bank, an affiliate of the former State Savings Bank of the USSR. The National Bank serves as Azerbaijan's central bank, empowered to issue the national currency, the Azerbaijani manat, and to supervise all commercial banks. Two major commercial banks are the state-owned International Bank of Azerbaijan and the United Universal Joint-Stock Bank.
Pushed up by spending and demand growth, the 2007 Q1 inflation rate reached 16.6%. Nominal incomes and monthly wages climbed 29% and 25% respectively against this figure, but price increases in non-oil industry encouraged inflation in the country. Azerbaijan shows some signs of the so-called "Dutch disease" because of the fast growing energy sector, which causes inflation.
Two thirds of Azerbaijan is rich in oil and natural gas. The region of the Lesser Caucasus accounts for most of the country's gold, silver, iron, copper, titanium, chromium, manganese, cobalt, molybdenum, complex ore and antimony. In September 1994, a 30-year contract was signed between the State Oil Company of Azerbaijan Republic (SOCAR) and 13 oil companies, among them Amoco, BP, Exxon, LUKoil, and Statoil. As Western oil companies are able to tap deepwater oilfields untouched by the Soviet exploitation, Azerbaijan is considered one of the most important spots in the world for oil exploration and development. Meanwhile the State Oil Fund was established as an extra-budgetary fund to ensure the macroeconomic stability, transparency in the management of oil revenue, and the safeguarding of resources for future generations.
At the beginning of 2007 there were 4755100 hectares of utilized agricultural area. In the same year the total wood resources counted 136 million m³. Azerbaijan's agricultural scientific research institutes are focused on the meadows and pastures, the horticulture and subtropical crops, the green vegetables, the viticulture and wine-making, the cotton growing and the medicinal plants. In some lands it is profitable to grow grain, potatoes, sugar beet, cotton and tobacco. The Caspian fishing industry is concentrated on the dwindling stocks of sturgeon and beluga. In 2002 the Azerbaijani merchant marine had 54 ships.
Some part of most products before imported from abroad has begun to be produced locally (among them are Coca Cola by Coca Cola Bottlers LTD, beer by Baki-Kastel, parquet by Nehir and oil pipes by EUPEC Pipe Coating Azerbaijan).
Azerbaijan is also an important economic hub in terms of the raw materials transportation. The Baku-Tbilisi-Ceyhan pipeline (BTC) became operational in May 2006 and stretches over 1,774 kilometers through the territory of Azerbaijan (440 km), Georgia (260 km) and Turkey (1114 km). The BTC is designed to transport up to 50 million tons of crude oil annually and carries oil from the Caspian Sea oilfields to global markets. The South Caucasus Pipeline, also stretching through the territory of Azerbaijan, Georgia and Turkey, became operational in the end of 2006 and offers additional gas supply to European market from the Shah Deniz gas field. It is expected to produce up to 296 billion cubic metres of natural gas per year. Azerbaijan also plays a major role in the EU-sponsored Silk Road Project.
In 2002 Azerbaijan led the way in per capita mobile phone use within the CIS. Public pay phones are available for local calls and require a purchase token from the telephone exchange or some shops and kiosks. Tokens allow a call of indefinite duration. As of 2005, there were 1,091,400 main telephone lines and 408,000 internet users. There are two GSM mobile network operators and four CDMA.
Broad gauge railways in 2005 stretched for 2,957 km and electrified railways numbered 1,278 km. The number of airports in 2006 reached thirty six, there was also one heliport.
From the total population as of April, 2006 there were 4,380,000 (nearly 51%) city dwellers and a rural population of 4,060,000 (49%). 51% of the total population were female. The gender ratio for total population in that year was therefore 0.94 males per female.
2006 population growth rate was 0.66%, compared to 1.14% worldwide. A significant factor restricting the population growth is rather a high level of migration. In 2005 for instance 1,342 men and 1,564 women left the country due to labour migration. In 2006 Azerbaijan saw migration of -4.38/1,000 persons.
The highest morbidity in 2005 was among respiratory diseases (806.9 diseases per 10,000 of total population). The highest 2005 morbidity for infectious and parasitic diseases was noted among influenza and acute respiratory infections (4168,2 per 100,000 population). 2007 estimate for total life expectancy is 66 years, 70.7 years for women and 61.9 for men.
According to official figures, between 93.4% and 96% of the population is Muslim, of which 85% are Shia and 15% Sunni. Christians compose of 3-4% of the population of which most are Russian and Armenian Orthodox. In 2003 there were 250 Roman Catholics. Other Christian denominations as of 2002 include Lutherans, Baptists and Molokans. There are also Jewish, Bahá'í, Hare Krishna and Jehovah's Witnesses communities. Some of adherents are within the so-called Nehemiah Church, Star in the East Church and the Cathedral of Praise Church.
Azerbaijan folk consists of Azerbaijanis, the representative part of society, as well as of nations and ethnic groups, compactly living in various areas of the country. There are radio broadcasts in Kurdish, Lezgin, Talysh, Georgian, Russian and Armenian languages, which are financed from the state budget. The local radio station in Balakan organizes broadcasts in the Avar language and in Khachmaz also in Tat. In Baku several newspapers are published in Russian, Kurdish (Dengi Kurd), Lezgin (Samur) and Talysh languages. Jewish society "Sokhnut" publishes the newspaper Aziz.
Among national musical instruments there are fourteen string instruments, eight percussion instruments and six wind instruments.
Azerbaijan national and traditional dress, are the Chokha and Papakhi.
Azerbaijan will make its debut appearance at the Eurovision Song Contest 2008, an event that has previously been used to showcase other former Soviet and Eastern Bloc states.
Entries, submitted on the UNESCO World Heritage tentative list include the Gobustan State Reserve, the Fire Temple of Baku, the Momine Khatun Mausoleum and the Khan Palace in Sheki.


Amateur astronomy, a subset of astronomy, is a hobby whose participants enjoy studying and observing celestial objects.
The amateur astronomer is one who does not depend on the field of astronomy as a primary source of income or support, and does not have a professional degree or advanced academic training. Many amateurs are beginners, while others have a high degree in astronomy and often assist and work along side professional astronomers.
Amateur astronomy is usually associated with viewing the night sky when most celestial objects and events are visible, but sometimes amateur astronomers also operate during the day for events such as sunspots and solar eclipses. Amateur astronomers often look at the sky using nothing more than their eyes, but common tools for amateur astronomy include portable telescopes and binoculars.
People have studied the sky throughout history in an amateur framework, without any formal method of funding. It is only within about the past century, however, that amateur astronomy has become an activity clearly distinguished from professional astronomy, and other related activities.
Collectively, amateur astronomers observe a variety of celestial objects and phenomena. Common targets of amateur astronomers include the Moon, planets, stars, comets, meteor showers, and a variety of deep sky objects such as star clusters, galaxies, and nebulae. Many amateurs like to specialise in observing particular objects, types of objects, or types of events which interest them. One branch of amateur astronomy, amateur astrophotography, involves the taking of photos of the night sky. Astrophotography has become more popular for amateurs in recent times, as relatively sophisticated equipment, such as high quality CCD cameras, has become more affordable.
Most amateurs work at visible wavelengths, but a small minority experiment with wavelengths outside the visible spectrum. The pioneer of amateur radio astronomy was Karl Jansky who started observing the sky at radio wavelengths in the 1930s, and interest has increased over time. Non-visual amateur astronomy includes the use of infrared filters on conventional telescopes, and also the use of radio telescopes. Some amateur astronomers use home-made radio telescopes, while others use radio telescopes that were originally built for astronomy research but have since been made available for use by amateurs. The One-Mile Telescope is one such example.
Amateur astronomers use a range of instruments to study the sky, depending on a combination of their interests and resources. Methods include simply looking at the night sky with the naked eye, using binoculars, and using a variety of telescopes of varying power and quality, as well as additional sophisticated equipment, such as cameras, to study light from the sky in both the visual and non-visual parts of the spectrum. Commercial telescopes are available and used, but in some places it is also common for amateur astronomers to build (or commission the building of) their own custom telescope. Some people even focus on amateur telescope making as their primary interest within the hobby of amateur astronomy.
Although specialised and experienced amateur astronomers tend to acquire more specialised and more powerful equipment over time, relatively simple equipment is often preferred for certain tasks. Binoculars, for instance, although generally of lower power than the majority of telescopes, also tend to provide a wider field of view, which is preferable for looking at some objects in the night sky.
Amateur astronomers also use star charts that, depending on experience and intentions, may range from simple planispheres through to detailed charts of very specific areas of the night sky. A range of astronomy software is available and used by amateur astronomers, including software that generates maps of the sky, software to assist with astrophotography, and software to perform various calculations pertaining to astronomical phenomena.
Amateur astronomers often like to keep records of their observations, which usually takes the form of an observing log. Observing logs typically record details about which objects were observed and when, as well as describing the details that were seen. Sketching is sometimes used within logs, and photographic records of observations have also been used in recent times.
The Internet is an essential tool of amateur astronomers. Almost all astronomy clubs, even those with very few members, have a web site. The popularity of CCD imaging among amateurs means large numbers of web sites written by individuals about their images and equipment. Much of the social interaction of amateur astronomy occurs on mailing lists or discussion groups. Yahoo groups and Google groups host numerous astronomy lists. A great deal of the commerce of amateur astronomy, the buying and selling of equipment, occurs online. Many amateurs use online tools to plan their nightly observing sessions using tools such as the Clear Sky Chart.
Many methods are used in amateur astronomy to locate items in the sky, but most are variations of a few specific techniques.
Star hopping is a method often used by amateur astronomers with low-tech equipment such as binoculars or a manually driven telescope. It involves the use of maps (or memory) to locate known landmark stars, and "hopping" between them. Because of its simplicity, star hopping is a very common method for finding objects that are close to naked-eye stars.
More advanced methods of locating objects in the sky include setting circles, which assist with pointing telescopes to positions in the sky that are known to contain objects of interest, and GOTO telescopes, which are fully automated telescopes that are capable of locating objects on demand (having first been calibrated).
Setting circles are angular measurement scales that can be placed on the two main rotation axes of some telescopes. Since the widespread adoption of digital setting circles, any classical engraved setting circle is now specifically identified as an "analog setting circle" (ASC). By knowing the coordinates of an object (usually given in equatorial coordinates), the telescope user can use the setting circle to align the telescope in the appropriate direction before looking through its eyepiece. A computerized setting circle is called a "digital setting circle" (DSC). Although digital setting circles can be used to display a telescope's RA and Dec coordinates, they are not simply a digital read-out of what can be seen on the telescope's analog setting circles. As with go-to telescopes, digital setting circle computers (commercial names include Argo Navis, Sky Commander, and NGC Max) actually contain databases of tens of thousands of celestial objects and projections of planet positions.
To find an object, such as globular cluster NGC 6712, one does not need to look up the RA and Dec coordinates in a book, and then move the telescope to those numerical readings. Rather, the object is chosen from the database and arrow markers appear in the display which indicate the direction to move the telescope. The telescope is moved until the distance value reaches zero. When both the RA and Dec axes are thus "zeroed out", the object should be in the eyepiece. The user therefore does not have to go back and forth from some other database (such as a book or laptop) to match the desired object's listed coordinates to the coordinates on the telescope. However, many DSCs, and also go-to systems, can work in conjunction with laptop sky programs.
Computerized systems provide the further advantage of computing coordinate precession. Traditional printed sources are subtitled by the epoch year, which refers to the positions of celestial objects at a given time to the nearest year (e.g. J2005, J2007). Most such printed sources have been updated for intervals of only about every fifty years (e.g. J1900, J1950, J2000). Computerized sources, on the other hand, are able to calculate the right ascension and declination of the "epoch of date" to the exact instant of observation.
GOTO telescopes have become more popular in recent times as technology has improved and prices have been reduced. With these computer-driven telescopes, the user typically enters the name of the item of interest and the mechanics of the telescope point the telescope towards that item automatically. They have several notable advantages for amateur astronomers intent on research. For example, GOTO telescopes tend to be faster for locating items of interest than star hopping, allowing more time for studying of the object. GOTO also allows manufacturers to add equatorial tracking to mechanicaly simpler alt-azmuth telescope mounts, allowing them to produce an over all less expensive product.
Because GOTO telescopes have become increasingly affordable, a new type of beginning amateur astronomer has emerged, in that GOTO telescopes offer a form of instant gratification, sometimes allowing difficult objects to be found quickly without requiring the experience of learning to find them.
In the early 1990s, the amateur astronomy community engaged in some debate, usually light-hearted, about which method is superior. Some astronomers argued that beginning with the lower end of technology and using star hopping techniques is an excellent method of learning the sky, and that a good knowledge of the night sky can be advantageous for people who prefer simpler equipment with less calibration and setup time, and is therefore more versatile. Star hopping involves the use of printed media that is dependent on computer generated sources. The user prints out star maps at home or uses books, atlases, and magazine articles that have computer generated graphics in them to aid in the quest to find an object.
GOTO telescopes, on the other hand, do make the hobby more accessible. They may be preferred by people who are more serious about studying objects, because less time and effort are required for finding objects when they are well prepared. But digital setting circle or go-to systems also provide touring functions whereby the user can set parameters such as magnitude and class of object, and, for example, view a series of planetary nebulae in Cygnus. A user who has discovered that his list of close double stars is impossible to view because of the seeing conditions can select an alternative viewing program within minutes. Many middle-aged and older amateur astronomers discovered that electronic pointing systems not only were convenient but spared them the difficult postures and associated aches and pains that go with pointing a telescope at zenith (with the common straight-through finder) or near to the horizon (on elevated mounts the finder can be out of reach). The explosion of astrophotography, in which a webcam or CCD camera is mounted on a telescope and downloads data to a nearby laptop, further enhanced demand for robotic systems that would point the telescope while the operator could stay seated and set imaging parameters.
Amateur astronomers engage in many imaging techniques including film and CCD astrophotography. Because CCD imagers are linear, image processing may be used to subtract away the effects of lightpollution, which has increased the popularity of astrophotography in urban areas.
Scientific research is most often not the main goal for many amateur astronomers, unlike professional astronomy. Work of scientific merit is possible, however, and many amateurs successfully contribute to the knowledge base of professional astronomers. Astronomy is sometimes promoted as one of the few remaining sciences for which amateurs can still contribute useful data. To recognise this, the Astronomical Society of the Pacific annually gives Amateur Achievement Awards for significant contributions to astronomy by amateurs.
The majority of scientific contributions by amateur astronomers are in the area of data collection. In particular, this applies where large numbers of amateur astronomers with small telescopes are more effective than the relatively small number of large telescopes that are available to professional astronomers. Several organisations, such as the Center for Backyard Astrophysics, exist to help coordinate these contributions.
Amateur astronomers often contribute toward activities such as monitoring the changes in brightness of variable stars, helping to track asteroids, and observing occultations to determine both the shape of asteroids and the shape of the terrain on the apparent edge of the Moon as seen from Earth. With more advanced equipment, but still cheap in comparison to professional setups, amateur astronomers can measure the light spectrum emitted from astronomical objects, which can yield high-quality scientific data if the measurements are performed with due care. A relatively recent for amateur astronomers is searching for overlooked phenomena (e.g. Kreutz Sungrazers) in the vast libraries of digital images and other data captured by Earth and space based observatories, much of which is available over the Internet.
In the past and present, amateur astronomers have played a major role in discovering new comets. Recently however, funding of projects such as the Lincoln Near-Earth Asteroid Research and Near Earth Asteroid Tracking projects has meant that most comets are now discovered by automated systems, long before it is possible for amateurs to see them.
There are a large number of amateur astronomical societies around the world that serve as a meeting point for those interested in amateur astronomy, whether they be people who are actively interested in observing or "armchair astronomers" who may be simply interested in the topic. Societies range widely in their goals, depending on a variety of factors such as geographic spread, local circumstances, size, and membership. For instance, a local society in the middle of a large city may have regular meetings with speakers, focusing less on observing the night sky if the membership is less able to observe due to factors such as light pollution.
It is common for local societies to hold regular meetings, which may include activities such as star parties or presentations. Societies are also a meeting point for people with particular interests, such as amateur telescope making.

Aikido is a Japanese martial art developed by Morihei Ueshiba as a synthesis of his martial studies, philosophy, and religious beliefs. Aikido is often translated as "the Way of unifying (with) life energy" or as "the Way of harmonious spirit." Ueshiba's goal was to create an art that practitioners could use to defend themselves while also protecting their attacker from injury.
Aikido techniques are normally performed by "blending" with the motion of the attacker, rather than directly opposing the attack. The aikidoka (aikido practitioner) redirects the attacker's momentum, using minimum effort, with various types of throws or joint locks. Aikido can be categorized under the general umbrella of grappling arts.
Aikido derives mainly from the martial art of Daitō-ryū Aiki-jūjutsu, but began to diverge from it in the late 1920s, partly due to Ueshiba's involvement with the Ōmoto-kyō religion. Ueshiba's early students' documents bear the term aiki-jūjutsu. Many of Ueshiba's senior students have different approaches to aikido, depending on when they studied with him. Today aikido is found all over the world in a number of styles, with broad ranges of interpretation and emphasis. However, they all share techniques learned from Ueshiba and most have concern for the well-being of the attacker.
The term connects the practice of aikido with the philosophical concept of Tao, which can be found in martial arts such as judo and kendo, and in more peaceful arts such as Japanese calligraphy () and flower arranging (). The term refers to the martial arts principle or tactic of blending with an attacker's movements for the purpose of controlling their actions with minimal effort. One applies by understanding the rhythm and intent of the attacker to find the optimal position and timing to apply a counter-technique. Historically, was mastered for the purpose of killing; however, in aikido, one seeks to neutralise an aggressor without causing harm. The founder of aikido declared, "To control aggression without inflicting injury is the Art of Peace." A number of aikido practitioners interpret aikido metaphorically, seeing parallels between aikido techniques and other methods for conflict resolution. These kanji are identical to the Korean versions of the characters that form the word hapkido, a Korean martial art. Although there are no known direct connections between the two arts, it is suspected that the founders of both arts trained in Daitō-ryū Aiki-jūjutsu.
Aikido was created by Morihei Ueshiba (植芝 盛平, 14 December 1883–26 April 1969), referred to by some aikido practitioners as ("Great Teacher"). Ueshiba envisioned aikido not only as the synthesis of his martial training, but also an expression of his personal philosophy of universal peace and reconciliation. During Ueshiba's lifetime and continuing today, aikido has evolved from the koryū (old-style martial arts) that Ueshiba studied into a wide variety of expressions by martial artists throughout the world.
Ueshiba developed aikido primarily during the late 1920s through the 1930s through the synthesis of the older martial arts that he had studied. The core martial art from which aikido derives is Daitō-ryū aiki-jūjutsu, which Ueshiba studied directly with Takeda Sokaku, the revivor of that art. Additionally, Ueshiba is known to have studied Tenjin Shin'yō-ryū with Tozawa Tokusaburō in Tokyo in 1901, Gotōha Yagyū Shingan-ryū under Nakai Masakatsu in Sakai from 1903 to 1908, and judo with Kiyoichi Takagi (高木 喜代子, 1894–1972) in Tanabe in 1911.
The art of Daitō-ryū is the primary technical influence on aikido. Along with empty-handed throwing and joint-locking techniques, Ueshiba incorporated training movements with weapons, such as those for the spear (), short staff (), and perhaps the bayonet. However, aikido derives much of its technical structure from the art of swordsmanship ().
Ueshiba moved to Hokkaidō in 1912, and began studying under Takeda Sokaku in 1915. His official association with Daitō-ryū continued until 1937. However, during the latter part of that period, Ueshiba had already begun to distance himself from Takeda and the Daitō-ryū. At that time Ueshiba was referring to his martial art as "Aiki Budō". It is unclear exactly when Ueshiba began using the name "aikido", but it became the official name of the art in 1942 when the Greater Japan Martial Virtue Society () was engaged in a government sponsored reorganization and centralization of Japanese martial arts.
After Ueshiba left Hokkaidō in 1919, he met and was profoundly influenced by Onisaburo Deguchi, the spiritual leader of the Ōmoto-kyō religion (a neo-Shinto movement) in Ayabe. One of the primary features of Ōmoto-kyō is its emphasis on the attainment of utopia during one's life. This was a great influence on Ueshiba's martial arts philosophy of extending love and compassion, especially to those who seek to harm others. Aikido demonstrates this philosophy in its emphasis on mastering martial arts so that one may receive an attack and harmlessly redirect it. In an ideal resolution, not only is the receiver unharmed, but so is the attacker.
In addition to the effect on his spiritual growth, the connection with Deguchi gave Ueshiba entry to elite political and military circles as a martial artist. As a result of this exposure, he was able to attract not only financial backing but also gifted students. Several of these students would found their own styles of aikido.
Aikido was first brought to the West in 1951 by Minoru Mochizuki with a visit to France where he introduced aikido techniques to judo students. He was followed by Tadashi Abe in 1952 who came as the official Aikikai Hombu representative, remaining in France for seven years. Kenji Tomiki toured with a delegation of various martial arts through fifteen continental states of the United States in 1953. Later in that year, Koichi Tohei was sent by Aikikai Hombu to Hawaii, for a full year, where he set up several dojo. This was followed up by several further visits and is considered the formal introduction of aikido to the United States. The United Kingdom followed in 1955; Italy in 1964; Germany and Australia in 1965. Designated "Delegate for Europe and Africa" by Morihei Ueshiba himself, Masamichi Noro arrived in France in September 1961. Today there are aikido dojo available to train throughout the world.
The biggest aikido organisation is the Aikikai Foundation which remains under the control of the Ueshiba family. However, aikido has many styles, mostly formed by Morihei Ueshiba's major students.
The earliest independent styles to emerge were Yoseikan Aikido, begun by Minoru Mochizuki in 1931, Yoshinkan Aikido founded by Gozo Shioda in 1955, and Shodokan Aikido, founded by Kenji Tomiki in 1967. The emergence of these styles pre-dated Ueshiba's death and did not cause any major upheavals when they were formalized. Shodokan Aikido, however, was controversial, since it introduced a unique rule-based competition that some felt was contrary to the spirit of aikido.
After Ueshiba's death in 1969, two more major styles emerged. Significant controversy arose with the departure of the Aikikai Hombu Dojo's chief instructor Koichi Tohei, in 1974. Tohei left as a result of a disagreement with the son of the founder, Kisshomaru Ueshiba, who at that time headed the Aikikai Foundation. The disagreement was over the proper role of ki development in regular aikido training. After Tohei left, he formed his own style, called Shin Shin Toitsu Aikido, and the organization which governs it, the Ki Society.
A final major style evolved from Ueshiba's retirement in Iwama, Ibaraki, and the teaching methodology of long term student Morihiro Saito. It is unofficially referred to as the "Iwama style", and at one point a number of its followers formed a loose network of schools they called Iwama Ryu. Although Iwama style practitioners remained part of the Aikikai until Saito's death in 2002, followers of Saito subsequently split into two groups; one remaining with the Aikikai and the other forming the independent organization the Shinshin Aikishuren Kai, in 2004 around Saito's son Hitohiro Saito.
Today, the major styles of aikido are each run by a separate governing organization, have their own headquarters in Japan, and have an international breadth.
In aikido, as in virtually all Japanese martial arts, there are both physical and mental aspects of training. The physical training in aikido is diverse, covering both general physical fitness and conditioning, as well as specific techniques. Because a substantial portion of any aikido curriculum consists of throws, the first thing most students learn is how to safely fall or roll. The specific techniques for attack include both strikes and grabs; the techniques for defense consist of throws and pins. After basic techniques are learned, students study freestyle defense against multiple opponents, and in certain styles, techniques with weapons.
Physical training goals pursued in conjunction with aikido include controlled relaxation, flexibility, and endurance, with less emphasis on strength training. In aikido technique, pushing or extending movements are much more common than pulling or contracting movements found in other arts, and this distinction can be applied to general fitness goals for the aikido practitioner.
Certain anaerobic fitness activities, such as weight training, emphasize contractionary power, in which specific muscles or muscle groups are isolated and worked to improve tone, mass, and power. Aikido-related training instead emphasizes the use of coordinated whole-body movement and balance, more similar to yoga or pilates. For example, many dojo begin each class with warm-up exercises, which may include stretching and break falls.
Aikido training is based primarily on two partners practicing pre-arranged forms (kata) rather than freestyle practice. The basic pattern is for the receiver of the technique (uke) to initiate an attack against the thrower (投げ nage, also referred to as 取り tori, or 仕手 shite, depending on aikido style), who neutralises this attack with an aikido technique.
Both halves of the technique, that of uke and that of nage, are considered essential to aikido training. Both are studying aikido principles of blending and adaptation. Nage learns to blend with and control attacking energy, while uke learns to become calm and flexible in the disadvantageous, off-balance positions in which nage places them. This "receiving" of the technique is called ukemi. Uke continuously seeks to regain balance and cover vulnerabilities (e.g. an exposed side), while nage uses position and timing to keep uke off-balance and vulnerable. In more advanced training, uke will sometimes apply reversal techniques to regain balance and pin or throw nage.
Ukemi refers to the act of receiving a technique. Good ukemi involves a parry or breakfall that is used to avoid pain or injury, such as joint dislocations or atemi.
Aikido techniques are usually a defense against an attack; therefore, to practice aikido with their partner, students must learn to deliver various types of attacks. Although attacks are not studied as thoroughly as in striking-based arts, "honest" attacks (a strong strike or an immobilizing grab) are needed to study correct and effective application of technique.
Aikido makes use of body movement (tai sabaki) to blend with uke. For example, an "entering" (irimi) technique consists of movements inward towards uke, while a "turning" technique uses a pivoting motion.
Additionally, an "inside" technique takes place in front of uke, whereas an "outside" technique takes place to his side; a "front" technique is applied with motion to the front of uke, and a "rear" version is applied with motion towards the rear of uke, usually by incorporating a turning or pivoting motion. Finally, most techniques can be performed while in a seated posture (seiza). Seated techniques are called suwari-waza.
Thus, from fewer than twenty basic techniques, there are thousands of possible implementations. For instance, ikkyō can be applied to an opponent moving forward with a strike (perhaps with an ura type of movement to redirect the incoming force), or to an opponent who has already struck and is now moving back to reestablish distance (perhaps an omote-waza version). Specific aikido kata are typically referred to with the formula "attack-technique(-modifier)". For instance, katate-dori ikkyō refers to any ikkyō technique executed when uke is holding one wrist. This could be further specified as katate-dori ikkyō omote, referring to any forward-moving ikkyō technique from that grab.
Atemi (当て身) are strikes (or feints) employed during an aikido technique. Some view atemi as attacks against "vital points" meant to cause damage in and of themselves. For instance, Gōzō Shioda described using atemi in a brawl to quickly down a gang's leader. Others consider atemi, especially to the face, to be methods of distraction meant to enable other techniques. A strike, whether or not it is blocked, can startle the target and break his or her concentration. The target may also become unbalanced in attempting to avoid the blow, for example by jerking the head back, which may allow for an easier throw.
Many sayings about atemi are attributed to Morihei Ueshiba, who considered them an essential element of technique.
Weapons training in aikido traditionally includes the short staff (jō), wooden sword (bokken), and knife (tantō). Today, some schools also incorporate firearms-disarming techniques. Both weapon-taking and weapon-retention are sometimes taught, to integrate armed and unarmed aspects, although some schools of aikido do not train with weapons at all. Others, such as the Iwama style of Morihiro Saito, usually spend substantial time with bokken and jō, practised under the names aiki-ken, and aiki-jō, respectively. The founder developed much of empty handed aikido from traditional sword and spear movements, so the practice of these movements is generally for the purpose of giving insight into the origin of techniques and movements, as well as vital practice of these basic building blocks.
One feature of aikido is training to defend oneself against multiple attackers. Freestyle (randori, or jiyūwaza) practice with multiple attackers is a key part of most curricula and is required for the higher level ranks. Randori exercises a person's ability to intuitively perform techniques in an unstructured environment. Strategic choice of techniques, based on how they reposition the student relative to other attackers, is important in randori training. For instance, an ura technique might be used to neutralise the current attacker while turning to face attackers approaching from behind.
In Shodokan Aikido, randori differs in that it is not performed with multiple persons with defined roles of defender and attacker, but between two people, where both participants attack, defend, and counter at will. In this respect it resembles judo randori.
In applying a technique during training, it is the responsibility of nage to prevent injury to uke by employing a speed and force of application that is commensurate with their partner's proficiency in ukemi. Injuries (especially those to the joints), when they do occur in aikido, are often the result of nage misjudging the ability of uke to receive the throw or pin.
A study of injuries in the martial arts showed that while the type of injuries varied considerably from one art to the other, the differences in overall rates of injury were much less pronounced. Soft tissue injuries are one of the most common types of injuries found within aikido although a few deaths from repetitive "shihōnage" have been reported.
Aikido training is mental as well as physical, emphasizing the ability to relax the mind and body even under the stress of dangerous situations. This is necessary to enable the practitioner to perform the bold enter-and-blend movements that underlie aikido techniques, wherein an attack is met with confidence and directness. Morihei Ueshiba once remarked that one "must be willing to receive 99% of an opponent's attack and stare death in the face" in order to execute techniques without hesitation. As a martial art concerned not only with fighting proficiency but also with the betterment of daily life, this mental aspect is of key importance to aikido practitioners.
The study of ki is a critical component of aikido, and its study defies categorization as either "physical" or "mental" training, as it encompasses both. The original kanji for ki was 氣 (shown right), and is a symbolic representation of a lid covering a pot full of rice; the "nourishing vapors" contained within are ki.
The character "ki" is used in everyday Japanese terms, such as "health", or "shyness". Ki is most often understood as unified physical and mental intention, however it is often found in traditional martial arts related with "life energy". Gōzō Shioda's Yoshinkan Aikido, considered one of the 'hard styles', largely follows Ueshiba's teachings from before World War II, and surmises that the secret to ki lies in timing and the application of the whole body's strength to a single point. In later years, Ueshiba's application of ki in aikido took on a softer, more gentle feel. This was his Takemusu Aiki and many of his later students teach about ki from this perspective. Koichi Tohei's Ki Society centers almost exclusively around the study of the empirical (albeit subjective) experience of ki with students ranked separately in aikido techniques and ki development.
Aikido practitioners, commonly called aikidōka, generally progress by promotion through a series of "grades" (kyū), followed by a series of "degrees" (dan), pursuant to formal testing procedures. Most aikido organisations use only white and black belts to distinguish rank, but some use various belt colors. Testing requirements vary, so a particular rank in one organization is not always comparable or interchangeable with the rank of another.
The uniform worn for practicing aikido (aikidōgi) is similar to the training uniform (keikogi) used in most other modern martial arts; simple trousers and a wraparound jacket, usually white. Both thick ("judo-style"), and thin ("karate-style") cotton tops are used. Aikido-specific tops are also available with shorter sleeves which reach to just below the elbow.
Most aikido systems also add a pair of wide pleated black or indigo trousers called a hakama. In many styles its use is reserved for practitioners with black belt (dan) ranks, while others allow all practitioners or female practitioners to wear a hakama regardless of rank.
The most common criticism of aikido is that it suffers from a lack of realism in training. This generalized observation manifests in several different facets of practice. First, the attacks initiated by uke (and which nage must defend against) have been criticized as being "sloppy," and "little more than caricatures of an attack." This creates a domino effect of training ineffective defensive techniques by nage, and the underdevelopment of strength and conditioning needed for safe practice. To counteract this, a number of styles allow both training partners, after having demonstrated proficiency in being able to protect themselves and their training partners, to become less compliant over time. Other styles, most notably Shodokan Aikido, have addressed the issue by introducing fully resistive training and a competitive format.
Another criticism, related to the first, is that after the end of Ueshiba's seclusion in Iwama from 1942 to the mid 1950s, he increasingly emphasized the spiritual and philosophical aspects of aikido. As a result, strikes to vital points by nage, entering (irimi) and initiation of techniques by nage, the distinction between omote and ura techniques, and the practice of weapons, were all deemphasized or eliminated from practice. Lack of training in these areas is thought to lead to an overall loss of effectiveness by some aikido practitioners.


Art refers to a diverse range of human activities and artifacts, and may be used to cover all or any of the arts, including music, literature and other forms. It is most often used to refer specifically to the visual arts, including media such as painting, sculpture, and printmaking. However it can also be applied to forms of art that stimulate the other senses, such as music, an auditory art. Aesthetics is the branch of philosophy which considers art.
Traditionally the term art was used to refer to any skill or mastery, a concept which altered during the Romantic period, when art came to be seen as "a special faculty of the human mind to be classified with religion and science". Generally art is a (product of) human activity, made with the intention of stimulating the human senses as well as the human mind; by transmitting emotions and/or ideas. Beyond this description, there is no general agreed-upon definition of art. Art is also able to illustrate abstract thought and its expressions can elicit previously hidden emotions in its audience.
The evaluation of art has become especially problematic since the 20th century. Richard Wollheim distinguishes three approaches: the Realist, whereby aesthetic quality is an absolute value independent of any human view; the Objectivist, whereby it is also an absolute value, but is dependent on general human experience; and the Relativist position, whereby it is not an absolute value, but depends on, and varies with, the human experience of different humans. An object may be characterized by the intentions, or lack thereof, of its creator, regardless of its apparent purpose. A cup, which ostensibly can be used as a container, may be considered art if intended solely as an ornament, while a painting may be deemed craft if mass-produced.
Visual art is defined as the arrangement of colors, forms, or other elements "in a manner that affects the sense of beauty, specifically the production of the beautiful in a graphic or plastic medium". The nature of art has been described by Wollheim as "one of the most elusive of the traditional problems of human culture". It has been defined as a vehicle for the expression or communication of emotions and ideas, a means for exploring and appreciating formal elements for their own sake, and as mimesis or representation. Leo Tolstoy identified art as a use of indirect means to communicate from one person to another. Benedetto Croce and R.G. Collingwood advanced the idealist view that art expresses emotions, and that the work of art therefore essentially exists in the mind of the creator. Art as form has its roots in the philosophy of Immanuel Kant, and was developed in the early twentieth century by Roger Fry and Clive Bell. Art as mimesis or representation has deep roots in the philosophy of Aristotle.
The most common usage of the word "art," which rose to prominence after 1750, is understood to denote skill used to produce an aesthetic result. Britannica Online defines it as "the use of skill and imagination in the creation of aesthetic objects, environments, or experiences that can be shared with others." By any of these definitions of the word, artistic works have existed for almost as long as humankind: from early pre-historic art to contemporary art. Much has been written about the concept of "art". Where Adorno said in 1970 "It is now taken for granted that nothing which concerns art can be taken for granted any more[..],", The first and broadest sense of art is the one that has remained closest to the older Latin meaning, which roughly translates to "skill" or "craft," and also from an Indo-European root meaning "arrangement" or "to arrange". In this sense, art is whatever is described as having undergone a deliberate process of arrangement by an agent. A few examples where this meaning proves very broad include artifact, artificial, artifice, artillery, medical arts, and military arts. However, there are many other colloquial uses of the word, all with some relation to its etymology.
The second and more recent sense of the word art is as an abbreviation for creative art or fine art. Fine art means that a skill is being used to express the artist’s creativity, or to engage the audience’s aesthetic sensibilities, or to draw the audience towards consideration of the finer things. Often, if the skill is being used in a common or practical way, people will consider it a craft instead of art. Likewise, if the skill is being used in a commercial or industrial way, it will be considered Commercial art instead of art. On the other hand, crafts and design are sometimes considered applied art. Some art followers have argued that the difference between fine art and applied art has more to do with value judgments made about the art than any clear definitional difference. However, even fine art often has goals beyond pure creativity and self-expression. The purpose of works of art may be to communicate ideas, such as in politically-, spiritually-, or philosophically-motivated art; to create a sense of beauty (see aesthetics); to explore the nature of perception; for pleasure; or to generate strong emotions. The purpose may also be seemingly nonexistent.
The ultimate derivation of fine in fine art comes from the philosophy of Aristotle, who proposed four causes or explanations of a thing. The final cause of a thing is the purpose for its existence, and the term fine art is derived from this notion. If the final cause of an artwork is simply the artwork itself, "art for art's sake", and not a means to another end, then that artwork could appropriately be called fine. The closely related concept of beauty is classically defined as "that which when seen, pleases". Pleasure is the final cause of beauty and thus is not a means to another end, but an end in itself.
Art can describe several things: a study of creative skill, a process of using the creative skill, a product of the creative skill, or the audience’s experience with the creative skill. The creative arts (art as discipline) are a collection of disciplines (arts) that produce artworks (art as objects) that are compelled by a personal drive (art as activity) and echo or reflect a message, mood, or symbolism for the viewer to interpret (art as experience). Artworks can be defined by purposeful, creative interpretations of limitless concepts or ideas in order to communicate something to another person. Artworks can be explicitly made for this purpose or interpreted based on images or objects. Art is something that stimulates an individual's thoughts, emotions, beliefs, or ideas through the senses. It is also an expression of an idea and it can take many different forms and serve many different purposes. Although the application of scientific theories to derive a new scientific theory involves skill and results in the "creation" of something new, this represents science only and is not categorized as art.
After Greenberg, several important art theorists emerged, such as Michael Fried, T. J. Clark, Rosalind Krauss, Linda Nochlin and Griselda Pollock among others. Though only originally intended as a way of understanding a specific set of artists, Greenberg's definition of Modern Art underlies most of the ideas of art within the various art movements of the 20th century and early 21st century. The art of Marcel Duchamp becomes clear when seen within this context; when submitting a urinal, titled fountain, to the Society of Independent Artists exhibit in 1917 he was critiquing the art exhibition using its own methods.
Pop artists like Andy Warhol became both noteworthy and influential through critiquing popular culture, as well as the art world, through the language of that popular culture. Certain radical artists of the 1980s, 1990s, and 2000s took those ideas further by expanding this technique of self-criticism beyond high art to all cultural image-making, including fashion images, comics, billboards and pornography.
One of the defining characteristics of fine art as opposed to applied art is the absence of any clear usefulness or utilitarian value. However, this requirement is sometimes criticized as being class prejudice against labor and utility. Opponents of the view that art cannot be useful, argue that all human activity has some utilitarian function, and the objects claimed to be "non-utilitarian" actually have the function of attempting to mystify and codify flawed social hierarchies. It is also sometimes argued that even seemingly non-useful art is not useless, but rather that its use is the effect it has on the psyche of the creator or viewer.
Art is also used by art therapists, psychotherapists and clinical psychologists as art therapy. Art can also be used as a tool of Personality Test. The end product is not the principal goal in this case, but rather a process of healing, through creative acts, is sought. The resultant piece of artwork may also offer insight into the troubles experienced by the subject and may suggest suitable approaches to be used in more conventional forms of psychiatric therapy.
Graffiti art and other types of street art are graphics and images that are spray-painted or stencilled on publicly viewable walls, buildings, buses, trains, and bridges, usually without permission. This type of art is part of various youth cultures, such as the US hip-hop culture. It is used to express political views and depict creative images.
In a social context, art can serve to boost the public's morale. Art is often utilized as a form of propaganda, and thus can be used to subtly influence popular conceptions or mood. In some cases, artworks are appropriated to be used in this manner, without the creator having initially intended the art to be used as propaganda. From an anthropological perspective, art is often a way of passing ideas and concepts on to later generations in a (somewhat) universal language. The interpretation of this language depends upon the observer’s perspective and context. So conversely the very subjectivity of art demonstrates its importance in facilitating the exchange and discussion of rival ideas, or to provide a social context in which disparate groups of people might congregate and mingle.
It is common in the history of art for people to dispute whether a particular form or work, or particular piece of work counts as art or not. In fact for much of the past century the idea of art has been to simply challenge what art is. Philosophers of Art call these disputes "classificatory disputes about art." For example, Ancient Greek philosophers debated about whether or not ethics should be considered the "art of living well". Classificatory disputes in the 20th century included: cubist and impressionist paintings, Duchamp’s Fountain, the movies, superlative imitations of banknotes, propaganda, and even a crucifix immersed in urine. Conceptual art often intentionally pushes the boundaries of what counts as art. New media such as Video games slowly become co-opted by artists and/or recognized as art forms in its own right, though these new classification shifts are not universally adopted and remain the subject of dispute.
Theodore Gericault's "Raft of the Medusa" (1820), was a social commentary on a current event, unprecedented at the time. Edouard Manet's "Le Déjeuner sur l'Herbe" (1863), was considered scandalous not because of the nude woman, but because she is seated next to fully-dressed men. John Singer Sargent's "Madame Pierre Gautreau (Madam X)" (1884), caused a huge uproar over the reddish pink used to color the woman's ear lobe, considered far too suggestive and supposedly ruining the high-society model's reputation.
In the twentieth century, Pablo Picasso's Guernica (1937) used arresting cubist techniques and stark monochromatic oils, to depict the harrowing consequences of a contemporary bombing of a small, ancient Basque town. Leon Golub's Interrogation III (1981), depicts a female nude, hooded detainee strapped to a chair, her legs open to reveal her sexual organs, surrounded by two tormentors dressed in everyday clothing. Andres Serrano's Piss Christ (1989) is a photograph of a crucifix, sacred to the Christian religion and representing Christ's sacrifice and final suffering, submerged in a glass of the artist's own urine. The resulting uproar led to comments in the United States Senate about public funding of the arts.
In the twenty-first century, Eric Fischl created Tumbling Woman as a memorial to those who jumped or fell to their death in the attacks on the World Trade Center on September 11, 2001. Initially installed at Rockefeller Center in New York City, within a year the work was removed as too disturbing.
Art has been perceived by some as belonging to some social classes and often excluding others. In this context, art is seen as an upper-class activity associated with wealth, the ability to purchase art, and the leisure required to pursue or enjoy it. For example, the palaces of Versailles or the Hermitage in St. Petersburg with their vast collections of art, amassed by the fabulously wealthy royalty of Europe exemplify this view. Collecting such art is the preserve of the rich, or of governments and institutions.
Fine and expensive goods have been popular markers of status in many cultures, and continue to be so today. There has been a cultural push in the other direction since at least 1793, when the Louvre, which had been a private palace of the Kings of France, was opened to the public as an art museum during the French Revolution. Most modern public museums and art education programs for children in schools can be traced back to this impulse to have art available to everyone. Museums in the United States tend to be gifts from the very rich to the masses (The Metropolitan Museum of Art in New York City, for example, was created by John Taylor Johnston, a railroad executive whose personal art collection seeded the museum.) But despite all this, at least one of the important functions of art in the 21st century remains as a marker of wealth and social status.
The creative arts are often divided into more specific categories, such as decorative arts, plastic arts, performing arts, or literature. So for example painting is a form of visual art, and poetry is a form of literature. An art form is a specific form for artistic expression to take; it is a more specific term than art, but less specific than genre. An artistic medium is the substance the artistic work is made out of. So for example, stone and bronze are both mediums that sculpture uses sometimes. Multiple forms can share a medium (poetry and music, both use sound), or one form can use multiple media.
An artwork, artist’s, or movement's style is the distinctive method and form that art takes. Any loose brushy, dripped or poured abstract painting is called expressionistic (with a lower case "e" and the "ic" at the end). Often these styles are linked with a particular historical period, set of ideas, and particular artistic movement. So Jackson Pollock is called an Abstract Expressionist. Because a particular style has very specific cultural meanings it is important to be sensitive to differences in technique. Roy Lichtenstein's paintings are not pointillist, despite his uses of dots, because they are not aligned with the original proponents of Pointillism. Lichtenstein used Ben-Day dots: they are evenly-spaced and create flat areas of color. These types of dots were used to color comic strips and are intended to combine the "high" art of painting with the "low" art of comics - to comment on culture and its unreality. Pointillism employs dots that are spaced in a way to create variation in color and depth - it was an attempt to paint images that were closer to the way we really see color - an attempt to get closer to reality. They both use dots but the meaning is opposite.
Art predates history; sculptures, cave paintings, rock paintings, and petroglyphs from the Upper Paleolithic starting roughly 40,000 years ago have been found, but the precise meaning of such art is often disputed because so little is known about the cultures that produced them. The oldest art objects in the world: a series of tiny, drilled snail shells about 75,000yrs old, were discovered in a South African cave.
In Byzantine and Gothic art of the Western Middle Ages, art focused on the expression of Biblical and not material truths, and emphasized methods which would show the higher unseen glory of a heavenly world, such as the use of gold in paintings, or glass in mosaics or windows, which also presented figures in idealized, patterned (flat) forms.
The western Renaissance saw a return to valuation of the material world, and the place of humans in it, and this paradigm shift is reflected in art forms, which show the corporeality of the human body, and the three dimensional reality of landscape.
In the east, Islamic art's rejection of iconography led to emphasis on geometric patterns, Islamic calligraphy, and architecture. Further east, religion dominated artistic styles and forms too. India and Tibet saw emphasis on painted sculptures and dance with religious painting borrowing many conventions from sculpture and tending to bright contrasting colors with emphasis on outlines. China saw many art forms flourish, jade carving, bronzework, pottery (including the stunning terracotta army of Emperor Qin), poetry, calligraphy, music, painting, drama, fiction, etc. Chinese styles vary greatly from era to era and are traditionally named after the ruling dynasty. So, for example, Tang Dynasty paintings are monochromatic and sparse, emphasizing idealized landscapes, but Ming Dynasty paintings are busy, colorful, and focus on telling stories via setting and composition. Japan names its styles after imperial dynasties too, and also saw much interplay between the styles of calligraphy and painting. Woodblock printing became important in Japan after the 17th century.
The western Age of Enlightenment in the 18th century saw artistic depictions of physical and rational certainties of the clockwork universe, as well as politically revolutionary visions of a post-monarchist world, such as Blake’s portrayal of Newton as a divine geometer, or David’s propagandistic paintings. This led to Romantic rejections of this in favor of pictures of the emotional side and individuality of humans, exemplified in the novels of Goethe. The late 19th century then saw a host of artistic movements, such as academic art, symbolism, impressionism and fauvism among others.
By the 20th century these pictures were falling apart, shattered not only by new discoveries of relativity by Einstein and of unseen psychology by Freud, but also by unprecedented technological development accelerated by the implosion of civilisation in two world wars. The history of twentieth century art is a narrative of endless possibilities and the search for new standards, each being torn down in succession by the next. Thus the parameters of Impressionism, Expressionism, Fauvism, Cubism, Dadaism, Surrealism, etc cannot be maintained very much beyond the time of their invention. Increasing global interaction during this time saw an equivalent influence of other cultures into Western art, such as Pablo Picasso being influenced by African sculpture. Japanese woodblock prints (which had themselves been influenced by Western Renaissance draftsmanship) had an immense influence on Impressionism and subsequent development. Later, African sculptures were taken up by Picasso and to some extent by Matisse. Similarly, the west has had huge impacts on Eastern art in 19th and 20th century, with originally western ideas like Communism and Post-Modernism exerting powerful influence on artistic styles.
Modernism, the idealistic search for truth, gave way in the latter half of the 20th century to a realization of its unattainability. Relativity was accepted as an unavoidable truth, which led to the period of contemporary art and postmodern criticism, where cultures of the world and of history are seen as changing forms, which can be appreciated and drawn from only with irony. Furthermore the separation of cultures is increasingly blurred and some argue it is now more appropriate to think in terms of a global culture, rather than regional cultures.
Art tends to facilitate intuitive rather than rational understanding, and is usually consciously created with this intention. Fine art intentionally serves no other purpose. As a result of this impetus, works of art are elusive, refractive to attempts at classification, because they can be appreciated in more than one way, and are often susceptible to many different interpretations. In the case of Gericault's Raft of the Medusa, special knowledge concerning the shipwreck that the painting depicts is not a prerequisite to appreciating it, but allows the appreciation of Gericault's political intentions in the piece. Even art that superficially depicts a mundane event or object, may invite reflection upon elevated themes.
Traditionally, the highest achievements of art demonstrate a high level of ability or fluency within a medium. This characteristic might be considered a point of contention, since many modern artists (most notably, conceptual artists) do not themselves create the works they conceive, or do not even create the work in a conventional, demonstrative sense. Art has a transformative capacity: confers particularly appealing or aesthetically satisfying structures or forms upon an original set of unrelated, passive constituents.
Art can connote a sense of trained ability or mastery of a medium. Art can also simply refer to the developed and efficient use of a language to convey meaning with immediacy and or depth. Art is an act of expressing our feelings, thoughts, and observations. There is an understanding that is reached with the material as a result of handling it, which facilitates one's thought processes.
A common view is that the epithet "art", particular in its elevated sense, requires a certain level of creative expertise by the artist, whether this be a demonstration of technical ability or an originality in stylistic approach such as in the plays of Shakespeare, or a combination of these two. Traditionally skill of execution was viewed as a quality inseparable from art and thus necessary for its success; for Leonardo da Vinci, art, neither more nor less than his other endeavors, was a manifestation of skill. Rembrandt's work, now praised for its ephemeral virtues, was most admired by his contemporaries for its virtuosity. At the turn of the 20th century, the adroit performances of John Singer Sargent were alternately admired and viewed with skepticism for their manual fluency, yet at nearly the same time the artist who would become the era's most recognized and peripatetic iconoclast, Pablo Picasso, was completing a traditional academic training at which he excelled.
A common contemporary criticism of some modern art occurs along the lines of objecting to the apparent lack of skill or ability required in the production of the artistic object. One might take Tracey Emin's My Bed, or Hirst's The Physical Impossibility of Death in the Mind of Someone Living, as examples of pieces wherein the artist exercised little to no traditionally recognised set of skills, but may be said to have innovated by exercising skill in manipulating the mass media as a medium. In the first case, Emin simply slept (and engaged in other activities) in her bed before placing the result in a gallery. She has been insistent that there is a high degree of selection and arrangement in this work, which include objects such as underwear and bottles around the bed. The shocking mundanity of this arrangement has proved to be startling enough to lead others to begin to interpret the work as art. In the second case, Hirst came up with the conceptual design for the artwork. Although he physically participated in the creation of this piece, he has left the eventual creation of many other works to employed artisans. In this case the celebrity of Hirst is founded entirely on his ability to produce shocking concepts. The actual production is, as with most objects, a matter of assembly. These approaches are exemplary of a particular kind of contemporary art known as conceptual art.
Somewhat in relation to the above, the word art is also used to apply judgments of value, as in such expressions like "that meal was a work of art" (the cook is an artist), or "the art of deception," (the highly attained level of skill of the deceiver is praised). It is this use of the word as a measure of high quality and high value that gives the term its flavor of subjectivity.
Making judgments of value requires a basis for criticism. At the simplest level, a way to determine whether the impact of the object on the senses meets the criteria to be considered art, is whether it is perceived to be attractive or repulsive. Though perception is always colored by experience, and is necessarily subjective, it is commonly taken that - that which is not aesthetically satisfying in some fashion cannot be art. However, "good" art is not always or even regularly aesthetically appealing to a majority of viewers. In other words, an artist's prime motivation need not be the pursuit of the aesthetic. Also, art often depicts terrible images made for social, moral, or thought-provoking reasons. For example, Francisco Goya's painting depicting the Spanish shootings of 3rd of May 1808, is a graphic depiction of a firing squad executing several pleading civilians. Yet at the same time, the horrific imagery demonstrates Goya's keen artistic ability in composition and execution and produces fitting social and political outrage. Thus, the debate continues as to what mode of aesthetic satisfaction, if any, is required to define 'art'.
The assumption of new values or the rebellion against accepted notions of what is aesthetically superior need not occur concurrently with a complete abandonment of the pursuit of that which is aesthetically appealing. Indeed, the reverse is often true, that in the revision of what is popularly conceived of as being aesthetically appealing, allows for a re-invigoration of aesthetic sensibility, and a new appreciation for the standards of art itself. Countless schools have proposed their own ways to define quality, yet they all seem to agree in at least one point: once their aesthetic choices are accepted, the value of the work of art is determined by its capacity to transcend the limits of its chosen medium in order to strike some universal chord by the rarity of the skill of the artist or in its accurate reflection in what is termed the zeitgeist.
Art is often intended to appeal and connect with human emotion. It can arouse aesthetic or moral feelings, and can be understood as a way of communicating these feelings. Artists express something so that their audience is aroused to some extent, but they do not have to do so consciously. Art explores what is commonly termed as the human condition that is essentially what it is to be human.
Effective art often brings about some new insight concerning the human condition either singly or en-mass, which is not necessarily always positive, or necessarily widens the boundaries of collective human ability. The degree of skill that the artist has, will affect their ability to trigger an emotional response and thereby provide new insights, the ability to manipulate them at will shows exemplary skill and determination.

An actor, actress, player or rarely thespian (see terminology) is a person who acts in a dramatic production and who works in film, television, theatre, or radio in that capacity. The ancient Greek word for an actor, hypokrites, when rendered as a verb means "to interpret"; in this sense, an actor is one who interprets a dramatic character.
The word actor refers to one who acts, while actress refers specifically to a female who acts. The Oxford English Dictionary states that originally "'actor' was used for both sexes". The English word actress does not derive from the Latin actrix, probably not even by way of French actrice; according to the Oxford English Dictionary, actress was "probably formed independently" in English. As actress is a specifically feminine word, some feminists assert that the word is sexist. Gender-neutral usage of actor has re-emerged in modern English, especially when referring to male and female performers collectively, but actress remains a commonly used word.
The gender-neutral term player was common in film in the early days of the Production Code, but is now generally deemed archaic. However, it remains in use in the theatre, often incorporated into the name of a theatre group or company (such as the East West Players).
The first recorded case of an actor performing took place in 534 BC (probably on 23 November, though the changes in calendar over the years make it hard to determine exactly) when the Greek performer Thespis stepped on to the stage at the Theatre Dionysus and became the first known person to speak words as a character in a play or story. Prior to Thespis' act, stories were only known to be told in song and dance and in third person narrative. In honour of Thespis,a 6th century B.C poet, actors are commonly called Thespians. Theatrical legend to this day maintains that Thespis exists as a mischievous spirit, and disasters in the theatre are sometimes blamed on his ghostly intervention.
Actors were traditionally not people of high status, and in the Early Middle Ages travelling acting troupes were often viewed with distrust. In many parts of Europe, actors could not even receive a Christian burial, and traditional beliefs of the region and time period held that this left any actor forever condemned. However, this negative perception was largely reversed in the 19th and 20th centuries as acting has become an honored and popular profession and art. Part of the cause is the easier popular access to dramatic film entertainment and the resulting rise of the movie star — as regards both their social status and the salaries they command. The combination of public presence and wealth has profoundly rehabilitated their image.
In the past, only men could become actors in some societies. In the ancient Greece and Rome and the medieval world, it was considered disgraceful for a woman to go on the stage, and this belief continued right up until the 17th century, when in Venice it was broken. In the time of William Shakespeare, women's roles were generally played by men or boys. The British prohibition was ended in the reign of Charles II who enjoyed watching female actors (actresses) on stage.
Shakespeare is believed to have been commenting on the acting style and techniques of his era when Hamlet gives his advice to the players in the play-within-the-play. He encourages the actors to "speak the speech.. as I pronounced it to you," and avoid "saw[ing] the air too much with your hand", because even in a "whirlwind of passion, you must.. give it smoothness." On the other hand, Hamlet urges the players to "Be not too tame neither." He suggests that they make sure to "suit the action to the word, the word to the action", taking care to "o'erstep not the modesty of nature." As well, he told the players to not ".. let those that play your clowns.. laugh, to set on some quantity of barren spectators to laugh too," which Hamlet considered to be a "villainous" and "pitiful" tactic.
The English critic Benedict Nightingale discussed and compared great classical actors of the long dead past, and the present, and their magical effects upon audiences, in this 1983 article from the New York Times, available online.
Historically, acting was considered a man's profession; so, in Shakespeare's time, for instance, men and boys played all roles, including the female parts. This was the case until the English Restoration of the theater in 1660, the first occurrence of the term actress in the OED being by Dryden in 1700.
In Japan, men (onnagata) took over the female roles in kabuki theatre when women were banned from performing on stage during the Edo period. However, some forms of Chinese drama have females playing all the roles.
In modern times, women sometimes play the roles of prepubescent boys. The stage role of Peter Pan, for example, is traditionally played by a woman, as are the principal boy and dame in British pantomime. This is uncommon in film, however, except in animated films and television programmes, where boys are sometimes voiced by women. For example, in The Simpsons the voice of Bart Simpson is provided by Nancy Cartwright. Opera has several "pants roles" traditionally sung by women, usually mezzo-sopranos. Examples are Hansel in Hänsel und Gretel, and Cherubino in The Marriage of Figaro.
Having an actor dress as the opposite sex for comic effect is also a long standing tradition in comic theatre and film. Most of Shakespeare's comedies include instances of overt cross-dressing, such as Francis Flute in "A Midsummer Night's Dream. The movie A Funny Thing Happened on the Way to the Forum stars Jack Gilford dressing as a young bride. Tony Curtis and Jack Lemmon famously posed as women to escape gangsters in the Billy Wilder film Some Like It Hot. Cross-dressing for comic effect was a frequently used device in most of the thirty Carry On films. Dustin Hoffman and Robin Williams each appeared in a hit comedy film in which they played most scenes dressed as a woman.
Several roles in modern plays and musicals are played by a member of the opposite sex (rather than a character cross-dressing), such as the character Edna Turnblad in Hairspray — played by Divine in the original film, Harvey Fierstein in the Broadway musical, and John Travolta in the 2007 movie musical. Occasionally the issue is further complicated through a woman acting as a man pretending to be a woman, like Julie Andrews in Victor/Victoria or Gwyneth Paltrow in Shakespeare in Love".


Agnostida (the agnostids) is an order of trilobite. These small trilobites first appeared toward the end of the Early Cambrian and thrived in the Middle Cambrian. They are present in the lower Cambrian fossil record along with trilobites from Orders Redlichiida, Corynexochida, and Ptychopariida. The last agnostids went extinct in the Late Ordovician.
The Agnostida are divided into two suborders -- Agnostina and Eodiscina -- that are then divided into a number of families. As a group, agnostids have pygidia (tails) that are so similar in size and shape to their cephalons (heads) that it is difficult to distinguish which end is which. Most agnostid species were eyeless.
The systematic position of Order Agnostida within Class Trilobita remains uncertain, and there has been continuing debate whether they are trilobites or a stem group. The challenge to the status has focused on the Agnostina partly because juveniles of one genus have been found with legs greatly different from those of adult trilobites, suggesting they are separately descended from Crustaceans. Other researchers have suggested, based on cladistic analyses, that Eodiscina and Agnostida are closely united, and that the Eodiscina descended from the trilobite Order Ptychopariida.
Scientists have long debated whether the agnostids lived a pelagic or a benthic lifestyle. Their lack of eyes, a morphology not well-suited for swimming, and their fossils found in association with other benthic trilobites all suggest a benthic (bottom-dwelling) mode of life. They likely lived on areas of the ocean floor that received little or no light and fed on detritus that descended from upper layers of the sea to the bottom. In contrast, their wide geographic dispersion in the fossil record is uncharacteristic of benthic animals, suggesting a pelagic existence. The thoracic segment appears to form a hinge between the head and pygidium allowing for a bivalved ostracodan-type lifestyle. Furthermore, the orientation of the thoracic appendages appears ill suited for benthic living.
Agnostina are generally referred to simply as "agnostids" even though they probably should be called "agnostines".


An abortion is the removal or expulsion of an embryo or fetus from the uterus, resulting in or caused by its death. The spontaneous expulsion of a fetus or embryo before the 20th week is commonly known as a miscarriage. Induced abortion is the removal or expulsion of an embryo or fetus by medical, surgical, or other means at any point during human pregnancy for therapeutic or elective reasons. The approximate number of induced abortions performed worldwide in 2003 was 42 million.
Throughout recorded history, abortion has been induced by various traditional medicine methods, including botanical abortifacients, the use of sharpened tools, and abdominal pressure.
The moral and legal aspects of abortion are subject to intense social debate in many parts of the world. Aspects of this debate can include the public health impact of unsafe or illegal abortion as well as legal abortion's effect upon crime rates, and the ramifications of sex-selective practices. Other debates may include suggested but unproven effects of abortion including the abortion-breast cancer hypothesis, post-abortion syndrome, and fetal pain.
Modern Western abortion laws can be traced back to English common law, which allowed abortion before the "quickening" of the fetus. Currently, abortion law varies from country to country, with regard to religious, moral, and cultural sensibilities.
In medical terminology, the term abortion refers to two basic phenomena: miscarriage (spontaneous abortion) and induced abortion. In common parlance, the term "abortion" is synonymous with induced abortion. However, in medical texts, the word 'abortion' might exclusively refer to, or may also refer to, spontaneous abortion (miscarriage).
Spontaneous abortion is the expulsion of an embryo or fetus due to accidental trauma or natural causes. Most miscarriages are due to incorrect replication of chromosomes; they can also be caused by environmental factors. Spontaneous abortions, generally referred to as miscarriages, occur when an embryo or fetus is lost due to natural causes before the 20th week of gestation. A pregnancy that ends between 20 and 37 weeks of gestation, if it results in a live-born infant, is known as a "premature birth". When a fetus dies in utero after about 20 weeks, or during delivery, it is termed a "stillbirth". Premature births and stillbirths are generally not considered to be miscarriages although usage of these terms can sometimes overlap.
Most miscarriages occur very early in pregnancy. Between 10% and 50% of pregnancies end in miscarriage, depending upon the age and health of the pregnant woman. In most cases, they occur so early in the pregnancy that the woman is not even aware that she was pregnant.
The risk of spontaneous abortion decreases sharply after the 8th week. This risk is greater in those with a known history of several spontaneous abortions or an induced abortion, those with systemic diseases, and those over age 35. Other causes can be infection (of either the woman or fetus), immune response, or serious systemic disease. A spontaneous abortion can also be caused by accidental trauma; intentional trauma to cause miscarriage is considered induced abortion or feticide.
An abortion is considered to be elective if it is performed for any other reason.
In the first 12 weeks, suction-aspiration or vacuum abortion is the most common method. Manual Vacuum aspiration (MVA) abortion, consists of removing the fetus or embryo by suction using a manual syringe, while electric vacuum aspiration (EVA) abortion uses an electric pump. These techniques are comparable, and differ in the mechanism used to apply suction, how early in pregnancy they can be used, and whether cervical dilation is necessary. MVA, also known as "mini-suction" and "menstrual extraction", can be used in very early pregnancy, and does not require cervical dilation. Surgical techniques are sometimes referred to as 'Suction (or surgical) Termination Of Pregnancy' (STOP). From the 15th week until approximately the 26th, dilation and evacuation (D&E) is used. D&E consists of opening the cervix of the uterus and emptying it using surgical instruments and suction.
Dilation and curettage (D&C), the second most common method of abortion, is a standard gynecological procedure performed for a variety of reasons, including examination of the uterine lining for possible malignancy, investigation of abnormal bleeding, and abortion. Curettage refers to cleaning the walls of the uterus with a curette. The World Health Organization recommends this procedure, also called sharp curettage, only when MVA is unavailable. The term D and C, or sometimes suction curette, is used as a euphemism for the first trimester abortion procedure, whichever the method used.
Other techniques must be used to induce abortion in the second trimester. Premature delivery can be induced with prostaglandin; this can be coupled with injecting the amniotic fluid with caustic solutions containing saline or urea. After the 16th week of gestation, abortions can be induced by intact dilation and extraction (IDX) (also called intrauterine cranial decompression), which requires surgical decompression of the fetus's head before evacuation. IDX is sometimes called "partial-birth abortion," which has been federally banned in the United States. A hysterotomy abortion is a procedure similar to a caesarean section, and is performed under general anesthesia because it is considered major abdominal surgery. It requires a smaller incision than a caesarean section and is used during later stages of pregnancy.
From the 20th to 23rd week of gestation, an injection to stop the fetal heart can be used as the first phase of the surgical abortion procedure to ensure that the fetus is not born alive.
Effective in the first trimester of pregnancy, non-surgical abortions (referred to as 'medical abortions') comprise 10% of all abortions in the United States and Europe. Combined regimens include methotrexate or mifepristone, followed by a prostaglandin (either misoprostol or gemeprost: misoprostol is used in the U.S.; gemeprost is used in the UK and Sweden.) When used within 49 days gestation, approximately 92% of women undergoing medical abortion with a combined regimen completed it without surgical intervention. Misoprostol can be used alone, but has a lower efficacy rate than combined regimens. In cases of failure of medical abortion, vacuum or manual aspiration is used to complete the abortion surgically.
Historically, a number of herbs reputed to possess abortifacient properties have been used in folk medicine: tansy, pennyroyal, black cohosh, and the now-extinct silphium (see history of abortion). The use of herbs in such a manner can cause serious — even lethal — side effects, such as multiple organ failure, and is not recommended by physicians.
Abortion is sometimes attempted by causing trauma to the abdomen. The degree of force, if severe, can cause serious internal injuries without necessarily succeeding in inducing miscarriage. Both accidental and deliberate abortions of this kind can be subject to criminal liability in many countries. In Burma, Indonesia, Malaysia, the Philippines, and Thailand, there is an ancient tradition of attempting abortion through forceful abdominal massage.
Reported methods of unsafe, self-induced abortion include misuse of misoprostol, and insertion of non-surgical implements such as knitting needles and clothes hangers into the uterus. These methods are rarely seen in developed countries where surgical abortion is legal and available.
The incidence and reasons for induced abortion vary regionally. It has been estimated that approximately 46 million abortions are performed worldwide every year. Of these, 26 million are said to occur in places where abortion is legal; the other 20 million happen where the procedure is illegal. Some countries, such as Belgium (11.2 per 100 known pregnancies) and the Netherlands (10.6 per 100), have a low rate of induced abortion, while others like Russia (62.6 per 100) and Vietnam (43.7 per 100) have a comparatively high rate. The world ratio is 26 induced abortions per 100 known pregnancies.
Abortion rates also vary depending on the stage of pregnancy and the method practiced. In 2003, from data collected in those areas of the United States that sufficiently reported gestational age, it was found that 88.2% of abortions were conducted at or prior to 12 weeks, 10.4% from 13 to 20 weeks, and 1.4% at or after 21 weeks. 90.9% of these were classified as having been done by "curettage" (suction-aspiration, Dilation and curettage, Dilation and evacuation), 7.7% by "medical" means (mifepristone), 0.4% by "intrauterine instillation" (saline or prostaglandin), and 1.0% by "other" (including hysterotomy and hysterectomy). The Guttmacher Institute estimated there were 2,200 intact dilation and extraction procedures in the U.S. during 2000; this accounts for 0.17% of the total number of abortions performed that year. Similarly, in England and Wales in 2006, 89% of terminations occurred at or under 12 weeks, 9% between 13 to 19 weeks, and 1.5% at or over 20 weeks. 64% of those reported were by vacuum aspiration, 6% by D&E, and 30% were medical.
A 1998 aggregated study, from 27 countries, on the reasons women seek to terminate their pregnancies concluded that common factors cited to have influenced the abortion decision were: desire to delay or end childbearing, concern over the interruption of work or education, issues of financial or relationship stability, and perceived immaturity. A 2004 study in which American women at clinics answered a questionnaire yielded similar results. In Finland and the United States, concern for the health risks posed by pregnancy in individual cases was not a factor commonly given; however, in Bangladesh, India, and Kenya health concerns were cited by women more frequently as reasons for having an abortion. 1% of women in the 2004 survey-based U.S. study became pregnant as a result of rape and 0.5% as a result of incest. Another American study in 2002 concluded that 54% of women who had an abortion were using a form of contraception at the time of becoming pregnant while 46% were not. Inconsistent use was reported by 49% of those using condoms and 76% of those using the combined oral contraceptive pill; 42% of those using condoms reported failure through slipping or breakage.
Some abortions are undergone as the result of societal pressures. These might include the stigmatization of disabled persons, preference for children of a specific sex, disapproval of single motherhood, insufficient economic support for families, lack of access to or rejection of contraceptive methods, or efforts toward population control (such as China's one-child policy). These factors can sometimes result in compulsory abortion or sex-selective abortion.
Early-term surgical abortion is a simple procedure which is safer than childbirth when performed before the 16th week. Abortion methods, like most minimally invasive procedures, carry a small potential for serious complications. The risk of complications can increase depending on how far pregnancy has progressed.
Women typically experience minor pain during first-trimester abortion procedures. In a 1979 study of 2,299 patients, 97% reported experiencing some degree of pain. Patients rated the pain as being less than earache or toothache, but more than headache or backache.
Some practitioners advocate using minimal anaesthesia so the patient can alert them to possible complications. Others recommend general anaesthesia, to prevent patient movement, which might cause a perforation. General anaesthesia carries its own risks, including death, which is why public health officials recommend against its routine use.
Induced abortion can be traced to ancient times. There is evidence to suggest that, historically, pregnancies were terminated through a number of methods, including the administration of abortifacient herbs, the use of sharpened implements, the application of abdominal pressure, and other techniques.
The Hippocratic Oath, the chief statement of medical ethics for Hippocratic physicians in Ancient Greece, forbade doctors from helping to procure an abortion by pessary. Soranus, a second-century Greek physician, suggested in his work Gynaecology that women wishing to abort their pregnancies should engage in energetic exercise, energetic jumping, carrying heavy objects, and riding animals. He also prescribed a number of recipes for herbal baths, pessaries, and bloodletting, but advised against the use of sharp instruments to induce miscarriage due to the risk of organ perforation. It is also believed that, in addition to using it as a contraceptive, the ancient Greeks relied upon silphium as an abortifacient. Such folk remedies, however, varied in effectiveness and were not without risk. Tansy and pennyroyal, for example, are two poisonous herbs with serious side effects that have at times been used to terminate pregnancy.
Abortion in the 19th century continued, despite bans in both the United Kingdom and the United States, as the disguised, but nonetheless open, advertisement of services in the Victorian era suggests.
In the 20th century the Soviet Union (1919), Nazi Germany (1935) and Sweden (1938) were among the first countries to legalize certain or all forms of abortion.
A number of complex issues exist in the debate over abortion. These, like the suggested effects upon health listed above, are a focus of research and a fixture of discussion among members on all sides of the controversy.
A theory attempts to draw a correlation between the United States' unprecedented nationwide decline of the overall crime rate during the 1990s and the decriminalization of abortion 20 years prior.
The suggestion was brought to widespread attention by a 1999 academic paper, The Impact of Legalized Abortion on Crime, authored by the economists Steven D. Levitt and John Donohue. They attributed the drop in crime to a reduction in individuals said to have a higher statistical probability of committing crimes: unwanted children, especially those born to mothers who are African-American, impoverished, adolescent, uneducated, and single. The change coincided with what would have been the adolescence, or peak years of potential criminality, of those who had not been born as a result of Roe v. Wade and similar cases. Donohue and Levitt's study also noted that states which legalized abortion before the rest of the nation experienced the lowering crime rate pattern earlier, and those with higher abortion rates had more pronounced reductions.
Fellow economists Christopher Foote and Christopher Goetz criticized the methodology in the Donohue-Levitt study, noting a lack of accommodation for statewide yearly variations such as cocaine use, and recalculating based on incidence of crime per capita; they found no statistically significant results. Levitt and Donohue responded to this by presenting an adjusted data set which took into account these concerns and reported that the data maintained the statistical significance of their initial paper.
Such research has been criticized by some as being utilitarian, discriminatory as to race and socioeconomic class, and as promoting eugenics as a solution to crime. Levitt states in his book Freakonomics that they are neither promoting nor negating any course of action — merely reporting data as economists.
The advent of both sonography and amniocentesis has allowed parents to determine sex before birth. This has led to the occurrence of sex-selective abortion or the targeted termination of a fetus based upon its sex.
It is suggested that sex-selective abortion might be partially responsible for the noticeable disparities between the birth rates of male and female children in some places. The preference for male children is reported in many areas of Asia, and abortion used to limit female births has been reported in Mainland China, Taiwan, South Korea, and India.
In India, the economic role of men, the costs associated with dowries, and a Hindu tradition which dictates that funeral rites must be performed by a male relative have led to a cultural preference for sons. The widespread availability of diagnostic testing, during the 1970s and '80s, led to advertisements for services which read, "Invest 500 rupees [for a sex test] now, save 50,000 rupees [for a dowry] later." In 1991, the male-to-female sex ratio in India was skewed from its biological norm of 105 to 100, to an average of 108 to 100. Researchers have asserted that between 1985 and 2005 as many as 10 million female fetuses may have been selectively aborted. The Indian government passed an official ban of pre-natal sex screening in 1994 and moved to pass a complete ban of sex-selective abortion in 2002.
In the People's Republic of China, there is also a historic son preference. The implementation of the one-child policy in 1979, in response to population concerns, led to an increased disparity in the sex ratio as parents attempted to circumvent the law through sex-selective abortion or the abandonment of unwanted daughters. Sex-selective abortion might be an influence on the shift from the baseline male-to-female birth rate to an elevated national rate of 117:100 reported in 2002. The trend was more pronounced in rural regions: as high as 130:100 in Guangdong and 135:100 in Hainan. A ban upon the practice of sex-selective abortion was enacted in 2003.
Where and when access to safe abortion has been barred, due to explicit sanctions or general unavailability, women seeking to terminate their pregnancies have sometimes resorted to unsafe methods.
"Back-alley abortion" is a slang term for any abortion not practiced under generally accepted standards of sanitation and professionalism. The World Health Organization (WHO) defines an unsafe abortion as being, "a procedure..carried out by persons lacking the necessary skills or in an environment that does not conform to minimal medical standards, or both." This can include a person without medical training, a professional health provider operating in sub-standard conditions, or the woman herself.
Unsafe abortion remains a public health concern today due to the higher incidence and severity of its associated complications, such as incomplete abortion, sepsis, hemorrhage, and damage to internal organs. WHO estimates that 19 million unsafe abortions occur around the world annually and that 68,000 of these result in the woman's death. Complications of unsafe abortion are said to account, globally, for approximately 13% of all maternal mortalities, with regional estimates including 12% in Asia, 25% in Latin America, and 13% in sub-Saharan Africa. A 2007 study published in the The Lancet found that, although the global rate of abortion declined from 45.6 million in 1995 to 41.6 million in 2003, unsafe procedures still accounted for 48% of all abortions performed in 2003. Health education, access to family planning, and improvements in health care during and after abortion have been proposed to address this phenomenon.
In the history of abortion, induced abortion has been the source of considerable debate, controversy, and activism. An individual's position on the complex ethical, moral, philosophical, biological, and legal issues is often related to his or her value system. Opinions of abortion may be best described as being a combination of beliefs on its morality, and beliefs on the responsibility, ethical scope, and proper extent of governmental authorities in public policy. Religious ethics also has an influence upon both personal opinion and the greater debate over abortion (see religion and abortion).
In both public and private debate, arguments presented in favor of or against abortion focus on either the moral permissibility of an induced abortion, or justification of laws permitting or restricting abortion. Arguments on morality and legality tend to collide and combine, complicating the issue at hand.
Debate also focuses on whether the pregnant woman should have to notify and/or have the consent of others in distinct cases: a minor, her parents; a legally-married or common-law wife, her husband; or a pregnant woman, the biological father. In a 2003 Gallup poll in the United States, 79% of male and 67% of female respondents were in favor of spousal notification; overall support was 72% with 26% opposed.
A number of opinion polls around the world have explored public opinion regarding the issue of abortion. Results have varied from poll to poll, country to country, and region to region, while varying with regard to different aspects of the issue.
A May 2005 survey examined attitudes toward abortion in 10 European countries, asking polltakers whether they agreed with the statement, "If a woman doesn't want children, she should be allowed to have an abortion". The highest level of approval was 81% (in the Czech Republic); the lowest was 47% (in Poland).
In North America, a December 2001 poll surveyed Canadian opinion on abortion, asking Canadians in what circumstances they believe abortion should be permitted; 32% responded that they believe abortion should be legal in all circumstances, 52% that it should be legal in certain circumstances, and 14% that it should be legal in no circumstances. A similar poll in January 2006 surveyed people in the United States about U.S. opinion on abortion; 33% said that abortion should be "permitted only in cases such as rape, incest or to save the woman's life", 27% said that abortion should be "permitted in all cases", 15% that it should be "permitted, but subject to greater restrictions than it is now", 17% said that it should "only be permitted to save the woman's life", and 5% said that it should "never" be permitted. A November 2005 poll in Mexico found that 73.4% think abortion should not be legalized while 11.2% think it should.
Of attitudes in South and Central America, a December 2003 survey found that 30% of Argentines thought that abortion in Argentina should be allowed "regardless of situation", 47% that it should be allowed "under some circumstances", and 23% that it should not be allowed "regardless of situation". A March 2007 poll regarding the abortion law in Brazil found that 65% of Brazilians believe that it "should not be modified", 16% that it should be expanded "to allow abortion in other cases", 10% that abortion should be "decriminalized", and 5% were "not sure". A July 2005 poll in Colombia found that 65.6% said they thought that abortion should remain illegal, 26.9% that it should be made legal, and 7.5% that they were unsure.
The "abortion-breast cancer (ABC) hypothesis" (also referred to by supporters as the abortion-breast cancer link) is an unsupported hypothesis that posits a causal relationship between induced abortion and an increased risk of developing breast cancer. In early pregnancy, levels of estrogen increase, leading to breast growth in preparation for lactation. The hypothesis proposes that if this process is interrupted by an abortion – before full maturity in the third trimester – then more relatively vulnerable immature cells could be left than there were prior to the pregnancy, resulting in a greater potential risk of breast cancer. While early research suggested the possibility of a correlative relationship between breast cancer and abortion, the causal hypothesis was proposed based on a reinterpretation of rat studies conducted in the 1980s. Abortion is not considered a breast cancer risk by any major cancer organization, yet the hypothesis continues to be championed by pro-life activists like Dr. Joel Brind, Dr. Angela Lanfranchi and Dr. Karen Malec.
Though the hypothesis has been largely rejected by the scientific community, the ongoing promotion of the abortion-breast cancer hypothesis by pro-life advocates is seen by some as a part of the current pro-life "women-centered" strategy against abortion. In the past, pro-life advocates have sought legal action regarding disclosure of the abortion-breast cancer issue. While suits brought short-term legal and political intervention, the scientific community responded in the form of the 2003 NCI consensus workshop. The current scientific consensus that abortion does not increase the risk of breast cancer has solidified with the publication of large prospective cohort studies which find no significant association between abortion and breast cancer. Nevertheless, the subject continues to be one of mostly political but some scientific debate.
Some proposed negative psychological effects of abortion have been referred to by pro-life advocates as a separate condition called "post-abortion syndrome". However, the existence of "post-abortion syndrome" is not recognized by any medical or psychological organization, and some physicians and pro-choice advocates have argued that the effort to popularize the idea of a "post-abortion syndrome" is a tactic used by pro-life advocates for political purposes.
Fetal pain, its existence, and its implications are debated politically and academically.
Most medical researchers agree pain cannot be felt until the third trimester of pregnancy.However, there may be an emerging consensus among developmental neurobiologists that the establishment of thalamocortical connections" (at about 26 weeks) is a critical event with regard to fetal perception of pain. Nevertheless, because pain can involve sensory, emotional and cognitive factors, it is "impossible to know" when painful experiences may become possible, even if it is known when thalamocortical connections are established in the 26th week.
Whether a fetus has the ability to feel pain and to suffer is part of the abortion debate. For example, legislation has been proposed by pro-life advocates requiring abortion providers to tell a woman that the fetus may feel pain during the abortion procedure, and that require her to accept or decline anesthesia for the fetus.
Before the scientific discovery that human development begins at fertilization, English common law allowed abortions to be performed before "quickening", the earliest perception of fetal movement by a woman during pregnancy, until both pre- and post-quickening abortions were criminalized by Lord Ellenborough's Act in 1803. In 1861, the British Parliament passed the Offences Against the Person Act, which continued to outlaw abortion and served as a model for similar prohibitions in some other nations. The Soviet Union, with legislation in 1920, and Iceland, with legislation in 1935, were two of the first countries to generally allow abortion. The second half of the 20th century saw the liberalization of abortion laws in other countries. The Abortion Act 1967 allowed abortion for limited reasons in the United Kingdom. In the 1973 case, Roe v. Wade, the United States Supreme Court struck down state laws banning abortion, ruling that such laws violated an implied right to privacy in the United States Constitution. The Supreme Court of Canada, similarly, in the case of R. v. Morgentaler, discarded its criminal code regarding abortion in 1988, after ruling that such restrictions violated the security of person guaranteed to women under the Canadian Charter of Rights and Freedoms. Canada later struck down provincial regulations of abortion in the case of R. v. Morgentaler (1993)." By contrast, abortion in Ireland was affected by the addition of an amendment to the Irish Constitution in 1983 by popular referendum, recognizing "the right to life of the unborn".
Other countries, in which abortion is normally illegal, will allow one to be performed in the case of rape, incest, or danger to the pregnant woman's life or health. A few nations ban abortion entirely: Chile, El Salvador, Malta, and Nicaragua, although in 2006 the Chilean government began the free distribution of emergency contraception. In Bangladesh, abortion is illegal, but the government has long supported a network of "menstrual regulation clinics", where menstrual extraction (manual vacuum aspiration) can be performed as menstrual hygiene.

In law, an abstract is a brief statement that contains the most important points of a long legal document or of several related legal papers.
The Abstract of Title, used in real estate transactions, is the more common form of abstract. An abstract of title lists all the owners of a piece of land, a house, or a building before it came into possession of the present owner. The abstract also records all deeds, wills, mortgages, and other documents that affect ownership of the property. An abstract describes a chain of transfers from owner to owner and any agreements by former owners that are binding on later owners.
A Clear Title to property is one that clearly states any obligation in the deed to the property. It reveals no breaks in the chain of legal ownership. After the records of the property have been traced and the title has been found clear, it is sometimes guaranteed, or insured. In a few states, a more efficient system of insuring title real properties provides for registration of a clear title with public authorities. After this is accomplished, no abstract of title is necessary.
In the context of patent law and specifically in prior art searches, searching through abstracts is a common way to find relevant prior art document to question to novelty or inventive step (or non-obviousness in United States patent law) of an invention. Under United States patent law, the abstract may be called "Abstract of the Disclosure".
Certain government bureaucracies, such as a department of motor vehicles will issue an abstract of a completed transaction or an updated record intended to serve as a proof of compliance with some administrative requirement. This is often done in advance of the update of reporting databases and/or the issuance of official documents.

Alan Alda (born January 28, 1936) is a five-time Emmy Award-winning, six-time Golden Globe-winning, Academy Award-nominated American actor. He is perhaps most famous for his role as Hawkeye Pierce in the television series M*A*S*H. During the 1970s and 1980s he was viewed as the archetypal sympathetic male, though in recent years he has appeared in roles which counter that image.
Alda was born "'Alphonso Joseph D'Abruzzo"' in New York City. His father, Robert Alda (1914-1986) aka Alphonso Giovanni Giuseppe Roberto D'Abruzzo, was an actor and singer, and his mother, Joan Brown, was crowned Miss New York in a beauty pageant. Alda is of Italian and Irish descent. His adopted surname "Alda" is a combination of ALfonso and "D'A"bruzzo. Alda has a half-brother, actor Antony Alda.
Alda contracted polio, aged 7, during an epidemic. His parents administered a painful treatment, developed by Sister Elizabeth Kenny, where hot woolen blankets were applied to the limbs and the muscles were stretched by massage. This treatment, though brutal, allowed Alda to recover much movement.
He attended Archbishop Stepinac High School in White Plains, New York and later received his bachelor's degree from Fordham College of Fordham University in the Bronx in 1956, where he was a student staff member of its FM radio station, WFUV. During his junior year, he studied in Europe where he acted in a play in Rome and performed with his father on television in Amsterdam. After graduation, he joined the U.S. Army Reserve and served a six-month tour of duty as a gunnery officer in Korea following the Korean War. A year after graduation, he married Arlene Weiss, with whom he has three daughters; Eve, Elizabeth, and Beatrice, and seven grandchildren. Arlene Alda is an accomplished photographer, author, and musician.
Alda was a member of the Compass Players in the late 1950s. He has also been an activist for feminism for many years.
Alda has been a longtime resident of Leonia, New Jersey.
On the October 5, 2007, episode of the British talk show Loose Women, Alan said he would still be working at a theatre in St. Louis if he had not landed the role on M*A*S*H.
Alda began his career in the 1950s as a member of the Compass Players comedy revue. In 1966 he starred in the musical The Apple Tree on Broadway, where he was nominated for the Tony award as Best Actor in a Musical.
in Gone Are The Days, a 1963 film version of the highly successflul Broadway play Purlie! Victorious which co-starred veteran black actors Ruby Dee and her husband, the late Ossie Davis. Other film roles would follow, such as his portrayal of the now late author, humorist and actor George Plimpton in film Paper Lion (1968), The Extraordinary Seaman (1969), and The Mephisto Waltz (1971).
In early 1972 Alda auditioned for and was selected to play the role of "Hawkeye Pierce" in the TV adaptation of the 1970 film M*A*S*H, for which would later be nominated for 21 Emmy Awards, winning five. He took part in writing 13 episodes, and directed 32. When he won his first Emmy Award for writing, he was so happy that he performed a cartwheel before running up to the stage to accept the award. He also was the first person to win Emmy Awards for acting, writing, and directing for the same series. Richard Hooker, who wrote the novel on which M*A*S*H was based, did not like Alan Alda's portrayal of Hawkeye Pierce (Hooker, a Republican, had based Hawkeye on himself, whereas Alda took the character in a more left-wing direction). Alda also directed the show's 1983 2½ hour series finale "Goodbye, Farewell, and Amen" which remains the single most watched episode of a TV series. Alda is in fact the only series regular to appear in each and every one of 251 episodes.
As more and more of the original series writers left the series, Alda gained more control and by the final seasons he had become project and creative consultant. Under his watch, M*A*S*H more openly addressed political issues. As a result, the 11 years of M*A*S*H are generally split into two eras: The Larry Gelbart/Gene Reynolds "comedy" years (1972-1977), and the Alan Alda "dramatic" years (1977-1983). During this time, Alda frequently appeared as a panelist on the 1968 revival of "What's My Line? He also appeared as a panelist on I've Got a Secret during its 1972 syndication revival.
Alda's prominence in the enormously successful M*A*S*H gave him a platform to speak out on political topics, and he has been a strong and vocal supporter of women's rights. In 1976, the Boston Globe dubbed him "the quintessential Honorary Woman: a feminist icon" for his activism on behalf of the Equal Rights Amendment. As a liberal activist he has been a target for some political and social conservatives.
Alan Alda has also played Nobel Prize-winning physicist Richard Feynman in the play QED, which has only one other character. Although Peter Parnell wrote the play, Alda both produced and inspired it. Alda has also appeared frequently in the films of Woody Allen, and he has been a guest star five times on ER, playing Dr. Kerry Weaver's mentor, Gabriel Lawrence. During the later episodes, it was revealed that Dr. Lawrence was suffering from the early stages of Alzheimer's. Alda also had a co-starring role as Dr. Robert Gallo in the 1993 TV movie And the Band Played On.
During M*A*S*H's run and continuing through the 1980s, Alda embarked on a successful career as a writer and director, with the ensemble dramedy The Four Seasons being perhaps his most notable hit. 1990s "Betsy's Wedding is his last directing credit to date. After M*A*S*H Alda took on a series of roles that either parodied or directly contradicted his "nice guy" image. His role as a pompous celebrity comedian in Crimes and Misdemeanors was widely seen as a self-parody, although Alda denied this.
Alda denies that in 1995 he briefly considered running for the United States Senate in New Jersey. About this time, he starred as the President in Michael Moore's political satire/comedy film Canadian Bacon. In 1996, Alda played Henry Ford in Camping With Henry and Tom, based on the book by Mark St. Germain. Beginning in 2004, Alda was a regular cast member on the NBC program The West Wing, portraying Republican U.S. Senator and presidential hopeful Arnold Vinick, until the show's conclusion in May 2006. He made his premiere in the sixth season's eighth episode, "In The Room," and was added to the opening credits with the thirteenth episode, "King Corn." In August 2006, Alda won an Emmy for his portrayal of Arnold Vinick in the final season of The West Wing.
Owen Brewster in Martin Scorsese's Academy-Award winning film The Aviator in which he co-starred with Leonardo DiCaprio.
Alda also wrote several of the stories and poems that appeared in Marlo Thomas's Free to Be.. You and Me television show.
In the spring of 2005, Alda starred as Shelly Levene in the Tony Award-winning Broadway revival of David Mamet's Glengarry Glen Ross, for which he received a Tony Award nomination for Best Featured Actor in a Play.
It has become quite common for Alda in his later roles to have some reference to his early work in M*A*S*H. In a line on ER, his character mentions that he uses a surgical technique that is "an old army trick." Alda's West Wing character has also made at least one reference to Korea when he said, "I could take these people to the DMZ and it still wouldn't take their minds off ethanol and abortion.
St. Jude's Children's Hospital produced one-hour special TV show Fighting for Life. He and his wife, Arlene are also close friends of Marlo Thomas, who is very active in fund raising for the hospital her father founded. The special featured Ben Bowen as one of six patients being treated for childhood cancer at Saint Jude.
In 2005, Alda published his first round of memoirs, "Never Have Your Dog Stuffed: and Other Things I've Learned. Among other stories, he recalls his intestines becoming strangulated while on location in Chile for his PBS show Scientific American Frontiers, during which he mildly surprised a young doctor with his understanding of medical procedures, which he learned from M*A*S*H". He also talks about his mother's battle with schizophrenia. The title comes from an incident in his childhood, when Alda was distraught about his dog dying and his well-meaning father had the animal stuffed. Alda was horrified by the results, and took from this that sometimes we have to accept things as they are, rather than desperately and fruitlessly trying to change them.
In 2006, Alda contributed his voice to a part in the audio book of Max Brooks' World War Z. In this book, he voiced Arthur Sinclair Jr. the director of the United States Government's fictional "Department of Strategic Resources (DeStRes)".
His second memoir, Things I Overheard While Talking to Myself, weaves together advice from public speeches he has given with personal recollections about his life and beliefs.


American football, known in the United States simply as football, is a competitive team sport known for mixing strategy with intense physical play. The object of the game is to score points by advancing the ball into the opposing team's end zone. The ball can be advanced by carrying it (a running play) or by throwing it to a teammate (a passing play). Points can be scored in a variety of ways, including carrying the ball over the goal line, catching a pass from beyond the goal line, tackling an opposing ball carrier in his own end zone, or kicking the ball through the goal posts on the opposing side. The winner is the team with the most points when time expires at the end of the last play.
American football is known for having only a small following outside the United States, despite attempts by the National Football League (NFL) to globalize the game.
The history of American football can be traced to early versions of rugby football. Both games have their origin in varieties of football played in the United Kingdom in the mid-19th century, in which a ball is kicked at a goal and/or run over a line.
American football resulted from several major divergences from rugby football, most notably the rule changes instituted by Walter Camp, considered the "Father of American Football". Among these important changes were the introduction of the line of scrimmage and of down-and-distance rules. In the late 19th and early 20th centuries, gameplay developments by college coaches such as Amos Alonzo Stagg, Knute Rockne, and Glenn "Pop" Warner helped take advantage of the newly introduced forward pass. The popularity of collegiate football grew as it became the dominant version of the sport for the first half of the twentieth century. Bowl games, a college football tradition, attracted a national audience for collegiate teams. Bolstered by fierce rivalries, college football still holds widespread appeal in the US.
The origin of professional football can be traced back to 1892, with William "Pudge" Heffelfinger's $500 contract to play in a game for the Allegheny Athletic Association against the Pittsburgh Athletic Club. In 1920 the American Professional Football Association was formed. This league changed its name to the National Football League (NFL) two years later, and eventually became the major league of American football. Primarily a sport of Midwestern, industrial towns in the United States, professional football eventually became a national phenomenon. Football's increasing popularity is usually traced to the 1958 NFL Championship Game, a contest that has been dubbed the "Greatest Game Ever Played". A rival league to the NFL, the American Football League (AFL), began play in 1960; the pressure it put on the senior league led to a merger between the two leagues and the creation of the Super Bowl, which has become the most watched television event in the United States on an annual basis.
The object of American football is to score more points than the opposing team within the time limit.
American football is played on a field 360 feet (120 yards/109.7 m) long by 160 feet (53.3 yards/48.8 m) wide. The longer boundary lines are sidelines, while the shorter boundary lines are end lines. Near each end of the field is a goal line; they are 100 yards (91.4 m) apart. A scoring area called an end zone extends 10 yards (9.1 m) beyond each goal line to each end line.
Yard lines cross the field every 5 yd, and are numbered every 10 yards from each goal line to the 50-yard line, or midfield (similar to a typical rugby league field). Two rows of lines, known as inbounds lines or hash marks, parallel the sidelines near the middle of the field. All plays start with the ball on or between the hash marks.
At the back of each end zone are two goalposts (also called uprights) that are 18.5 feet (5.6 m) apart (24 feet (7.3 m) in high school). The posts are connected by a crossbar 10 feet (305 cm) from the ground.
Each team has 11 players on the field at a time. However, teams may substitute for any or all of their players, if time allows, during the break between plays. As a result, players have very specialized roles, and, sometimes (although rarely) almost all of the (at least) 46 active players on an NFL team will play in any given game. Thus, teams are divided into three separate units: the offense, the defense and the special teams.
Whatever the first team chooses, the second team has the option on the other choice (for example, if the first team elects to receive at the start of the game, the second team can decide which goal to defend).
At the start of the second half, the options to kick, receive, or choose a goal to defend are presented to the captains again. The team which did not choose first to start the first half (or which deferred its privilege to choose first) now gets first choice of options.
A standard football game consists of four 15-minute (typically 12 minutes in high-school football) quarters, with a half-time intermission after the second quarter. The clock stops after certain plays; therefore, a game can last considerably longer (often more than three hours in real time), and if a game is broadcast on television, TV timeouts are taken at certain intervals of the game to broadcast commercials outside of game action. If an NFL game is tied after four quarters, the teams play an additional period lasting up to 15 minutes. In an NFL overtime game, the first team that scores wins, even if the other team does not get a possession; this is referred to as sudden death. In a regular-season NFL game, if neither team scores in overtime, the game is a tie. In an NFL playoff game, additional overtime periods are played, as needed, to determine a winner. College overtime rules are more complicated and are described in Overtime (sport).
Advancing the ball in American football resembles the six-tackle rule and the play-the-ball in rugby league. The team that takes possession of the ball (the offense) has four attempts, called downs, to advance the ball 10 yd towards their opponent's (the defense's) end zone. When the offense gains 10 yards, it gets a first down, which means the team has another set of four downs to gain yet another 10 yards or score with. If the offense fails to gain a first down (10 yards) after 4 downs, the other team gets possession of the ball at the spot of the football, beginning with their first down.
Except at the beginning of halves and after scores, the ball is always put into play by a snap. Offensive players line up facing defensive players at the line of scrimmage (the position on the field where the play begins). One offensive player, the center, then passes (or "snaps") the ball between his legs to a teammate, usually the quarterback.
Officials blow a whistle to notify players that the down is over.
Each half begins with a kickoff. Teams also kick off after scoring touchdowns and field goals. The ball is kicked using a kicking tee from the team's own 30 yd line in the NFL and college football (as of the 2007 season). The other team's kick returner tries to catch the ball and advance it as far as possible. Where he is stopped is the point where the offense will begin its drive, or series of offensive plays. If the kick returner catches the ball in his own end zone, he can either run with the ball, or elect for a touchback by kneeling in the end zone, in which case the receiving team then starts its offensive drive from its own 20 yard line. A touchback also occurs when the kick goes out-of-bounds in the end zone. A kickoff that goes out-of-bounds anywhere other than the end zone before being touched by the receiving team is considered an illegal procedure penalty, and the ball will be placed where it went out of bounds or 30 yd from the kickoff spot, depending on which is more advantageous to the opposite team. Unlike with punts, once a kickoff goes 10 yards, it can be recovered by the kicking team. A team, especially one who is losing, can try to take advantage of this by attempting an onside kick. Punts and turnovers in the end zone can also end in a touchback.
After safeties, the team that gave up the points must free kick the ball to the other team from its own 20 yard line.
Fouls (a type of rule violation) are punished with penalties against the offending team. Most penalties result in moving the football towards the offending team's end zone. If the penalty would move the ball more than half the distance towards the offender's end zone, the penalty becomes half the distance to the goal instead of its normal value.
Most penalties result in replaying the down. Some defensive penalties give the offense an automatic first down. Conversely, some offensive penalties result in loss of a down (loss of the right to repeat the down). If a penalty gives the offensive team enough yardage to gain a first down, they get a first down, as usual.
If a foul occurs during a down, an official throws a yellow flag near the spot of the foul. When the down ends, the team that did not commit the foul has the option of accepting the penalty, or declining the penalty and accepting the result of the down.
Under certain circumstances clipping and blocking in the back are legal.
Variations on these basic rules exist, particularly touch and flag football, which are designed as non-contact or limited-contact alternatives to the relative violence of regular American football. In touch and flag football, tackling is not permitted. Offensive players are "tackled" when a defender tags them or removes a flag from their body, respectively. Both of these varieties are played mainly in informal settings such as intramural or youth games. Another variation is "wrap", where a player is "tackled" when another player wraps his arms around the ball carrier. Professional, intercollegiate, and varsity-level high school football invariably use the standard tackling rules.
Another variation is with the number of players on the field. In sparsely populated areas, it is not uncommon to find high school football teams playing nine-man football, eight-man football or six-man football. Players often play on offense as well as defense. The Arena Football League is a league that plays eight-man football, but also plays indoors and on a much smaller playing surface.
Most football players have highly specialized roles. At the college and NFL levels, most play only offense or only defense.
At least seven players must line up on the line of scrimmage on every offensive play. The other players may line up anywhere behind the line. The exact number of running backs, wide receivers and tight ends may differ on any given play. For example, if the team needs only 1 yard, it may use three tight ends, two running backs and no wide receivers. On the other hand, if it needs 20 yards, it may replace all of its running backs and tight ends with wide receivers.
In contrast to members of the offense, the rules of professional football (NFL Rulebook) and American college football NCAA Rulebook) do not specify starting position, movement, or coverage zones for members of the defensive team, except that they must be in the defensive zone at the start of play. The positions, movements and responsibilities of all defensive players are assigned by the team by selection of certain coverages, or patterns of placement and assignment of responsibilities. The positional roles are customary. These roles have varied over the history of American football. The following are customary defensive positions used in many coverages in modern American football.
The units of players who handle kicking plays are known as special teams. Three important special-teams players are the punter, who handles punts, the placekicker or kicker, who kicks off and attempts field goals and extra points, and the long snapper, who snaps the ball for extra points, field goals, and punts. Also included on special teams are the returners. These players return punts or kickoffs and try to get in good field position. These players can also score touchdowns.
NCAA and high school rules specify only that offensive linemen must have numbers in the 50-79 range, but the NCAA "strongly recommends" that quarterbacks and running backs have numbers below 50 and wide receivers numbers above 79. This helps officials as it means that numbers 50 to 79 are ineligible receivers, or players that may never receive a forward pass. There are no numbering restrictions on defensive players in the NCAA, other than that no two players with the same jersey number can be on the field at the same time.
Because the game stops after every down, giving teams a chance to call a new play, strategy plays a major role in football. Each team has a playbook of dozens to hundreds of plays. Ideally, each play is a scripted, strategically sound team-coordinated endeavor. Some plays are very safe; they are likely to get only a few yards. Other plays have the potential for long gains but at a greater risk of a loss of yardage or a turnover.
Generally speaking, rushing plays are less risky than passing plays. However, there are relatively safe passing plays and risky running plays. To deceive the other team, some passing plays are designed to resemble running plays and vice versa. These are referred to as play-action passes and draws. There are many trick or gadget plays, such as when a team lines up as if it intends to punt and then tries to run or pass for a first down. Such high-risk plays are a great thrill to the fans when they work. However, they can spell disaster if the opposing team realizes the deception and acts accordingly.
The defense also plans plays in response to expectations of what the offense will do. For example, a "blitz" (using linebackers or defensive backs to charge the quarterback) is often attempted when the team on defense expects a pass. A blitz makes downfield passing more difficult but exposes the defense to big gains if the offensive line stems the rush.
Many hours of preparation and strategizing, including film review by both players and coaches, go into the days between football games. This, along with the demanding physicality of football (see below), is why teams typically play at most one game per week.
American football is a collision sport. To stop the offense from advancing the ball, the defense must tackle the player with the ball by knocking or pulling him down. As such, defensive players must use some form of physical contact to bring the ball-carrier to the ground, within certain rules and guidelines. Tacklers cannot kick or punch the runner. They also cannot grab the face mask of the runner's helmet or lead into a tackle with their own helmet. Despite these and other rules regarding unnecessary roughness, most other forms of tackling are legal. Blockers and defenders trying to evade them also have wide leeway in trying to force their opponents out of the way. Quarterbacks are regularly hit by defenders coming on full speed from outside the quarterback's field of vision. This is commonly known as a blindside.
To compensate for this, players must wear special protective equipment, such as a padded plastic helmet, shoulder pads, hip pads and knee pads. These protective pads were introduced decades ago and have improved ever since to help minimize lasting injury to players. An unintended consequence of all the safety equipment has resulted in increasing levels of violence in the game. Players may now hurl themselves at one another at high speeds without a significant chance of injury. The injuries that do result tend to be severe and often season or career-ending and sometimes fatal. In previous years with less padding, tackling more closely resembled tackles in Rugby football. Better helmets have allowed players to use their helmets as weapons. This form of tackling is particularily unwise, due to the great potential for brain or spinal injury. All this has caused the various leagues, especially the NFL, to implement a complicated series of penalties for various types of contact. Most recently, virtually any contact with the helmet of a defensive player on the quarterback, or any contact to the quarterback's head, is now a foul.
Despite protective equipment and rule changes to emphasize safety, injuries remain very common in football. It is increasingly rare, for example, for NFL quarterbacks or running backs (who take the most direct hits) to make it through an entire season without missing some time to injury. Additionally, 28 football players, mostly high schoolers, died from direct football injuries in the years 2000-05 and an additional 68 died indirectly from dehydration or other examples of "non-physical" dangers, according to the National Center for Catastrophic Sport Injury Research. Concussions are common, with about 41,000 suffered every year among high school players according to the Brain Injury Association of Arizona.
Extra and optional equipment such as neck rolls, spider pads, rib protectors, and elbow pads help against injury as well, though they do not tend to be used by the majority of players due to their lack of requirement.
The danger of football and the equipment required to reduce it make regulation football impractical for casual play. Flag football and touch football are less violent variants of the game popular among recreational players.
Befitting its status as a popular sport, football is played in leagues of different size, age and quality, in all regions of the country. Organized football is played almost exclusively by men and boys, although a few amateur and semi-professional women's leagues have begun play in recent years.
The 32-team National Football League (NFL) is currently the only major professional American football league in North America. At least two new professional American Football Leagues are slated to begin playing in 2008, the All-American Football League and the United Football League. There are American football leagues located in over 50 countries in the world (see List of leagues of American and Canadian football). A few of the more popular international leagues are the German Football League (GFL) and the Japanese X-League. The NFL does not operate any developmental leagues currently since the folding of NFL Europa. Players unable to make an NFL team sometimes play in other leagues such as the Arena Football League or Canadian Football League, both of which have rules differing somewhat from those of the NFL.
College football is also popular throughout North America. A majority of colleges and universities have football teams, often with dedicated football stadiums. These teams mostly play other similarly sized schools. The largest, most popular collegiate teams routinely fill stadiums larger than 75,000. Four college football stadiums, The University of Michigan's Michigan Stadium, Penn State's Beaver Stadium, The University of Tennessee's Neyland Stadium and Ohio State's Ohio Stadium, seat more than 100,000 fans and usually sell out. The weekly autumn ritual of college football includes marching bands, cheerleaders, homecoming, parties, the tailgate party; it forms an important part of the culture in much of smalltown America. Football is generally the major source of revenue to the athletic programs of schools, public and private, in the United States.
Most American high schools field football teams. Schools that are too small to field the minimum number of players play variants of football that specify six, seven, eight or nine players instead of the normal eleven. High school football is popular, especially in Texas, Florida, Ohio, Indiana, Illinois, California, Colorado, Pennsylvania, and the Southern United States, where many schools regularly fill stadiums holding over 10,000 fans, and can afford artificial playing surfaces.
Football is played recreationally by amateur and youth teams (e.g. the American Youth Football and Pop Warner little-league programs). There are also many "semi-pro" teams in leagues where the players are paid to play but at a small enough salary that they generally must also hold a full-time job.
Due to the speed and violence of the sport, many non-organized football games involve variations of the rules to minimize contact. These include touch football and flag football.
Football is an autumn sport. A season typically begins in mid-to-late August and runs through December, into January. The professional playoffs run through January, and the Super Bowl is often played in the first week of February. The NFL draft is usually held in April, in which eligible college football players are selected by NFL teams, the order of selection determined by the teams' final regular season records.
It is a long-standing tradition in the United States (though not universally observed) that high school football games are played on Friday night, college games on Saturday, and professional games on Sunday. In the 1970s, the NFL began to schedule one game on Monday nights. Beginning in 2006, the NFL began scheduling games on Thursday and Saturday nights after the college football regular season concludes in mid-November, aired on the NFL Network. In recent years, nationally televised Thursday night college games have become a weekly fixture on ESPN, and most nights of the week feature at least one college game, though most games are still played on the traditional Saturday.
Certain fall and winter holidays—such as the NFL's Thanksgiving Classic and numerous New Year's Day college bowl games—have traditional football games associated with them.
Outside the United States, the sport is referred to as "American football" (or a translation thereof) to differentiate it from other football codes. In Australia and New Zealand the game is known as Gridiron football, although in the United States the term gridiron refers only to the playing field itself. In much of the world, the term football is ambiguous and can refer to a number of different codes.
The NFL has attempted to introduce the game to other nations and operated a developmental league, NFL Europa, with teams in five German cities and one in the Netherlands, but this league folded following the 2007 season. The professional Canadian Football League and collegiate Canadian Interuniversity Sport play under the only slightly different Canadian rules.
In Japan, the X-League is a professional league with 60 teams in four divisions, using promotion and relegation. After the post-season playoffs, the X-League champion is determined in the Japan X Bowl. There are also over 200 universities fielding teams, with the national collegiate championship determined by the Koshien Bowl. The professional and collegiate champions then face each other in the Rice Bowl to determine the national champion.
In Germany, the German Football League whose elite division is called bundesliga, has 12 teams partitioned into north and south conferences. The finalists from the playoffs determine the German champion during the German Bowl.
The International Federation of American Football is the governing body for American football with 45 member associations from North and South America, Europe, Asia and Oceania. The IFAF also oversees the American Football World Cup, which is held every four years. Japan won the first two World Cups, held in 1999 and 2003. Team USA, which had not participated in the previous World Cups, won the title in 2007.
Despite this, the game has been slow to catch on in most countries. On October 2, 2005, the Arizona Cardinals and San Francisco 49ers played the first regular season NFL game outside of the United States, in Mexico City's Estadio Azteca. In 2012, The United States Naval Academy will play the University of Notre Dame in Dublin, Ireland.


The American Revolutionary War (1775–1783), also known as the American War of Independence, was, at least initially, a civil war between the Kingdom of Great Britain and thirteen British colonies on the North American continent (as well as some naval conflict). The war was the culmination of the political American Revolution, whereby the colonists overthrew Royalist rule. In 1775, Revolutionaries seized control of each of the thirteen colonial governments, set up the Second Continental Congress, and formed a Continental Army. The following year, they formally declared their independence as a new nation, the United States of America. From this time on, other European nations which rivalled Britain as colonial powers provided support for the rebels, at first secretly, later openly. Meanwhile, Native Americans and African Americans served on both sides.
Throughout the war, the British were able to use their naval superiority to capture and occupy coastal cities, but control of the countryside (where 90% of the population lived) largely eluded them due to their relatively small land army. In early 1778, shortly after an American victory at Saratoga, France signed treaties of alliance with the new nation, and declared war on Britain that summer; Spain and the Netherlands also went to war with Britain over the next two years. French involvement proved decisive, with a French naval victory in the Chesapeake leading to the surrender of a British army at Yorktown in 1781. The Treaty of Paris in 1783 ended the war and recognized the sovereignty of the United States over the territory bounded by what is now Canada to the north, Florida to the south, and the Mississippi River to the west.
Seeking to coordinate military efforts, the Continental Congress established (on paper) a regular army in June 1775, and appointed George Washington as commander-in-chief. The development of the Continental Army was always a work in progress, and Washington used both his regulars and state militia throughout the war. The United States Marine Corps traces its institutional roots to the Continental Marines of the war, formed at Tun Tavern in Philadelphia, by a resolution of the Continental Congress on November 10 1775, a date regarded and celebrated as the birthday of the Marine Corps. At the end of the American Revolution in 1783, both the Continental Navy and Continental Marines were disbanded. About 250,000 men served as regulars or as militiamen for the Revolutionary cause in the eight years of the war, but there were never more than 90,000 total men under arms at one time. Armies were small by European standards of the era; the greatest number of men that Washington personally commanded in the field at any one time was fewer than 17,000. This could be attributed to tactical preferences, but it also could be because of lack of powder on the American side.
Early in 1775, the British Army consisted of about 36,000 men worldwide, but wartime recruitment steadily increased this number. Additionally, over the course of the war the British hired about 30,000 soldiers from German princes; these soldiers were called "Hessians" because many of them came from Hesse-Kassel. The troops were mercenaries in the sense of professionals who were hired out by their prince. Germans made up about one-third of the British troop strength in North America. By 1779, the number of British and German troops stationed in North America was over 60,000, although these were spread from Canada to Florida.
African Americans — slave and free — served on both sides during the war. The British actively recruited slaves belonging to Patriot masters. Because of manpower shortages, George Washington lifted the ban on black enlistment in the Continental Army in January 1776. Small all-black units were formed in Rhode Island and Massachusetts; many were slaves promised freedom for serving. Another all-black unit came from Haiti with French forces. At least 5,000 black soldiers fought for the Revolutionary cause and more than 20,000 black soldiers fought on the British side.
Most Native Americans east of the Mississippi River were affected by the war, and many communities were divided over the question of how to respond to the conflict. Most Native Americans opposed the United States, since native lands were threatened by expanding American settlement. An estimated 13,000 warriors fought on the British side; the largest group, the Iroquois Confederacy, fielded about 1,500 men.
Before the war, Boston had been the scene of much revolutionary activity, leading to the Massachusetts Government Act that ended home rule as a punishment in 1774. Popular resistance to these measures, however, compelled the newly appointed royal officials in Massachusetts to resign or to seek refuge in Boston. Lieutenant General Thomas Gage, the British North American commander-in chief, commanded four regiments of British regulars (about 4,000 men) from his headquarters in Boston, but the countryside was in the hands of the Revolutionaries.
On the night of April 18 1775, General Gage sent 700 men to seize munitions stored by the colonial militia at Concord, Massachusetts. Riders including Paul Revere alerted the countryside, and when British troops entered Lexington on the morning of April 19, they found 77 minutemen formed up on the village green. Shots were exchanged, killing several minutemen. The British moved on to Concord, where a detachment of three companies was engaged and routed at the North Bridge by a force of 500 minutemen. As the British retreated back to Boston, thousands of militiamen attacked them along the roads, inflicting great damage before timely British reinforcements prevented a total disaster. With the Battles of Lexington and Concord, the war had begun.
The militia converged on Boston, bottling up the British in the city. About 4,500 more British soldiers arrived by sea, and on June 17, 1775, British forces under General William Howe seized the Charlestown peninsula at the Battle of Bunker Hill. The Americans fell back, but British losses were so heavy that the attack was not followed up. The siege was not broken, and Gage was soon replaced by Howe as the British commander-in-chief.
In July 1775, newly appointed General Washington arrived outside Boston to take charge of the colonial forces and to organize the Continental Army. Realizing his army's desperate shortage of gunpowder, Washington asked for new sources. Arsenals were raided and some manufacturing was attempted; 90% of the supply (2 million pounds) was imported by the end of 1776, mostly from France.
The standoff continued throughout the fall and winter. In early March 1776, heavy cannons that the patriots had captured at Fort Ticonderoga were placed on Dorchester Heights by Major Henry Knox. Since the artillery now overlooked the British positions, Howe's situation was untenable, and the British fled on March 17, 1776, sailing to their naval base at Halifax, Nova Scotia Washington then moved most of the Continental Army to fortify New York City.
Colonel James Livingston led the 1st Canadian Regiment at the Battle of Quebec (1775) and Moses Hazen led the 2nd Canadian Regiment to support the American cause at the Battle of Saint-Pierre. They both continued to fight for the Americans until the end of the war.
During the long standoff at Boston, the Continental Congress sought a way to seize the initiative elsewhere. Congress had initially invited the French Canadians to join them as the fourteenth colony, but when that failed to happen, Congress authorized an invasion of Canada. The goal was to remove British rule from the primarily francophone province of Quebec (comprising present-day Quebec).
Two Canada-bound expeditions were undertaken. On September 16, 1775, Brigadier General Richard Montgomery marched north from Fort Ticonderoga with about 1,700 militiamen, capturing Montreal on November 13. General Guy Carleton, the governor of Canada, escaped to Quebec City. The second expedition, led by Colonel Benedict Arnold, was a logistical nightmare, with many men succumbing to smallpox. By the time Arnold reached Quebec City in early November, he had but 600 of his original 1,100 men. Montgomery's force joined Arnold's, and they attacked Quebec City on December 31, but were soundly defeated by Carleton. The remaining Americans held on outside Quebec City until the spring of 1776, and then withdrew.
Another attempt was made by the Americans to push back towards Quebec, but they failed at Trois-Rivières on June 8, 1776. Carleton then launched his own invasion and defeated Arnold at the Battle of Valcour Island in October. Arnold fell back to Fort Ticonderoga, where the invasion of Canada had begun. The invasion of Canada ended as a disaster for the Americans, but Arnold's efforts in 1776 delayed a full-scale British counteroffensive until the Saratoga campaign of 1777.
Having withdrawn his army from Boston, General Howe now focused on capturing New York City. To defend the city, General Washington divided his 20,000 soldiers between Long Island and Manhattan. While British troops were assembling on Staten Island for the campaign, Washington had the newly issued Declaration of American Independence read to his men. No longer was there any possibility of compromise. On August 27, 1776, after landing about 22,000 men on Long Island, the British drove the Americans back to Brooklyn Heights in the largest battle of the entire Revolution. Howe then laid siege to fortifications there, but Washington managed to evacuate his army to Manhattan.
On September 15, Howe landed about 12,000 men on lower Manhattan, quickly taking control of New York City. The Americans withdrew to Harlem Heights, where they skirmished the next day but held their ground. When Howe moved to encircle Washington's army in October, the Americans again fell back, and a battle at White Plains was fought on October 28. Once more Washington retreated, and Howe returned to Manhattan and captured Fort Washington in mid November, taking about 2,000 prisoners (with an additional 1,000 having been captured during the battle for Long Island). Thus began the infamous "prison ships" system the British maintained in New York for the remainder of the war, in which more American soldiers and sailors died of neglect than died in every battle of the entire war, combined.
General Lord Cornwallis continued to chase Washington's army through New Jersey, until the Americans withdrew across the Delaware River into Pennsylvania in early December. With the campaign at an apparent conclusion for the season, the British entered winter quarters. Although Howe had missed several opportunities to crush the diminishing American army, he had killed or captured over 5,000 Americans.
The outlook of the Continental Army was bleak. "These are the times that try men's souls," wrote Thomas Paine, who was with the army on the retreat. The army had dwindled to fewer than 5,000 men fit for duty, and would be reduced to 1,400 after enlistments expired at the end of the year. Congress had abandoned Philadelphia in despair, although popular resistance to British occupation was growing in the countryside.
Washington decided to take the offensive, stealthily crossing the Delaware on Christmas night and capturing nearly 1,000 Hessians at the Battle of Trenton on December 26, 1776. Cornwallis marched to retake Trenton but was outmaneuvered by Washington, who successfully attacked the British rearguard at Princeton on January 3, 1777. Washington then entered winter quarters at Morristown, New Jersey, having given a morale boost to the American cause. New Jersey militia continued to harass British and Hessian forces throughout the winter, forcing the British to retreat to their base in and around New York City.
town from behind. The loyalists were too poorly organized to be effective, but as late as 1781 senior officials in London, misled by Loyalist exiles, placed their confidence in their rising.
When the British began to plan operations for 1777, they had two main armies in North America: Carleton's army in Canada, and Howe's army in New York. In London, Lord George Germain approved campaigns for these armies which, because of miscommunication, poor planning, and rivalries between commanders, did not work in conjunction. Although Howe successfully captured Philadelphia, the northern army was lost in a disastrous surrender at Saratoga. Both Carleton and Howe resigned after the 1777 campaign.
The first of the 1777 campaigns was an expedition from Canada led by General John Burgoyne. The goal was to seize the Lake Champlain and Hudson River corridor, effectively isolating New England from the rest of the American colonies. Burgoyne's invasion had two components: he would lead about 10,000 men along Lake Champlain towards Albany, New York, while a second column of about 2,000 men, led by Barry St. Leger, would move down the Mohawk River valley and link up with Burgoyne in Albany, New York.
Burgoyne set off in June, and recaptured Fort Ticonderoga in early July. Thereafter, his march was slowed by Americans who knocked down trees in his path. A detachment was sent out to seize supplies but was decisively defeated by American militia in August, depriving Burgoyne of nearly 1,000 men.
Meanwhile, St. Leger — half of his force Native Americans led by Sayenqueraghta — had laid siege to Fort Stanwix. American militiamen and their Native American allies marched to relieve the siege but were ambushed and scattered at the Battle of Oriskany. When a second relief expedition approached, this time led by Benedict Arnold, St. Leger broke off the siege and retreated to Canada.
Burgoyne's army was now reduced to about 6,000 men. Despite these setbacks, he determined to push on towards Albany — a fateful decision which would later produce much controversy. An American army of 8,000 men, commanded by the General Horatio Gates, had entrenched about 10 miles (16 km) south of Saratoga, New York. Burgoyne tried to outflank the Americans but was checked at the first battle of Saratoga in September. Burgoyne's situation was desperate, but he now hoped that help from Howe's army in New York City might be on the way. It was not: Howe had instead sailed away on an expedition to capture Philadelphia. American militiamen flocked to Gates' army, swelling his force to 11,000 by the beginning of October. After being badly beaten at the second battle of Saratoga, Burgoyne surrendered on October 17.
Saratoga was the turning point of the war. Revolutionary confidence and determination, suffering from Howe's successful occupation of Philadelphia, was renewed. More importantly, the victory encouraged France to make an open alliance with the Americans, after two years of semi-secret support. For the British, the war had now become much more complicated.
Having secured New York City in 1776, General Howe concentrated on capturing Philadelphia, the seat of the Revolutionary government, in 1777. He moved slowly, landing 15,000 troops in late August at the northern end of Chesapeake Bay. Washington positioned his 11,000 men between Howe and Philadelphia but was driven back at the Battle of Brandywine on September 11, 1777. The Continental Congress once again abandoned Philadelphia, and on September 26, Howe finally outmaneuvered Washington and marched into the city unopposed. Washington unsuccessfully attacked the British encampment in nearby Germantown in early October and then retreated to watch and wait.
After repelling a British attack at White Marsh, Washington and his army encamped at Valley Forge in December 1777, about 20 miles (32 km) from Philadelphia, where they stayed for the next six months. Over the winter, 2,500 men (out of 10,000) died from disease and exposure. The next spring, however, the army emerged from Valley Forge in good order, thanks in part to a training program supervised by Baron von Steuben. Indeed, von Steuben introduced the most modern Prussian methods of organization and tactics.
General Clinton replaced Howe as British commander-in-chief. French entry into the war had changed British strategy, and Clinton abandoned Philadelphia in order to reinforce New York City, now vulnerable to French naval power. Washington shadowed Clinton on his withdrawal and forced a draw at the battle at Monmouth on June 28, 1778, the last major battle in the north. Clinton's army went to New York City in July, just before a French fleet under Admiral d'Estaing arrived off the American coast. Washington's army returned to White Plains, New York, north of the city. Although both armies were back where they had been two years earlier, the nature of the war had now changed.
In 1778, the war over the rebellion in North America became international; spreading not only to Europe, but to the European colonies, chiefly in India. After learning of the American victory in Saratoga, France signed the Treaty of Alliance with the United States on February 6, 1778. Spain entered the war as an ally of France in June 1779, a renewal of the Bourbon Family Compact. Unlike France, however, Spain initially refused to recognize the independence of the United States — Spain was not keen on encouraging similar anti-colonial rebellions in the Spanish Empire. Both countries had quietly provided assistance to the Americans since the beginning of the war, hoping to dilute British power. So too had the Netherlands, eventually brought into open war at the end of 1780.
splinter the Congress; and "would keep the rebels harassed, anxious, and poor, until the day when, by a natural and inevitable process, discontent and disappointment were converted into penitence and remorse" and they would beg to return to his authority. The plan meant destruction for the Loyalists and loyal Native Americans, and indefinite prolongation of a costly war, as well as the risk of disaster as the French and Spanish were assembling an armada to invade the British isles and seize London. The British planned to re-subjugate the rebellious colonies after dealing with their European allies.
French entry into the war meant that British naval superiority was now contested. The Franco-American alliance began poorly, however, with failed operations at Rhode Island in 1778 and Savannah, Georgia, in 1779. Part of the problem was that France and the United States had different military priorities: France hoped to capture British possessions in the West Indies before helping to secure American independence. While French financial assistance to the American war effort was already of critical importance, French military aid to the Americans would not show positive results until the arrival in July 1780 of a large force of soldiers led by the Comte de Rochambeau.
Spain entered the war on the side of the Americans with the goal of recapturing Gibraltar and Minorca, which had been lost to the British in 1704. Gibraltar was besieged for more than three years, but the British garrison stubbornly resisted for years and was finally resupplied after Admiral Rodney's victory in the "Moonlight Battle" (January, 1780). Further Franco-Spanish efforts to capture Gibraltar were unsuccessful. One notable success took place on February 5, 1782 when Spanish and French forces captured Minorca, which Spain retained after the war.
There was much action in the West Indies, with several islands changing hands, especially in the Lesser Antilles. At the Battle of the Saintes in April 1782, a victory by Rodney's fleet over the French Admiral de Grasse frustrated the hopes of France and Spain to take Jamaica and other colonies from the British. On May 8, 1782, Count Bernardo de Gálvez, the Spanish governor of Louisiana, captured the British naval base at New Providence in the Bahamas. Nevertheless, except for the French retention of the small island of Tobago, sovereignty in the West Indies was returned to the status quo ante bellum in the 1783 peace treaty.
On the Gulf Coast, Gálvez seized three British Mississippi River outposts in 1779: Manchac, Baton Rouge, and Natchez. Gálvez then captured Mobile in 1780 and forced the surrender of the British outpost at Pensacola in 1781. His actions led to Spain acquiring East and West Florida in the peace settlement.
In 1780, the British struck against the United Provinces of the Netherlands in order to preempt Dutch involvement in the League of Armed Neutrality, a declaration of several European powers that they would conduct neutral trade during the war. Britain was not willing to allow the Netherlands to openly give aid to the American rebels. Agitation by Dutch radicals and a friendly attitude towards the United States by the Dutch government — both influenced by the American Revolution — also encouraged the British to attack. The Fourth Anglo-Dutch War lasted into 1784 and was disastrous to the Dutch mercantile economy.
During the first three years of the American Revolutionary War, the primary military encounters were in the north. After French entry into the war, the British turned their attention to the southern colonies, where they hoped to regain control by recruiting Loyalists. This southern strategy also had the advantage of keeping the Royal Navy closer to the Caribbean, where the British needed to defend their possessions against the French and Spanish.
On December 29, 1778, an expeditionary corps from Clinton's army in New York captured Savannah, Georgia. An attempt by French and American forces to retake Savannah failed on October 9, 1779. Clinton then besieged Charleston, capturing it on May 12, 1780. With relatively few casualties, Clinton had seized the South's biggest city and seaport, paving the way for what seemed like certain conquest of the South.
The remnants of the southern Continental Army began to withdraw to North Carolina but were pursued by Lt. Colonel Banastre Tarleton, who defeated them at the Waxhaws on May 29, 1780. With these events, organized American military activity in the region collapsed, though the war was carried on by partisans such as Francis Marion. Cornwallis took over British operations, while Horatio Gates arrived to command the American effort. On August 16, 1780, Gates was defeated at the Battle of Camden, setting the stage for Cornwallis to invade North Carolina.
Cornwallis' victories quickly turned, however. One wing of his army was utterly defeated at the Battle of Kings Mountain on October 7, 1780. Tarleton was decisively defeated at the Battle of Cowpens on January 17, 1781, by American General Daniel Morgan.
General Nathanael Greene, Gates' replacement, proceeded to wear down the British in a series of battles, each of them tactically a victory for the British but giving no strategic advantage to the victors. Greene summed up his approach in a motto that would become famous: "We fight, get beat, rise, and fight again." Unable to capture or destroy Greene's army, Cornwallis moved north to Virginia.
In March 1781, General Washington dispatched General Lafayette to defend Virginia. The young Frenchman skirmished with Cornwallis, avoiding a decisive battle while gathering reinforcements. Cornwallis was unable to trap Lafayette, and so he moved his forces to Yorktown, Virginia, in July so the Royal Navy could return his army to New York.
West of the Appalachian Mountains and along the Canadian border, the American Revolutionary War was an "Indian War." Most Native Americans supported the British. Like the Iroquois Confederacy, tribes such as the Cherokees and the Shawnees split into factions.
The British supplied their native allies with muskets and gunpowder and advised raids against civilian settlements, especially in New York, Kentucky, and Pennsylvania. Joint Iroquois-Loyalist attacks in the Wyoming Valley and at Cherry Valley in 1778 provoked Washington to send the Sullivan Expedition into western New York during the summer of 1779. There was little fighting as Sullivan systematically destroyed the Native American winter food supplies, forcing them to flee permanently to British bases in Canada and the Niagara Falls area.
In the Ohio Country and the Illinois Country, the Virginia frontiersman George Rogers Clark attempted to neutralize British influence among the Ohio tribes by capturing the outposts of Kaskaskia and Vincennes in the summer of 1778. When General Henry Hamilton, the British commander at Detroit, retook Vincennes, Clark returned in a surprise march in February 1779 and captured Hamilton himself.
In 1782 came the Gnadenhütten massacre, when Pennsylvania militiamen killed about a hundred neutral Native Americans. In August 1782, in one of the last major encounters of the war, a force of 200 Kentucky militia was defeated at the Battle of Blue Licks.
The northern, southern, and naval theaters of the war converged in 1781 at Yorktown, Virginia. In early September, French naval forces defeated a British fleet at the Battle of the Chesapeake, cutting off Cornwallis' escape. Washington hurriedly moved American and French troops from New York, and a combined Franco-American force of 17,000 men commenced the siege of Yorktown in early October. Cornwallis' position quickly became untenable, and he surrendered his army on October 19 1781.
With the surrender at Yorktown, King George lost control of Parliament to the peace party, and there were no further major military activities on land. The British had 30,000 garrison troops occupying New York City, Charleston, and Savannah. The war continued at sea between the British and the French fleets in the West Indies. The British might have sent more troops to attack the colonists if not for the numerous American ships attacking British shipping lanes worldwide. Due to the impact on British pocketbooks, the merchants put pressure on Parliament to end the war.
In London as political support for the war plummeted after Yorktown, Prime Minister Lord North resigned in March 1782. In April 1782, the Commons voted to end the war in America. Preliminary peace articles were signed in Paris at the end of November, 1782; the formal end of the war did not occur until the Treaty of Paris was signed on September 3, 1783, and the United States Congress of the Confederation ratified the treaty on January 14, 1784. The last British troops left New York City on November 25, 1783.
Britain negotiated the Paris peace treaty without consulting her Native American allies and ceded all Native American territory between the Appalachian Mountains and the Mississippi River to the United States. Full of resentment, Native Americans reluctantly confirmed these land cessions with the United States in a series of treaties, but the fighting would be renewed in conflicts along the frontier in the coming years, the largest being the Northwest Indian War.
The total loss of life resulting from the American Revolutionary War is unknown. As was typical in the wars of the era, disease claimed more lives than battle. Historian Joseph Ellis suggests that Washington's decision to have his troops inoculated against the smallpox epidemic was one of his most important decisions.
An estimated 25,000 American Revolutionaries died during active military service. About 8,000 of these deaths were in battle; the other 17,000 deaths were from disease, including about 8,000 who died while prisoners of war. The number of Revolutionaries seriously wounded or disabled by the war has been estimated from 8,500 to 25,000. The total American military casualty figure was therefore as high as 50,000.
About 171,000 seamen served for the British during the war; about 25 to 50 percent of them had been pressed into service. About 1,240 were killed in battle, while 18,500 died from disease. The greatest killer was scurvy, a disease known at the time to be easily preventable by issuing lemon juice to sailors. About 42,000 British seamen deserted during the war.
Approximately 1,200 Germans were killed in action and 6,354 died from illness or accident. About 16,000 of the remaining German troops returned home, but roughly 5,500 remained in the United States after the war for various reasons, many eventually becoming American citizens. No reliable statistics exist for the number of casualties among other groups, including Loyalists, British regulars, Native Americans, French and Spanish troops, and civilians.
The British spent about £80 million and ended with a national debt of £250 million, which it easily financed at about £9.5 million a year in interest. The French spent 1.3 billion livres (about £56 million). Their total national debt was £187 million, which they could not easily finance; over half the French national revenue went to debt service in the 1780s. The debt crisis became a major enabling factor of the French Revolution as the government was unable to raise taxes without public approval. The United States spent $37 million at the national level plus $114 million by the states. This was mostly covered by loans from France and the Netherlands, loans from Americans, and issuance of more and more paper money (which became "not worth a continental.") The U.S. finally solved its debt problem in the 1790s.
The war of American independence could be summed up as a civil war fought on foreign soil, as opposing forces comprised both nations' residents. One could argue that after the Declaration of Independence on July 4, 1776, it was a war between two different nations, the Americans and the British. However, both sides were technically of English or European descent; as a result one could compare the American Revolutionary War to the English Civil War, in which the Parliamentarians and Royalists were both English, but in their own way, two different nations or factions. That said, it is a war that America could not have survived without French assistance. In addition, Britain had significant military disadvantages. Distance was a major problem: most troops and supplies had to be shipped across the Atlantic Ocean. The British usually had logistical problems whenever they operated away from port cities, while the Americans had local sources of manpower and food and were more familiar with (and acclimated to) the territory. Additionally, ocean travel meant that British communications were always about two months out of date: by the time British generals in America received their orders from London, the military situation had usually changed.
Suppressing a rebellion in America also posed other problems. Since the colonies covered a large area and had not been united before the war, there was no central area of strategic importance. In Europe, the capture of a capital often meant the end of a war; in America, when the British seized cities such as New York and Philadelphia, the war continued unabated. Furthermore, the large size of the colonies meant that the British lacked the manpower to control them by force. Once any area had been occupied, troops had to be kept there or the Revolutionaries would regain control, and these troops were thus unavailable for further offensive operations. The British had sufficient troops to defeat the Americans on the battlefield but not enough to simultaneously occupy the colonies. This manpower shortage became critical after French and Spanish entry into the war, because British troops had to be dispersed in several theaters, where previously they had been concentrated in America.
The British also had the difficult task of fighting the war while simultaneously retaining the allegiance of Loyalists. Loyalist support was important, since the goal of the war was to keep the colonies in the British Empire, but this imposed numerous military limitations. Early in the war, the Howe brothers served as peace commissioners while simultaneously conducting the war effort, a dual role which may have limited their effectiveness. Additionally, the British could have recruited more slaves and Native Americans to fight the war, but this would have alienated many Loyalists, even more so than the controversial hiring of German mercenaries. The need to retain Loyalist allegiance also meant that the British were unable to use the harsh methods of suppressing rebellion they employed in Ireland and Scotland. Even with these limitations, many potentially neutral colonists were nonetheless driven into the ranks of the Revolutionaries because of the war. This combination of factors led ultimately to the downfall of British rule in America and the rise of the revolutionaries' own independent nation, the United States of America.
Out of the approximately 107 battles of the American Revolutionary War, the British and their allies won 48. Tactically, out of the 48 battles, 15 were decisive conflicts and 4 were Pyrrhic. The Americans and their allies won 39 battles. Of these, 7 were decisive (most of the decisive engagements were won by France and Spain) and 1 was Pyrrhic. Twenty of the battles ended inconclusively.
To avoid duplication, notes for sections with a link to a "Main article" will be found in the linked article.
These are some of the standard works about the war in general which are not listed above; books about specific campaigns, battles, units, and individuals can be found in those articles.


The ampere, in practice often shortened to amp, (symbol: A) is a unit of electric current, or amount of electric charge per second. The ampere is an SI base unit, and is named after André-Marie Ampère, one of the main discoverers of electromagnetism.
The ampere is a constant current which, if maintained in two straight parallel conductors of infinite length, of negligible circular cross section, and placed 1 metre apart in a vacuum, would produce between these conductors a force equal to 2×10–7 newton per metre of length. For a description of this force law, see Serway. See also Ampère's force law.
The ampere is a base unit, along with the metre, kelvin, second, mole, candela and the kilogram: it is defined without reference to the quantity of electric charge.
Because it is a base unit, the definition of the ampere is not tied to any other electrical unit. The definition for the ampere is equivalent to fixing a value of the magnetic constant at μ0 4π×10−7 H/m. Prior to 1948, the so-called "international ampere" was used, defined in terms of the electrolytic deposition rate of silver. The older unit is equal to 0.999 85 A.
The ampere is most accurately realized using a watt balance, but is in practice maintained via Ohm's Law from the units of EMF and resistance, the volt and the ohm, since the latter two can be tied to physical phenomena that are relatively easy to reproduce, the Josephson junction and the quantum Hall effect, respectively. The official realization of a standard ampere is discussed in NIST Special publication 330 Barry N Taylor (editor) Appendix 2, p. 56.
Since a coulomb is approximately equal to 6.24150948×1018 elementary charges, one ampere is approximately equivalent to 6.24150948×1018 elementary charges, such as electrons, moving past a boundary in one second.
This redefinition of the kilogram has the effect of fixing the elementary charge to be e = 1.60217653 C and would result in a functionally equivalent definition for the coulomb as being the sum of exactly 6 241 509 479 607 717 888 elementary charges and the ampere as being the electrical current of exactly 6 241 509 479 607 717 888 elementary charges per second. This is consistent with the current 2002 CODATA value for the elementary charge which is 1.60217653×10-19 ± 0.00000014×10-19 C.


The following terms are used in American football and Canadian football, but see also the glossary of Canadian football.
First down is the first of the plays; fourth is the last down in American, and third in Canadian, football. A first down occurs after a change of possession of the ball, after advancing the ball 10 yards following a previous first down or after certain penalties.
Maryland-I : An I formation with two fullbacks and a tailback.


In mathematics, computing, linguistics and related disciplines, an algorithm is a type of effective method in which a definite list of well-defined instructions for completing a task, when given an initial state, will proceed through a well-defined series of successive states, eventually terminating in an end-state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as probabilistic algorithms, incorporate randomness.
The concept of an algorithm originated as a means of recording procedures for solving mathematical problems such as finding the common divisor of two numbers or multiplying two numbers; such algorithms were in use by the Babylonians as early as 1600 BC.
A partial formalization of the concept began with attempts to solve the Entscheidungsproblem (the "decision problem") that David Hilbert posed in 1928. Subsequent formalizations were framed as attempts to define "effective calculability"(Kleene 1943:274) or "effective method" (Rosser 1939:225); those formalizations included the Gödel-Herbrand-Kleene recursive functions of 1930, 1934 and 1935, Alonzo Church's lambda calculus of 1936, Emil Post's "Formulation I" of 1936, and Alan Turing's Turing machines of 1936-7 and 1939.
Al-Khwārizmī, Persian astronomer and mathematician, wrote a treatise in Arabic in 825 AD, On Calculation with Hindu Numerals. (See algorism). It was translated into Latin in the 12th century as Algoritmi de numero Indorum (al-Daffa 1977), which title was likely intended to mean "[Book by] Algoritmus on the numbers of the Indians", where "Algoritmi" was the translator's rendition of the author's name in the genitive case; but people misunderstanding the title treated Algoritmi as a Latin plural and this led to the word "algorithm" (Latin algorismus) coming to mean "calculation method". The intrusive "th" is most likely due to a false cognate with the Greek αριθμος (arithmos) meaning "number".
The concept of algorithm is also used to define the notion of decidability (logic). That notion is central for explaining how formal systems come into being starting from a small set of axioms and rules. In logic, the time that an algorithm requires to complete cannot be measured, as it is not apparently related with our customary physical dimension. From such uncertainties, that characterize ongoing work, stems the unavailability of a definition of algorithm that suits both concrete (in some sense) and abstract usage of the term.
Typically, when an algorithm is associated with processing information, data are read from an input source or device, written to an output sink or device, and/or stored for further processing. Stored data are regarded as part of the internal state of the entity performing the algorithm. In practice, the state is stored in a data structure, but an algorithm requires the internal data only for specific operation sets called abstract data types.
For any such computational process, the algorithm must be rigorously defined: specified in the way it applies in all possible circumstances that could arise. That is, any conditional steps must be systematically dealt with, case-by-case; the criteria for each case must be clear (and computable).
Because an algorithm is a precise list of precise steps, the order of computation will almost always be critical to the functioning of the algorithm. Instructions are usually assumed to be listed explicitly, and are described as starting "from the top" and going "down to the bottom", an idea that is described more formally by flow of control.
So far, this discussion of the formalization of an algorithm has assumed the premises of imperative programming. This is the most common conception, and it attempts to describe a task in discrete, "mechanical" means. Unique to this conception of formalized algorithms is the assignment operation, setting the value of a variable. It derives from the intuition of "memory" as a scratchpad. There is an example below of such an assignment.
For some alternate conceptions of what constitutes an algorithm see functional programming and logic programming.
Some writers restrict the definition of algorithm to procedures that eventually finish. In such a category Kleene places the "decision procedure or decision method or algorithm for the question" (Kleene 1952:136). Others, including Kleene, include procedures that could run forever without stopping; such a procedure has been called a "computational method" (Knuth 1997:5) or "calculation procedure or algorithm" (Kleene 1952:137); however, Kleene notes that such a method must eventually exhibit "some object" (Kleene 1952:137).
But if the length of the process is not known in advance, then 'trying' it may not be decisive, because if the process does go on forever — then at no time will we ever be sure of the answer (Minsky 1967:105).
As it happens, no other method can do any better, as was shown by Alan Turing with his celebrated result on the undecidability of the so-called halting problem. There is no algorithmic procedure for determining of arbitrary algorithms whether or not they terminate from given starting states. The analysis of algorithms for their likelihood of termination is called termination analysis.
We normally require auxiliary evidence for this (that the algorithm correctly defines a mu recursive function), e.g. in the form of an inductive proof that, for each argument value, the computation terminates with a unique value (Minsky 1967:186).
Algorithms can be expressed in many kinds of notation, including natural languages, pseudocode, flowcharts, and programming languages. Natural language expressions of algorithms tend to be verbose and ambiguous, and are rarely used for complex or technical algorithms. Pseudocode and flowcharts are structured ways to express algorithms that avoid many of the ambiguities common in natural language statements, while remaining independent of a particular implementation language. Programming languages are primarily intended for expressing algorithms in a form that can be executed by a computer, but are often used as a way to define or document algorithms.
There is a wide variety of representations possible and one can express a given Turing machine program as a sequence of machine tables (see more at finite state machine and state transition table), as flowcharts (see more at state diagram), or as a form of rudimentary machine code or assembly code called "sets of quadruples" (see more at Turing machine).
Sometimes it is helpful in the description of an algorithm to supplement small "flow charts" (state diagrams) with natural-language and/or arithmetic expressions written inside "block diagrams" to summarize what the "flow charts" are accomplishing.
Most algorithms are intended to be implemented as computer programs. However, algorithms are also implemented by other means, such as in a biological neural network (for example, the human brain implementing arithmetic or an insect looking for food), in an electrical circuit, or in a mechanical device.
 Input: A non-empty list of numbers L.
 Output: The largest number in the list L.
For a more complex example of an algorithm, see Euclid's algorithm for the greatest common divisor, one of the earliest algorithms known.
As it happens, it is important to know how much of a particular resource (such as time or storage) is required for a given algorithm. Methods have been developed for the analysis of algorithms to obtain such quantitative answers; for example, the algorithm above has a time requirement of O(n), using the big O notation with n as the length of the list. At all times the algorithm only needs to remember two values: the largest number found so far, and its current position in the input list. Therefore it is said to have a space requirement of O(1), if the space required to store the input numbers is not counted, or O (log n) if it is counted.
Different algorithms may complete the same task with a different set of instructions in less or more time, space, or effort than others. For example, given two different recipes for making potato salad, one may have peel the potato before boil the potato while the other presents the steps in the reverse order, yet they both call for these steps to be repeated for all potatoes and end when the potato salad is ready to be eaten.
The analysis and study of algorithms is a discipline of computer science, and is often practiced abstractly without the use of a specific programming language or implementation. In this sense, algorithm analysis resembles other mathematical disciplines in that it focuses on the underlying properties of the algorithm and not on the specifics of any particular implementation. Usually pseudocode is used for analysis as it is the simplest and most general representation.
There are various ways to classify algorithms, each with its own merits.
One way to classify algorithms is by implementation means.
Every field of science has its own problems and needs efficient algorithms. Related problems in one field are often studied together. Some example classes are search algorithms, sorting algorithms, merge algorithms, numerical algorithms, graph algorithms, string algorithms, computational geometric algorithms, combinatorial algorithms, machine learning, cryptography, data compression algorithms and parsing techniques.
Fields tend to overlap with each other, and algorithm advances in one field may improve those of other, sometimes completely unrelated, fields. For example, dynamic programming was originally invented for optimization of resource consumption in industry, but is now used in solving a broad range of problems in many fields.
Algorithms can be classified by the amount of time they need to complete compared to their input size. There is a wide variety: some algorithms complete in linear time relative to input size, some do so in an exponential amount of time or even worse, and some never halt. Additionally, some problems may have multiple algorithms of differing complexity, while other problems might have no algorithms or no known efficient algorithms. There are also mappings from some problems to other problems. Owing to this, it was found to be more suitable to classify the problems themselves instead of the algorithms into equivalence classes based on the complexity of the best possible algorithms for them.
Another way to classify algorithms is by computing power. This is typically done by considering some collection (class) of algorithms. A recursive class of algorithms is one that includes algorithms for all Turing computable functions. Looking at classes of algorithms allows for the possibility of restricting the available computational resources (time and memory) used in a computation. A subrecursive class of algorithms is one in which not all Turing computable functions can be obtained. For example, the algorithms that run in polynomial time suffice for many important types of computation but do not exhaust all Turing computable functions. The class algorithms implemented by primitive recursive functions is another subrecursive class.
Burgin (2005, p. 24) uses a generalized definition of algorithms that relaxes the common requirement that the output of the algorithm that computes a function must be determined after a finite number of steps. He defines a a super-recursive class of algorithms as "a class of algorithms in which it is possible to compute functions not computable by any Turing machine" (Burgin 2005, p. 107). This is closely related to the study of methods of hypercomputation.
Algorithms, by themselves, are not usually patentable. In the United States, a claim consisting solely of simple manipulations of abstract concepts, numbers, or signals do not constitute "processes" (USPTO 2006) and hence algorithms are not patentable (as in Gottschalk v. Benson). However, practical applications of algorithms are sometimes patentable. For example, in Diamond v. Diehr, the application of a simple feedback algorithm to aid in the curing of synthetic rubber was deemed patentable. The patenting of software is highly controversial, and there are highly criticized patents involving algorithms, especially data compression algorithms, such as Unisys' LZW patent.
Additionally, some cryptographic algorithms have export restrictions (see export of cryptography).
The word algorithm comes from the name of the 9th century Persian mathematician Abu Abdullah Muhammad ibn Musa al-Khwarizmi whose works introduced Indian numerals and algebraic concepts. He worked in Baghdad at the time when it was the centre of scientific studies and trade. The word algorism originally referred only to the rules of performing arithmetic using Arabic numerals but evolved via European Latin translation of al-Khwarizmi's name into algorithm by the 18th century. The word evolved to include all definite procedures for solving problems or performing tasks.
Tally-marks: To keep track of their flocks, their sacks of grain and their money the ancients used tallying: accumulating stones or marks scratched on sticks, or making discrete symbols in clay. Through the Babylonian and Egyptian use of marks and symbols, eventually Roman numerals and the abacus evolved (Dilson, p.16–41). Tally marks appear prominently in unary numeral system arithmetic used in Turing machine and Post-Turing machine computations.


Botanically, an annual plant is a plant that usually germinates, flowers and dies in one year. True annuals will only live longer than a year if they are prevented from setting seed. Some seedless plants can also be considered annuals even though they do not flower.
In gardening, annual often refers to a plant grown outdoors in the spring and summer and surviving just for one growing season.
Many food plants are, or are grown as, annuals, including most domesticated grains. Some perennials and biennials are grown in gardens as annuals for convenience, particularly if they are not considered cold hardy for the local climate. Carrot, celery and parsley are true biennials that are usually grown as annual crops for their edible roots, petioles and leaves, respectively. Tomato, sweet potato and bell pepper are tender perennials usually grown as annuals.
Ornamental annualer perennials commonly grown as annuals are impatiens, wax begonia, snapdragon, Pelargonium, coleus and petunia. Some biennials that can be grown as annuals are pansy and hollyhock.
One seed-to-seed life cycle for an annual can occur in as little as a month in some species, though most last several months. Oilseed rapa can go from seed-to-seed in about five weeks under a bank of fluorescent lamps in a school classroom. Many desert annuals are termed ephemerals because their seed-to-seed life cycle is only a few weeks. They spend most of the year as seeds to survive dry conditions.
Examples of true annuals include corn, lettuce, pea, cauliflower, watermelon, bean, zinnia and marigold.
Summer annuals sprout, flower and die within the same spring/summer/fall. The lawn weed, crabgrass, is a summer annual.
Winter Annuals are plants that have an annual life span but tend to germanate in the fall or winter and bloom in late autumn/fall, winter or early spring. The plants grow and bloom during the cool season when most other plants are dormant or other annuals are in seed form waiting for warmer weather to germinate. Winter annuals die after flowering and setting seed, the seeds wait to germinate until the soil temperature is cool again in the fall or winter. Winter annuals typically grow low to the ground, where they are usually sheltered from the coldest nights by snow cover, and make use of warm periods in winter for growth when the snow melts. Some common winter annuals include henbit, deadnettle, chickweed, and winter cress. Winter annuals are important ecologically, as they provide vegetative cover that prevents soil erosion during winter and early spring when no other cover exists and they provide fresh vegetation for animals and birds that feed on them.
Although they are often considered to be weeds in gardens, this viewpoint is not always necessary, as most of them die when the soil temperature warms up again in early to late spring when other plants are still dormant and have not yet leafed out.
Even though they do not compete directly with cultivated plants, sometimes winter annuals are considered a pest in commercial agriculture, because they can be hosts for insect pests or fungal diseases (ovary smut - Microbotryum sp) which attack crops being cultivated. Ironically, the property that they prevent the soil from drying out can also be problematic for commercial agriculture.


Atlas, in modern usage, most commonly refers to a collection of maps, traditionally bound into book form.


Mouthwash or mouth rinse is a product used for oral hygiene. Antiseptic and anti-plaque mouth rinse claims to kill the bacterial plaque that causes caries, gingivitis, and bad breath. Anti-cavity mouth rinse uses fluoride to protect against tooth decay. However, it is generally agreed that the use of mouthwash does not eliminate the need for both brushing and flossing. In the absence of a ready-made mouthwash, gargling with plain water is preferable, to remove food particles, sugars and other pollutants in the mouth.
Mouth washes may also be used to help remove mucous and food particles deeper down in the throat. Alcoholic and strong flavored mouth washes may cause coughing for this purpose.
The first known reference to mouth rinsing is in the Chinese medicine, about 2700 BCE, for treatment of gingivitis. Later, in the Greek and Roman periods, mouthrinsing following mechanical cleansing became common among the upper classes, and Hippocrates recommended a mixture of salt, alum and vinegar. The Jewish Talmud, dating back about 1800 years, suggests a cure for gum ailments containing "dough water" and olive oil.
Anton van Leeuwenhoek, the famous 17th century microscopist, discovered living organisms (living, because they were motile) in deposits on the teeth (what we now call dental plaque). He also found organisms in water from the canal next to his home in Delft. He experimented with samples by adding vinegar or brandy and found that this resulted in the immediate immobilization or killing of the organisms suspended in water. Next he tried rinsing the mouth of himself and somebody else with a rather foul mouthwash containing vinegar or brandy and found that living organisms remained in the dental plaque. He concluded — correctly — that the mouthwash either did not reach, or was not present long enough, to kill the plaque organisms.
That remained the state of affairs until the late 1960s when Harald Loe (at the time a professor at the Royal Dental College in Aarhus, Denmark) demonstrated that a chlorhexidine compound could prevent the build-up of dental plaque. The reason for chlorhexidine effectiveness is that it strongly adheres to surfaces in the mouth and thus remains present in effective concentrations for many hours.
Common use involves rinsing the mouth with about 20ml (2/3 fl oz) of mouthwash two times a day after brushing. The wash is typically swished or gargled for about half a minute and then spat out. In some brands, the expectorate is stained, so that one can see the bacteria and debris. However it is probably advisable to use mouthwash at least an hour after brushing with toothpaste, since the anionic compounds in the toothpaste can inactivate cationic agents present in the mouthrinse. Probably the most effective time to rinse and gargle with a mouthrinse is at bed time.
Active ingredients in commercial brands of mouthwash can include thymol, eucalyptol, hexetidine, methyl salicylate, menthol, chlorhexidine gluconate, benzalkonium chloride, cetylpyridinium chloride, methylparaben, hydrogen peroxide, domiphen bromide and sometimes fluoride, enzymes and calcium. Ingredients also include water, sweeteners such as sorbitol, Sucralose, sodium saccharine, and xylitol (which doubles as a bacterial inhibitor).
Sometimes a significant amount of alcohol (up to around 20%) is added, as a carrier for the flavor, to provide "bite" and to contribute an antibacterial effect. Because of the alcohol content, it is possible to fail a breathalyzer test after rinsing; in addition, alcohol is a drying agent and may worsen chronic bad breath. As such, it is possible for alcoholics to abuse mouthwash. Recently, some assumptions were made of a possible carcinogenic character of alcohol used in mouthrinses, but no clear evidence was found. Commercial mouthwashes usually contain a preservative such as sodium benzoate to preserve freshness once the container has been opened. Many newer brands are alcohol-free and contain odor-elimination agents such as oxidizers, as well as odor-preventing agents such as zinc ion technology to keep future bad breath from developing.
A salt mouthwash is a home treatment for mouth infections and/or injuries, or post extraction, and is made by dissolving a teaspoon of salt in a cup of warm water. Plain (diluted) hydrogen peroxide is another common mouthwash.
One thing to note is that many commercial mouthwashes are very acidic on the pH scale. If you have heartburn, acid reflux or acid indigestion, it is important to use a mouthwash with a neutral pH to avoid irritation.


Alexander the Great (Greek: or, Megas Alexandros; July 20 356 BC – June 10 323 BC), also known as Alexander III, was an ancient Greek king (basileus) of Macedon (336–323 BC). He was one of the most successful military commanders in history, and was undefeated in battle. By the time of his death, he had conquered most of the world known to the ancient Greeks.
Following the unification of the multiple city-states of ancient Greece under the rule of his father, Philip II of Macedon (a labour Alexander had to repeat because the southern Greeks rebelled after Philip's death), Alexander conquered the Achaemenid Persian Empire, including Anatolia, Syria, Phoenicia, Judea, Gaza, Egypt, Bactria, and Mesopotamia, and extended the boundaries of his own empire as far as Punjab, India.
Prior to his death, Alexander had already made plans for military and mercantile expansions into the Arabian peninsula, after which he was to turn his armies to the west (Carthage, Rome, and the Iberian Peninsula). His original vision had been to the east, though, to the ends of the world and the Great Outer Sea, as described by his boyhood tutor Aristotle.
Alexander integrated many foreigners into his army, leading some scholars to credit him with a "policy of fusion." He also encouraged marriages between his soldiers and foreigners; he himself went on to marry two foreign princesses.
Alexander died after twelve years of constant military campaigning, possibly as a result of malaria, poisoning, typhoid fever, viral encephalitis or the consequences of alcoholism. His legacy and conquests lived on long after him, and ushered in centuries of Greek settlement and cultural influence over distant areas. This period is known as the Hellenistic Age, and featured a combination of Greek, Middle Eastern and Indian culture. Alexander himself was featured prominently in the history and myth of both Greek and non-Greek cultures. His exploits inspired a literary tradition in which he appeared as a legendary hero in the tradition of Achilles.
Born in Pella, capital of Macedon, Alexander was the son of King Philip II of Macedon and of his fourth wife Olympias, an Epirote princess. On his mother's side, he was a second cousin of Pyrrhus of Epirus, who himself would go on to become a celebrated general; thus, there are notable examples of military genius on both sides of his family. According to Plutarch, his father was descended from Heracles through Karanus of Macedon and his mother descended from Aeacus through Neoptolemus and Achilles. Plutarch relates that both Philip and Olympias dreamt of their son's future birth. In Philip's dream, he sealed her womb with the seal of the lion. Alarmed by this, he consulted the seer Aristander of Telmessos, who determined that his wife was pregnant and that the child would have the character of a lion. Another odd coincidence is that the temple of Artemis in Ephesus was set afire on the night of his birth. Plutarch's explanation is that the Gods were too busy watching over Alexander to care for the temple.
According to five historians of antiquity (Arrian, Curtius, Diodorus, Justin, and Plutarch), after his visit to the Oracle of Ammon at Siwa, rumors spread that the Oracle had revealed Alexander's father to be Zeus, rather than Philip. In support of this, Plutarch (Alexander 3.1,3) claims that Philip avoided Olympias' bed because of her affinity for sleeping in the company of snakes.
In his early years, Alexander was raised by his nurse Lanike, who was Cleitus' older sister. Later, Alexander was educated by a strict teacher: Leonidas, himself a relative of Olympias. Leonidas' frugal ways are known to us through the extant record: reportedly, when Alexander threw a large amount of sacrificial incense into a fire, Leonidas reprimanded him, telling him that he could waste as much incense as he wished once he had conquered the spice bearing regions. Years later, following Alexander's conquest of Gaza, a city directly on the Persian spice trade route, the young king sent back over 15 tons of myrrh to Leonidas as a retort. It was Aristotle, though, who was Alexander's most famous and important tutor. The famous philosopher trained Alexander in rhetoric and literature, and stimulated his interest in science, medicine, and philosophy. His gift to Alexander, a copy of the Iliad, was purportedly among the young king's most prized possessions--and was kept under his pillow, along with a dagger.
When Alexander was ten years old, a Thessalian brought a horse of such quality to sell to Philip that it was labeled a prodigy. As it turned out, though, the horse was so wild that no man could mount him. Young Alexander, recognizing that the horse's own shadow was the source of its fear, went to the steed and turned him towards the sun. Upon doing so, the horse calmed down, and the young king easily mounted and rode him. His father and other people who saw this were very impressed; Philip kissed him with tears of joy and said "My son, seek thee out a kingdom equal to thyself; Macedon has not room for thee." This horse was named Bucephalus, meaning "ox-headed"--though there is the possibility that the name refers to the brand that denoted the horse's origin. Bucephalus would be Alexander's companion throughout his journeys, and was truly loved: when the horse died (due to old age, according to Plutarch, for he was already 30; other sources claim that Bucephalus died of wounds sustained in a battle in India), Alexander named a city after him called Bocephia or Bucephala.
In 340 BC, Philip led an attack on Byzantium, leaving Alexander, now aged 16, to act as regent of Macedon. Shortly after, in 339 BC, Philip took a fifth wife, Cleopatra Eurydice. While Alexander's mother Olympias was from Epirus, Cleopatra Eurydice was a true Macedonian; this led to political machinations over whether Alexander was the best heir for the Agead throne. During the wedding feast, Attalus, the uncle of the bride, supposedly gave a toast for the marriage to result in a legitimate heir to the throne of Macedon. Alexander responded by hurling his goblet at Attalus, shouting "What am I, a bastard then?" In response, Phillip drew his sword and moved towards Alexander, but fell in a drunken stupor over the drinking couches. Alexander then famously remarked: "Here is the man planning on conquering from Greece to Asia, and he cannot even move from one table to another." Following this episode, Alexander and his mother left Macedon; his sister (also named Cleopatra) remained.
Eventually Philip and Alexander would reconcile; the son returned home, but Olympias remained in Epirus. In 338 BC Alexander fought under his father at the decisive Battle of Chaeronea against the city-states of Athens and Thebes. Phillip entrusted Alexander with the left wing of his army, which entailed facing the Sacred Band of Thebes, an elite hoplite corps hitherto regarded as invincible. Though few details of the battle survive to us, what is known is that Alexander annihilated this corps. After the battle, Philip led a wild celebration; Alexander is notably absent from the accounts describing it. It is speculated that Alexander personally treated Demades, a notable orator of Athens, who had opposed Athenian alignment against Philip. He went on to draw up and present a peace plan, which the assembled Athenian army voted on and approved. Philip was content to deprive Thebes of its dominion over Boeotia and leave a Macedonian garrison in the citadel. A few months later, the League of Corinth was formed, and Phillip was acclaimed Hegemon of the Hellenes.
In 336 BC Philip was assassinated at the wedding of his daughter Cleopatra to her uncle King Alexander of Epirus. Theories abound regarding the motives behind the killing, but a common story presented the assassin as a disgraced former lover of the king--the young nobleman Pausanias of Orestis. He held a grudge against Philip because the king had ignored his grievances regarding an outrage on his person. Some believed that Philip's murder was planned with the knowledge and involvement of Alexander, Olympias, or both. Still other theories pointed to Darius III, the recently crowned King of Persia. Regardless, after Philip's death, the army proclaimed Alexander, then aged 20, as the new king of Macedon.
Greek cities like Athens and Thebes, which had been forced to pledge allegiance to Philip, saw in the relatively untested new king an opportunity to regain full independence. Alexander moved swiftly and Thebes, which had been most active against him, submitted when he appeared at its gates. The assembled Greeks at the Isthmus of Corinth, with the exception of the Spartans, elected him to the command against Persia, which had previously been bestowed upon his father. The next year (335 BC), Alexander felt free to engage the Thracians and the Illyrians in order to secure the Danube as the northern boundary of the Macedonian kingdom. While he was triumphantly campaigning north, the Thebans and Athenians rebelled once again. Alexander reacted immediately and while the other cities once again hesitated, Thebes decided this time to resist with the utmost vigor. The resistance was useless; in the end, the city was conquered with great bloodshed. Thebes was razed to the ground and its territory divided between the other Boeotian cities. Moreover, the Thebans themselves were sold into slavery; Alexander spared only the priests, the leaders of the pro-Macedonian party, and the descendants of Pindar, whose house was the only one left standing.
The end of Thebes cowed Athens into submission. According to Plutarch, a special Athenian embassy led by Phocion, an opponent of the anti-Macedonian faction, was able to persuade Alexander to give up his demand for the exile of leaders of the anti-Macedonian party, most particularly Demosthenes.
Alexander's army crossed the Hellespont with approximately 42,000 soldiers from Macedon, various Greek city-states, and mercenaries and tribute soldiers from Thrace, Paionia, and Illyria. After an initial victory against Persian forces at the Battle of the Granicus, Alexander accepted the surrender of the Persian provincial capital and treasury of Sardis and proceeded down the Ionian coast. At Halicarnassus, Alexander successfully waged the first of many sieges, eventually forcing his opponents, the mercenary captain Memnon of Rhodes and the Persian satrap of Caria, Orontobates, to withdraw by sea. Alexander left Caria in the hands of Ada, who was ruler of Caria before being deposed by her brother Pixodarus. From Halicarnassus, Alexander proceeded into mountainous Lycia and the Pamphylian plain, asserting control over all coastal cities and denying them to his enemy. From Pamphylia onward, the coast held no major ports and so Alexander moved inland. At Termessos, Alexander humbled but did not storm the Pisidian city. At the ancient Phrygian capital of Gordium, Alexander "undid" the hitherto unsolvable Gordian Knot, a feat said to await the future "king of Asia." According to the most vivid story, Alexander proclaimed that it did not matter how the knot was undone, and he hacked it apart with his sword. Another version claims that he did not use the sword, but simply realized that the simplest way to undo the knot was to simply remove a central peg from the chariot--around which the knot was tied.
Alexander's army crossed the Cilician Gates, met and defeated the main Persian army under the command of Darius III at the Battle of Issus in 333 BC. Darius was forced to flee the battle after his army broke, and in doing so left behind his wife, his two daughters, his mother Sisygambis, and a fabulous amount of treasure. He afterwards offered a peace treaty to Alexander, the concession of the lands he had already conquered, and a ransom of 10,000 talents for his family. Alexander replied that since he was now king of Asia, it was he alone who decided territorial divisions. Proceeding down the Mediterranean coast, he took Tyre and Gaza after famous sieges (see Siege of Tyre).
In 332 BC Alexander attempted to lead his army into Nubia. He was confronted with the brilliant military formation devised by their warrior queen, Candace of Meroë. She led her army in the opposition from on top of an elephant. Daunted by the prospect of defeat while engaging with her opposing army, he concluded it would be best to withdraw his forces and he chose to enter Egypt instead.
During 332–331 BC, Alexander was welcomed as a liberator in Persian-occupied Egypt and was pronounced the son of Zeus by Egyptian priests of the deity Amun at the Oracle of Siwa Oasis in the Libyan desert. Henceforth, Alexander often referred to Zeus-Ammon as his true father, and subsequent currency depicted him, adorned with ram horns as a symbol of his divinity. He founded Alexandria in Egypt, which would become the prosperous capital of the Ptolemaic dynasty after his death.
Leaving Egypt, Alexander marched eastward into Assyria (now northern Iraq) and defeated Darius once more at the Battle of Gaugamela. Once again, Darius was forced to leave the field, and Alexander chased him as far as Arbela. While Darius fled over the mountains to Ecbatana (modern Hamedan), Alexander marched to Babylon.
From Babylon, Alexander went to Susa, one of the Achaemenid capitals, and captured its legendary treasury. Sending the bulk of his army to the Persian capital of Persepolis via the Royal Road, Alexander stormed and captured the Persian Gates (in the modern Zagros Mountains), then sprinted for Persepolis before its treasury could be looted. It was here that Alexander was said to have stared at the crumbled statue of Xerxes and decided to leave it on the ground--a symbolic gesture of vengeance. During their stay at the capital, a fire broke out in the eastern palace of Xerxes and spread to the rest of the city. Theories abound as to whether this was the result of a drunken accident, or a deliberate act of revenge for the burning of the Acropolis of Athens during the Second Persian War. The Book of Arda Wiraz, a Zoroastrian work composed in the 3rd or 4th century AD, also speaks of archives containing "all the Avesta and Zand, written upon prepared cow-skins, and with gold ink" that were destroyed; but it must be said that this statement is often treated by scholars with a certain measure of skepticism, because it is generally thought that for many centuries the Avesta was transmitted mainly orally by the Magi.
Alexander then set off in pursuit of Darius anew. The Persian king was no longer in control of his destiny, having been taken prisoner by Bessus, his Bactrian satrap and kinsman. As Alexander approached, Bessus had his men murder the Great King and then declared himself Darius' successor as Artaxerxes V before retreating into Central Asia to launch a guerrilla campaign against Alexander. With the death of Darius, Alexander declared the war of vengeance over, and released his Greek and other allies from service in the League campaign (although he allowed those that wished to re-enlist as mercenaries in his army).
His three-year campaign, first against Bessus and then against Spitamenes, the satrap of Sogdiana, took Alexander through Media, Parthia, Aria (West Afghanistan), Drangiana, Arachosia (South and Central Afghanistan), Bactria (North and Central Afghanistan), and Scythia. In the process of doing so, he captured and refounded Herat and Maracanda. Moreover, he founded a series of new cities, all called Alexandria, including modern Kandahar in Afghanistan, and Alexandria Eschate ("The Furthest") in modern Tajikistan. In the end, both of his opponents were defeated after having been betrayed by their men--Bessus in 329 BC, and Spitamenes the year after.
During this time, Alexander adopted some elements of Persian dress and customs at his court, notably the custom of proskynesis, a symbolic kissing of the hand that Persians paid to their social superiors, but a practice that the Greeks disapproved. The Greeks regarded the gesture as the province of deities and believed that Alexander meant to deify himself by requiring it. This cost him much in the sympathies of many of his countrymen. Here, too, a plot against his life was revealed, and one of his officers, Philotas, was executed for failing to bring the plot to his attention. The death of the son necessitated the death of the father, and thus Parmenion, who had been charged with guarding the treasury at Ecbatana, was assassinated by command of Alexander, so he might not make attempts at vengeance. Most infamously, Alexander personally slew the man who had saved his life at Granicus, Cleitus the Black, during a drunken argument at Maracanda. Later in the Central Asian campaign, a second plot against his life was revealed, this one instigated by his own royal pages. His official historian, Callisthenes of Olynthus (who had fallen out of favor with the king by leading the opposition to his attempt to introduce proskynesis), was implicated in the plot; there has never been a consensus as to his actual involvement in the conspiracy.
After the death of Spitamenes and his marriage to Roxana (Roshanak in Bactrian) to cement his relations with his new Central Asian satrapies, in 326 BC Alexander was finally free to turn his attention to the Indian subcontinent. Alexander invited all the chieftains of the former satrapy of Gandhara, in the north of what is now Pakistan, to come to him and submit to his authority. Ambhi (Greek: Omphis), ruler of Taxila, whose kingdom extended from the Indus to the Jhelum (Greek:Hydaspes), complied. But the chieftains of some hilly clans including the, Aspasioi and Assakenoi sections of the Kambojas (classical names), known in Indian texts as Ashvayanas and Ashvakayanas (names referring to the equestrian nature of their society from the Sanskrit root word Ashva meaning horse), refused to submit.
Alexander personally took command of the shield-bearing guards, foot-companions, archers, Agrianians and horse-javelin-men and led them against the Kamboja clans—the Aspasioi of Kunar/Alishang valleys, the Guraeans of the Guraeus (Panjkora) valley, and the Assakenoi of the Swat and Buner valleys. Writes one modern historian: "They were brave people and it was hard work for Alexander to take their strongholds, of which Massaga and Aornus need special mention." A fierce contest ensued with the Aspasioi in which Alexander himself was wounded in the shoulder by a dart but eventually the Aspasioi lost the fight; 40,000 of them were enslaved. The Assakenoi faced Alexander with an army of 30,000 cavalry, 38,000 infantry and 30 elephants. They had fought bravely and offered stubborn resistance to the invader in many of their strongholds like cities of Ora, Bazira and Massaga. The fort of Massaga could only be reduced after several days of bloody fighting in which Alexander himself was wounded seriously in the ankle. When the Chieftain of Massaga fell in the battle, the supreme command of the army went to his old mother Cleophis (q.v.) who also stood determined to defend her motherland to the last extremity. The example of Cleophis assuming the supreme command of the military also brought the entire women of the locality into the fighting. Alexander could only reduce Massaga by resorting to political strategem and actions of betrayal. According to Curtius: "Not only did Alexander slaughter the entire population of Massaga, but also did he reduce its buildings to rubbles." A similar manslaughter then followed at Ora, another stronghold of the Assakenoi.
In the aftermath of general slaughter and arson committed by Alexander at Massaga and Ora, numerous Assakenians people fled to a high fortress called Aornos. Alexander followed them close behind their heels and captured the strategic hill-fort but only after the fourth day of a bloody fight. The story of Massaga was repeated at Aornos and a similar carnage on the tribal-people followed here too.
Sisikottos, who had helped Alexander in this campaign, was made the governor of Aornos. After reducing Aornos, Alexander crossed the Indus and fought and is believed to have won an epic battle against a local ruler Porus (original Indian name Raja Puru), who ruled a region in the Punjab, in the Battle of Hydaspes in 326 BC.
After the battle, Alexander was greatly impressed by Porus for his bravery in battle, and therefore made an alliance with him and appointed him as satrap of his own kingdom, even adding some land he did not own before. Alexander then named one of the two new cities that he founded, Bucephala, in honor of the horse who had brought him to India, who had died during the Battle of Hydaspes. Alexander continued on to conquer all the headwaters of the Indus River.
Alexander, after the meeting with his officer Coenus, was convinced that it was better to return. Alexander was forced to turn south. Along the way his army ran into the Malli clans (in modern day Multan). The Malli were the most warlike clans in South Asia during that period. Alexander's army challenged the Malli, and the ensuing battle led them to the Malli citadel. During the assault, Alexander himself was wounded seriously by a Mallian arrow. His forces, believing their king dead, took the citadel and unleashed their fury on the Malli who had taken refuge within it,perpetrating a massacre,sparing neither man,woman nor child. Following this, the surviving Malli surrendered to Alexander's forces, and his beleaguered army moved on.He sent much of his army to Carmania (modern southern Iran) with his general Craterus, and commissioned a fleet to explore the Persian Gulf shore under his admiral Nearchus, while he led the rest of his forces back to Persia by the southern route through the Gedrosian Desert (now part of southern Iran and Makran now part of Pakistan).
Alexander left forces in India however. In the territory of the Indus, he nominated his officer Peithon as a satrap, a position he would hold for the next ten years until 316 BC, and in the Punjab he left Eudemus in charge of the army, at the side of the satrap Porus and Taxiles. Eudemus became ruler of a part of the Punjab after their death. Both rulers returned to the West in 316 BC with their armies. In 321 BCE, Chandragupta Maurya founded the Maurya Empire in India and overthrew the Greek satraps.
Discovering that many of his satraps and military governors had misbehaved in his absence, Alexander executed a number of them as examples on his way to Susa. As a gesture of thanks, he paid off the debts of his soldiers, and announced that he would send those over-aged and disabled veterans back to Macedonia under Craterus, but his troops misunderstood his intention and mutinied at the town of Opis, refusing to be sent away and bitterly criticizing his adoption of Persian customs and dress and the introduction of Persian officers and soldiers into Macedonian units. Alexander executed the ringleaders of the mutiny, but forgave the rank and file. In an attempt to craft a lasting harmony between his Macedonian and Persian subjects, he held a mass marriage of his senior officers to Persian and other noblewomen at Susa, but few of those marriages seem to have lasted much beyond a year.
His attempts to merge Persian culture with his Greek soldiers also included training a regiment of Persian boys in the ways of Macedonians. Most historians believe that Alexander adopted the Persian royal title of Shahanshah (meaning: "The King of Kings").
It is claimed that Alexander wanted to overrun or integrate the Arabian peninsula, but this theory is widely disputed. It was assumed that Alexander would turn westwards and attack Carthage and Italy, had he conquered Arabia.
After traveling to Ecbatana to retrieve the bulk of the Persian treasure, his closest friend and possibly lover Hephaestion died of an illness, or possibly of poisoning. Alexander mourned by Hephaestion's side for six months.
On the afternoon of June 10–11, 323 BC, Alexander died in the palace of Nebuchadrezzar II of Babylon. He was just one month short of attaining 33 years of age. Various theories have been proposed for the cause of his death which include poisoning by the sons of Antipater or others, sickness that followed a drinking party, or a relapse of the malaria he had contracted in 336 BC.
It is known that on May 29, Alexander participated in a banquet organized by his friend Medius of Larissa. After some heavy drinking, immediately before or after a bath, he was forced into bed due to severe illness. The rumors of his illness circulated with the troops causing them to be more and more anxious. On June 9, the generals decided to let the soldiers see their king alive one last time. They were admitted to his presence one at a time. Because the king was too ill to speak, he confined himself to moving his hand. The day after, Alexander was dead.
The poisoning theory derives from the story held in antiquity by Justin and Curtius. The original story stated that Cassander, son of Antipater, viceroy of Greece, brought the poison to Alexander in Babylon in a mule's hoof, and that Alexander's royal cupbearer, Iollas, brother of Cassander, administered it. Many had powerful motivations for seeing Alexander gone, and were none the worse for it after his death. Deadly agents that could have killed Alexander in one or more doses include hellebore and strychnine. In R. Lane Fox's opinion, the strongest argument against the poison theory is the fact that twelve days had passed between the start of his illness and his death and in the ancient world, such long-acting poisons were probably not available.
The warrior culture of Macedon favoured the sword over strychnine, and many ancient historians, like Plutarch and Arrian, maintained that Alexander was not poisoned, but died of natural causes. Instead, it is likely that Alexander died of malaria or typhoid fever, which were rampant in ancient Babylon. Other illnesses could have also been the culprit, including acute pancreatitis or the West Nile virus. Recently, theories have been advanced stating that Alexander may have died from the treatment not the disease. Hellebore, believed to have been widely used as a medicine at the time but deadly in large doses, may have been overused by the impatient king to speed his recovery, with deadly results. Disease-related theories often cite the fact that Alexander's health had fallen to dangerously low levels after years of heavy drinking and suffering several appalling wounds (including one in India that nearly claimed his life), and that it was only a matter of time before one sickness or another finally killed him.
No story is conclusive. Alexander's death has been reinterpreted many times over the centuries. What is certain is that Alexander died of a high fever on June 10 or 11 of 323 BC.
On his death bed, his marshals asked him to whom he bequeathed his kingdom. Since Alexander had no obvious and legitimate heir (his son Alexander IV would be born after his death, and his other son was by a concubine, not a wife), it was a question of vital importance. There is some debate to what Alexander replied. Some believe that Alexander said, "Kratisto" (that is, "To the strongest!") or "Krat'eroi" (to the stronger).
Alexander may have said, "Krater'oi" (to Craterus). This is possible because the Greek pronunciation of "the stronger" and "Craterus" differ only by the position of the accented syllable. Most scholars believe that if Alexander did intend to choose one of his generals, his obvious choice would have been Craterus because he was the commander of the largest part of the army (infantry), because he had proven himself to be an excellent strategist, and because he displayed traits of the "ideal" Macedonian. But Craterus was not around, and the others may have chosen to hear "Krat'eroi" — the stronger. Regardless of his reply, Craterus does not appear to have pressed the issue. The empire then split amongst his successors (the Diadochi).
Before long, accusations of foul play were being thrown about by his generals at one another, and no contemporaneous source can be fully trusted.
Alexander's body was placed in a gold anthropoid sarcophagus, which was in turn placed in a second gold casket and covered with a purple robe. Alexander's coffin was placed, together with his armour, in a gold carriage that had a vaulted roof supported by an Ionic peristyle. The decoration of the carriage was very lavish and is described in great detail by Diodoros.
According to one legend, Alexander was preserved in a clay vessel full of honey (which can act as a preservative) and interred in a glass coffin. According to Aelian (Varia Historia 12.64), Ptolemy stole the body and brought it to Alexandria, where it was on display until Late Antiquity. It was here that Ptolemy IX, one of the last successors of Ptolemy I, replaced Alexander's sarcophagus with a glass one, and melted the original down in order to strike emergency gold issues of his coinage. The citizens of Alexandria were outraged at this and soon after, Ptolemy IX was killed.
The Roman emperor Caligula was said to have looted the tomb, stealing Alexander's breastplate, and wearing it. Around 200 AD, Emperor Septimius Severus closed Alexander's tomb to the public. His son and successor, Caracalla, was a great admirer of Alexander, and visited the tomb in his own reign. After this, details on the fate of the tomb are sketchy.
The so-called "Alexander Sarcophagus," discovered near Sidon and now in the Istanbul Archaeology Museum, is now generally thought to be that of Abdylonymus, whom Hephaestion had appointed as the king of Sidon by Alexander's order. The sarcophagus depicts Alexander and his companions hunting and in battle with the Persians.
Some classical authors, such as Diodorus, relate that Alexander had given detailed written instructions to Craterus some time before his death. Although Craterus had already started to implement Alexander's orders, such as the building of a fleet in Cilicia for expedition against Carthage, Alexander's successors chose not to further implement them, on the grounds that they were impractical and extravagant.
Alexander's lifelong companion was Hephaestion, the son of a Macedonian noble. Hephaestion also held the position of second-in-command of Alexander's forces until his death, which devastated Alexander. The full extent of his relationship with Hephaestion is the subject of much historical speculation.
Alexander married two women: Roxana, daughter of a Bactrian nobleman, Oxyartes, and Stateira, a Persian princess and daughter of Darius III of Persia. There is also an accepted tradition of a third wife- Parysatis whom he is supposed to have married in Persia though nothing is known about her. Another personage from the court of Darius III with whom he was intimate was the male eunuch Bagoas. His son by Roxana, Alexander IV of Macedon, was killed after the death of his father, before he reached adulthood.
Alexander was admired during his lifetime for treating all his lovers humanely.
After Alexander's death, in 323 BC, the rule of his Empire was given to Alexander's half-brother Philip Arridaeus and Alexander's son Alexander IV. However, since Philip was mentally ill and the son of Alexander still a baby, two regents were named in Perdiccas (who had received Alexander's ring at his death) and Craterus (who may have been the one mentioned as successor by Alexander), although Perdiccas quickly managed to take sole power.
Perdiccas soon eliminated several of his opponents, killing about 30 (Diodorus Siculus), and at the Partition of Babylon named former generals of Alexander as satraps of the various regions of his Empire. In 321 BC Perdiccas was assassinated by his own troops during his conflict with Ptolemy, leading to the Partition of Triparadisus, in which Antipater was named as the new regent, and the satrapies again shared between the various generals. From that time, Alexander's officers were focused on the explicit formation of rival monarchies and territorial states.
Ultimately, the conflict was settled after the Battle of Ipsus in Phrygia in 301 BC. Alexander's empire was divided at first into four major portions: Cassander ruled in Macedon, Lysimachus in Thrace, Seleucus in Mesopotamia and Persia, and Ptolemy I Soter in the Levant and Egypt. Antigonus ruled for a while in Anatolia and Syria but was eventually defeated by the other generals at Ipsus (301 BC). Control over Indian territory passed to Chandragupta Maurya, the first Maurya emperor, who further expanded his dominions after a settlement with Seleucus.
By the 1st century BC though, most of the Hellenistic territories in the West had been absorbed by the Roman Republic. In the East, they had been dramatically reduced by the expansion of the Parthian Empire. The territories further east seceded to form the Greco-Bactrian kingdom (250-140 BC), which further expanded into India to form the Indo-Greek kingdom (180 BC-10 AD).
The Ptolemy dynasty persisted in Egypt until the epoch of the queen Cleopatra, best known for her alliances with Julius Caesar and Mark Antony, just before the Roman republic officially became the Roman Empire.
Alexander's conquests also had long term cultural effects, with the flourishing of Hellenistic civilization throughout the Middle East and Central Asia, and the development of Greco-Buddhist art in the Indian subcontinent. Alexander and his successors were tolerant of non-Greek religious practices, and interesting syncretisms developed in the new Greek towns he founded in Central Asia. The first realistic portrayals of the Buddha appeared at this time; they are reminiscent of Greek statues of Apollo. Several Buddhist traditions may have been influenced by the ancient Greek religion; the concept of Boddhisatvas is reminiscent of Greek divine heroes, and some Mahayana ceremonial practices (burning incense, gifts of flowers and food placed on altars) are similar to those practiced by the ancient Greeks. Zen Buddhism draws in part on the ideas of Greek stoics, such as Zeno.
Among other effects, the Hellenistic, or koine dialect of Greek became the lingua franca throughout the so-called civilized world. For instance the standard version of the Hebrew Scriptures used among the Jews of the diaspora, especially in Egypt, during the life of Jesus was the Greek Septuagint translation, which was compiled ca 200 BC by seventy-odd scholars under the patronage of the Macedonian ruler Ptolemy II Philadelphus. Thus many Jews from Egypt or Rome would have trouble understanding the teachings of the scholars in the Temple in Jerusalem who were using the Hebrew original text and an Aramaic translation, being themselves only acquainted with the Greek version. There has been much speculation on the issue whether Jesus spoke Koine Greek as the Gospel-writers, themselves writing in Greek, don't say anything decisive about the matter.
In the late Republic and early Empire, educated Roman citizens used Latin only for legal, political, and ceremonial purposes, and used Greek to discuss philosophy or any other intellectual topic. No Roman wanted to hear it said that his mastery of the Greek language was weak. Throughout the Roman world, the one language spoken everywhere was Alexander's Greek.
Alexander and his exploits were admired by many Romans who wanted to associate themselves with his achievements, although very little is known about Roman-Macedonian diplomatic relations of that time. Julius Caesar wept in Spain at the mere sight of Alexander's statue and Pompey the Great rummaged through the closets of conquered nations for Alexander's 260-year-old cloak, which the Roman general then wore as the costume of greatness. However, in his zeal to honor Alexander, Augustus accidentally broke the nose off the Macedonian's mummified corpse while laying a wreath at the hero's shrine in Alexandria, Egypt. The unbalanced emperor Caligula later took the dead king's armor from that tomb and donned it for luck. The Macriani, a Roman family that rose to the imperial throne in the 3rd century A.D. always kept images of Alexander on their persons, either stamped into their bracelets and rings or stitched into their garments. Even their dinnerware bore Alexander's face, with the story of the king's life displayed around the rims of special bowls.
In the summer of 1995, during the archaeological work of the season centered on excavating the remains of domestic architecture of early-Roman date, a statue of Alexander was recovered from the structure, which was richly decorated with mosaic and marble pavements and probably was constructed in the 1st century AD and occupied until the 3rd century.
Modern opinion on Alexander has run the gamut from the idea that he believed he was on a divinely-inspired mission to unite the human race, to the view that he was a megalomaniac bent on world domination. Such views tend to be anachronistic, and the sources allow for a variety of interpretations. Much about Alexander's personality and aims remains enigmatic. There were no disinterested commentators in Alexander's own time or soon afterward, so all accounts need to be read with skepticism.
Alexander is remembered as a legendary hero in Europe and much of both Southwest Asia and Central Asia, where he is known as Iskander or Iskandar Zulkarnain. To Zoroastrians, on the other hand, he is remembered as the conqueror of their first great empire and as the destroyer of Persepolis. Ancient sources are generally written with an agenda of either glorifying or denigrating the man, making it difficult to evaluate his actual character. Most refer to a growing instability and megalomania in the years following Gaugamela, but it has been suggested that this simply reflects the Greek stereotype of an orientalizing king.
The murder of his friend Cleitus, which Alexander deeply and immediately regretted, is often cited as a sign of his paranoia, as is his execution of Philotas and his general Parmenion for failure to pass along details of a plot against him. There is also the view that this may have been more prudence than paranoia.
Modern Alexandrists continue to debate these same issues, among others, in modern times. One unresolved topic involves whether Alexander was actually attempting to better the world by his conquests, or whether his purpose was primarily to rule the world.
Partially in response to the ubiquity of positive portrayals of Alexander, an alternate character is sometimes presented which emphasizes some of Alexander's negative aspects. Some proponents of this view cite the destructions of Thebes, Tyre, Persepolis, and Gaza as examples of atrocities, and argue that Alexander preferred to fight rather than negotiate. It is further claimed, in response to the view that Alexander was generally tolerant of the cultures of those whom he conquered, that his attempts at cultural fusion were severely practical and that he never actually admired Persian art or culture. To this way of thinking, Alexander was, first and foremost, a general rather than a statesman.
Alexander's character also suffers from the interpretation of historians who themselves are subject to the bias and idealisms of their own time. Good examples are W. W. Tarn, who wrote during the late 19th century and early 20th century, and who saw Alexander in an extremely good light, and Peter Green, who wrote after World War II and for whom Alexander did little that was not inherently selfish or ambition-driven. Tarn wrote in an age where world conquest and warrior-heroes were acceptable, even encouraged, whereas Green wrote with the backdrop of the Holocaust and nuclear weapons.
In addition to cuneiform evidence from Babylonia that is still being discovered and translated, there are numerous Greek and Latin texts about Alexander. The primary sources, texts written by people who actually knew Alexander or who gathered information from men who served with Alexander, are all lost, apart from a few inscriptions and some letter-fragments of dubious authenticity. Contemporaries who wrote full accounts of his life include the historian Callisthenes, Alexander's general Ptolemy, Aristobulus, Nearchus, and Onesicritus. Another influential account is by Cleitarchus who, while not a direct witness of Alexander's expedition, used sources which had just been published. His work was to be the backbone of that of Timagenes, who heavily influenced many historians whose work still survives. None of these works survives, but we do have later works based on these primary sources.
The five main surviving accounts are by Arrian, Curtius, Plutarch, Diodorus, and Justin.
To these five main sources some like to add the Metz Epitome, an anonymous late Latin work that narrates Alexander's campaigns from Hyrcania to India. Much is also recounted incidentally in other authors, including Strabo, Athenaeus, Polyaenus, Aelian, and others.
In the first centuries after Alexander's death, probably in Alexandria, a quantity of the more legendary material coalesced into a text known as the Alexander Romance, later falsely ascribed to the historian Callisthenes and therefore known as Pseudo-Callisthenes. This text underwent numerous expansions and revisions throughout Antiquity and the Middle Ages, exhibiting a plasticity unseen in "higher" literary forms. Latin and Syriac translations were made in Late Antiquity. From these, versions were developed in all the major languages of Europe and the Middle East, including Armenian, Georgian, Persian, Arabic, Turkish, Hebrew, Serbian, Slavonic, Romanian, Hungarian, German, English, Italian, and French. The "Romance" is regarded by many Western scholars as the source of the account of Alexander given in the Qur'an (Sura The Cave). It is the source of many incidents in Ferdowsi's "Shahnama". A Mongolian version is also extant. Some believe that, excepting certain religious texts, it is the most widely-read work of pre-modern times.
Alexander is also a character of Greek folklore (and other regions), as the protagonist of 'apocryphal' tales of bravery. A maritime legend says that his sister is a mermaid and asks the sailors if her brother is still alive. The unsuspecting sailor who answers truthfully arouses the mermaid's wrath and his boat perishes in the waves; a sailor mindful of the circumstances will answer "He lives and reigns, and conquers the world", and the sea about his boat will immediately calm. Alexander is also a character of a standard play in the Karagiozis repertory, "Alexander the Great and the Accursed Serpent". The ancient Greek poet Adrianus composed an epic poem on the history of Alexander the Great, called the Alexandriad, which was probably still extant in the 10th century, but which is now lost to us.
Daniel 8:5-8 and 21-22 states that a King of Greece will conquer the Medes and Persians but then die at the height of his power and have his kingdom broken into four kingdoms. This is sometimes taken as a reference to Alexander.
Alexander was briefly mentioned in the first Book of the Maccabees Chapter 1, verses 1-7.
He was described as Alexander son of Philip the Macedonian. He defeated Darius, king of the Persians and succeeded him as king (Alexander previously became king of Greece). He gathered a strong army and ruled over countries and nations. He fell sick and perceived that he was dying so he summoned his officers and divided his kingdom among them. After Alexander reigned for twelve years, he died.
Alexander the Great sometimes is identified in Persian and Arabic traditions sources as Dhul-Qarnayn, Arabic for the "Two-Horned One", possibly a reference to the appearance of a horn-headed figure that appears on coins minted during his rule and later imitated in ancient Middle Eastern coinage. Accounts of Dhul-Qarnayn appear in the Qur'an, and so may refer to Alexander.
References to Alexander may also be found in the Persian tradition. The same traditions from the Pseudo-Callisthenes were combined in Persia with Sassanid Persian ideas about Alexander in the Iskandarnamah. In this tradition, Alexander built a wall of iron and melted copper in which Gog and Magog are confined.
Some Muslim scholars disagree that Alexander was Dhul-Qarnayn. There are actually some theories that Dhul-Qarnayn was a Persian King with a vast Empire as well, possibly King Cyrus the Great. The reason being is Dhul-Qarnayn is described in the Holy Quran as a monotheist believer who worshipped Allah (God). This, it is claimed, removes Alexander as a candidate for Dhul-Qarnayn as Alexander was a polytheist. Yet contemporaneous Persian nobles would have practiced Zurvanism, thus disqualifying them on the same basis.
The Shahnameh of Ferdowsi, one of the oldest books written in modern Persian, has a chapter about Alexander. It is a book of epic poetry written around 1000 AD, and is believed to have played an important role in the survival of the Persian language in the face of Arabic influence. It starts with a mythical history of Iran and then gives a story of Alexander, followed by a brief mention of the Arsacids. The accounts after that, still in epic poetry, portray historical figures. Alexander is described as a child of a Persian king, Daraaye Darab (the last in the list of kings in the book whose names do not match historical kings), and a daughter of Philip, a Roman king. However, due to problems in the relationship between the Persian king and Philip's daughter, she is sent back to Rome. Alexander is born to her afterwards, but Philip claims him as his own son and keeps the true identity of the child secret.
al-Iskandar al- Makduni al-Yunani (Alexander the Macedonian,the Greek) in Arabic, Alexander Mokdon in Hebrew, and Tre-Qarnayia in Aramaic (the two-horned one, apparently due to an image on coins minted during his rule that seemingly depicted him with the two ram's horns of the Egyptian god Ammon), al-Iskandar al-Akbar الاسكندر الاكبر (Alexander the Great) in Arabic, Sikandar-e-azam (سکندر اعظم) in Urdu and Skandar in Pashto. Sikandar, his name in Urdu and Hindi, is also a term used as a synonym for "expert" or "extremely skilled".
Around seventy towns or outposts are claimed to have been founded by Alexander. Diodorus Siculus credits Alexander with planning cities on a grid plan.
Alexander has figured in works of both "high" and popular culture from his own era to the modern day.


Alfred Habdank Skarbek Korzybski (/kɔˈʃɪpski/) (July 3, 1879 – March 1, 1950), was a Polish-American philosopher and scientist most remembered for developing the theory of general semantics.
He was born in Warsaw, Congress Poland. He came from an aristocratic family whose members had worked as mathematicians, scientists, and engineers for generations. He learned Polish at home and Russian in the schools; and having a French governess and a German governess, he became fluent in four languages as a child. As an adult, he chose to train as an engineer.
Korzybski was educated at the Warsaw University of Technology. During the First World War Korzybski served as an intelligence officer in the Russian Army. After being wounded in his leg and suffering other injuries, he came to North America in 1916 (first to Canada, then the United States) to coordinate the shipment of artillery to the war front. He also lectured to Polish-American audiences about the conflict, promoting the sale of war bonds. Following the war, he decided to remain in the United States, becoming a naturalized citizen in 1940. His first book, Manhood of Humanity, was published in 1921. In the book, he proposed and explained in detail a new theory of humankind: mankind as a time-binding class of life.
Korzybski's work culminated in the founding of a discipline that he called general semantics (GS). As Korzybski explicitly said, GS should not be confused with semantics, a different subject. The basic principles of general semantics, which include time-binding, are outlined in Science and Sanity, published in 1933. In 1938 Korzybski founded the Institute of General Semantics and directed it until his death in Lakeville, Connecticut, USA.
Many supporters and critics of Korzybski reduced his rather complex system to a simple matter of what he said about the verb 'to be.' His system, however, is based primarily on such terminology as the different 'orders of abstraction,' and formulations such as 'consciousness of abstracting.' It is often said that Korzybski opposed the use of the verb "to be," an unfortunate exaggeration (see 'Criticisms' below). He thought that certain uses of the verb "to be," called the "is of identity" and the "is of predication," were faulty in structure, e.g. a statement such as, "Joe is a fool" (said of a person named 'Joe' who has done something that we regard as foolish). In Korzybski's system, one's assessment of Joe belongs to a higher order of abstraction than Joe himself. Korzybski's remedy was to deny identity; in this example, to be continually aware that 'Joe' is not what we call him. We find Joe not in the verbal domain, the world of words, but the nonverbal domain (the two, he said, amount to different orders of abstraction). This was expressed in Korzybski's most famous premise, "the map is not the territory." Note that this premise uses the phrase "is not", a form of "to be"; this and many other examples show that he did not intend to abandon "to be" as such. In fact, he expressly said that there were no structural problems with the verb "to be" when used as an auxiliary verb or when used to state existence or location. It was even 'OK' sometimes to use the faulty forms of the verb 'to be,' as long as one was aware of their structural limitations.
One day, Korzybski was giving a lecture to a group of students, and he suddenly interrupted the lesson in order to retrieve a packet of biscuits, wrapped in white paper, from his briefcase. He muttered that he just had to eat something, and he asked the students on the seats in the front row, if they would also like a biscuit. A few students took a biscuit. "Nice biscuit, don't you think", said Korzybski, while he took a second one. The students were chewing vigorously. Then he tore the white paper from the biscuits, in order to reveal the original packaging. On it was a big picture of a dog's head and the words "Dog Cookies". The students looked at the package, and were shocked. Two of them wanted to throw up, put their hands in front of their mouths, and ran out of the lecture hall to the toilet. "You see, ladies and gentlemen", Korzybski remarked, "I have just demonstrated that people don't just eat food, but also words, and that the taste of the former is often outdone by the taste of the latter." Apparently his prank aimed to illustrate how some human suffering originates from the confusion or conflation of linguistic representations of reality and reality itself. (Source: R. Diekstra, Haarlemmer Dagblad, 1993, cited by L. Derks & J. Hollander, Essenties van NLP (Utrecht: Servire, 1996), p. 58).
In part the General Semantics tradition was upheld by Samuel I. Hayakawa, who did have a falling out with Korzybski. When asked over what, Hayakawa is said to have replied: "Words".

Asteroids is a video arcade game released in 1979 by Atari Inc. It was one of the most popular and influential games of the Golden Age of Arcade Games. Asteroids uses vector graphics and a two-dimensional view that wraps around in both screen axes. The player controls a spaceship in an asteroid field which is periodically traversed by flying saucers. The object of the game is to shoot and destroy asteroids and saucers while not colliding with either, or being hit by the saucers' counter-fire.
Asteroids was inspired, in a roundabout way, by the seminal Spacewar! the first computer-based video game. In 1977 a stand-up arcade game version was produced as Space Wars, which included a number of optional versions and added a floating asteroid as a visual device. Asteroids is essentially a one-player version of Spacewar! featuring the "wedge" ship from the original and promoting the asteroids to be the main opponent.
The game was conceived by Lyle Rains and programmed and designed by Ed Logg. Asteroids was a hit in the United States and became Atari's best selling game of all time. Atari had been in the process of releasing another vector game, Lunar Lander, but demand for Asteroids was so high they stopped further production of Lunar Lander so they could begin building Asteroids. The first 200 Asteroids machines were sent out in Lunar Lander cabinets. Asteroids was so popular that video arcade owners sometimes had to install larger boxes to hold the amount of quarters that were spent by players.
The objective of Asteroids is to score as many points as possible by destroying asteroids and flying saucers. The player controls a ship that can rotate left and right, fire shots straight forward, and thrust forward. As the ship moves, momentum is not conserved — the ship eventually comes to a stop again when not thrusting. The player can also send their ship into hyperspace, causing it to disappear and reappear in a random location on the screen (with the risk of self-destructing or appearing on top of an asteroid).
Each stage starts with a few asteroids drifting in random directions on the screen. Objects wrap around screen edges — for instance, an asteroid that drifts off the top edge of the screen reappears at the bottom and continues moving in the same direction. As the player shoots asteroids, they break into smaller asteroids that frequently move faster and are more difficult to hit. Smaller asteroids also score higher points. Periodically, a flying saucer appears on one side of the screen and moves across to the other before disappearing again. The saucers are of two kinds: Large saucers fire in random directions, while small saucers aim at the player's ship.
The minimalist soundtrack features a memorable deep-toned electronic "heartbeat", which quickens as the asteroid density is reduced by the player's fire.
Once the screen has been cleared of all asteroids and flying saucers, a new set of large asteroids appears. The number of asteroids increases each round up to a maximum of twelve. The game is over when the player has lost all of his/her lives.
Like many games of its time, Asteroids contains several bugs that were mostly the result of the original programmers underestimating the game's popularity or the skill of its players. The maximum possible score in this game is 99,990 points, after which it "rolls over" back to zero. Also, an oversight in the small saucer's programming gave rise to a popular strategy known as "lurking" — because the saucer could only shoot directly at the player's position on the screen, the player could "hide" at the opposite end of the screen and shoot across the screen boundary, while remaining relatively safe. This led to experienced players being able to play indefinitely on a single credit. This oversight was addressed in the game's sequel, Asteroids Deluxe, and led to significant changes in the way game developers designed and tested their games in the future.
On some early versions of the game, it was also possible to hide the ship in the score area indefinitely without being hit by asteroids.
The Asteroids arcade machine is a vector game. This means that the game graphics are composed entirely of lines which are drawn on a vector monitor. The hardware consists primarily of a standard MOS 6502 CPU, which executes the game program, and the Digital Vector Generator (DVG), vector processing circuitry developed by Atari themselves. As the 6502 by itself was too slow to control both the game play and the vector hardware at the same time, the latter task was delegated to the DVG.
The original design concepts of the DVG came out of Atari's off-campus research lab in Grass Valley, CA, in 1978. The prototype was given to engineer Howard Delman, who refined it, produced it, and then added additional features for Atari's first vector game, Lunar Lander. When it was decided that Asteroids would be a vector game as well, Delman modified a Lunar Lander circuit board for Ed Logg. More memory was added, as was the circuitry for the many sounds in the game. That original Asteroids prototype board still exists, and is currently in Delman's personal collection.
For each picture frame, the 6502 writes graphics commands for the DVG into a defined area of RAM (the vector RAM), and then asks the DVG to draw the corresponding vector image on the screen. The DVG reads the commands and generates appropriate signals for the vector monitor. There are DVG commands for positioning the cathode ray, for drawing a line to a specified destination, calling a subroutine with further commands, and so on.
The main Asteroids game program uses only 6 KB of ROM code. Another 2 KB of vector ROM contains the descriptions of the main graphical elements (rocks, saucer, player's ship, explosion pictures, letters, and digits) in the form of DVG commands.
The Killer List of Videogames (KLOV) credits this game as one of the "Top 100 Videogames." Readers of the KLOV credit it as the seventh most popular game.
The gameplay in Asteroids was imitated by many games that followed. For example, one of the objects of Sinistar is to shoot asteroids in order to get them to release resources which the player needs to collect.
Asteroids has been ported to multiple systems, including many of Atari's systems (Atari 2600, 7800, Atari Lynx) and many others. The 2600 port was the first game to utilize a bank-switched cartridge, doubling available ROM space. A port was in development for the 5200 and advertised as a launch title but never officially released, although an unofficial release was produced by AtariAge. 1993 saw a release for PCs with Windows 3.1 as part of the original Microsoft Arcade package. Also, a new version of Asteroids was developed for PlayStation, Nintendo 64, Windows, and the Game Boy Color in the late 1990s. A port was also included on Atari's Cosmos system, but the system never saw release. Many of the recent TV Games series of old Atari games have included either the 2600 or arcade versions of Asteroids. Atari has also used the game for its other late '90s and 2000's anthology series. Essentially, if one looks for this game, one will be able to find it somewhere.
Asteroids was released via Xbox Live Arcade for the Xbox 360 on November 28, 2007, with an option for special revamped HD graphics and a high-speed "throttle monkey" mode.
There have been countless unofficial ports of Asteroids produced. These include near-copies such as Acornsoft's Meteors, as well as those with expanded gameplay and background, such as Astrogeddon, Stardust, Spheres of Chaos and Astro Fire.
Glu Mobile released a licensed cellular phone version of Asteroids that includes the original game as well as updated gameplay, skins, and modes.
On November 13, 1982, 15-year-old Scott Safran, of Cherry Hill, NJ, set a world record of 41,336,440 points on the classic arcade game Asteroids. He beat the 40,101,910 point score set by Leo Daniels of Carolina Beach on February 6, 1982. To congratulate Safran on his accomplishment, the Twin Galaxies Intergalactic Scoreboard searched for him for more than fifteen years, until 2002, when it was discovered that he had died in an accident in 1989. In a special ceremony in Philadelphia on April 27, 2002, Walter Day of Twin Galaxies presented a special award to the surviving members of Scott Safran's family, commemorating the Asteroid Champion's achievement.
In March 2004, Portland, Oregon resident Bill Carlton attempted to break the world record for playing an arcade version of Asteroids, playing over 27 hours before his machine malfunctioned, ending his record run. He scored 12.7 million points, putting him in 5th place in the all-time Asteroids rankings.
Comedian Jim Norton (Frunkus) once got the record score for the game Asteroids. This led him to have his picture on a local New Jersey paper.
In July of 1982, two men in Hyde Park, NY played on one quarter and got a score of 48,830,930. They actually quit the game because they were just too run down. Matthew Collier and John Denver both of Hyde Park at the time, alternated every 100,000 pts which took about 12 minutes, trying to briefly nap on their off time. The lengthy session took 84 hours, as they played in a laundry mat after convincing the owner to allow them to lock themselves in at night. Both men were only 17 at the time, and tried to contact Guinness, but they seemed uninterested at the time, because so many records were falling so often in the video game field. They did make the local radio and newspapers, but that was the extent of their 15 minutes of fame. Although John did not master many other games at the time, Matt had mastered almost all of them, spending almost every quarter he earned on video games.
In 1982, Buckner and Garcia recorded a song titled "Hyperspace", using sound effects from the game, and released it on the album Pac-Man Fever.


Asparagales is an order of flowering plants. The order must include the family Asparagaceae, but other families included in the order have varied markedly between different classifications.
Note: "+.." = optional segregrate family, that may be split off from the preceding family.
APG II has consolidated some of the families in the earlier APG system, while recognizing an alternative, that allows smaller families to be seggregated and still follow the 'APG system'. Under the new classification system a taxonomist could, for example, correctly choose to include the daylilies (Hemerocallis) in family Hemerocallidaceae, or in family Xanthorrhoeaceae.
The Cronquist system did not recognise the order, and placed many of the plants involved in order Liliales (in subclass Liliidae in class Liliopsida [= monocotyledons]). Some genera were even included in family Liliaceae.
The Wettstein system, last revision of 1935, did not recognise such an order, and placed many of the plants involved in order Liliiflorae in class Monocotyledones.


Alismatales is an order of flowering plants. The order will of necessity contain the family Alismataceae.
Thus circumscribed, the order contains about 165 genera in 14 families, with a cosmopolitan distribution. Most of the families are composed of herbaceous plants, commonly found in aquatic environments. The flowers are usually arranged in inflorescences, and the mature seeds lack endosperm.
The biggest departure from earlier systems (see below) is the inclusion of family Araceae. By its inclusion the order has grown enormously in number of species. The family Araceae alone accounts for about a hundred genera, totalling over two thousand species. The rest of families together contain just about five hundred species.
The Cronquist subclass Alismatidae conformed fairly closely to the order Alismatales as circumscribed by APG, minus the family Araceae.
The Dahlgren superorder Alismatanae conformed fairly closely to the order Alismatales as circumscribed by APG, minus the family Araceae.
The Wettstein system, last version in 1935, and the Engler system, update in 1964, used the name Helobiae for the order.


The Apiales are an order of flowering plants. The families given at right are typical of newer classifications, though there is some slight variation, and in particular the Torriceliaceae may be divided. These families are placed within the asterid group of dicotyledons.
Under this definition well-known members include carrots, celery, parsley, and ivy.
Under the Cronquist system, only the Apiaceae and Araliaceae were included here, and the restricted order was placed among the rosids rather than the asterids. The Pittosporaceae were placed within the Rosales, and the other forms within the family Cornaceae.


The Asterales are an order of dicotyledonous flowering plants which include the composite family Asteraceae (sunflowers, daisies, thistles etc.) and its related families.
The order is cosmopolitic, and includes mostly herbaceous species, although a small number of trees (Lobelia) and shrubs is also present.
The Asterales can be characterized on the morphological and molecular level. Synapomorphies include the oligosaccharide inulin as the nutrients storage, and the stamens are usually aggregated densely around the style or even are fused into a tube around it. The last property is probably associated with the plunger (or secondary) pollination, which is common among the families of the order.
The Asterales include about eleven families, the largest of which are Asteraceae, with about 25,000 species, and Campanulaceae, with about 2,000 species. The remaining families count together for less than 500 species. The two large families are cosmopolitic with center of mass in the northern hemisphere, and the smaller ones are usually confined to Australia and the adjacent areas, or sometimes South America.
Under the Cronquist system, Asteraceae was the only family in the group, but newer systems (e. g. APG II) have expanded it.
The Asterales order probably originated in the Cretaceous on the supercontinent Gondwana, in the area which is now Australia and Asia. Although most extant species are herbaceous, the examination of the basal families in the order suggests that the common ancestor of the order was an arborescent plant.
Fossil evidence of the Asterales is rare and belongs to rather recent epochs, so the precise estimation of the order's age is quite difficult. An Oligocene pollen is known for Asteraceae and Goodeniaceae, and seeds from Oligocene and Miocene are known for Menyanthaceae and Campanulaceae respectively.
The Asteraceae include some species grown for food, including sunflower (Helianthus annuus), lettuce (Lactuca sativa) and chicory (Cichorium). Many spices and medicinal herbs are also present.
Of horticultural importance are the Asteraceae (e. g. chrysanthemum) and Campanulaceae.

Asteroids, also called minor planets or planetoids, are a class of astronomical objects. The term asteroid is generally used to indicate a diverse group of small celestial bodies in the solar system that orbit around the Sun. "Asteroid", Greek for "star-like", is the most commonly used word in the English literature for minor planets, which is the term preferred by the International Astronomical Union, while other languages prefer planetoid, Greek for "planet-like", because it more or less describes what they are. In late August 2006, the IAU introduced a new class "small solar system bodies" (SSSB), to include most objects thus far classified as minor planets and comets. At the same time, the term "dwarf planet" was created for classifying the largest of the minor planets.
The first asteroid to be discovered, Ceres, is the largest asteroid known to date and is now classified as a dwarf planet. All others are currently classified as small solar system bodies. The vast majority of asteroids are found within the main asteroid belt, with elliptical orbits between those of Mars and Jupiter. It is thought that these asteroids are remnants of the protoplanetary disc, and in this region the accretion of planetesimals into a larger planet or planets during the formative period of the solar system was prevented by large gravitational perturbations by Jupiter. Some asteroids have moons or are found in co-orbiting pairs known as binary systems.
Hundreds of thousands of asteroids have been discovered within the solar system at the present rate of discovery around 5,000 per month. Of the more that 400,000 registered minor planets, 178,283 have orbits known well enough to be assigned permanent official numbers. Of these, 14,366 have official names. The lowest-numbered, unnamed minor planet is ; the highest-numbered named minor planet is 164215 Doloreshill.
Current estimates put the total number of asteroids above 1 km in diameter in the solar system to be between 1.1 and 1.9 million. The largest asteroid in the inner solar system is 1 Ceres, with diameters of 975 × 909 km. Two other large inner solar system belt asteroids are 2 Pallas and 4 Vesta; both have diameters of ~500 km. Vesta is the only main belt asteroid that is sometimes visible to the naked eye (on some very rare occasions, a near-Earth asteroid may briefly become visible without technical aid; see 99942 Apophis).
The mass of all the asteroids of the Main Belt is estimated to be about 3.0-3.6 kg, or about 4 percent of the mass of the Moon. Of this, Ceres comprises 0.95 kg, some 32 percent of the total. Adding in the next three most massive asteroids, 4 Vesta (9%), 2 Pallas (7%), and 10 Hygiea (3%), brings this figure up to 51%; while the three after that, 511 Davida (1.2%), 704 Interamnia (1.0%), and 3 Juno (0.9%), only add another 3% to the total mass. The number of asteroids then increases rapidly as their individual masses decrease.
Asteroids are commonly classified according to two criteria: the characteristics of their orbits, and features of their reflectance spectrum.
Many asteroids have been placed in groups and families based on their orbital characteristics. It is customary to name a group of asteroids after the first member of that group to be discovered. Groups are relatively loose dynamical associations, whereas families are much "tighter" and result from the catastrophic break-up of a large parent asteroid sometime in the past.
For a full listing of known asteroid groups and families, see minor planet and asteroid family.
This list has since been expanded to include a number of other asteroid types. The number of types continues to grow as more asteroids are studied. See Asteroid spectral types for more detail or :Category:Asteroid spectral classes for a list.
Note that the proportion of known asteroids falling into the various spectral types does not necessarily reflect the proportion of all asteroids that are of that type; some types are easier to detect than others, biasing the totals.
However, the correspondence between spectral class and composition is not always very good, and there are a variety of classifications in use. This has led to significant confusion. While asteroids of different spectral classifications are likely to be composed of different materials, there are no assurances that asteroids within the same taxonomic class are composed of similar materials.
At present, the spectral classification based on several coarse resolution spectroscopic surveys in the 1990s is still the standard. Scientists have been unable to agree on a better taxonomic system, largely due to the difficulty of obtaining detailed measurements consistently for a large sample of asteroids (e.g. finer resolution spectra, or non-spectral data such as densities would be very useful).
Asteroid discovery methods have drastically improved over the past two centuries.
In the last years of the 18th century, Baron Franz Xaver von Zach organized a group of 24 astronomers to search the sky for the "missing planet" predicted at about 2.8 AU from the Sun by the Titius-Bode law, partly as a consequence of the discovery, by Sir William Herschel in 1781, of the planet Uranus at the distance "predicted" by the law. This task required that hand-drawn sky charts be prepared for all stars in the zodiacal band down to an agreed-upon limit of faintness. On subsequent nights, the sky would be charted again and any moving object would, hopefully, be spotted. The expected motion of the missing planet was about 30 seconds of arc per hour, readily discernible by observers.
Ironically, the first asteroid, 1 Ceres, was not discovered by a member of the group, but rather by accident in 1801 by Giuseppe Piazzi, director of the observatory of Palermo in Sicily. He discovered a new star-like object in Taurus and followed the displacement of this object during several nights. His colleague, Carl Friedrich Gauss, used these observations to determine the exact distance from this unknown object to the Earth. Gauss' calculations placed the object between the planets Mars and Jupiter. Piazzi named it after Ceres, the Roman goddess of agriculture.
Three other asteroids (2 Pallas, 3 Juno, and 4 Vesta) were discovered over the next few years, with Vesta found in 1807. After eight more years of fruitless searches, most astronomers assumed that there were no more and abandoned any further searches.
However, Karl Ludwig Hencke persisted, and began searching for more asteroids in 1830. Fifteen years later, he found 5 Astraea, the first new asteroid in 38 years. He also found 6 Hebe less than two years later. After this, other astronomers joined in the search and at least one new asteroid was discovered every year after that (except the wartime year 1945). Notable asteroid hunters of this early era were J. R. Hind, Annibale de Gasparis, Robert Luther, H. M. S. Goldschmidt, Jean Chacornac, James Ferguson, Norman Robert Pogson, E. W. Tempel, J. C. Watson, C. H. F. Peters, A. Borrelly, J. Palisa, the Henry brothers and Auguste Charlois.
In 1891, however, Max Wolf pioneered the use of astrophotography to detect asteroids, which appeared as short streaks on long-exposure photographic plates. This drastically increased the rate of detection compared with previous visual methods: Wolf alone discovered 248 asteroids, beginning with 323 Brucia, whereas only slightly more than 300 had been discovered up to that point. Still, a century later, only a few thousand asteroids were identified, numbered and named. It was known that there were many more, but most astronomers did not bother with them, calling them "vermin of the skies".
Until 1998, asteroids were discovered by a four-step process. First, a region of the sky was photographed by a wide-field telescope, or Astrograph. Pairs of photographs were taken, typically one hour apart. Multiple pairs could be taken over a series of days. Second, the two films of the same region were viewed under a stereoscope. Any body in orbit around the Sun would move slightly between the pair of films. Under the stereoscope, the image of the body would appear to float slightly above the background of stars. Third, once a moving body was identified, its location would be measured precisely using a digitizing microscope. The location would be measured relative to known star locations.
These first three steps do not constitute asteroid discovery: the observer has only found an apparition, which gets a provisional designation, made up of the year of discovery, a letter representing the week of discovery, and finally a letter and a number indicating the discovery's sequential number (example: ).
The final step of discovery is to send the locations and time of observations to Brian Marsden of the Minor Planet Center, where computer programs that determine whether an apparition ties together previous apparitions into a single orbit. If so, the object receives a catalogue number and the observer of the first apparition with a calculated orbit is declared the discoverer, and granted honor of naming the object subject to the approval of the International Astronomical Union.
There is increasing interest in identifying asteroids whose orbits cross Earth's, and that could, given enough time, collide with Earth (see Earth-crosser asteroids). The three most important groups of near-Earth asteroids are the Apollos, Amors, and Atens. Various asteroid deflection strategies have been proposed, as early as the 1960s.
The near-Earth asteroid 433 Eros had been discovered as long ago as 1898, and the 1930s brought a flurry of similar objects. In order of discovery, these were: 1221 Amor, 1862 Apollo, 2101 Adonis, and finally 69230 Hermes, which approached within 0.005 AU of the Earth in 1937. Astronomers began to realize the possibilities of Earth impact.
Two events in later decades increased the level of alarm: the increasing acceptance of Walter Alvarez' hypothesis that an impact event resulted in the Cretaceous-Tertiary extinction, and the 1994 observation of Comet Shoemaker-Levy 9 crashing into Jupiter. The U.S. military also declassified the information that its military satellites, built to detect nuclear explosions, had detected hundreds of upper-atmosphere impacts by objects ranging from one to 10 metres across.
The LINEAR system alone has discovered 84,764 asteroids, as of August 28, 2007. Between all of the automated systems, 4711 near-Earth asteroids have been discovered including over 600 more than 1 km in diameter.
A newly discovered asteroid is given a provisional designation consisting of the year of discovery and an alphanumeric code (such as ). Once its orbit has been confirmed, it is given a number, and later may also be given a name (e.g. 433 Eros). The formal naming convention uses parentheses around the number (e.g. (433) Eros), but dropping the parentheses is quite common. Informally, it is common to drop the number altogether, or to drop it after the first mention when a name is repeated in running text.
Asteroids that have been given a number but not a name keep their provisional designation, e.g. (29075) 1950 DA. As modern discovery techniques are discovering vast numbers of new asteroids, they are increasingly being left unnamed. The first asteroid to be left unnamed was for a long time (3360) 1981 VA, now 3360 Syrinx; as of November 2006, this distinction is now held by. On rare occasions, a small body's provisional designation may become used as a name in itself: the still unnamed gave its name to a group of Kuiper belt objects which became known as cubewanos.
Asteroids are awarded with an official number once their orbits are confirmed. With the increasing rapidity of asteroid discovery, asteroids are currently being awarded six-figure numbers. The switch from five figures to six figures arrived with the publication of the Minor Planet Circular (MPC) of October 19, 2005, which saw the highest numbered asteroid jump from 99947 to 118161. This change caused a small "Y2k"-like crisis for various automated data services, since only five digits were allowed in most data formats for the asteroid number. Most services have now widened the asteroid number field. For those which did not, the problem has been addressed in some cases by having the leftmost digit (the ten-thousands place) use the alphabet as a digit extension. A=10, B=11,., Z=35, a=36,., z=61. A high number such as 120437 is thus cross-referenced as C0437 on some lists.
The first few asteroids were named after figures from Graeco-Roman mythology, but as such names started the names of famous people, literary characters, discoverer's wives, children, and even television characters were used.
The first asteroid to be given a non-mythological name was 20 Massalia, named after the city of Marseilles. For some time only female (or feminized) names were used; Alexander von Humboldt was the first man to have an asteroid named after him, but his name was feminized to 54 Alexandra. This unspoken tradition lasted until 334 Chicago was named; even then, oddly feminised names show up in the list for years afterward.
As the number of asteroids began to run into the hundreds, and eventually the thousands, discoverers began to give them increasingly frivolous names. The first hints of this were 482 Petrina and 483 Seppina, named after the discoverer's pet dogs. However, there was little controversy about this until 1971, upon the naming of 2309 Mr. Spock (which was not even named after the Star Trek character, but after the discoverer's cat who supposedly bore a resemblance to him). Although the IAU subsequently banned pet names as sources, eccentric asteroid names are still being proposed and accepted, such as 4321 Zero, 6042 Cheshirecat, 9007 James Bond, 13579 Allodd, 24680 Alleven, 128036 Rafaelnadal or 26858 Misterrogers.
Asteroid naming is not always a free-for-all: there are some types of asteroid for which rules have developed about the sources of names. For instance Centaurs (asteroids orbiting between Saturn and Neptune) are all named after mythological centaurs, Trojans after heroes from the Trojan War, and trans-Neptunian objects after underworld spirits.
Another well-established rule is that comets are named after their discoverer(s), whereas asteroids are not. One way to "circumvent" this rule has been for astronomers to exchange the courtesy of naming their discoveries after each other. A particular exception to this rule is 96747 Crespodasilva, which was named after its discoverer, Lucy d'Escoffier Crespo da Silva, because she died shortly after the discovery, at age 22. A few objects are also cross-listed as both comets and asteroids, such as 4015 Wilson-Harrington and 107P/Wilson-Harrington.
Johann Franz Encke made a major change in the Berliner Astronomisches Jahrbuch (BAJ, "Berlin Astronomical Yearbook") for 1854. He introduced encircled numbers instead of symbols, although his numbering began with Astraea, the first four asteroids continuing to be denoted by their traditional symbols. This symbolic innovation was adopted very quickly by the astronomical community. The following year (1855), Astraea's number was bumped up to 5, but Ceres through Vesta would be listed by their numbers only in the 1867 edition. A few more asteroids (28 Bellona, 35 Leukothea, and 37 Fides) would be given symbols as well as using the numbering scheme. The circle would become a pair of parentheses, and the parentheses sometimes omitted altogether over the next few decades.
Until the age of space travel, objects in the asteroid belt were merely pinpricks of light in even the largest telescopes and their shapes and terrain remained a mystery.
The first close-up photographs of asteroid-like objects were taken in 1971 when the Mariner 9 probe imaged Phobos and Deimos, the two small moons of Mars, which are probably captured asteroids. These images revealed the irregular, potato-like shapes of most asteroids, as did subsequent images from the Voyager probes of the small moons of the gas giants.
The first true asteroid to be photographed in close-up was 951 Gaspra in 1991, followed in 1993 by 243 Ida and its moon Dactyl, all of which were imaged by the Galileo probe en route to Jupiter.
The first dedicated asteroid probe was NEAR Shoemaker, which photographed 253 Mathilde in 1997, before entering into orbit around 433 Eros, finally landing on its surface in 2001.
Other asteroids briefly visited by spacecraft en route to other destinations include 9969 Braille (by Deep Space 1 in 1999), and 5535 Annefrank (by Stardust in 2002).
In September 2005, the Japanese Hayabusa probe started studying 25143 Itokawa in detail and may return samples of its surface to earth. The Hayabusa mission has been plagued with difficulties, including the failure of two of its three control wheels, rendering it difficult to maintain its orientation to the sun to collect solar energy. Following that, the next asteroid encounters will involve the European Rosetta probe (launched in 2004), which will study 2867 Šteins and 21 Lutetia in 2008 and 2010.
In September 2007, NASA launched the Dawn Mission, which will orbit the dwarf planet Ceres and the asteroid 4 Vesta in 2011-2015, with its mission possibly then extended to 2 Pallas.
It has been suggested that asteroids might be used in the future as a source of materials which may be rare or exhausted on earth (asteroid mining), or materials for constructing space habitats (see Colonization of the asteroids). Materials that are heavy and expensive to launch from earth may someday be mined from asteroids and used for space manufacturing and construction.
Asteroids and asteroid belts are a staple of science fiction stories. Asteroids play several potential roles in science fiction: as places which human beings might colonize; as resources for extracting minerals; as a hazard encountered by spaceships travelling between two other points; and as a threat to life on Earth due to potential impacts.

Generally, to allocute in law means "to speak out formally." In the field of apologetics, allocution is generally done in defense of a belief. In politics, one may allocute before a legislative body in an effort to influence their position on an issue. In law, it is generally meant to state specifically and in detail what one did and for what reason, often in relation to commission of a crime.
In most United States jurisdictions a defendant is allowed the opportunity to allocute — that is, explain himself — before sentence is passed. Some jurisdictions hold this as an absolute right, and in its absence, a sentence may potentially be overturned, with the result that a new sentencing hearing must be held.
Allocution is sometimes required of a defendant who pleads guilty to a crime in a plea bargain in exchange for a reduced sentence. In this instance, allocution can serve to provide closure for victims or their families. In principle, it removes any doubt as to the exact nature of the defendant's guilt in the matter. However, there have been many cases in which the defendant allocuted to a crime that he did not commit, often because this was a requirement to receiving a lesser sentence.
The term "allocution" is generally only in use in jurisdictions in the United States, though there are vaguely similar processes in other common law countries.
For example in Australia the term "allocutus" will be used. It will be used by the Clerk of Arraigns or another formal associate of the Court. It will generally be phrased as "Prisoner at the Bar, you have been found Guilty by a jury of your peers of the offense of XYZ. Do you have anything to say as to why the sentence of this Court should not now be passed upon you?". The defense counsel will then make a "plea in mitigation" (also called "submissions on penalty") wherein he or she will attempt to mitigate the relative seriousness of the offense and heavily refer to and rely upon the defendant's previous good character and good works (if any). The right to make a plea in mitigation in Australia is absolute. If a judge or magistrate were to refuse to hear such a plea, or obviously fail to properly consider it, then the sentence would, without doubt, be overturned on appeal.
In many other jurisdictions it is for the defense lawyer to mitigate on his client's behalf, and the defendant himself will rarely have the opportunity to speak.
The original party holds all control over the information. They decide when, how and how much information to give to the information services consumer. The consumer has no control over in this model.
Examples of this type of communication include radio and traditional television programs such as the news.

An affidavit is a formal sworn statement of fact, signed by the declarant (who is called the affiant or deponent) and witnessed (as to the veracity of the affiant's signature) by a taker of oaths, such as a notary public. The name is Medieval Latin for he has declared upon oath.
In American jurisprudence, under the rules for hearsay, admission of an unsupported affidavit as evidence is unusual (especially if the affiant is not available for cross-examination) with regard to material facts which may be dispositive of the matter at bar. Affidavits from persons who are dead or otherwise incapacitated, or who cannot be located or made to appear may be accepted by the court, but usually only in the presence of corroborating evidence. An affidavit which reflected a better grasp of the facts close in time to the actual events may be used to refresh a witness' recollection. Materials used to refresh recollection are admissible as evidence. If the affiant is a party in the case, the affiant's opponent may be successful in having the affidavit admitted as evidence, as statements by a party-opponent are not considered hearsay.
Some types of motions will not be accepted by the court unless accompanied by an independent sworn statement or other evidence, in support of the need for the motion. In such a case, a court will accept an affidavit from the filing attorney in support of the motion, as certain assumptions are made, to wit: The affidavit in place of sworn testimony promotes judicial economy. The lawyer is an officer of the court and knows that a false swearing by him, if found out, could be grounds for severe penalty up to and including disbarment. The lawyer if called upon would be able to present independent and more detailed evidence to prove the facts set forth in his affidavit.
The acceptance of an affidavit by one society does not confirm its acceptance as a legal document in other jurisdictions. Equally, the acceptance that a lawyer is an officer of the court (for swearing the affidavit)is not a given. This matter is addressed by the use of the Apostille (see Wikipedia). Apostille is a means of certification. It is commonly used in English to refer to the legalization of a document for international use under the terms of the 1961 Hague Convention Abolishing the Requirement of Legalization for Foreign Public Documents. Documents which have been notarized by a notary public, and certain other documents, and then certified with a conformant apostille are accepted for legal use in all the nations that have signed the Hague Convention. Thus most Affidavits now require to be Apostilled if used for cross border issues.
Affidavits are made in a similar way as to England and Wales, although "make oath" is sometimes omitted. A declaration may be substituted for an affidavit in most cases for those opposed to swearing oaths. The person making the affidavit is known as the deponent but does not sign the affidavit. The affidavit concludes in the standard format "sworn (declared) before me, [name of commissioner for oaths/solicitor], a commissioner for oaths (solicitor), on the [date] at [location] in the county/city of [county/city], and I know the deponent (declarant)", and it is signed and stamped by the commissioner for oaths.


Aries (, symbol, Unicode ♈) is one of the constellations of the zodiac. It lies between Pisces to the west and Big Dipper to the east.
Aries' stars are rather faint except for α Ari (Hamal) and β Ari (Sharatan). Other important stars are γ Ari (Mesarthim) and δ Ari (Botein).
Teegarden's star, a recent discovery in the constellation, is one of Sun's closest neighbors around 12 light years away. It exhibits one of the largest proper motions known at about 5.06 arc seconds/yr.
The few deep sky objects in Aries are very dim. They include the galaxies NGC 697 (northwest of β Ari), NGC 772 (southeast of β Ari), NGC 972 (in the constellation's northern corner), and NGC 1156 (northwest of δ Ari).
The stars of the constellation Aries can be connected in an alternative way, which graphically shows the ram running (or jumping).
The ram's head consists of the stars α Ari, λ Ari, and β Ari: α Ari being of the second magnitude and beta Arietis of the third magnitude.
The ram's body consists of the stars α Ari, η Ari, ε Ari, 41 Ari, and 35 Ari: ε Ari and 41 Ari being of the fourth magnitude.
The ram's tail consists of the stars 35 Ari, 41 Ari, and 39 Ari.
The star γ Ari, of fourth magnitude, represents the ram's front foot, and the star δ Ari, also of fourth magnitude, represents the ram's hind foot.
The Western astrological sign Aries of the tropical zodiac (March 21–April 20) differs from the astronomical constellation and the Hindu astrological sign of the sidereal zodiac (August 15 - October 15).

Aquarius (, ) is the eleventh sign of the zodiac, situated between Capricornus and Pisces. Its symbol is (), Unicode ♒, representing part of a stream of water.
Aquarius is one of the oldest recognized constellations along the zodiac, the sun's apparent path. It is found in a region often called the Sea due to its profusion of watery constellations such as Cetus, Pisces, Eridanus, etc. Sometimes, the river Eridanus is depicted spilling from Aquarius' watering pot.
There are three deep sky objects that are on the Messier catalog: the globular clusters Messier 2, Messier 72, and the open cluster Messier 73.
Two well-known planetary nebulae are located in Aquarius: the Saturn Nebula (NGC 7009), to the southwest of η Aquarii; and the famous Helix Nebula (NGC 7293), southwest of δ Aquarii.
The best-known myth identifies Aquarius with Ganymede, a beautiful youth with whom Zeus fell in love, and whom he (in the disguise of an eagle, represented as the constellation Aquila) carried off to Olympus to be cup bearer to the gods. Crater is sometimes identified as his cup.
Aquarius generally resembles the figure of a man, and when considering fainter humanly visible stars, it takes on the image of a man with a bucket from which is pouring a stream. Aquarius was also identified as the pourer of the waters which flooded the earth in the Great Flood, in the ancient Greek version of the myth. As such, the constellation Eridanus was sometimes identified as being a river poured out by Aquarius.
It may also, together with the constellation Pegasus, be part of the origin of the myth of the Mares of Diomedes, which forms one of The Twelve Labours of Heracles. Its association with pouring out rivers, and the nearby constellation of Capricornus, may be the source of the myth of the Augean stable, which forms another of the labours.
The Western astrological sign Aquarius of the tropical zodiac (January 20/21–February 18/19) differs from the astronomical constellation and the Hindu astrological sign of the sidereal zodiac (February 16–March 11).
Individuals born under the Aquarius sign are, by western astrologers, thought to have a creative, progressive (sometimes rebellious), and independent character.
According to astrology-inspired New Age mythology, and according to the gospel of The 5th Dimension, we're now living in the Age of Aquarius. Each Age is 2000 years long, approximately, with the Precession of the Equinoxes marking the beginning and end of each Age.
The stars of the constellation Aquarius can be connected in an alternative way, which graphically shows the water bearer running while holding a vessel from which water is spilling.
The water bearer's head is formed by the quadrangle of barney α Aqr, γ Aqr, η Aqr, and π Aqr: α Aqr being of the third magnitude. Star ζ Aqr, lodged within the quadrangle, represents an eye.
The water bearer's torso is formed by the stars α Aqr and β Aqr, with β Aqr being of the third magnitude.
The water bearer's left leg is formed by the stars β Aqr and ι Aqr, whereas his right leg is formed by the stars β Aqr, ν Aqr, μ Aqr, and ε Aqr, with these last two stars representing a foot.
The water bearer's arm is formed by the stars α Aqr, θ Aqr, and λ Aqr, with λ Aqr being the hand.
The water bearer is holding a vessel, perhaps a jar, which is formed by the stars ψ¹ Aqr, φ Aqr, λ Aqr, τ Aqr, and δ Aqr. The open top of the vessel consists of the triangle of stars ψ¹ Aqr, φ Aqr, and λ Aqr.
Water is being poured from the vessel in a pair of streamlines. The streamline on the left is formed by the stars ψ¹ Aqr, 98 Aqr, 99 Aqr, and 101 Aqr. The streamline on the right is formed by the stars ψ¹ Aqr, 88 Aqr, 89 Aqr, and 86 Aqr.


Anime ( listen in Japanese, but typically or /ˈænɪmə/ in English) is an abbreviation of the English word "animation", originating in Japan through the roots of Manga. Although the term is used in Japan to refer to animation in general, in English usage the term most popularly refers to material originating from Japan, a subset of animation.
Anime is traditionally hand drawn, but computer assisted techniques have become quite common in recent years. The subjects of anime represent most major genres of fiction, and anime is available in most motion-picture media ranging from television broadcast to literature.
The history of anime begins at the start of the 20th century, when Japanese filmmakers experimented with the animation techniques that were being explored in France, Germany, the United States, and Russia. The oldest known anime is in 1907, a three second clip of a sailor boy.
By the 1930s, animation became an alternative format of storytelling compared to the underdeveloped live-action industry in Japan. Unlike America, the live-action industry in Japan remained a small market and suffered from budgeting, location, and casting restrictions. The lack of Western-looking actors, for example, made it next to impossible to shoot films set in Europe, America, or fantasy worlds that do not naturally involve Japan. Animation allowed artists to create any characters and settings.
The success of Disney's 1937 feature film Snow White and the Seven Dwarfs influenced Japanese animators. Osamu Tezuka adapted and simplified many Disney animation techniques to reduce the costs and number of frames in the production. This was intended to be a temporary measure to allow him to produce material on a tight schedule with an inexperienced animation staff.
During the 1970s, there was a surge of growth in the popularity of manga—which were often later animated—especially those of Osamu Tezuka, who has been called a "legend" and the "god of manga". His work and that of other pioneers in the field, inspired characteristics and genres that are fundamental elements of anime today. The giant robot genre (known as "Mecha" outside Japan), for instance, took shape under Tezuka, developed into the Super Robot genre under Go Nagai and others, and was revolutionized at the end of the decade by Yoshiyuki Tomino who developed the Real Robot genre. Robot anime like the Gundam and Macross series became instant classics in the 1980s, and the robot genre of anime is still one of the most common in Japan and worldwide today. In the 1980s, anime became more accepted in the mainstream in Japan (although less than manga), and experienced a boom in production. Following a few successful adaptations of anime in overseas markets in the 1980s, anime gained increased acceptance in those markets in the 1990s and even more in the 2000s.
In Japanese, the English term animation is written in katakana as アニメーション (animēshon, ). The shortened term, anime (アニメ), emerged in the 1970s. Both the original and abbreviated forms are valid and interchangeable in Japanese, but the shorter form is more commonly used.
The pronunciation of anime in Japanese, [ɑnime], differs significantly from the Standard English which have different vowels and stress. (In Japanese each mora carries equal stress.) As with a few other Japanese words such as saké, Pokémon, and Kobo Abé, anime is sometimes spelled animé in English, with an acute accent over the final e, to cue the reader that the letter is pronounced, not silent as would be expected in English. However, this accent does not appear in any commonly used system of romanized Japanese and is not in frequent enough use to be recognised by the Oxford English Dictionary.
In Japan, the term does not specify an animation's nation of origin or style; instead, it is used as a blanket term to refer to all forms of animation from around the world. In English, dictionary sources define anime as "a Japanese style of motion-picture animation" or "a style of animation developed in Japan". Non-Japanese works that borrow stylization from anime is commonly referred to as "anime-influenced animation" but it is not unusual for a viewer who doesn't know the country of origin of such material to refer to it as simply "anime". Some works are co-productions with non-Japanese companies, such as the Cartoon Network and Production I.G series IGPX or Ōban Star-Racers, which may or may not be considered anime by different viewers. DVD outlets in the UK are increasingly categorising animated material aimed at an older market as anime, regardless of style or country of origin. Such titles include Æon Flux, Hellboy and Spawn. In English-speaking anime fandom, it is generally accepted that an animated production can only be known as "anime" if it is an animated (normally 2D), professionally produced, feature film (though not necessarily a "movie") created by a Japanese company for the Japanese market.
In English, anime can be used as a common noun ("Do you watch anime?") or as a suppletive adjective ("The anime Guyver is different from the movie Guyver"). It may also be used as a mass noun, as in "How much anime have you collected?" and therefore is not pluralized as animes.
Anime is occasionally referred to as Japanimation, but this term has fallen into disuse. Japanimation saw the most usage during the 1970s and 1980s, but was supplanted by anime in the mid-1990s as the material became more widely known in English-speaking countries. In general, the term now only appears in nostalgic contexts. Although the term was coined outside Japan to refer to animation imported from Japan, it is now used primarily in Japan, to refer to domestic animation; since anime does not identify the country of origin in Japanese usage, Japanimation is used to distinguish Japanese work from that of the rest of the world.
In Japan, manga can additionally refer to both animation and comics (although the use of manga to refer to animation is mostly restricted to non-fans). Among English speakers, manga usually has the stricter meaning of "Japanese comics". An alternate explanation is that it is due to the prominence of Manga Entertainment, a distributor of anime to the US and UK markets. Because Manga Entertainment originated in the UK the use of the term is common outside of Japan. The portmanteau "animanga" has been used to collectively refer to anime and manga, though it is also a term used to describe comics produced from animation cels.
Anime is commonly referred as an art form. As a visual medium, it naturally places a large emphasis towards visual styles. The styles can vary from artist to artist or by studio to studio. Some titles make extensive use of common stylization: FLCL, for example, is known for its wild, exaggerated stylization. In contrast, titles such as Only Yesterday or Jin-Roh take much more realistic approaches, featuring few stylistic exaggerations.
Another stylistic element is that of the use of lines. In anime the lines are often influenced more from a stylistic look from brush work, rather than that of the calligrapher's pen. This may be due to the fact that Japanese was traditionally written with a brush and has had a large influence on Japanese art, thus how the lines are treated tend to be different from the Western art. Western lettering was done with a calligrapher's pen. The influences of these things can most influentially be seen in the amount of tapering and thickness of the lines involved.
Anime also tends to borrow many elements from manga including text in the background, and borrowing panel layouts from the manga as well. For example, an opening may employ manga panels to tell the story, or to dramatize a point for humorous effect. This is best demonstrated in the anime Kare Kano.
Body proportions emulated in anime come from proportions of the human body. The height of the head is considered as the base unit of proportion. Head heights can vary as long as the remainder of the body remain proportional. Most anime characters are about seven to eight heads tall, and extreme heights are set around nine heads tall.
Variations to proportion can be modded. Chibi or super deformed characters feature a non-proportionally small body compared to the head. Sometimes specific body parts, like legs, are shortened or elongated for added emphasis. Mostly chibi are two to four heads tall. Some anime works like Crayon Shin-chan completely disregard these proportions. It is enough such that it resembles a Western cartoon. For exaggeration, certain body features are increased in proportion.
A common approach is the large eyes style drawn on many anime and manga characters. Osamu Tezuka was inspired by the exaggerated features of American cartoon characters such as Betty Boop, Mickey Mouse, and Disney's Bambi. Tezuka found that large eyes style allowed his characters to show emotions distinctly. When Tezuka began drawing Ribbon no Kishi, the first manga specifically targeted at young girls, Tezuka further exaggerated the size of the characters' eyes. Indeed, through Ribbon no Kishi, Tezuka set a stylistic template that later shōjo artists tended to follow.
Coloring is added to give eyes, particularly the cornea, some depth. The depth is accomplished by applying variable color shading. Generally, a mixture of a light shade, the tone color, and a dark shade is used. Cultural anthropologist Matt Thorn argues that Japanese animators and audiences do not perceive such stylized eyes as inherently more or less foreign.
However, not all anime have large eyes. For example Hayao Miyazaki is known for not having large eyes and having realistic hair colors on his characters. In addition many other productions also have been known to use smaller eyes. This design tends to have more resemblance to traditional Japanese art. Some characters have even smaller eyes, where simple black dots are used.
A wide variety of facial expressions are used by characters to denote moods and thoughts. Anime uses a different set of facial expressions in comparison to western animation.
Other stylistic elements are common as well; often in comedic anime, characters that are shocked or surprised will perform a "face fault", in which they display an extremely exaggerated expression. Angry characters may exhibit a "vein" or "stressmark" effect, where lines representing bulging veins will appear on their forehead. Angry women will sometimes summon a mallet from nowhere and strike someone with it, leading to the concept of Hammerspace and cartoon physics. Male characters will develop a bloody nose around their female love interests (typically to indicate arousal, based on an old wives' tale). Embarrassed characters either produce a massive sweat-drop (which has become one of the most widely recognized stereotype motifs of anime) or produce a visibly red blush beneath the eyes, especially as a manifestation of repressed romantic feelings. While common, the use of face faults is optional. Some anime, usually with political plots and other more serious subject matters, have abandoned the use of face faults such as Gundam Wing and Teknoman.
Some non-human characters further diversify the array of characters. Some include robots, animals, spirits, and demons. Also, hybrid beings such as catgirls or hanyō are also created. Non-humanoid characters have a very wide variety of shapes and sizes, which can range from miniature characters to those the size of skyscrapers. The use of size proportions will vary.
The typical style for non-humans is a dramatization of size for most, or a drastic shrinkage for others. Typical spirits and demons as well as robots and some animals will be shown out of proportion and sometimes the size of skyscrapers and buildings. Often for the purpose of giving the impression of great power or often synced with mecha-anime series in which the main character uses a giant robot to defeat another giant robot or creature. Some robots and animals though are shown to be accurate sized or even miniature for the sake of comical or story important reasons.
The basics of anime are based on traditional animation. While anime is considered separate from cartoons, anime still uses multiple still images in rapid succession to produce the animated visual effect. Like all animation, the production processes of storyboarding, voice acting, character design, cel production, etc. still apply. With improvements in computer technology, computer animation increased the efficiency of the whole production process.
Anime is often considered a form of limited animation. That means that stylistically, even in bigger productions the conventions of limited animation are used to fool the eye into thinking there is more movement than there is. Many of the techniques used a comprised with cost-cutting measures while working under a set budget.
Anime scenes place emphasis on achieving three-dimensional views. Backgrounds depict the scenes' atmosphere. For example, anime often puts emphasis on changing seasons, as can be seen in numerous anime, such as Tenchi Muyo. Sometimes actual settings have been duplicated into an anime. The backgrounds for the Melancholy of Haruhi Suzumiya are based on various locations within the suburb of Nishinomiya, Hyogo, Japan.
Camera angles, camera movement, and lighting play an important role in scenes. Directors often have the discretion of determining viewing angles for scenes, particularly regarding backgrounds. In addition, camera angles show perspective. Directors can also choose camera effects within cinematography, such as panning, zooming, facial closeup, and panoramic.
Anime has many genres typically found in any mass media form. Such genres include action, adventure, children's stories, comedy, drama, erotica (more specifically ecchi or hentai), medieval fantasy, occult/horror, romance, and science fiction. Most anime includes content from several different genres, as well as a variety of thematic elements. Thus, some series may be categorized under multiple genres. For example, Neon Genesis Evangelion might be considered to fall into the genres of post-apocalyptic, science fiction, mecha, and drama.
A show may have a seemingly simple surface plot, but at the same time may feature a far more complex, deeper storyline and character development. It is not uncommon for an action themed anime to also involve humor, romance, and even social commentary. The same can be applied to a romance themed anime in that it may involve an action element, or in some cases brutal violence.
The following is a list of the major genres and designations that are specific to anime and manga.
Demographic describes the intended target audience.
While anime had entered markets beyond Japan in the 1960s, it grew as a major cultural export during its market expansion during the 1980s and 1990s. The anime market for the United States alone is "worth approximately $4.35 billion, according to the Japan External Trade Organization". Anime has also been a commercial success in Asia, Europe and Latin America, where anime has become even more mainstream than in the United States. For example, the Saint Seiya video game was released in Europe due to the popularity of the show even years after the series has been off-air.
Anime distribution companies handled the licensing and distribution of anime beyond Japan. Licensed anime is modified by distributors through dubbing into the language of the country and adding language subtitles to the Japanese language track. Using a similar global distribution pattern as Hollywood, the world is divided into five regions.
Some editing of cultural references may occur to better follow the references of the non-Japanese culture. Certain companies may remove any objectionable content, complying with domestic law. This editing process was far more prevalent in the past (e.g. Robotech), but its use has declined because of the demand for anime in its original form. This "light touch" approach to localization has favored viewers formerly unfamiliar with anime. The use of such methods is evident by the success of Naruto and Cartoon Network's Adult Swim programming block, both of which employ minor edits.
With the advent of DVD, it was possible to include multiple language tracks into a simple product. This was not the case with VHS cassette, in which separate VHS media were used and with each VHS cassette priced the same as a single DVD. The "light touch" approach also applies to DVD releases as they often include both the dubbed audio and the original Japanese audio with subtitles, typically unedited. Anime edited for television is usually released on DVD "uncut," with all scenes intact.
TV networks regularly broadcast anime programming. In Japan, major national TV networks, such as TV Tokyo broadcast anime regularly. Smaller regional stations broadcast anime under the UHF. In the United States, Cable TV channels such as Cartoon Network, Disney, Sci-Fi, and others dedicate some of their time slots for anime. Then the Anime Network specifically shows anime. Sony based Animax and Disney's Jetix channel broadcast anime within many countries in the world. Anime Central solely broadcast's Anime in the UK.
Although it is a violation of copyright laws in many countries, some fans add subtitles to anime on their own. These are distributed as fansubs. The ethical implications of producing, distributing, or watching fansubs are topics of much controversy even when fansub groups do not profit from their activities. Once the series has been licensed outside of Japan, fansub groups often cease distribution of their work. In one case, Media Factory Incorporated requested that no fansubs of their material be made, which was respected by the fansub community. In another instance, Bandai specifically thanked fansubbers for their role in helping to make The Melancholy of Haruhi Suzumiya popular in the English speaking world.
The Internet had played a significant role in the exposure of anime beyond Japan. Prior to the 1990s, anime has had limited exposure beyond Japan's borders. Coincidentally, as the popularity of the Internet grew, so did for anime. Much of the fandom of anime grew through the Internet. The combination of internet communities and increasing amounts of anime material, from video to images, helped spur the growth of fandom. As the Internet gained more widespread use, Internet advertising revenues grew from 1.6 billion yen to over 180 billion yen between 1995 and 2005.
Anime has become commercially profitable in western countries as early commercially successful western adaptations of anime, such as Astro Boy, have revealed. The phenomenal success of Nintendo's multi-billion dollar Pokémon franchise was helped greatly by the spin-off anime series that, first broadcast in the late 1990s, is still running worldwide to this day. In doing so, anime has made significant impacts upon Western culture. Since the 19th century, many Westerners have expressed a particular interest towards Japan. Anime dramatically exposed more Westerners to the culture of Japan. Aside from anime, other facets of Japanese culture increased in popularity. Worldwide, the number of people studying Japanese increased. In 1984, the Japanese Language Profiency test was devised to meet increasing demand. Anime-influenced animation refers to non-Japanese works of animation that emulate the visual style of anime. Most of these works are created by studios in the United States, Europe, and non-Japanese Asia; and they generally incorporate stylizations, methods, and gags described in anime physics. In the case of Avatar: The Last Airbender. Often, production crews either are fans of anime or are required to view anime. Some creators cite anime as a source of inspiration with their own series. Furthermore, a French production team for Ōban Star-Racers moved to Tokyo to collaborate with a Japanese production team from Hal Film Maker. Critics and the general anime fanbase do not consider them as anime.
Some American animated television series have singled out anime styling with satirical intent, for example South Park (with "Chinpokomon" and "Good Times With Weapons"). South Park has a notable drawing style, which was itself parodied in "Brittle Bullet", the fifth episode of the anime FLCL, released several months after "Chinpokomon" aired. This intent on satirizing anime is the springboard for the basic premise of Kappa Mikey, a Nicktoons Network original cartoon. Even cliches normally found in anime are parodied in Perfect Hair Forever. Also, in the episode "The Son Also Draws" of Family Guy parodies anime with an appearance by Speed Racer and his trainer. The two speak in poorly-dubbed English, with every phrase punctuated by a "Ha-HA!". Anime conventions began to appear in the early 1990s, during the Anime boom, starting with Anime Expo, Animethon, Otakon, and JACON. Currently anime conventions are held annually in various cities across the Americas, Asia, and Europe. Many attendees participate in cosplay, where they dress up as anime characters. Also, guests from Japan ranging from artists, directors, and music groups are invited.


Ankara is the capital of Turkey and the country's second largest city after İstanbul. The city has a population (as of 2007) of 4,140,890 (Province 4,466,756), and a mean elevation of 850 m (2800 ft). It was formerly known as Angora. The Hittites gave it the name Ankuwash before 1200 BC, the Galatians and Romans called it Ancyra, and in the classical, Hellenistic, and Byzantine periods it was known as Ánkyra. Ankara also serves as the capital of the Province of Ankara.
Centrally located in Anatolia, Ankara is an important commercial and industrial city. It is the center of the Turkish Government, and houses all foreign embassies. It is an important crossroads of trade, strategically located at the center of Turkey's highway and railway networks, and serves as the marketing center for the surrounding agricultural area. The city was famous for its long-haired Angora goat and its prized wool (mohair), a unique breed of cat (Angora cat), white rabbits and their prized wool (Angora wool), pears, honey, and the region's muscat grapes.
Ankara is situated upon a steep and rocky hill, which rises 150 m above the plain on the left bank of the Enguri Su, a tributary of the Sakarya (Sangarius) river. The city is located at 39°52'30" North, 32°52' East (). Ankara is one of the driest places in Turkey and is surrounded by a barren steppe vegetation, with various Hittite, Phrygian, Hellenistic, Roman, Byzantine, and Ottoman archaeological sites. It has a harsh, dry continental climate with cold, snowy winters and hot, dry summers. Rainfall occurs mostly during the spring and autumn.
The hill which overlooks the city is crowned by the ruins of the old castle, which adds to the picturesqueness of the view, but only a few historic structures surrounding the old citadel have survived to our date. There are, however, many finely preserved remains of Hellenistic, Roman and Byzantine architecture, the most remarkable being the Temple of Augustus and Rome (20 BC) which is also known as the Monumentum Ancyranum.
The region's vibrant history can be traced back to the Bronze Age Hatti civilization, which was succeeded in the 2nd millennium BC by the Hittites, in the 10th century BC by the Phrygians, and later by the Lydians, Persians, Macedonians, Galatians, Romans, Byzantines, and Turks (Seljuk Empire then Ottoman Empire and then Turkey).
The oldest settlements in and around the city center of Ankara belong to the Hatti civilization which lived during the Bronze Age. Artifacts discovered in the city have revealed that the Hittites called Ankara with the name Ankuwash prior to 1200 BC. The city significantly grew in size and importance under the Phrygians starting from around 1000 BC, experiencing a large expansion following the mass migration from Gordion, the capital of Phrygia, after an earthquake which severely damaged that city in antiquity. In Phrygian tradition, King Midas was venerated as the founder of Ancyra, but Pausanias mentions that the city was actually far older, in line with the present-day knowledge that we have on its history.
Phrygian rule was succeeded first by Lydian and later by Persian rule, though the strongly Phrygian character of the peasantry remained, as evidenced by the gravestones of the much later Roman period. Persian sovereignty lasted until the Persians' defeat at the hands of the Macedonian king Alexander the Great who conquered the city in 333 BC. Alexander came from Gordion to Ankara and stayed in the city for a short period. After his death at Babylon in 323 BC and the subsequent division of his empire amongst his generals, Ankara and its environs fell into the share of Antigonus. Apart from the Phrygian period in which the city experienced its largest expansion in the ancient times, another important expansion took place under the Greeks of Pontos who came there and developed the city as a trading center for the commerce of goods between the Black Sea ports and Crimea to the north; Assyria, Cyprus, and Lebanon to the south; and Georgia, Armenia and Persia to the east. By that time the city also took its name Áγκυρα - Ànkyra (meaning anchor in Greek) which is still used by the Turks with the slightly modified form of Ankara.
In 278 BC, the city, along with the rest of central Anatolia, was occupied by the Celtic race of Galatians, who were the first to make Ankara one of their main tribal centres, the headquarters of the Tectosages tribe. Other centres were Pessinos, today's Balhisar, for the Trocmi tribe; and Tavium, to the east of Ankara, for the Tolstibogii tribe. The city was then known as Ancyra. The Celtic element was probably relatively small in numbers; a warrior aristocracy which ruled over Phrygian-speaking peasants. However, the Celtic language continued to spoken in Galatia for many centuries. At the end of the 4th century AD, St. Jerome, a native of Galatia, observed that the language spoken around Ankara was very similar to that being spoken in the northwest of the Roman world near Trier.
The city was subsequently conquered by Augustus in 25 BC and passed under the control of the Roman Empire. Now the capital city of the Roman province of Galatia, Ancyra continued to be a center of great commercial importance. Ankara is also famous for the Monumentum Ancyranum (Temple of Augustus and Rome) which contains the official record of the Acts of Augustus, known as the Res Gestae Divi Augusti, an inscription cut in marble on the walls of this temple. The ruins of Ancyra still furnish today valuable bas-reliefs, inscriptions and other architectural fragments.
Augustus decided to make Ancyra one of three main administrative centres in central Anatolia. The town was then populated by Phrygians and Celts—the Galatians who spoke a language closely related to Welsh and Gaelic. Ancyra was the center of a tribe known as the Tectosages, and Augustus upgraded it into a major provincial capital for his empire. Two other Galatian tribal centres, Tavium near Yozgat, and Pessinus (Balhisar) to the west, near Sivrihisar, continued to be reasonably important settlements in the Roman period, but it was Ancyra that grew into a grand metropolis.
An estimated 200,000 people lived in Ancyra in good times during the Roman Empire, a far greater number than was to be the case after the fall of the Roman Empire until the early twentieth century. A small river, the Ankara Çayı, ran through the centre of the Roman town. It has now been covered over and diverted, but it formed the northern boundary of the old town during the Roman, Byzantine and Ottoman periods. Çankaya, the rim of the majestic hill to the south of the present city center, stood well outside the Roman city, but may have been a summer resort. In the 19th century, the remains of at least one Roman villa or large house were still standing not far from where the Çankaya Presidential Residence stands today. To the west, the Roman city extended until the area of the Gençlik Park and Railway Station, while on the southern side of the hill, it may have extended downwards as far as the site presently occupied by Hacettepe University. It was thus a sizeable city by any standards and much larger than the Roman towns of Gaul or Britannia.
Ancyra's importance rested on the fact was that it was the junction point where the roads in northern Anatolia running north-south and east-west intersected. The great imperial road running east passed through Ankara and a succession of emperors and their armies came this way. They were not the only ones to use the Roman highway network, which was equally convenient for invaders. In the second half of the 3rd century, Ancyra was invaded in rapid succession by the Goths coming from the west (who rode far into the heart of Cappadocia, taking slaves and pillaging) and later by the Arabs. For about a decade, the town was one of the western outposts of one of the most brilliant queens of the ancient world, the Arab empress Zenobia from Palmyra in the Syrian desert, who took advantage of a period of weakness and disorder in the Roman Empire to set up a short-lived state of her own.
The town was reincorporated into the Roman Empire under the Emperor Aurelian in 272. The tetrarchy, a system of multiple (up to four) emperors introduced by Diocletian (284-305), seems to have engaged in a substantial programme of rebuilding and of road construction from Ankara westwards to Germe and Dorylaeum (now Eskişehir).
In its heyday, Roman Ankara was a large market and trading center but it also functioned as a major administrative capital, where a high official ruled from the city's Praetorium, a large administrative palace or office. During the 3rd century, life in Ancyra, as in other Anatolian towns, seems to have become somewhat militarised in response to the invasions and instability of the town. In this period, like other cities of central Anatolia, Ankara was also undergoing Christianisation.
Early martyrs, about whom little is known, included Proklos and Hilarios who were natives of the otherwise unknown village of Kallippi, near Ancyra, and suffered repression under the emperor Trajan (98-117). In the 280s AD we hear of Philumenos, a Christian corn merchant from southern Anatolia, being captured and martyred in Ankara, and Eustathius.
Like in other Roman towns, the reign of Diocletian marked the culmination point of repression against Christians. In 303, Ancyra was one of the towns where the co-Emperors Diocletian and his deputy Galerius launched their anti-Christian persecution. In Ancyra, their first target was the 38-year-old Bishop of the town, whose name was Clement. Clement's life describes how he was taken to Rome, then sent back, and forced to undergo many interrogations and hardship before he, and his brother, and various companions were put to death. The remains of the church of St. Clement can be found today in a building just off Işıklar Caddesi in the Ulus district. Quite possibly this marks the site where Clement was originally buried. Four years later, a doctor of the town named Plato and his brother Antiochus also became celebrated martyrs under Galerius. Theodotus of Ancyra is also venerated as a saint.
However, the persecution proved unsuccessful and in 314 Ancyra was the center of an important council of the early church; which considered ecclesiastical policy for the reconstruction of the Christian church after the persecutions, and in particular the treatment of 'lapsi'—Christians who had given in and conformed to paganism during these persecutions.
Three councils were held in the former capital of Galatia in Asia Minor, during the 4th century. The first, an orthodox plenary synod, was held in 314, and its 25 disciplinary canons constitute one of the most important documents in the early history of the administration of the Sacrament of Penance. Nine of them deal with conditions for the reconciliation of the lapsi; the others, with marriage, alienations of church property, etc.
Though paganism was probably tottering in Ancyra in Clement's day, it may still have been the majority religion. Twenty years later, Christianity and monotheism had taken its place. Ancyra quickly turned into a Christian city, with a life dominated by monks and priests and theological disputes. The town council or senate gave way to the bishop as the main local figurehead. During the middle of the 4th century, Ancyra was involved in the complex theological disputes over the nature of Christ, and a form of Arianism seems to have originated there.
The synod of 358 was a Semi-Arian conciliabulum, presided over by Basil of Ancyra. It condemned the grosser Arian blasphemies, but set forth an equally heretical doctrine in the proposition that the Son was in all things similar to the Father, but not identical in substance.
In 362-363, the Emperor Julian the Apostate passed through Ancyra on his way to an ill-fated campaign against the Persians, and according to Christian sources, engaged in a persecution of various holy men. The stone base for a statue, with an inscription describing Julian as "Lord of the whole world from the British Ocean to the barbarian nations", can still be seen, built into the eastern side of the inner circuit of the walls of Ankara Castle. The Column of Julian which was erected in honor of the emperor's visit to the city in 362 still stands today. In 375, Arian bishops met at Ancyra and deposed several bishops, among them St. Gregory of Nyssa. The modern Ankara, also known in some Western texts as Angora, remains a Roman Catholic titular see in the former Roman province of Galatia in Asia Minor, suffragan of Laodicea. Its episcopal list is given in Gams, "Series episc. Eccl. cath."; also that of another Ancyra in Phrygia Pacatiana.
In the later 4th century Ancyra became something of an imperial holiday resort. After Constantinople became the East Roman capital, emperors in the 4th and 5th centuries would retire from the humid summer weather on the Bosphorus to the drier mountain atmosphere of Ancyra. Theodosius II (408-450) kept his court in Ancyra in the summers. Laws issued in Ancyra testify to the time they spent there. The city's military as well as logistical significance lasted well into the long Byzantine reign. Although Ancyra fell into the hands of several Arab armies numerous times after the 6th century, it remained an important crossroads polis within the Byzantine Empire until the late 11th century.
In 1071, the Seljuk Sultan Alparslan opened the gates of Anatolia for the Turks with his victory at the Battle of Manzikert (Malazgirt). He then annexed Ankara, an important location for military transportation and natural resources, to his territory in 1073. Orhan I, second Bey of the Ottoman Empire, captured the city in 1356. Another Turkic ruler, Timur, defeated the Ottomans at the Battle of Ankara in 1402 and captured the city, but in 1403 Ankara was again under Ottoman control.
Following the Ottoman defeat at World War I, the Ottoman capital Istanbul and much of Anatolia were occupied by the Allies, who planned to share these lands between the United Kingdom, France, Italy and Greece, leaving the Turks only a small piece of land in central Asia Minor. In response, the leader of the Turkish nationalist movement, Kemal Atatürk, established the headquarters of his resistance movement in Ankara in 1920 (see Treaty of Sèvres and Turkish War of Independence). After the War of Independence was won, the Turkish nationalists replaced the Ottoman Empire with the Republic of Turkey on October 29, 1923. A few days earlier, Ankara had replaced İstanbul (formerly Constantinople) as the new Turkish capital city, on October 13, 1923.
After Ankara became the capital of the newly founded Republic of Turkey, new development divided the city into an old section, called Ulus, and a new section, called Yenişehir. Ancient buildings reflecting Roman, Byzantine, and Ottoman history and narrow winding streets mark the old section. The new section, now centered around Kızılay, has the trappings of a more modern city: wide streets, hotels, theaters, shopping malls, and high-rises. Government offices and foreign embassies are also located in the new section.
Ankara has experienced a phenomenal growth since it was made Turkey's capital. It was "a small town of no importance" when it was made the capital of Turkey. In 1924, the year after the government had moved there, Ankara had about 35,000 residents. By 1927 there were 44,553 residents and by 1950 the population had grown to 286,781. By 2007 its population was well over five million.
Ankara has many parks and open spaces mainly established in the early years of the Republic and well maintained and expanded thereafter. The most important of these parks are: Gençlik Park (houses an amusement park with a large pond for rowing), the Botanical Garden, Seğmenler Park, Anayasa Park, Kuğulu Park (famous for the swans received as a gift from the Chinese government), Abdi İpekçi Park, Güven Park (see above for the monument), Kurtuluş Park (has an ice-skating rink), Altınpark]link title (also a prominent exposition/fair area), Harikalar Diyarı (claimed to be Biggest Park of Europe inside city borders) and Göksu Park.
Atatürk Forest Farm and Zoo (Atatürk Orman Çiftliği) is an expansive recreational farming area which houses a zoo, several small agricultural farms, greenhouses, restaurants, a dairy farm and a brewery. It is a pleasant place to spend a day with family, be it for having picnics, hiking, biking or simply enjoying good food and nature. There is also an exact replica of the house where Atatürk was born in 1881, in Thessaloniki, Greece. Visitors to the "Çiftlik" (farm) as it is affectionately called by Ankarans, can sample such famous products of the farm such as old-fashioned beer and ice cream, fresh dairy products and meat rolls/kebaps made on charcoal, at a traditional restaurant (Merkez Lokantası, Central Restaurant), cafés and other establishments scattered around the farm.
Foreign visitors to Ankara usually like to visit the old shops in Çıkrıkçılar Yokuşu (Weavers' Road) near Ulus, where myriad things ranging from traditional fabrics, hand-woven carpets and leather products can be found at bargain prices. Bakırcılar Çarşısı (Bazaar of Coppersmiths) is particularly popular, and many interesting items, not just of copper, can be found here like jewelry, carpets, costumes, antiques and embroidery. Up the hill to the castle gate, there are many shops selling a huge and fresh collection of spices, dried fruits, nuts, and other produce.
Modern shopping areas are mostly found in Kızılay, or on Tunalı Hilmi Avenue, including the modern mall of Karum which is located towards the end of the Avenue; and in the Atakule Tower at Çankaya, the quarter with the highest elevation in the city, which commands a magnificent view over the whole city and also has a revolving restaurant at the top where the complete panorama can be enjoyed in a more leisurely fashion.
As Ankara started expanding westward in the 1970s, there are several modern, suburbia-style developments and mini-cities along the western highway, also known as the Eskişehir Road. The Armada and CEPA malls on the highway, the Galleria in Ümitköy, and a huge mall in Bilkent Center offer North American and European style shopping opportunities (these places can be reached following the Eskişehir Highway). There is also the newly expanded Ankamall at the outskirts, on the Istanbul Highway, which houses most of the well-known European brands. This mall is the largest throughout the Ankara region.
In addition the city is served by several private theatre companies among which Ankara Sanat Tiyatrosu who have their own stage in the city centre is a notable example.
Esenboğa International Airport, located in the north-east of the city, is the main airport of Ankara.
Ankara Intercity Bus Terminal (Turkish: Ankara Şehirlerarası Terminal İşletmesi, AŞTİ) is an important part of the bus network which covers every neighbourhood in the city.
The central train station, "Ankara Garı" of the Turkish State Railways (Turkish: Türkiye Cumhuriyeti Devlet Demiryolları, TCDD), is an important hub connecting the western and eastern parts of the country. High-speed rail services are to be operated between Ankara and Istanbul, beginning in 2009.
The Electricity, Gas, Bus General Directorate (EGO) operates the Ankara Metro and other forms of public transportation. Ankara is currently served by suburban rail and two subway lines with about 300,000 total daily commuters, and three additional subway lines are under construction.
Like in all the other cities of Turkey, football is the most popular sport in Ankara. The city has four football clubs currently competing in the Turkcell Super League: Gençlerbirliği (finished 5th in the league on the 2006-07 season), Büyükşehir Belediye Ankaraspor (finished 7th in the league on the 2006-07 season), and Ankaragücü (finished 13th in the league on the 2006/2007 season). The fourth club, Gençlerbirliği OFTAŞ has moved to participate in the Turkcell Super League during the 2007-08 season which started on August 10, 2007. Ankara 19 Mayıs Stadium is the venue for football games and has a capacity of 21,250 (all-seater).
In the Turkish Basketball League, Ankara is represented by Türk Telekom and CASA TED Ankara Kolejliler.
Ankara Buz Pateni Sarayı is where the ice skating and ice hockey competitions take place in the city.
There are many popular spots for skateboarding which is active in the city since the 1980s. Skaters in Ankara usually meet in the park near the Grand National Assembly of Turkey.
Ankara is also home to a world famous cat breed — the Turkish Angora, called Ankara Kedisi in Turkish. They are medium to small in size, longhaired, long-bodied, relatively fine-boned. Besides their beauty and athletic grace, Turkish Angora cats are also well known for their intelligence. For instance, it is not uncommon for an Angora cat to play fetch or to open doors.

Arabic (الْعَرَبيّة ' or just عَرَبيْ ') is the largest living member of the Semitic language family in terms of speakers. Classified as Central Semitic, it is closely related to Hebrew and Aramaic, and has its roots in a Proto-Semitic common ancestor. Modern Arabic is classified as a macrolanguage with 27 sub-languages in ISO 639-3. These varieties are spoken throughout the Arab world, and Standard Arabic is widely studied and known throughout the Islamic world.
Modern Standard Arabic derives from Classical Arabic, the only surviving member of the Old North Arabian dialect group, attested epigraphically since the 6th century, which has been a literary language and the liturgical language of Islam since the 7th century.
Arabic has lent many words to other languages of the Islamic world, as Latin has contributed to most European languages. And in turn, it has also borrowed from those languages, as well as Persian and Sanskrit from early contacts with their affiliated regions. During the Middle Ages, Arabic was a major vehicle of culture, especially in science, mathematics and philosophy, with the result that many European languages have also borrowed numerous words from it, especially Spanish and Portuguese due to both the proximity of European and Arab civilization and 700 years of caliphate government in the Iberian peninsula (see Al-Andalus).
The term "Arabic" may refer to either literary Arabic ((al-)fuṣḥā الفصحى) or the many localized varieties of Arabic commonly called "colloquial Arabic." Arabs consider literary Arabic as the standard language and tend to view everything else as mere dialects. Literary Arabic (اللغة العربية الفصحى translit: "the most eloquent Arabic language"), refers both to the language of present-day media across North Africa and the Middle East and to the language of the Qur'an. (The expression media here includes most television and radio, and practically all written matter, including all books, newspapers, magazines, documents of every kind, and reading primers for small children.) "Colloquial" or "dialectal" Arabic refers to the many national or regional varieties derived from Classical Arabic, spoken across North Africa and the Middle East, which constitute the everyday spoken language. These sometimes differ enough to be mutually incomprehensible. These dialects are typically unwritten, although a certain amount of literature (particularly plays and poetry) exists in many of them. They are often used to varying degrees in informal spoken media, such as soap operas and talk shows. Literary Arabic or classical Arabic is the official language of all Arab countries and is the only form of Arabic taught in schools at all stages.
The sociolinguistic situation of Arabic in modern times provides a prime example of the linguistic phenomenon of diglossia, which is the normal use of two separate varieties of the same language, usually in different social situations. In the case of Arabic, educated Arabs of any nationality can be assumed to speak both their local dialect and their school-taught literary Arabic. This diglossic situation facilitates code switching where a speaker switches back and forth between the two varieties of the language, sometimes even within the same sentence. When educated Arabs of different nationalities engage in conversation (for example, a Moroccan speaking with a Lebanese), both switch into Literary Arabic for the sake of communication.
Like other languages, literary Arabic continues to evolve. Classical Arabic (especially from the pre-Islamic to the Abbasid period, including Qur'anic Arabic) can be distinguished from Modern Standard Arabic (MSA) as used today. Classical Arabic is considered normative; modern authors attempt (with varying degrees of success) to follow the syntactic and grammatical norms laid down by Classical grammarians (such as Sibawayh), and to use the vocabulary defined in Classical dictionaries (such as the Lisān al-Arab.) However, many modern terms would have been mysterious to a Classical author, whether taken from other languages (for example, فيلم film) or coined from existing lexical resources (for example, هاتف hātif "telephone" = "caller"). Structural influence from foreign languages or from the colloquials has also affected Modern Standard Arabic: for example, MSA texts sometimes use the format "A, B, C, and D" when listing things, whereas Classical Arabic prefers "A and B and C and D", and subject-initial sentences may be more common in MSA than in Classical Arabic. For these reasons, Modern Standard Arabic is generally treated separately in non-Arab sources.
The influence of Arabic has been most profound in Islamic countries. Arabic is a major source of vocabulary for languages as diverse as Berber, Kurdish, Persian, Swahili, Urdu, Hindi (especially the spoken variety), Turkish, Malay and Indonesian, as well as other languages in countries where these languages are spoken. For example, the Arabic word for book (/kitāb/) is used in all the languages listed, apart from Malay and Indonesian (where it specifically means "religious book"). In addition, Spanish and Portuguese both have large numbers of Arabic loan words, and English has quite a few. Other languages such as Maltese and Kinubi derive from Arabic, rather than merely borrowing vocabulary or grammar rules.
The terms borrowed range from religious terminology (like Berber taẓallit "prayer" < salat), academic terms (like Uyghur mentiq "logic"), economic items (like English "sugar") to placeholders (like Spanish fulano "so-and-so") and everyday conjunctions (like Urdu lekin "but".) Most Berber varieties (such as Kabyle), along with Swahili, borrow some numbers from Arabic. Most Islamic religious terms are direct borrowings from Arabic, such as salat 'prayer' and imam 'prayer leader'. In languages not directly in contact with the Arab world, Arabic loanwords are often mediated by other languages rather than being transferred directly from Arabic; for example, most Arabic loanwords in Urdu entered through Persian, and many older Arabic loanwords in Hausa were borrowed from Kanuri.
Many words in English and other European languages are derived from Arabic, often through other European languages, especially Spanish and Italian. Among them are commonly-used words like "sugar" (sukkar), "cotton" (quṭn) and "magazine" (""). English words more recognizably of Arabic origin include "algebra", "alcohol", "alchemy", "alkali" and "zenith." Some words in common use, such as "intention" and "information", were originally calques of Arabic philosophical terms.
Arabic is the language of the Qur'an. Traditionally, Muslims deem it impossible to translate the Qur'an in a way that would reflect its exact meaning in a different language. Some schools of thought maintain that it should not be translated at all. Arabic is often associated with Islam, but it is also spoken by Arab Christians, Arab Druze, Mizrahi Jews and Iraqi Mandaeans.
Most of the world's Muslims do not speak Arabic as their native language but can read the script and recite the words of religious texts.
Modern Arabic is considered to be part of the Arabo-Canaanite sub-branch of the central group of West Semitic languages. While Arabic is not the oldest of the Semitic languages, it shares many features with the common ancestor for all Semitic languages in the Afro-Asiatic group of languages: Proto-Semitic whose phonological, morphological, and syntactic features have been determined by linguists. Many linguists consider Arabic to be the most Semitic of any modern Semitic languages in terms of how completely it preserves the features of Proto-Semitic.
The earliest Proto-Arabic, or Ancient North Arabian, texts are the Hasaean inscriptions of eastern Saudi Arabia, from the 8th century BC, written not in the modern Arabic alphabet, nor in its Nabataean ancestor, but in variants of the epigraphic South Arabian musnad. These are followed by 6th-century BC Lihyanite texts from southeastern Saudi Arabia and the Thamudic texts found throughout Arabia and the Sinai, and not in reality connected with Thamud. Later come the Safaitic inscriptions beginning in the 1st century BC, and the many Arabic personal names attested in Nabataean inscriptions (which are, however, written in Aramaic). From about the 2nd century BC, a few inscriptions from Qaryat al-Faw (near Sulayyil) reveal a dialect which is no longer considered "Proto-Arabic", but Pre-Classical Arabic.
By the fourth century AD, the Arab kingdoms of the Lakhmids in southern Iraq, the Ghassanids in southern Syria the Kindite Kingdom emerged in Central Arabia. Their courts were responsible for some notable examples of pre-Islamic Arabic poetry, and for some of the few surviving pre-Islamic Arabic inscriptions in the Arabic alphabet.
"Colloquial Arabic" is a collective term for the spoken varieties of Arabic used throughout the Arab world, which, as mentioned, differ radically from the literary language. The main dialectal division is between the North African dialects and those of the Middle East, followed by that between sedentary dialects and the much more conservative Bedouin dialects. Speakers of some of these dialects are unable to converse with speakers of another dialect of Arabic; in particular, while Middle Easterners can generally understand one another, they often have trouble understanding North Africans (although the converse is not true, due to the popularity of Middle Eastern—especially Egyptian—films and other media).
One factor in the differentiation of the dialects is influence from the languages previously spoken in the areas, which have typically provided a significant number of new words, and have sometimes also influenced pronunciation or word order; however, a much more significant factor for most dialects is, as among Romance languages, retention (or change of meaning) of different classical forms. Thus Iraqi aku, Levantine fīh, and North African kayən all mean "there is", and all come from classical Arabic forms (yakūn, fīhi, "kā'in respectively), but now sound very different.
The phonemes below reflect the pronunciation of Standard Arabic. There are minor variations from country to country.
Arabic has three vowels, with long and short forms of /a/, /i/, and /u/. There are also two diphthongs: /aj/ and /aw/.
See Arabic alphabet for explanations on the IPA phonetic symbols found in this chart.
Arabic has consonants traditionally termed "emphatic" /tˁ, dˁ, sˁ, ðˁ/ are both velarized [tˠ, dˠ, sˠ, ðˠ] and pharyngealised [tˁ, dˁ, sˁ, ðˁ]. This simultaneous velarization and pharyngealization is deemed "Retracted Tongue Root" by phonologists. In some transcription systems, emphasis is shown by capitalizing the letter e.g. /dˁ/ is written ‹D›; in others the letter is underlined or has a dot below it e.g. ‹ḍ›.
Vowels and consonants can be (phonologically) short or long. Long (geminate) consonants are normally written doubled in Latin transcription (i.e. bb, dd, etc.), reflecting the presence of the Arabic diacritic mark shaddah, which marks lengthened consonants. Such consonants are held twice as long as short consonants. This consonant lengthening is phonemically contrastive: e.g. qabala "he accepted" and qabbala "he kissed".
Arabic has two kinds of syllables: open syllables (CV) and (CVV) - and closed syllables (CVC), (CVVC) and (CVCC). Every syllable begins with a consonant - or else a consonant is borrowed from a previous word through elision – especially in the case of the definite article the, al- (used when starting an utterance) or _l (when following a word), e.g. baytu –l mudiir "house (of) the director", which becomes bay-tul-mu-diir" when divided syllabically. By itself, "the director" would be pronounced /al mudiːr/.
For example: ki-TAAB "book", KAA-tib "writer", MAK-tab "desk", ma-KAA-tib "desks", MAK-ta-ba "library", KA-ta-buu (MSA) "they wrote" = KA-ta-bu (dialect), ka-ta-BUU-hu (MSA) "they wrote it" = ka-ta-BUU (dialect), ka-TA-ba-taa (MSA) "they (dual, fem) wrote", ka-TAB-tu (MSA) "I wrote" = ka-TABT (dialect). Doubled consonants count as two consonants: ma-JAL-la "magazine", ma-HALL "palace".
In some dialects, there may be more or fewer phonemes than those listed in the chart above. For example, non-Arabic [v] is used in the Maghrebi dialects as well in the written language mostly for foreign names. Semitic [p] became [f] extremely early on in Arabic before it was written down; a few modern Arabic dialects, such as Iraqi (influenced by Persian and Turkish) distinguish between [p] and [b].
Interdental fricatives ([θ] and [ð]) are rendered as stops [t] and [d] in some dialects (such as Levantine, Egyptian, and much of the Maghreb); some of these dialects render them as [s] and [z] in "learned" words from the Standard language. Early in the expansion of Arabic, the separate emphatic phonemes [dˁ] and [ðˁ] coallesced into a single phoneme, becoming one or the other. Predictably, dialects without interdental fricatives use [dˁ] exclusively, while those with such fricatives use [ðˁ]. Again, in "learned" words from the Standard language, [ðˁ] is rendered as [zˁ] (in the Middle East) or [dˁ] (in North Africa) in dialects without interdental fricatives.
Nouns in Literary Arabic have three grammatical cases (nominative, accusative, and genitive [also used when the noun is governed by a preposition]); three numbers (singular, dual and plural); two genders (masculine and feminine); and three "states" (indefinite, definite, and construct). The cases of singular nouns (other than those that end in long ā) are indicated by suffixed short vowels (/-u/ for nominative, /-a/ for accusative, /-i/ for genitive). The feminine singular is often marked by /-at/, which is reduced to /-ah/ or /-a/ before a pause. Plural is indicated either through endings (the sound plural) or internal modification (the broken plural). Definite nouns include all proper nouns, all nouns in "construct state" and all nouns which are prefixed by the definite article /al-/. Indefinite singular nouns (other than those that end in long ā) add a final /-n/ to the case-marking vowels, giving /-un/, /-an/ or /-in/ (which is also referred to as nunation or tanwīn).
Verbs in Literary Arabic are marked for person (first, second, or third), gender, and number. They are conjugated in two major paradigms (termed perfective and imperfective, or past and non-past); two voices (active and passive); and five moods in the imperfective (indicative, imperative, subjunctive, jussive and energetic). There are also two participles (active and passive) and a verbal noun, but no infinitive. As indicated by the differing terms for the two tense systems, there is some disagreement over whether the distinction between the two systems should be most accurately characterized as tense, aspect or a combination of the two. The perfective aspect is constructed using fused suffixes that combine person, number and gender in a single morpheme, while the imperfective aspect is constructed using a combination of prefixes (primarily encoding person) and suffixes (primarily encoding gender and number). The moods other than imperative are primarily marked by suffixes (/u/ for indicative, /a/ for subjunctive, no ending for jussive, /an/ for energetic). The imperative has the endings of the jussive but lacks any prefixes. The passive is marked through internal vowel changes. Plural forms for the verb are only used when the subject is not mentioned, or is preceding it, and the feminine singular is used for all non-human plurals.
Adjectives in Literary Arabic are marked for case, number, gender and state, as for nouns. However, the plural of all non-human nouns is always combined with a singular feminine adjective, which takes the /-ah/ or /-at/ suffix.
Pronouns in Literary Arabic are marked for person, number and gender. There are two varieties, independent pronouns and enclitics. Enclitic pronouns are attached to the end of a verb, noun or preposition and indicate verbal and prepositional objects or possession of nouns. The first-person singular pronoun has a different enclitic form used for verbs (/-ni/) and for nouns or prepositions (/-ī/ after consonants, /-ya/ after vowels).
Nouns, verbs, pronouns and adjectives agree with each other in all respects. However, non-human plural nouns are grammatically considered to be feminine singular. Furthermore, a verb in a verb-initial sentence is marked as singular regardless of its semantic number when the subject of the verb is explicitly mentioned as a noun. Numerals between three and ten show "chiasmic" agreement, in that grammatically masculine numerals have feminine marking and vice-versa.
The spoken dialects have lost the case distinctions and make only limited use of the dual (it occurs only on nouns and its use is no longer required in all circumstances). They have lost the mood distinctions other than imperative, but many have since gained new moods through the use of prefixes (most often /bi-/ for indicative vs. unmarked subjunctive). They have also mostly lost the indefinite "nunation" and the internal passive. Modern Standard Arabic maintains the grammatical distinctions of Literary Arabic except that the energetic mood is almost never used; in addition, Modern Standard Arabic sometimes drop the final short vowels that indicate case and mood.
As in many other Semitic languages, Arabic verb formation is based on a (usually) triconsonantal root, which is not a word in itself but contains the semantic core. The consonants """, for example, indicate 'write', """ indicate 'read', """ indicate 'eat', etc. Words are formed by supplying the root with a vowel structure and with affixes. (Traditionally, Arabic grammarians have used the root """ 'do' as a template to discuss word formation.) From any particular root, up to fifteen different verbs can be formed, each with its own template; these are referred to by Western scholars as "form I", "form II",. up through "form XV". These forms, and their associated participles and verbal nouns, are the primary means of forming vocabulary in Arabic. Forms XI to XV are extremely rare.
The Arabic alphabet derives from the Aramaic script (through Syriac and then Nabatean), to which it bears a loose resemblance like that of Coptic or Cyrillic script to Greek script. Traditionally, there were several differences between the Western (North African) and Middle Eastern version of the alphabet—in particular, the fa and qaf had a dot underneath and a single dot above respectively in the Maghreb, and the order of the letters was slightly different (at least when they were used as numerals). However, the old Maghrebi variant has been abandoned except for calligraphic purposes in the Maghreb itself, and remains in use mainly in the Quranic schools (zaouias) of West Africa. Arabic, like all other Semitic languages (except for the Latin-written Maltese, and the languages with the Ge'ez script), is written from right to left. There are several styles of script, notably Naskh which is used in print and by computers, and Ruq'ah which is commonly used in handwriting.
After the definitive fixing of the Arabic script around 786, by Khalil ibn Ahmad al Farahidi, many styles were developed, both for the writing down of the Qur'an and other books, and for inscriptions on monuments as decoration.
Arabic calligraphy has not fallen out of use as calligraphy has in the Western world, and is still considered by Arabs as a major art form; calligraphers are held in great esteem. Being cursive by nature, unlike the Latin alphabet, Arabic script is used to write down a verse of the Qur'an, a Hadith, or simply a proverb, in a spectacular composition. The composition is often abstract, but sometimes the writing is shaped into an actual form such as that of an animal. Two of the current masters of the genre are Hassan Massoudy and Khaled Al Saa’i.
There are a number of different standards of Arabic transliteration: methods of accurately and efficiently representing Arabic with the Latin alphabet. There are multiple conflicting motivations for transliteration. Scholarly systems are intended to accurately and unambiguously represent the phonemes of Arabic, generally supplying making the phonetics more explicit than the original word in the Arabic alphabet. These systems are heavily reliant on diacritical marks such as "š" for sound equivalently written sh in English. In some cases, the sh or kh sounds can be represented by italicizing or underlining them -- that way, they can be distinguished from separate s and h sounds or k and h sounds, respectively. (Compare gashouse to gash.) At first sight, this may be difficult to recognize. Less scientific systems often use digraphs (like sh and kh), which are usually more simple to read, but sacrifice the definiteness of the scientific systems. Such systems may be intended to help readers who are neither Arabic speakers nor linguists to intuitively pronounce Arabic names and phrases. An example of such a system is the Bahá'í orthography. A third type of transliteration seeks to represent an equivalent of the Arabic spelling with Latin letters, for use by Arabic speakers when Arabic writing is not available (for example, when using an ASCII communication device).
An example is the system used by the US military, Standard Arabic Technical Transliteration System or SATTS, which represents each Arabic letter with a unique symbol in the ASCII range to provide a one-to-one mapping from Arabic to ASCII and back. This system, while facilitating typing on English keyboards, presents its own ambiguities and disadvantages. During the last few decades and especially since the 1990s, Western-invented text communication technologies have become prevalent in the Arab world, such as personal computers, the World Wide Web, email, Bulletin board systems, IRC, instant messaging and mobile phone text messaging. Most of these technologies originally had the ability to communicate using the Latin alphabet only, and some of them still do not have the Arabic alphabet as an optional feature. As a result, Arabic speaking users communicated in these technologies by transliterating the Arabic text using the Latin script, sometime known as IM Arabic.
To handle those Arabic letters that cannot be accurately represented using the Latin script, numerals and other characters were appropriated. For example, the numeral "3" may be used to represent the Arabic letter "ع", ayn. There is no universal name for this type of transliteration, but some have named it Arabic Chat Alphabet. Other systems of transliteration exist, such as using dots or capitalization to represent the "emphatic" counterparts of certain consonants. For instance, using capitalization, the letter "د", or daal, may be represented by d. Its emphatic counterpart, "ض", may be written as D.
In most of present-day North Africa, the Western Arabic numerals (0, 1, 2, 3, 4, 5, 6, 7, 8, 9) are used. However in Egypt and Arabic-speaking countries to the east of it, the Eastern Arabic numerals (٠.١.٢.٣.٤.٥.٦.٧.٨.٩) are in use. The lowest-valued digit appears on the right, so the order of digits on the page is the same as in Latin script; this reflects the way in which Arabic numbers are traditionally read (i.e. increasing order, so 1234 is "four and thirty and two hundred and one thousand"), though this reading has declined of late. Also sequences of digits such as telephone numbers are read from left to right.
Academy of the Arabic Language is the name of a number of language-regulation bodies formed in Arab countries. The most active are in Damascus and Cairo. They review language development, monitor new words and approve inclusion of new words into their published standard dictionaries. They also publish old and historical Arabic manuscripts.
Arabic language interests millions of non-Arabic speakers to learn it to different levels, mainly because it is the language of their holy book, the Quran, and all Islamic terms are Arabic. Arabic has been taught in many elementary and secondary schools, especially Muslim schools, worldwide. Many universities in the world today have classes for studying Arabic as a Foreign Language, as part of their foreign languages, Middle Eastern studies, religious studies, area studies departments, and even standalone Arabic language departments. Many Arabic language schools exist today to assist in gaining Arabic language skills outside academic education. Most of the Arabic language schools are located in the Arab world and some Muslim world countries. Software and books with tapes are also important part of Arabic learning, as many of Arabic learners may live in places where there are no academic or Arabic language school classes available. Radio series of Arabic language classes are also provided from some radio stations. A number of websites on the Internet provide online classes for all levels as a distance education means.


Apocalypse Now is a 1979 Academy Award, Cannes Palme d'Or and Golden Globe winning American film set during the Vietnam War. It tells the story of Army Captain Benjamin L. Willard who is sent into the jungle to assassinate United States Army Special Forces Colonel Walter E. Kurtz (played by Marlon Brando), who is said to have gone insane. The film has been viewed as a journey into the darkness of the human psyche.
The film stars Martin Sheen as Captain Benjamin L. Willard (based on Marlow in Conrad's novella), Marlon Brando as Colonel Kurtz, Dennis Hopper as a photojournalist, and Robert Duvall in an Oscar-nominated turn as the wild Lt. Colonel Bill Kilgore. The movie became notorious in the entertainment press due to its lengthy and troubled production. In the end, Coppola had to finance the film with his own money.
U.S. Army Captain Benjamin L. Willard has returned to Saigon; a seasoned veteran, he is deeply troubled and apparently no longer fit for civilian life. A group of intelligence officers approach him with a special mission: go up-river into the remote Cambodian jungle to find Colonel Walter E. Kurtz, a former member of the United States Army Special Forces.
Willard studies the intelligence files during the boat ride to the river entrance and learns that Kurtz, isolated in his compound, has assumed the role of a warlord and is worshipped by the natives and his own loyal men. Another officer, Colby, sent earlier to kill Kurtz, may have become one of his lieutenants.
Willard begins his trip up the Mekong River on a PBR (Patrol Boat, Riverine), with an eclectic crew composed of by-the-book and formal Chief Phillips, a black Navy boat commander; GM3 Lance B. Johnson, a tanned all-American California surfer; GM3 Tyrone, a.k.a. "Mr. Clean", a black 17-year-old from "some South Bronx shit-hole"; and the New Orleanian Engineman, Jay "Chef" Hicks.
The lighting and mood darken as the boat navigates upstream and Willard's silent obsession with Kurtz deepens. Incidents on the journey include a run-in with a tiger while Willard and Chef search for mangoes, an impromptu inspection of a Vietnamese sampan that leads to a massacre, a surreal stop at the last American outpost during a Vietnamese attack against a wood bridge under construction there, and the shocking deaths of both Clean and Chief Phillips during a gunfire ambush with hidden Viet Cong soldiers and a spear thrown by a native on the shore, respectively.
After arriving at Kurtz' outpost, Willard leaves Chef behind with orders to call in an air strike on the village if he does not return. They are met by a borderline-psychotic freelance photographer (Hopper) who explains Kurtz's greatness and philosophical skills to provoke his people into following him. Brought before Kurtz and held in captivity in a darkened temple, Willard’s constitution appears to weaken as Kurtz lectures him on his theories of war, humanity, and civilization. Kurtz explains his motives and philosophy in a famous and haunting monologue in which he praises the ruthlessness of the Viet Minh: If I had ten divisions of those men our troubles here would be over very quickly. You have to have men who are moral.. and at the same time who are able to utilize their primordial instincts to kill without feeling.. without passion.. without judgment.. without judgment. For it is judgment that defeats us.
While bound outside in the pouring rain, Willard is approached by Kurtz, who places the severed head of Chef in his lap. Coppola makes little explicit, but we come to believe that Willard and Kurtz develop an understanding nonetheless; Kurtz wishes to die at Willard's hands, and Willard, having subsequently granted Kurtz his wish, is offered the chance to succeed him in his warlord-demigod role. Juxtaposed with a ceremonial slaughtering of a water buffalo, Willard enters Kurtz's chamber during one of his message recordings, and kills him with a machete. This entire sequence is set to "The End" by The Doors, as is the sequence at the very beginning of the film. Lying bloody and dying on the ground, Kurtz whispers "The horror.. the horror," a line taken directly from Conrad's novella. Willard walks through the now-silent crowd of natives, makes returns to the PBR, and floats away as Kurtz's final words echo in the wind as the screen fades to black.
At the time of its release, many rumors surrounded the ending of Apocalypse Now. Coppola stated an ending was written in haste in which Willard and Kurtz joined forces and repelled the air strike on the compound; however, Coppola never fully agreed with the two going out in apocalyptic intensity, preferring to end the film in a more encouraging manner.
When Coppola originally organized the ending of the movie, he had two choices. One involved Willard leading Lance by the hand as everyone in Kurtz's base throws down their weapons, and ends with images of Willard's boat pulling away from Kurtz's compound superimposed over the face of a stone idol which then fades into black. Another option showed an air strike being called and the base being blown to bits in a spectacular display, consequently killing everyone left at the base.
The original 1978 theatrical release ended with Willard's boat, the stone statue, then fade to black with no credits. Later, when it was no longer practical to not have any credits, Coppola elected to show the credits superimposed over shots of Kurtz's base exploding (anamorphic rental prints circulated with this ending, and can be found in the hands of a few collectors); however, when Coppola heard that audiences interpreted this as an air strike called by Willard, Coppola pulled the film from its run, and put credits on a black screen. In the DVD commentary, Coppola explains that the images of explosions had not been intended to be part of the story; they were intended to be seen as completely separate from the film. He had added them to the credits because he had captured the footage during the demolition of the set in the Philippines, which was filmed with multiple cameras fitted with different film stocks and lenses to capture the explosions at different speeds.
Because of the confusion over the misinterpreted ending, there are multiple slightly varying versions of the ending credits. Some TV screenings maintain the explosion footage at the end, others do not, and there are several other versions.
The release ends with no credits, save for 'Copyright 1979 Omni Zoetrope' right after the film ends; This mirrors the lack of any opening titles, and supposedly stems from Coppola's original intention to "tour" the film as one would a play: the credits would have appeared on printed programs provided before the screening began. This was, in fact, done in certain cinemas and was repeated during the theatrical release of Apocalypse Now: Redux.
The first DVD of the theatrical version plays like the version, without beginning or ending credits, but has them on a separate part of the DVD. The credits to Apocalypse Now: Redux are different again: the credits play over a black background, but with ambient music by the Rhythm Devils.
In 2001, Coppola released Apocalypse Now Redux (Latin for "brought back") in cinemas and subsequently on DVD. This is an extended version that restores 49 minutes of scenes cut from the original film. Coppola has continued to circulate the original version as well: the two versions are packaged together in the Complete Dossier DVD, released on August 15, 2006.
The most significant footage added in the Redux version is an anticolonialism chapter involving the de Marais family's rubber plantation, a holdover from the colonization of French Indochina, featuring Coppola's two sons Giancarlo and Roman as children of the family. These scenes were removed from the 1979 cut, which premiered at Cannes. In behind the scenes footage in Hearts of Darkness, Coppola expresses his anger, on the set, at the technical aspects of the shot scenes, the result of tight allocation of resources. At the time of the Redux version, it was possible to digitally-enhance the footage to accomplish Coppola's vision. In the scenes, the French family patriarchs argue about the positive side of colonialism in Indochina and denounce the betrayal of the military men in the First Indochina War. Hubert de Marais argues that French politicians sacrificed entire battalions at Điện Biên Phủ, and tells Willard that the US created the Viet Cong (as the Viet Minh), to fend off Japanese invaders.
Other added material includes extra combat footage before Willard meets Kilgore, a humorous scene in which Willard's team steals Kilgore's surfboard (which sheds some light on the hunt for the mangoes), a follow-up scene to the dance of the Playboy playmates, in which Willard's team finds the playmates awaiting evacuation after their helicopter has run out of fuel, and a scene of Kurtz reading from a Time magazine article about the war, surrounded by Cambodian children.
Although inspired by Joseph Conrad's Heart of Darkness, the film deviates extensively from its source material. The novella, based on Conrad's real experiences as a steam paddleboat captain in Africa, is set in the Belgian Congo during the 19th century. Kurtz and Marlow (who is named Willard in the movie) both work for a Belgian trading company that brutally exploits its native African workers.
In the novella, Marlow is the pilot of a river boat sent to collect ivory from Kurtz's outpost, only gradually becoming infatuated with Kurtz. In fact, when he discovers Kurtz in terrible health, Marlow makes a concerted effort to bring him home safely. In the movie, Willard is an assassin dispatched to kill Kurtz. Nevertheless, the depiction of Kurtz as a god-like leader of a tribe of natives and his malarial fever, Kurtz's written exclamation "Exterminate the brutes!" (which appears in the film as "Drop the bomb. Exterminate them All!") and his final lines "The horror! The horror!" are taken from Conrad's novella.
Coppola argues that many episodes in the film — the spear and arrow attack on the boat, for example — respect the spirit of the novella and in particular its critique of the concepts of civilization and progress. While Coppola replaced European colonization with American interventionism, the message of Conrad's book is still clear.
The film was originally written in the late 1960s by John Milius, who would later direct films such as The Wind and the Lion, Red Dawn and Conan the Barbarian. Milius claims to have been inspired by his film professor's claim that no one had successfully adapted the book Heart of Darkness, despite attempts by such legendary directors as Orson Welles and Richard Brooks. Ironically, given that the finished film is seen as an anti-war movie, Milius, who is politically a rightist, originally conceived the title as a cynical answer to the leftist hippie slogan "Nirvana Now!" and his original screenplay includes several speeches by Kurtz extolling the virtues of combat and the warrior way of life.
The script was originally to be directed by George Lucas, who was then Coppola's protege at American Zoetrope. Coppola founded Zoetrope to create an alternative to the major Hollywood studios which would support the work of the rising generation of film-school graduates who would become known colloquially as "the movie brats." The war in Vietnam was still active at the time and the initial plan was to shoot Apocalypse Now guerilla-style in Vietnam itself. Warner Bros. which had a production deal with Zoetrope, refused to finance the project both for commercial reasons and the fear that the filmmakers would be killed trying to shoot it in a war zone. Lucas has claimed that the studio saw the project, as well as him and his colleagues, as "crazy." After Lucas found success with American Graffiti, Coppola chose to direct the film himself. This reportedly caused some friction between the two men. Coppola chose to finance the film entirely with his own assets, using money earned from the two Godfather films and a bank loan, in order to retain total creative control over the final product.
Coppola also rewrote the script to accommodate his vision, removing much of Milius's macho dialogue and changing the film's ending. Milius's original ending showed Kurtz and Willard joining forces to fight an American air assault on Kurtz's compound. The compound is destroyed in a massive air strike and Kurtz dies of his wounds as Willard looks on. Coppola dismissed this ending as cartoonish. The ending would be rewritten multiple times over the course of production and most of Kurtz's role would eventually be improvised by Marlon Brando. The film's narration was written during the editing process by Michael Herr, who had written the book Dispatches while a war correspondent in Vietnam.
Apocalypse Now was the first time Coppola worked with cinematographer Vittorio Storaro, who had shot several films for Bernardo Bertolucci, including The Conformist, one of Coppola's favorites, and Last Tango In Paris, which had also starred Marlon Brando.
It was said that Coppola had approached legendary B-movie director Roger Corman, Coppola's mentor who gave him his first break as a director about Corman's experience with shooting in the Philippines. (As much of the film was shot in the country, most notably the Pagsanjan River and Hidden Valley Springs), had Corman advising the director: "Don't go." as the film would start shooting during the country's monsoon season. Such weather helped fuel the shoot's history as being legendary for its length and difficulty; filming took so long, critics eventually began referring to it as "Apocalypse When?". The film went far over budget and over schedule for several reasons. A typhoon destroyed many of the sets, which had to be rebuilt at great expense. The Philippine Air Force helicopters used for shooting Col. Kilgore's attack on a Vietnamese village were constantly being called back by President Ferdinand Marcos to serve in actual combat against anti-government rebels.
The lead role of Captain Willard was to be played by Harvey Keitel but it was recast two weeks after shooting began. Keitel's footage was re-shot with Martin Sheen, who suffered a near-fatal heart attack during production and was suffering from alcoholism during the shoot. In 50 Films to See Before You Die, aired on the United Kingdom's Channel 4 on the 22 July 2006, Sheen reveals that the opening scene was completely improvised, that he had been drinking all day, his 36th birthday, before it was shot, and that he broke the mirror by accident. When he started bleeding, Coppola wanted to stop filming, but Sheen insisted that he continue. Watching the scene back, Sheen said it was good to see where he'd come from knowing that he was never going to go back there again. It took Sheen weeks to recover and return to the set, during which time the film was in danger of being shut down. Being similar in appearance and voice, Joe Estevez, Sheen's brother, stood in for Sheen in some of the long shots and would later record some of the film's narration.
Marlon Brando appeared on set massively overweight, despite his character's description as sick and emaciated. The majority of Brando's dialogue had to be improvised, despite the short time during which the actor was available.
Coppola famously said of the shoot: "We had access to too much money, too much equipment, and little by little we went insane." The director faced bankruptcy and financial ruin if the film was not finished or shut down; his personal investment and the bizarre circumstances of the production created immense personal pressure. According to the 1991 documentary, "Hearts of Darkness: A Filmmaker's Apocalypse" directed by Eleanor Coppola, George Hickenlooper and Fax Bahr, Coppola's marriage almost fell apart and the director suffered a nervous breakdown, including declaring to commit suicide three separate times through the making of the film.
The director, according to archival materials in the recent "Complete Dossier" edition, also stated that his plan was to create a single theater, in the geographical center of the United States (likely Kansas) that would show Apocalypse Now, and only Apocalypse Now. It would be specially tailored to the film, with 3D 70mm projectors, 5.1 surround sound, and the Sensurround system, which would vibrate the seats at the appropriate intervals. In his eyes, it would be "an event", and he likened it to travelling to Mount Rushmore. It was, incidentally, exactly the same idea which motivated Richard Wagner's Bayreuth Festival. Wagner's Parsifal was initially only to be shown in Bayreuth and Bayreuth too was chosen as the festival location because it is more or less in the heart of Germany. Considering that Wagner's music features so prominently in Apocalypse Now, Coppola may have been inspired by Wagner's example.
The original released version of the movie was just over two and a half hours long, and was a box-office success in the United States and overseas. It eventually made over 100 million dollars at the box office.
Coppola re-released the film in 2001 under the title Apocalypse Now Redux. The new print was supervised by Vittorio Storaro, who used a color process of his own invention to restore the film for release. Storaro has claimed that Apocalypse Now Redux looks better than the original release print of the film.
The catastrophic production of the film made it symbolic of the dangers of excessive directorial control over major productions. The shooting was said to have taken a toll on all involved, especially Coppola, both mentally and emotionally.
Apocalypse Now premiered in 1979 to mixed reviews and received polarized responses from audiences. It is said that it was as lauded as it was reviled. Many critics slammed the film, calling it overly pretentious, while others felt that it ended anticlimactically after a splendid first act.
Today, the film is widely regarded as a masterpiece of the New Hollywood era. It is on the AFI's 100 Years.. 100 Movies list at number 28. Kilgore's quote "I love the smell of napalm in the morning" was number 12 on the AFI's 100 Years.. 100 Movie Quotes list. In 2002, Sight and Sound magazine polled several critics to name the best film of the last 25 years and Apocalypse Now was named number one. It was also listed as the second best war film by viewers on Channel 4's 100 Greatest War Films, and ranked number 1 on Channel 4's 50 Films To See Before You Die.
In a 2004 poll of UK film fans, Blockbuster listed Kilgore's eulogy to napalm as the best movie speech.
A water buffalo was slaughtered with a machete for the climactic scene. It was in fact a real ritual performed by local natives, with Coppola and a film crew on the sidelines as honored guests. Although this was an American production subject to American animal cruelty laws, scenes like this filmed in the Philippines were not policed or monitored, and the American Humane Association gave the film an "unacceptable" rating.
The first home video releases of Apocalypse Now were pan-and-scan versions of the original Technovision anamorphic 2.35:1 print, and the closing credits, white on black background, were presented in compressed 1.33:1 full-frame format to allow all credit information to be seen on standard televisions. The first letterboxed appearance (on laserdisc on 12-29-1991) cropped the film to a 2:1 aspect ratio (conforming to the Univisium spec created by cinematographer Vittorio Storaro), featuring a small degree of pan-and-scan processing - notably in the opening shots in Willard's hotel room, featuring a composite montage - at the insistence of Coppola and Storaro. Although the end credits, from a videotape source, not a film print, were still crushed for 1.33:1 and zoomed to fit the anamorphic video frame. All DVD releases have maintained this aspect ratio in anamorphic widescreen, but present the film without the end credits, which were treated as a separate feature. As a DVD extra, the footage of the explosion of the Kurtz compound was featured without text credits but included a commentary by director Coppola explaining the various endings based on how the film was screened.
Several other actors who were, or later became, prominent stars have minor roles in the movie including Harrison Ford, G.D. Spradlin, Scott Glenn, and R. Lee Ermey. Fishburne was only fourteen years old when shooting began in March 1976, and was credited as "Larry Fishburne." Another cast member with a future as a prominent actor and film director was Martin Sheen's eldest son, Emilio Estevez, who played a young soldier in the movie. Apocalypse Now took so long to finish that Fishburne was seventeen (the same age as his character) by the time of its release.
In 2000 the United States Library of Congress deemed the film "culturally significant" and selected it for preservation in the National Film Registry.
The movie poster art for Apocalypse Now is by Bob Peak, who is considered an influential artist in the world of movie posters.


Sir Alfred Joseph Hitchcock KBE (August 13 1899 – April 29 1980) was an iconic and highly influential director and producer who pioneered many techniques in the suspense and thriller genres.
After a substantial film career in his native Britain, he moved to Hollywood and became an American citizen with dual nationality in 1956, thus he also remained a British subject.
Hitchcock directed more than fifty feature films in a career spanning six decades, from the silent film era, through the invention of talkies, to the colour era.
He was among the most consistently recognizable directors to the general public, and was one of the most successful film directors during his lifetime. He continues to be one of the best known and most popular filmmakers of all time.
Hitchcock became famous for his expert and largely unrivalled control of pace and suspense, and his films draw heavily on both fear and fantasy. The films are known for their droll humour and witticisms, and these cinematic works often portray innocent people caught up in circumstances beyond their control or understanding.
Hitchcock began his directing career in the United Kingdom in 1922. From 1939 onward, he worked primarily in the United States. In September, 1940, Hitchcock had purchased a 200 acre mountaintop estate for the sum of $40,000. Known as the 1870 Cornwall Ranch or ""Heart o' the Mountain" which was located at the end of Canham Road. The Ranch was perched high above Scotts Valley, California, and the Hitchcocks resided there from 1940 to 1972. The Hitchcocks became close friends with the parents of Joan Fontaine, after she had starred in his film, Rebecca". Years later, after a break-in at his estate, Hitchcock had replaced all of the accumulated paintings with studio-made copies, and the family had sold the estate in 1974, six years before Hitchcock's death.
Hitchcock and family had also purchased a second home in late 1942 at 10957 Bellagio Road in Los Angeles, just across from the Bel Air Country Club. Hitchcock died of renal failure in 1980.
Rebecca was the only one of his films to win the Academy Award for Best Picture, although four other films were also nominated. Hitchcock had never won an Academy Award for Best Director. He was, however, awarded the Irving G. Thalberg Memorial Award for lifetime achievement in 1967.
Alfred Hitchcock was born on August 13, 1899, in Leytonstone, London, the second son and youngest of three children of William Hitchcock (1862-1914), a greengrocer and poulterer, and his wife, Emma Jane Hitchcock (née Whelan; 1863-1942). His family was mostly Roman Catholic, being of Irish extraction. Hitchcock was sent to the Jesuit Classic school St. Ignatius College in Enfield, London. He often described his childhood as being very lonely and sheltered, which was compounded by his weight issues.
It is widely known that as a child, Hitchcock's father once sent him to their local police station with a note asking the officer to lock him away for ten minutes as punishment for behaving badly. This idea of being harshly treated or wrongfully accused is more than commonly reflected in Hitchcock's films.
His mother would often make him address her while standing at the foot of her bed, especially if he behaved badly, forcing him to stand there for hours. These experiences of Hitchcock would later be used for the portrayal of the character of Norman Bates in his movie Psycho.
Hitchcock's father died when he was 14. In the same year, he had left the Jesuit-run St Ignatius' College in Stamford Hill, his school at the time, to study at the School for Engineering and Navigation. After graduating, he became a draftsman and advertising designer with a cable company.
During this period, Hitchcock became intrigued by photography and started working in film production in London, working as a title-card designer for the London branch of what would become Paramount Pictures. In 1920, he had received a full-time position at Islington Studios with its American owner, Famous Players-Lasky and their British successor, Gainsborough Pictures, designing the titles for silent movies.
In 1925, Michael Balcon of Gainsborough Pictures gave Hitchcock an opportunity to direct his first film, The Pleasure Garden made at Ufa studios in Germany. The commercial failure of this film threatened to derail his promising career. Hitchcock rebounded in 1926 and made his debut in the thriller genre with the film, The Lodger: A Story of the London Fog. The film was a major commercial and critical success when it was released in January 1927 throughout the United Kingdom. As with many of his earlier works, this film was influenced by Expressionist techniques that Hitchcock had witnessed first-hand in Germany. This film was the first truly "Hitchcockian" film, incorporating such themes as the "wrong man".
Following the success of The Lodger, Hitchcock began initial efforts to promote himself in the media, and hired a publicist to imbue his growing reputation as one of the British film industry's rising stars. On December 2, 1926, Hitchcock married his assistant director, Alma Reville at the Brompton Oratory. Their first child, daughter Patricia, was born in 1928. Alma was to become Hitchcock's closest collaborator. She wrote some of his screenplays and (though often uncredited) worked with him on every one of his films.
In 1929, he began work on his tenth film Blackmail. While the film was still in production, the studio decided to make it one of Britain's first sound pictures. With the climax of the film taking place on the dome of the British Museum, Blackmail began the Hitchcock tradition of using famous landmarks as a backdrop for suspense sequences. In the PBS series The Men Who Made The Movies, Hitchcock had explained how he used early sound recording as a special element of the film, emphasizing the word "knife" in a conversation with the woman suspected of murder.
Hitchcock's next major success was in 1938 with his film The Lady Vanishes, a clever and fast-paced film about the search for a kindly old Englishwoman (Dame May Whitty), who disappears while onboard a train in the fictional country of Vandrika (a thinly-veiled version of Nazi Germany).
By 1938, Hitchcock had become known for his famous observation, "Actors are cattle." He once said that he first made this remark as early as the late 1920s, when he thought about stage actors who were snobbish about motion pictures. However, Michael Redgrave said that Hitchcock had made the statement during the filming of The Lady Vanishes. The phrase would haunt Hitchcock for years to come and would result in a funny incident during the filming of his 1941 production of Mr. & Mrs. Smith, when Carole Lombard brought some heifers onto the set to surprise the director.
At the end of the 1930's, Hitchcock was at the zenith of his artistic talents, and he was in a position to negotiate his own career options when David O. Selznick managed to entice him to Hollywood.
The suspense and the gallows humour that had become Hitchcock's trademark in film had continued to appear in his productions. The working arrangements with Selznick, however, were less than optimal. Selznick suffered from perennial money problems, and Hitchcock was often displeased with Selznick's creative control over his films. Consequently, Selznick ended up "loaning" Hitchcock to the larger studios more often than producing Hitchcock's films himself. In addition, Selznick, as well as fellow independent producer Samuel Goldwyn, made only a few films each year, so Selznick did not always have projects for Hitchcock to direct. Remarkably, Goldwyn had also negotiated with Hitchcock on a possible contract, only to be outbid by Selznick. Hitchcock was quickly impressed with the superior resources of the American studios compared to the financial restrictions he had frequently encountered in England. Nevertheless, Hitchcock's fondness for his homeland resulted in numerous American films set in, or filmed in, the United Kingdom, right up to his next-to-last film, Frenzy.
With the prestigious Selznick picture Rebecca in 1940, Hitchcock made his first American movie, although it was set in England and based on a novel by English author Daphne du Maurier and starred Sir Laurence Olivier and Joan Fontaine. This Gothic melodrama explores the fears of a naïve young bride who enters a great English country home and must grapple with the problems of a distant husband, a predatory housekeeper, and the legacy of her husband's late wife, the beautiful, mysterious Rebecca. The film won the Academy Award for Best Picture of 1940. However, the statuette went to Selznick as the film's producer, and the film failed to win the Best Director award for Hitchcock.
There were additional problems between Selznick and Hitchcock. Selznick was known to impose very restrictive rules upon Hitchcock, thereby hindering his creative control. Hitchcock was then forced to shoot the film as Selznick had wanted, immediately creating friction within their relationship. At the same time, Selznick complained about Hitchcock's "goddamn jigsaw cutting," which meant that the producer did not have nearly the leeway to create his own film as he liked, but had to follow Hitchcock's vision of the finished product. The film was the third longest of Hitchcock's films at 130 minutes, exceeded only by The Paradine Case at 132 minutes and North by Northwest at 136 minutes.
Hitchcock's second American film, the European-set thriller Foreign Correspondent (originally titled Personal History), was also nominated for Best Picture during that year. The movie was filmed in the first year of World War II and was inspired by the rapidly-changing events in Europe, as fictionally-covered by an American newspaper reporter portrayed by a wise-cracking Joel McCrea. The film cleverly used actual footage of European scenes and scenes filmed on a Hollywood backlot. Curiously, because of Hollywood's Production Code censorship, the film avoided direct references to Germany and Germans.
Hitchcock's films during the 1940s were diverse. The movies ranged from the romantic comedy Mr. & Mrs. Smith (1941) and the courtroom drama The Paradine Case (1947), to the dark and disturbing Shadow of a Doubt (1943).
Suspicion (1941) marked Hitchcock's first film as a producer as well as director. Hitchcock had used the north coast of Santa Cruz for the English coastline sequence. This film was to be actor Cary Grant's first time working with Hitchcock, and it was one of the few times that Grant would be cast in a sinister role. Joan Fontaine won Best Actress Oscar and New York Film Critics Circle Award for her outstanding performance in Suspicion.
Saboteur (1942) was the first of two films that Hitchcock made for Universal, a studio where he would continue his career during his later years. Hitchcock was then forced to utilize Universal contract players Robert Cummings and Priscilla Lane, both known for their work in comedies and light dramas. Hitchcock made the most of the situation and had received remarkably good performances from the two lead actors. Breaking with Hollywood conventions of the time, Hitchcock did extensive location filming, especially in New York City, and memorably depicted a confrontation between a suspected saboteur (Cummings) and a real saboteur (Norman Lloyd) atop the Statue of Liberty.
Shadow of a Doubt (1943), his personal favourite of all his films and the second of the early Universal films, was about young Charlotte "Charlie" Newton (Teresa Wright), who suspects her beloved uncle Charlie Oakley (Joseph Cotten) of being a serial murderer. In its use of overlapping characters, dialogue, and closeups it has provided a generation of film theorists with psychoanalytic potential, including Jacques Lacan and Slavoj Žižek. The film also harkens back to one of Cotten's best known films, Citizen Kane. Hitchcock again filmed extensively on location, this time in the Northern California city of Santa Rosa, during the summer of 1942. The director showcased his own personal fascination with crime and criminals when he had two of his characters discuss various ways of killing people, to the obvious annoyance of Charlotte.
Working at 20th Century Fox, Hitchcock had adapted a script of John Steinbeck's that had chronicled the experiences of the survivors of a German U-boat attack in the film Lifeboat (1944). Since the action sequences were confined to the small boat, the film was clearly the most confined of Hitchcock's films. While at Fox, Hitchcock seriously considered directing the film version of A.J. Cronin's novel about a Catholic priest in China, The Keys of the Kingdom, but the plans for this fell through. John M. Stahl ended up directing the 1944 film, which was produced by Joseph L. Mankiewicz and starred Gregory Peck, among other luminaries.
Returning to England for an extended visit in late 1943 and early 1944, Hitchcock filmed two short films for the Ministry of Information, Bon Voyage and Aventure Malgache. The films were made for France's free territories and were the only ones Hitchcock made in French; they feature typical Hitchcockian touches. In the 1990s, the two films were shown by Turner Classic Movies and released on home video.
In 1945, Hitchcock served as "treatment advisor" (in effect, a film-editor) for a Holocaust documentary produced by the British Army. The film, which recorded the liberation of Concentration Camps, remained unreleased until 1985, when it was completed by PBS Frontline and distributed under the title Memory of the Camps.
Hitchcock again worked for Selznick when he had directed Spellbound, which explored the then-fashionable subject of psychoanalysis and featured a dream sequence designed by Salvador Dalí. The dream sequence as it actually appears in the film is considerably shorter than was originally envisioned, which was to be several minutes long, because it proved to be too disturbing for the audience. Some of the memorable and original musical score by Miklos Rozsa was later adapted by the composer into a concert piano concerto.
Notorious (1946) followed Spellbound. As Selznick failed to see its potential, he allowed Hitchcock to make the film for RKO. From this point onwards, Hitchcock would produce his own films, giving him a far greater degree of freedom to pursue the projects that interested him. Notorious starred Hitchcock regulars Ingrid Bergman and Cary Grant and features a plot about Nazis, uranium, and South America. It was a huge box office success and has remained one of Hitchcock's most acclaimed films. His use of uranium as a plot device briefly led to Hitchcock's being under surveillance by the FBI. McGilligan wrote that Hitchcock consulted scientists about the development of an atomic bomb; Selznick complained that the notion was "science fiction," only to be confronted by the news stories of the detonation of two atomic bombs on Hiroshima and Nagasaki in Japan during 1945. These bombings had led to the end of World War II.
After completing his final film for Selznick, The Paradine Case (a promising courtroom drama that critics found lost momentum because it apparently ran too long and exhausted its resource of ideas), Hitchcock filmed his first color film, Rope, which appeared in 1948. Here Hitchcock experimented with marshalling suspense in a confined environment, as he had done earlier with Lifeboat (1943). He also experimented with exceptionally long takes — up to ten minutes long (see Themes and devices). Featuring James Stewart in the leading role, Rope was the first of four films Stewart would make for Hitchcock. It was based on the Leopold and Loeb case of the 1920s. Somehow Hitchcock's cameraman managed to move the bulky, heavy Technicolor camera quickly around the set as it followed the continuous action of the long takes.
Under Capricorn (1949), set in nineteenth-century Australia, also used the short-lived technique of long takes, but to a more limited extent. He again used Technicolor in this production, then returned to black and white films for several years. For Rope and Under Capricorn Hitchcock formed a production company with Sidney Bernstein, called Transatlantic Pictures, which became inactive after these two unsuccessful pictures. Hitchcock continued to produce his films for the rest of his life.
In 1950, Hitchcock filmed Stage Fright on location in the U.K. For the first time, Hitchcock matched one of Warner Brothers' biggest stars, Jane Wyman, with the sultry German actress Marlene Dietrich. Dietrich's daughter later wrote that Dietrich detested Wyman, although Wyman had just won the Best Actress Oscar for Johnny Belinda. Hitchcock may have exploited the offscreen animosity between Wyman and Dietrich in this offbeat, behind-the-scenes glimpse of London theatrical personalities, one of whom commits a murder. Hitchcock utilized a number of prominent British actors, including Michael Wilding, Richard Todd, and Alastair Sim. This was Hitchcock's first production for Warner Brothers, which had distributed Rope and Under Capricorn, because Transatlantic Pictures was experiencing financial difficulties.
With the film, Strangers on a Train (1951), based on the novel by Patricia Highsmith, Hitchcock combined many of the best elements from his preceding British and American films. Two men casually meet and speculate on removing people who are causing them difficulty. One of the men, though, takes this banter entirely seriously. With Farley Granger reprising some elements of his role from Rope, Strangers continued the director's interest in the narrative possibilities of blackmail and murder.
MCA head Lew Wasserman, whose client list included James Stewart, Janet Leigh, and other actors who would appear in Hitchcock's films, had a significant impact in packaging and marketing Hitchcock's films beginning in the 1950s. With Wasserman's help, Hitchcock received tremendous creative freedom from the studios, as well as substantive financial rewards as a result of Paramount's profit-sharing contract.
Three very popular films starring Grace Kelly followed. Dial M for Murder (1954) was adapted from the popular stage play by Frederick Knott. This was originally another experimental film, with Hitchcock using the technique of 3D cinematography, although the film was not released in this format at first; it did receive screenings in the early 1980s in 3D form. The film also marked a return to Technicolor productions for Hitchcock. Hitchcock moved to Paramount Pictures and filmed Rear Window, starring James Stewart and Kelly again, as well as Thelma Ritter and Raymond Burr. Here, the wheelchair-bound Stewart observes the movements of his neighbours across the courtyard and becomes convinced one of them has murdered his wife. Like Lifeboat and Rope, the movie was photographed almost entirely within the confines of a small space: Stewart's tiny studio apartment overlooking the massive courtyard set. To Catch a Thief, set in the French Riviera, starred Kelly and Cary Grant. It proved to be Hitchcock's last film with Kelly because she married Prince Rainier of Monaco in 1956 and the residents of her new homeland refused to allow her to make any more films.
The remake of his own 1934 film The Man Who Knew Too Much in 1956 followed, this time starring James Stewart and Doris Day, who sang the theme song, "Whatever Will Be, Will Be (Que Sera, Sera)" (which won the Oscar for "Best Music", and became a big hit for Day).
The Wrong Man (1957), Hitchcock's final film for Warner Brothers, was a low-key black and white production based on a real-life case of mistaken identity. This was the only film of Hitchcock's to star Henry Fonda.
Vertigo (1958) again starred Stewart, this time with Kim Novak and Barbara Bel Geddes. The film was a commercial failure, but has come to be viewed by many as one of Hitchcock's masterpieces; it is now placed highly in the Sight & Sound decade polls. It was premiered in the San Sebastian International Film Festival, where Hitchcock won a Silver Seashell.
By this time, Hitchcock had filmed in many areas of the United States. He followed Vertigo with three more successful films. All are also recognized as among his very best films: North by Northwest (1959), Psycho (1960), and The Birds (1963). The latter two films were particularly notable for their unconventional soundtracks, both orchestrated by Bernard Herrmann: the screeching strings played in the murder scene in Psycho exceeded the limits of the time, and The Birds dispensed completely with conventional instruments, instead using an electronically-produced soundtrack and an unaccompanied song by school children (just prior to the infamous attack at the historic Bodega Bay School). Also notable was that Santa Cruz was mentioned again as the place where the bird-phenomenon was said to have first occurred. These films are considered his last great films, after which his career started to lose pace (although some critics such as Robin Wood and Donald Spoto contend that Marnie, from 1964, is first-class Hitchcock, and some have argued that Frenzy is unfairly overlooked).
Failing health took its toll on Hitchcock, reducing his new film production during the last two decades of his life. Hitchcock had filmed two spy thrillers, Torn Curtain with Paul Newman and Julie Andrews and Topaz (based on a Leon Uris novel), which both received mixed reviews. In 1972, Hitchcock returned to London to film Frenzy, his last major success. For the first time, Hitchcock allowed nudity and profane language, which had before been taboo, in one of his films. Biographers have noted that Hitchcock had always pushed the limits of film censorship, often managing to fool Joseph Breen, the longtime head of Hollywood's Production Code. Many times Hitchcock slipped in subtle hints of improprieties forbidden by censorship until the mid-1960s. Yet Patrick McGilligan wrote that Breen and others often realized that Hitchcock was inserting such things and were actually amused as well as alarmed by Hitchcock's "inescapable inferences." Beginning with Torn Curtain, Hitchcock was finally able to blatantly include plot elements previously forbidden in American films and this continued for the remainder of his film career.
Family Plot (1976) was his last film. It related the escapades of "Madam" Blanche Tyler played by Barbara Harris, a fraudulent spiritualist, and her taxi driver lover Bruce Dern making a living from her phony powers. William Devane, Karen Black and Cathleen Nesbitt co-starred. It was the only Hitchcock film scored by John Williams.
When Hitchcock saw the Mel Brooks 1977 comedy-spoof of his work, High Anxiety, he enjoyed it, but Brooks initially feared that Hitchcock was not pleased because he walked out of the movie when it was over. Days later, Brooks fear proved untrue as Hitchcock had sent Brooks a bottle of champagne.
Near the end of his life, Hitchcock had worked on the script for a projected spy thriller, The Short Night, collaborating with screenwriters James Costigan and Ernest Lehman. Despite some preliminary work, the story was never filmed. This was due, primarily, to Hitchcock's own failing health and his concerns over the health of his wife, Alma, who had suffered a stroke. The script was eventually published posthumously, in a book on Hitchcock's last years.
Hitchcock was made a Knight Commander of the Order of the British Empire by Queen Elizabeth II in the 1980 New Year's Honours. He was entitled to use the title "Sir" because he remained a British subject when he adopted American citizenship in 1956.
He died just four months later, on April 29, before he received the opportunity to be formally invested by the Queen.
Alfred Hitchcock died from renal failure in his Bel-Air, Los Angeles home at the age of 80. His wife Alma Reville, and their daughter, Patricia Hitchcock O'Connell, both survived him.
A funeral service was held at Good Shepherd Catholic Church in Beverly Hills. His body was cremated and his ashes were scattered over the Pacific.
Many of Hitchcock's films contain cameo appearances by Hitchcock himself: the director would be seen for a brief moment boarding a bus, crossing in front of a building, standing in an apartment across the courtyard, or appearing in a photograph. This playful gesture became one of Hitchcock's signatures. As a recurring theme he would carry a musical instrument — especially memorable was the large double bass case that he wrestles onto the train at the beginning of Strangers on a Train.
In his earliest appearances he would fill in as an obscure extra, standing in a crowd or walking through a scene in a long camera shot (e.g. in his 1927 film The Lodger). But he became more prominent in his later appearances, as when he turns to see Jane Wyman's disguise when she passes him on the street in Stage Fright, and in stark silhouette in his final film Family Plot (1976).
Hitchcock seemed to delight in the technical challenges of filmmaking. In the film Lifeboat, Hitchcock stages the entire action of the movie in a small boat, yet manages to keep the cinematography from monotonous repetition (his trademark cameo appearance was a dilemma, given the limitations of the setting; so Hitchcock appears in a fictitious newspaper ad for a weight loss product). Similarly, the entire action in Rear Window either takes place or is seen from a single apartment.
In Spellbound, two unprecedented point-of-view shots were achieved by constructing a large wooden hand (which would appear to belong to the character whose point of view the camera took) and outsized props for it to hold: a bucket-sized glass of milk and a large wooden gun. For added novelty and impact, the climactic gunshot was hand-coloured red on some copies of the black-and-white print of the film.
Rope (1948) was another technical challenge: a film that appears to have been shot entirely in a single take. The film was actually shot in 10 takes of ranging from four and half to 10 minutes each, 10 minutes being the maximum amount of film that would fit in a single camera reel; some transitions between reels were hidden by having a dark object fill the entire screen for a moment. Hitchcock used those points to hide the cut, and began the next take with the camera in the same place.
His 1958 film Vertigo contains a camera technique that has been imitated and re-used many times by filmmakers, it has become known as the Hitchcock zoom.
Hitchcock's films sometimes feature characters struggling in their relationships with their mothers. In North by Northwest (1959), Roger Thornhill (Cary Grant's character) is an innocent man ridiculed by his mother for insisting that shadowy, murderous men are after him (in this case, they are). In The Birds (1963), the Rod Taylor character, an innocent man, finds his world under attack by vicious birds, and struggles to free himself of a clinging mother (Jessica Tandy). The killer in Frenzy (1972) has a loathing of women but idolizes his mother. The villain Bruno in Strangers on a Train hates his father, but has an incredibly close relationship with his mother (played by Marion Lorne). Sebastian (Claude Rains) in Notorious has a clearly conflictual relationship with his mother, who is (correctly) suspicious of his new bride Alicia Huberman (Ingrid Bergman). And, of course, Norman Bates' troubles with his mother in Psycho are infamous.
Hitchcock heroines tend to be lovely, cool blondes who seem proper at first but, when aroused by passion or danger, respond in a more sensual, animal, or even criminal way. As noted, the famous victims in The Lodger are all blondes. In The 39 Steps, Hitchcock's glamorous blonde star, Madeleine Carroll, is put in handcuffs. In Marnie (1964), the title character (played by Tippi Hedren) is a kleptomaniac. In To Catch a Thief (1955), Francie (Grace Kelly) offers to help a man she believes is a cat burglar. In Rear Window, Lisa (Grace Kelly again) risks her life by breaking into Lars Thorwald's apartment. And, most notoriously, in Psycho, Janet Leigh's unfortunate character steals $40,000 and is murdered by a reclusive lunatic. Hitchcock's last blonde heroine was - years after Dany Robin and her "daughter" Claude Jade in Topaz - Barbara Harris as a phony psychic turned amateur sleuth in his final film, 1976's Family Plot. In the same film, the diamond smuggler played by Karen Black could also fit that role, as she wears a long blonde wig in various scenes and becomes increasingly uncomfortable about her line of work.
Hitchcock saw that reliance on actors and actresses was a holdover from the theater tradition. He was a pioneer in using camera movement, camera set ups and montage to explore the outer reaches of cinematic art.
Most critics and Hitchcock scholars, including Donald Spoto and Roger Ebert, agree that Vertigo represents the director's most personal and revealing film, dealing with the obsessions of a man who crafts a woman into the woman he desires. Vertigo explores more frankly and at greater length his interest in the relation between sex and death than any other film in his filmography.
Hitchcock often said that his personal favourite was Shadow of a Doubt.
Hitchcock would storyboard each movie down to the finest detail. He was reported to have never even bothered looking through the viewfinder, since he didn't need to do so, though in publicity photos he was shown doing so. He also used this as an excuse to never have to change his films from his initial vision. If a studio asked him to change a film, he would claim that it was already shot in a single way, and that there were no alternate takes to consider.
However this view of Hitchcock as a director who relied more on pre-production than on the actual production itself has been challenged by the book Hitchcock At Work written by Bill Krohn, the American correspondent of Cahiers du Cinema. Krohn after investigating several script revisions, notes to other production personnel written by or to Hitchcock alongside inspection of storyboards and other production material has observed that Hitchcock's work often deviated from how the screenplay was written or how the film was originally envisioned. He noted that the myth of storyboards in relation to Hitchcock, often regurgitated by generations of commentators on Hitchcock's movies was to a great degree perpetuated by Hitchcock himself or the publicity arm of the studios. A great example would be the famous cropduster sequence of North by Northwest which wasn't storyboarded at all. After the scene was filmed, the publicity arm asked Hitchcock to make storyboards to promote the film and Hitchcock in turn hired an artist to match the scenes in detail. While Hitchcock did do a great deal of preparation for all his movies, he was fully cognizant that the actual film-making process often deviated from the best laid plans and was flexible to adapt to the changes and needs of production. Even on the occasions when storyboards were made, the scene which was shot did differ from it significantly.
Similarly much of Hitchcock's hatred of actors had been exaggerated. Hitchcock simply did not tolerate the method approach as he believed that actors should only concentrate on their performances and leave work on script and character to the directors and screenwriters. In a Sight and Sound interview, he stated that, ' the method actor is OK in the theatre because he has a free space to move about. But when it comes to cutting the face and what he sees and so forth, there must be some discipline'. During the making of Lifeboat, Walter Slezak, who played the German character, stated that Hitchcock knew the mechanics of acting better than anyone he knew. Several critics have observed that despite his reputation as a man who disliked actors, several actors who worked with him gave fine, often brilliant performances and these performances contribute to the film's success.
Regarding Hitchcock's sometimes less than pleasant relationship with actors, there was a persistent rumor that he had said that actors were cattle. Hitchcock later denied this, typically tongue-in-cheek, clarifying that he had only said that actors should be treated like cattle. Carole Lombard, tweaking Hitchcock and drumming up a little publicity, brought some cows along with her when she reported to the set of Mr. and Mrs. Smith. For Hitchcock, the actors, like the props, were part of the film's setting.
In the late 1950s the French New Wave critics, especially Éric Rohmer, Claude Chabrol, and François Truffaut, were among the first to see and promote his films as artistic works. Hitchcock was one of the first directors to whom they applied their auteur theory, which stresses the artistic authority of the director in the film-making process.
Hitchcock's innovations and vision have influenced a great number of filmmakers, producers, and actors. His influence helped start a trend for film directors to control artistic aspects of their movies without answering to the movie's producer.
Rebecca, which Hitchcock directed, won the 1940 Best Picture Oscar for its producer David O. Selznick. In addition to Rebecca and Suspicion, two other films Hitchcock directed, Foreign Correspondent and Spellbound, were nominated for Best Picture.
Hitchcock is considered the Best Film Director of all time by The Screen Directory.
Hitchcock was knighted in 1980.
Sixteen films directed by Hitchcock earned Oscar nominations, though only six of those films earned Hitchcock himself a nomination. The total number of Oscar nominations (including winners) earned by films he directed is fifty. Four of those films earned Best Picture nominations.
Along with Walt Disney, Hitchcock was one of the first prominent motion picture producers to fully envision just how popular the medium of television would become. From 1955 to 1965, Hitchcock was the host and producer of a long-running television series entitled Alfred Hitchcock Presents. While his films had made Hitchcock's name strongly associated with suspense, the TV series made Hitchcock a celebrity himself. His irony-tinged voice, image, and mannerisms became instantly recognizable and were often the subject of parody.
The title-theme of the show pictured a minimalist caricature of Hitchcock's profile (he drew it himself; it is composed of only nine lines) which his real silhouette then filled. His introductions before the stories in his program always included some sort of wry humor, such as the description of a recent multi-person execution hampered by having only one electric chair, while two are now shown with a sign "Two chairs--no waiting!" He directed a few episodes of the TV series himself, and he upset a number of movie production companies when he insisted on using his TV production crew to produce his motion picture Psycho. In the late 1980s, a new version of Alfred Hitchcock Presents was produced for television, making use of Hitchcock's original introductions in a colorised form.
"Hitch" used a curious little tune by the French composer Charles Gounod (1818-1893), the composer of the 1859 opera Faust, as the theme "song" for his television programs, after it was suggested to him by composer Bernard Herrmann. Arthur Fiedler and the Boston Pops Orchestra included the piece, Funeral March of a Marionette, in one of their extended play 45 rpm discs for RCA Victor during the 1950s.
Alfred Hitchcock appears as a character in the popular juvenile detective series, Alfred Hitchcock and the Three Investigators. The long-running detective series was created by Robert Arthur, who wrote the first several books, although other authors took over after he left the series. The Three Investigators -- Jupiter Jones, Bob Andrews and Peter Crenshaw -- were amateur detectives, slightly younger than the Hardy Boys. In the introduction to each book, "Alfred Hitchcock" introduces the mystery, and he sometimes refers a case to the boys to solve. At the end of each book, the boys report to Hitchcock, and sometimes give him a memento of their case.
When the real Alfred Hitchcock died, the fictional Hitchcock in the Three Investigators books was replaced by a retired detective named Hector Sebastian. At this time, the series title was changed from Alfred Hitchcock and the Three Investigators to The Three Investigators.
At the height of Hitchcock's success, he was also asked to introduce a set of books with his name attached. The series was a collection of short stories by popular short-story writers, primarily focused on suspense and thrillers. These titles included "Alfred Hitchcock's Anthology, Alfred Hitchcock Presents: Stories to be Read with the Door Locked, Alfred Hitchcock's Monster Museum, Alfred Hitchcock's Supernatural Tales of Terror and Suspense, Alfred Hitchcock's Spellbinders in Suspense, Alfred Hitchcock's Witch's Brew, Alfred Hitchcock's Ghostly Gallery, Alfred Hitchcock's A Hangman's Dozen and Alfred Hitchcock's Haunted Houseful. Hitchcock himself was not actually involved in the reading, reviewing, editing or selection of the short stories; in fact, even his introductions were ghost-written. The entire extent of his involvement with the project was to lend his name and collect a check.
Some notable writers whose works were used in the collection include Shirley Jackson (Strangers in Town, The Lottery), T.H. White (The Once and Future King), Robert Bloch, H. G. Wells (The War of the Worlds), Robert Louis Stevenson, Sir Arthur Conan Doyle, Mark Twain and the creator of The Three Investigators, Robert Arthur.
Hitchcock also wrote a mystery story for Look" magazine in 1943, "The Murder of Monty Woolley." This was a sequence of captioned photographs inviting the reader to inspect the pictures for clues to the murderer's identity; Hitchcock cast the performers as themselves: Woolley, Doris Merrick, and make-up man Guy Pearce, whom Hitchcock identified, in the last photo, as the murderer. The article was reprinted in Games Magazine in November/December 1980.
Hitchcock also had a serious fear of the police, which was the reason he said he never learned to drive. His reasoning was that if one never drove, then one would never have an opportunity to be pulled over by the police and issued a ticket. However, Patrick McGilligan wrote that "though Hitchcock pooh-poohed driving, insisting to interviewers that he didn't even know how, he often chauffeured his daughter to school at Marymount [a private academy for girls], and for a long time drove her to Sunday Mass." His fear of the police can be attributed to a circumstance encountered by Hitchcock in his youth, which he told a number of interviewers and mentioned in the PBS documentary The Men Who Made the Movies. In an attempt to punish Hitchcock for an instance of misbehavior, Alfred's father detailed in writing that the young Hitchcock had engaged in some form of childish mischief. Hitchcock's father then handed the description to Alfred, sending him to the local police station to demonstrate his wrongdoing. In response to the written notice, the on-duty police officer immediately brought Hitchcock to an empty cell and locked him there for a full 10 minutes, citing the justification for this action as a means to reprimand the young boy. Undoubtedly, history has recorded this incident as scarring. This perhaps influenced his signature theme in his movies where an innocent person would become entangled in the web of another guilty person's behaviour. This can be noted in many of his films, and a possible reason would be due to his hatred for authority, and his siding with the innocent. He also manages to convey this message to his audience in order to allow them to take his (the innocent) side.


Anacondas are four species of aquatic boa inhabiting the swamps and rivers of the dense forests of tropical South America. The Yellow Anaconda can be found as far south as northern Argentina.
There are two possible origins for the word 'anaconda.' It is perhaps an alteration of the Sinhalese word henakandaya, meaning 'whip snake' (literally, 'giant body'), or alternatively, the Tamil word anaikondran, which means 'elephant killer'. It is unclear how the name originated so far from the snake's native habitat; it is likely due to its vague similarity to the large Asian pythons. Local names for the anaconda in South America include the Spanish term matatoro, meaning 'bull killer', and the Native American terms sucuri and yakumama. Anacondas as members of the boa family are sometimes called water boas. The Latin name for Anaconda is Eunectes (from the Greek "Eυνήκτης", meaning "good swimmer").
There is some debate about the maximum size of anacondas, and there have been unverified claims of enormous snakes alleged to be as long as 30–45 m (98.4–147.6 ft).
a 1944 petroleum expedition in Colombia claimed to have measured an 11.43 m (37.5 ft) specimen, but this claim is not regarded as reliable; perhaps a more credible report came from scientist Vincent Roth, who claimed to have shot and killed a 10.3 m (33.8 ft) specimen. Anacondas can grow to about 23 feet long.
There are some reports from early explorers of the South American jungles seeing giant anacondas up to 18.2 m (60 ft) long, and some of the native peoples have reported seeing anacondas up to 15.2 m (50 ft) long, but these reports remain unverified.
Another claim of an extraordinarily large anaconda was made by adventurer Percy Fawcett. During his 1906 expedition, Fawcett wrote that he had shot an anaconda that measured some 18.9 m (62 ft) from nose to tail. Once published, Fawcett’s account was widely ridiculed. Decades later, Belgian zoologist Bernard Heuvelmans came to Fawcett's defence, arguing that Fawcett's writing was generally honest and reliable.
Historian Mike Dash writes of claims of still larger anacondas, alleged to be as long as 30–45 m (100–150 ft) — some of the sightings supported with photos (although those photos lack scale). Dash notes that if a 50–60 ft anaconda strains credulity, then a 150 ft long specimen is generally regarded as an outright impossibility.
It should be noted that the Wildlife Conservation Society has, since the early 20th century, offered a large cash reward (currently worth US$50,000) for live delivery of any snake of 30 feet or more in length. The prize has never been claimed. Also, in a study of 1,000 wild anacondas in Brazil, the largest captured was 17 ft long.
Recently an anaconda snake measuring over six meters and weighing nearly 150 kilos (330.8lbs) was captured in the backyard of an abandoned house in Parana, Brazil.
There have been very few instances of anacondas being bred in captivity. In October 2007, the New England Aquarium in Boston achieved a breakthrough when it was discovered that one of the aquarium's female anacondas was gravid. On January 1st, 2008, fourteen anaconda babies were born at the New England Aquarium. Anacondas, like other boas, give birth to live young.
Their colours are yellow and green.


Altaic is a proposed language family that includes 66 languages spoken by about 348 million people, mostly in and around Central Asia and northeast Asia.
The proponents of Altaic traditionally consider it to include the Turkic languages, the Mongolic languages, and the Tungusic languages (also called the Manchu-Tungus languages). Some also include Korean or Japonic, though this is controversial. A few linguists add Ainu.
Sometimes hypotheses that include only Turkic, Mongolic, and Tungusic are called "Micro-Altaic" and ones that include additional language families are called "Macro-Altaic".
The relationships among these languages are currently a matter of debate among historical linguists. Some scholars consider the apparent similarity among these languages to indicate a genetic relationship. Others propose that they are not a family derived from a common ancestor but a Sprachbund, a group of languages that have become similar in some ways by massive borrowing because of long language contact.
Altaic is itself part of the still more controversial Eurasiatic and Nostratic hypotheses.
The idea that the Turkic, Mongolic, and Tungusic languages are each others' closest relatives was allegedly first published by F.J. von Strahlenberg in 1730. However, as has been shown by A. Manaster Ramer and Paul Sidwell ("The truth about Strahlenberg's classification of the languages of Northeastern Eurasia", JSFOu 87, 1997, 139-160), Strahlenberg, who travelled in Russia as a prisoner of war after the Great Northern War, actually opposed the idea of a closer relationship between the languages which later became known as "Altaic".
The name "Altaic", as a designation of a large-scale language family which was initially also to comprise the Uralic languages, was coined in 1844 by M.A. Castrén.
As early as 1857, Anton Boller suggested adding Japanese. For Korean, G.J. Ramstedt and E.D. Polivanov put forward additional etymologies in the 1920s.
For much of the 19th and early 20th centuries, those few linguists who studied these language families regarded them as members of a common Ural-Altaic family, together with Finno-Ugric and Samoyedic, based on such shared features as vowel harmony and agglutination. While the Ural-Altaic hypothesis can still be found in encyclopedias, atlases, and similar general reference works, it has not had any adherents in the linguistics community for decades ("an idea now completely discarded" – Starostin et al. [2003:8]).
As a result of decades-long work, G.J. Ramstedt's book Einführung in die altaische Sprachwissenschaft, 'Introduction to Altaic Linguistics', was published in 1952 (two years after Ramstedt's death). It separated the Uralic languages (i.e. the Finno-Ugric and Samoyedic families) from the Altaic ones, added Korean and Japanese to the latter, and contained the first attempts to find regular correspondences in the sound systems and grammars of the Altaic language families.
Further contributions to Altaic studies, especially attempts to reconstruct the most recent common ancestor of the Altaic languages (the hypothetical Proto-Altaic language), were made in the 1950s and 1960s by linguists such as Nikolaus Poppe, K. Menges, Vera Cincius, Vladislav Illich-Svitych, S. Martin and Roy Andrew Miller. Most of these attempts did not include Korean or Japanese, judged to be too different from Turkic, Mongolic, and Tungusic.
There are two kinds of controversies about the Altaic family: the first is whether the family exists at all (or whether instead the similarities are borrowings), while the second is whether particular languages should be included. Notably, the inclusion of Japanese and Korean (especially as part of a proposed Buyeo family) is controversial and not generally accepted by Japanese linguists; see Altaic hypothesis of origin of Japanese.
Following Ramstedt's work and the subsequent developments in the 1950s, in the 1960s the pendulum swung in the other direction. G. Clauson, Gerhard Doerfer, and A. Shcherbak argued that the words and features shared by Turkic, Mongolic, and Tungusic were for the most part borrowings, and that the rest could be attributed to chance resemblances. They argued that while there were words shared by Turkic and Mongolic, by Mongolic and Tungusic, and by all three, there were none shared by Turkic and Tungusic but not Mongolic. If all three families had a common ancestor, we should expect losses to happen at random, not only at the geographical margins of the family; on the other hand, we should expect exactly the supposedly observed pattern if borrowing is responsible. Furthermore, they argued that many of the typological features of the supposedly Altaic languages, such as agglutinative morpology and SOV word order, usually occur together. In sum, the idea was that Turkic, Mongolic, and Tungusic form a Sprachbund – the result of convergence through intensive borrowing and long contact among speakers of languages that are not necessarily closely related. The proponents of this hypothesis are sometimes called "the Anti-Altaicists".
Doubt was also raised about the affinities of Korean and Japanese (defended by Roy Andrew Miller in 1971); in particular, some workers tried to connect Japanese to the Austronesian languages.
Starostin's (1991) lexicostatistical research showed that the Altaic groups shared about 15-20% of potential cognates within a 110-word Swadesh-Yakhontov list (e.g. Turkic-Mongolic 20%, Turkic-Tungusic 18%, Turkic-Korean 17%, Mongolic-Tungusic 22%, Mongolic-Korean 16%, Tungusic-Korean 21%). Some of these probable cognates may look doubtful, but many of them seem quite stable and can hardly be the result of mutual borrowing. Altogether, Starostin concluded that the Altaic grouping was substantiated, though "older than most other language families in Eurasia, such as Indo-European or Finno-Ugric, and this the reason why the modern Altaic languages preserve few commnon elements".
A further step in the debate was the publication of An Etymological Dictionary of the Altaic Languages by S. Starostin, A. Dybo, and O. Mudrak in 2003. The result of some twenty years of work, it contains 2800 proposed cognate sets, a complete set of regular sound correspondences, and a number of grammatical correspondences, as well as a few important changes to the reconstruction of Proto-Altaic; for example, while most of today's Altaic languages have vowel harmony, Proto-Altaic as reconstructed by Starostin et al. lacked it – instead various vowel assimilations between the first and second syllables of words occurred in Turkic, Mongolic, Tungusic, Korean, and Japonic. Importantly, it tries hard to distinguish loans between Turkic and Mongolic and between Mongolic and Tungusic from cognates, and it suggests words that occur in Turkic and Tungusic but not Mongolic (Starostin et al. 2003:20; all other combinations between the five branches also occur in the book).
Starostin's et aliorum "sincere […] hope that this publication will bring an end to this discussion" (Starostin et al. 2003:7) has not been fulfilled, however. The debate continues (e.g. Georg 2004, Vovin 2005, Starostin 2005, Georg 2005, Blažek 2006, A. Dybo and G. Starostin 2008).
It has been suggested that the Japonic languages could be Altaic but have an Austronesian or generally Austric substratum. This would (geographically) fit suggestions (e.g. Bengtson 2006) that Ainu is an Austric language.
Using the controversial phenetic method of multilateral comparison, Joseph Greenberg (2000) found a family consisting of Turkic, Mongolic, and Tungusic and a separate family consisting of Korean, Japanese, and Ainu.
Altaic languages in their diversity show a great depth, probably going back deep into the Mesolithic or even Upper Paleolithic period in Central Asia, following the disappearance of the Mansiyskoe lake (also called West Siberian lake), which occupied practically the whole territory of the western Siberian flatlands up to the foothills of the Kuznetsk Alatau and Altai. With the Late Glacial warming, up to the Atlantic Phase of the Post-Glacial Optimum, Mesolithic groups moved northwards into this area from the Hissar (6000-4000 BCE) and Keltiminar (5500-3500 BCE) cultures, which introduced the bow and arrow and the hunting dog, within what Kent Flannery has called the "broad-spectrum revolution". The Keltiminar culture practised a mobile hunting, gathering, fishing, and over time, an introduced stockbreeding seasonal-round subsistence system while inhabiting the semi-desert, desert, and deltaic areas of the Kara and Kyzyl Kum deserts, and the lower Amu Darya and Zeravshan rivers.
Some seek the origin of "Micro-Altaic" in the spread of the Karasuk culture, and the appearance of northern Mongol Dinlin elements. The Karasuk people lived in permanent settlements in frame-type houses. The economy was complex; they bred large-horned livestock, horses, and sheep. In the Karasuk period they developed a high level of bronze metallurgy. Characteristic of the Karasuk culture are extensive cemeteries. Tombs are fenced with stone slabs laid on crest. The Karasuk culture is a result of migration of the eastern part of the Dinlins, and had an influence as far as the Ordos region of China and across into Manchuria and northern Korea. The split between the Turkic and Mongolian languages, it is proposed, was the last division within the Proto-Altaic group, and it has been suggested that this occurred just prior to the Xiongnu period of Central Asian history.
Others, however, equate the Karasuk culture with the origin of the Karasuk languages, a recently proposed language family that includes the Yeniseian languages and Burushaski but not any possible members of Altaic. Associating languages with archeological discoveries in the absence of written evidence is never easy.
¹ This phoneme only occurred at the beginnings of words.
² These phonemes only occurred in the interior of words.
It is not clear whether /æ/, /ø/, /y/ were monophthongs as shown here (presumably [æ œ~ø ʏ~y]) or diphthongs ([i̯a~i̯ɑ i̯ɔ~i̯o i̯ʊ~i̯u]); the evidence is equivocal. In any case, however, they only occurred in the first (and sometimes only) syllable of any word.
Every vowel occurred in long and short versions which were different phonemes in the first syllable. Starostin et al. (2003) treat length together with pitch as a prosodic feature.
As reconstructed by Starostin et al. (2003), Proto-Altaic was a pitch accent or tone language; at least the first, and probably every, syllable could have high or low pitch.
If a Proto(-Macro)-Altaic language really existed, it should be possible to reconstruct regular sound correspondences between that protolanguage and its descendants; such correspondences would make it possible to distinguish cognates from loanwords (in many cases). Such attempts have repeatedly been made. The latest and (so far) most successful version is reproduced here, taken from Blažek's (2006) summary of the newest Altaic etymological dictionary (Starostin et al. 2003) and transcribed into the IPA.
When a Proto-Altaic phoneme developed differently depending on its position in a word (beginning, interior, or end), the special case (or all cases) is marked with a hyphen; for example, Proto-Altaic /pʰ/ disappears (marked "0") or becomes /j/ at the beginning of a Turkic word and becomes /p/ elsewhere in a Turkic word.
Only single consonants are considered here. In the middle of words, clusters of two consonants were allowed in Proto-Altaic as reconstructed by Starostin et al. (2003); the correspondence table of these clusters spans almost 7 pages in their book (83–89), and most clusters are only found in one or a few of the reconstructed roots.
/V/ symbolizes an uncertain vowel. Suffixes reconstructed for Proto-Turkic, Proto-Mongolic, Proto-Korean, or Proto-Japonic, but not attested in Old Turkic, Classical Mongolian, Middle Korean, or Old Japanese are marked with asterisks.
Personal pronouns are seldom borrowed between languages. Therefore the many correspondences between Altaic pronouns found by Starostin et al. (2003) could be rather strong evidence for the existence of Proto-Altaic. The table below is taken (with slight modifications) from Blažek (2006) and transcribed into IPA.
As above, forms not attested in Classical Mongolian or Middle Korean but reconstructed for their ancestors are marked with an asterisk, and /V/ represents an uncertain vowel.
The following table is a brief selection of further proposed cognates in basic vocabulary across the Altaic family (from Starostin et al. [2003]).


Austrian German (Österreichisches Deutsch) is the national standard variety of the German language spoken in Austria and South Tyrol.
As German is a Pluricentric language, Austrian German is another standard variety in addition to the German spoken in Germany. Much like the relationship between American and British English, Austrian German is simply another standard form of the German language. It is codified in the "Österreichisches Wörterbuch" which states specific grammar rules and is a dictionary using Austrian spelling. In addition to this standard variety, in everyday life, most Austrians speak one of a number of High German dialects.
While strong forms of the various dialects are not normally fully comprehensible to Northern Germans, there is virtually no communication barrier to speakers from Bavaria. The Central Austro-Bavarian dialects are more intelligible to speakers of Standard German than the Southern Austro-Bavarian dialects of Tyrol. Viennese, the Austro-Bavarian dialect of Vienna, is most frequently used in Germany for impersonations of the typical inhabitant of Austria. The people of Graz, the capital of Styria, speak yet another dialect which is not very Styrian and more easily understood by people from other parts of Austria than other Styrian dialects, for example from western Styria.
Simple words in the various dialects are very similar, but pronunciation is distinct for each and, after listening to a few spoken words it may be possible for an Austrian to realise which dialect is being spoken. However, in regard to the dialects of the deeper valleys of the Tyrol, other Tyroleans are often unable to understand them. Speakers from the different states of Austria can easily be distinguished from each other by their particular accents (probably more so than Bavarians), those of Carinthia, Styria, Vienna, Upper Austria, and the Tyrol being very characteristic. Speakers from those regions, even those speaking Standard German, can usually be easily identified by their accent, even by an untrained listener.
Several of the dialects have been influenced by contact with non-Germanic linguistic groups, such as the dialect of Carinthia, where in the past many speakers were bilingual with Slovenian, and the dialect of Vienna, which has been influenced by immigration during the Austro-Hungarian period, particularly from what is today the Czech Republic. The dialects of South Tyrol have been influenced by Italian, in particular with many loan words.
Interestingly, the geographic borderlines between the different accents (isoglosses) coincide strongly with the borders of the states and also with the border with Bavaria, with Bavarians having a markedly different rhythm of speech in spite of the similarities in the language.
In Austria, as in the German speaking parts of Switzerland and in southern Germany, verbs that express a state tend to use sein as the auxiliary verb in the perfect tense, as well as verbs of movement. Verbs which fall into this category include sitzen (to sit), liegen (to lie) and, in parts of Carinthia, schlafen (to sleep). Therefore the perfect tense of these verbs would be ich bin gesessen, ich bin gelegen and ich bin geschlafen respectively. For some verbs which fall into this category, the use of sein as the auxiliary in the perfect can change to haben to avoid confusion between two verbs that would otherwise look the same in this tense, as in the case of stehen (to stand) and gestehen (to confess). In the perfect these would be ich bin gestanden and ich habe gestanden respectively.
There are many official Austrian terms which differ from standard German. These include Jänner (January) rather than Januar, heuer (this year) rather than dieses Jahr and a whole series of foods and vegetables such as: Erdäpfel (potatoes) German Kartoffeln, Faschiertes (ground beef) German Hackfleisch, Fisolen (green beans) German Gartenbohne, Karfiol (cauliflower) German Blumenkohl, Karotte (carrot) German Möhre, Kohlsprossen (Brussels sprouts) German Rosenkohl, Marillen (apricots) German Aprikosen, Paradeiser (tomatoes) German Tomaten, Palatschinken (pancakes) German Pfannkuchen, Topfen (a semi-sweet cottage cheese) German Quark and Kren (horseradish) German Meerretich.
Austrians, in particular, will say "Grüß Gott!" (God greet (subj.) [you]!) when greeting someone, rather than the "Guten Tag!" used by Germans. Beside the official Austrian German, occasionally also Austrian dialects from various regions are seen in written form, containing a large number of contractions and abbreviations compared to standard German, which can be hard to understand for non-native speakers (although the same applies to German dialects in Germany and Switzerland).
With German being a pluricentric language, Austrian dialects should not be confused with the variety of Standard German spoken by most Austrians, which is distinct from that of Germany or Switzerland. Distinctions in vocabulary persist, for example, in culinary terms, where communication with Germans is frequently difficult, and administrative and legal language, which is due to Austria's exclusion from the development of a German nation-state in the late 19th century and its manifold particular traditions. A comprehensive collection of Austrian-German legal, administrative and economic terms is offered in: Markhardt, Heidemarie: Wörterbuch der österreichischen Rechts-, Wirtschafts- und Verwaltungsterminologie (Peter Lang, 2006).
When Austria became a member of the European Union, the Austrian variety of the German language (limited to 23 agricultural terms) was "protected" in the so-called Protocol no. 10 (1) regarding the use of specific Austrian terms of the German language in the framework of the European Union, which forms part of the Austrian EU accession treaty. Austrian German is the only variety of a pluricentric language recognised under international law / EU primary law. All facts concerning "Protocol no. 10" are documented in Markhardt, Heidemarie: Das österreichische Deutsch im Rahmen der EU, Peter Lang, 2005.


In mathematics, the axiom of choice, or AC, is an axiom of set theory. Intuitively speaking, the axiom of choice says that given any collection of bins, each containing at least one object, exactly one object can be selected from each bin, even if there are infinitely many bins and there is no "rule" for which object to pick from each. The axiom of choice is not required if the number of bins is finite or if such a selection "rule" is available.
It was formulated in 1904 by Ernst Zermelo. While it was originally controversial, it is now used without reservation by most mathematicians. However, there are schools of mathematical thought, primarily within set theory, that either reject the axiom of choice or investigate consequences of axioms inconsistent with AC.
Until the late 19th century, the axiom of choice was often used implicitly, although it had not yet been formally stated. For example, after having established that the set X contains only non-empty sets, a mathematician might have said "let F(s) be one of the members of s for all s in X." In general, it is impossible to prove that F exists without the axiom of choice, but this seems to have gone unnoticed until Zermelo.
For certain infinite sets X, it is also possible to avoid the axiom of choice. For example, suppose that the elements of X are sets of natural numbers. Every nonempty set of natural numbers has a smallest element, so to specify our choice function we can simply say that it maps each set to the least element of that set. This gives us a definite choice of an element from each set and we can write down an explicit expression that tells us what value our choice function takes. Any time it is possible to specify such an explicit choice, the axiom of choice is unnecessary.
The difficulty appears when there is no natural choice of elements from each set. If we cannot make explicit choices, how do we know that our set exists? For example, suppose that X is the set of all non-empty subsets of the real numbers. First we might try to proceed as if X were finite. If we try to choose an element from each set, then, because X is infinite, our choice procedure will never come to an end, and consequently, we will never be able to produce a choice function for all of X. So that won't work. Next we might try the trick of specifying the least element from each set. But some subsets of the real numbers don't have least elements. For example, the open interval (0,1) does not have a least element: If x is in (0,1), then so is x/2, and x/2 is always strictly smaller than x. So taking least elements doesn't work, either.
The reason that we are able to choose least elements from subsets of the natural numbers is the fact that the natural numbers come pre-equipped with a well-ordering: Every subset of the natural numbers has a unique least element under the natural ordering. Perhaps if we were clever we might say, "Even though the usual ordering of the real numbers does not work, it may be possible to find a different ordering of the real numbers which is a well-ordering. Then our choice function can choose the least element of every set under our unusual ordering." The problem then becomes that of constructing a well-ordering, which turns out to require the axiom of choice for its existence; every set can be well-ordered if and only if the axiom of choice is true.
A proof requiring the axiom of choice is necessarily nonconstructive: even if the proof establishes the existence of an object, it will still be impossible to specify exactly what that object is. For example, while the axiom of choice asserts that there is a well-ordering of the real numbers, it does not give us an example of one. As another example, a subset of the real numbers that is Lebesgue-unmeasurable can be proven to exist using the axiom of choice, but cannot be constructed. Some mathematicians dislike the axiom of choice because it produces intangibles. For example, constructivists posit that all existence proofs should be totally explicit; it should be possible to construct anything that is proven to exist. They reject the axiom of choice because it asserts the existence of an object without telling what it is. On the other hand, the mere fact that one has used the axiom of choice to prove the existence of a set does not mean that it cannot be constructed by another method.
Another reason that some mathematicians dislike the axiom of choice is that it implies the existence of some bizarre counterintuitive objects. An example of this is the Banach–Tarski paradox which says in effect that it is possible to "carve up" the 3-dimensional solid unit ball into finitely many pieces and, using only rotation and translation, reassemble the pieces into two balls each with the same volume as the original. Note that the proof, like all proofs involving the axiom of choice, is an existence proof only: it does not tell us how to carve up the unit sphere to make this happen, it simply tells us that it can be done.
On the other hand, the negation of the axiom of choice is also counterintuitive to some mathematicians. For example, the statement "For any two sets S and T, the cardinality of S is less than or equal to the cardinality of T or the cardinality of T is less than or equal to the cardinality of S" is equivalent to the axiom of choice. Put differently, if the axiom of choice is false, then there are sets S and T of incomparable size: neither can be mapped in a one-to-one fashion onto a subset of the other.
A third possibility is to prove theorems using neither the axiom of choice nor its negation, a tactic preferred in constructive mathematics. Such statements will be true in any model of Zermelo–Fraenkel set theory, regardless of the truth or falsity of the axiom of choice in that particular model. This renders any claim that relies on either the axiom of choice or its negation undecidable. For example, under such an assumption, the Banach–Tarski paradox is neither true nor false: It is impossible to construct a decomposition of the unit ball which can be reassembled into two unit balls, and it is also impossible to prove that it can't be done. However, the Banach–Tarski paradox can be rephrased as a statement about models of ZF by saying, "In any model of ZF in which AC is true, the Banach–Tarski paradox is true." Similarly, all the statements listed below which require choice or some weaker version thereof for their proof are undecidable in ZF, but since each is provable in any model of ZFC, there are models of ZF in which each statement is true.
There are several weaker statements which are not equivalent to the axiom of choice, but which are closely related. A simple one is the axiom of countable choice (ACω or CC), which states that a choice function exists for any countable set X. This usually suffices when trying to make statements about the real numbers, for example, because the rational numbers, which are countable, form a dense subset of the reals. This axiom has the advantage of being consistent with the axiom that every subset of the real numbers is Lebesgue-measurable.
See also the Boolean prime ideal theorem, the axiom of dependent choice (DC), and the axiom of uniformization.
By work of Kurt Gödel and Paul Cohen, the axiom of choice is logically independent of the other axioms of Zermelo–Fraenkel set theory (ZF). This means that neither it nor its negation can be proven to be true in ZF, if ZF is consistent. Consequently, if ZF is consistent, then ZFC is consistent and ZF¬C is also consistent. So the decision whether or not it is appropriate to make use of the axiom of choice in a proof cannot be made by appeal to other axioms of set theory. The decision must be made on other grounds.
One argument given in favor of using the axiom of choice is that it is convenient to use it: using it cannot hurt (cannot result in contradiction) and makes it possible to prove some propositions that otherwise could not be proved. Many theorems which are provable using choice are an elegant general character: every ideal in a ring is contained in a maximal ideal, every vector space has a basis, and every product of compact spaces is compact. Without the axiom of choice, these theorems may not hold for mathematical objects of large cardinality.
The proof of the independence result also shows that a wide class of mathematical statements, including all statements that can be phrased in the language of Peano arithmetic, are provable in ZF if and only if they are provable in ZFC. Statements in this class include the statement that P = NP, the Riemann hypothesis, and many other unsolved mathematical problems. When one attempts to solve problems in this class, it makes no difference whether ZF or ZFC is employed if the only question is the existence of a proof. It is possible, however, that there is a shorter proof of a theorem from ZFC than from ZF.
The axiom of choice is not the only significant statement which is independent of ZF. For example, the generalized continuum hypothesis (GCH) is not only independent of ZF, but also independent of ZF plus the axiom of choice (ZFC). However, ZF plus GCH implies AC, making GCH a strictly stronger claim than AC, even though they are both independent of ZF.
The axiom of constructibility and the generalized continuum hypothesis both imply the axiom of choice, but are strictly stronger than it.
In class theories such as Von Neumann–Bernays–Gödel set theory and Morse–Kelley set theory, there is a possible axiom called the axiom of global choice which is stronger than the axiom of choice for sets because it also applies to proper classes. And the axiom of global choice follows from the axiom of limitation of size.
There are a remarkable number of important statements that, assuming the axioms of ZF but neither AC nor ¬AC, are equivalent to the axiom of choice. The most important among them are Zorn's lemma and the well-ordering theorem. In fact, Zermelo initially introduced the axiom of choice in order to formalize his proof of the well-ordering principle.
There are several results in category theory which invoke the axiom of choice for their proof. These results might be weaker than, equivalent to, or stronger than the axiom of choice, depending on the strength of the technical foundations. For example, if one defines categories in terms of sets, that is, as sets of objects and morphisms (usually called a small category), or even locally small categories, whose hom-objects are sets, then there is no category of all sets, and so it is difficult for a category-theoretic formulation to apply to all sets. On the other hand, other foundational descriptions of category theory are considerably stronger, and an identical category-theoretic statement of choice may be stronger than the standard formulation, à la class theory, mentioned above.
One of the most interesting aspects of the axiom of choice is the large number of places in mathematics that it shows up. Here are some statements that require the axiom of choice in the sense that they are not provable from ZF but are provable from ZFC (ZF plus AC). Equivalently, these statements are true in all models of ZFC but false in some models of ZF.
Now, consider stronger forms of the negation of AC. For example, if we abbreviate by BP the claim that every set of real numbers has the property of Baire, then BP is stronger than ¬AC, which asserts the nonexistence of any choice function on perhaps only a single set of nonempty sets. Note that strengthened negations may be compatible with weakened forms of AC. For example, ZF + DC + BP is consistent, if ZF is.
It is also consistent with ZF + DC that every set of reals is Lebesgue measurable; however, this consistency result, due to Robert M. Solovay, cannot be proved in ZFC itself, but requires a mild large cardinal assumption (the existence of an inaccessible cardinal). The much stronger axiom of determinacy, or AD, implies that every set of reals is Lebesgue measurable, has the property of Baire, and has the perfect set property (all three of these results are refuted by AC itself). ZF + DC + AD is consistent provided that a sufficiently strong large cardinal axiom is consistent (the existence of infinitely many Woodin cardinals).
There are models of Zermelo-Fraenkel set theory in which the axiom of choice is false. We will abbreviate "Zermelo-Fraenkel set theory plus the negation of the axiom of choice" by ZF¬C. For certain models of ZF¬C, it is possible to prove the negation of some standard facts.
Note that any model of ZF¬C is also a model of ZF, so for each of the following statements, there exists a model of ZF in which that statement is true.
For proofs, see Thomas Jech, The Axiom of Choice, American Elsevier Pub. Co. New York, 1973.
and similarly for. However, without the law of the excluded middle, these equivalences can't be proven; in fact the two sets aren't even provably finite (in the usual sense of being in bijection with a natural number, though they would be in the Dedekind sense).
which implies.
so.
Thus.
As this could be done for any proposition, this completes the proof that the axiom of choice implies the law of the excluded middle. Forms of the axiom of separation are available in many constructive set theories. In the intuitionistic type theory of Per Martin-Löf, on the other hand, subsets of a type have different treatments. A form of the axiom of choice is a theorem, yet excluded middle is not.


Attila (406 – 453), also known as Attila the Hun or the Scourge of God or "King Attila the Hun", was Khan of the Huns from 434 until his death. He was leader of the Hunnic Empire which stretched from Germany to the Ural River and from the River Danube to the Baltic Sea (see map below). During his rule he was one of the most fearsome of the Western and Eastern Roman Empires' enemies: he invaded the Balkans twice, he marched through Gaul (modern day France) as far as Orleans before being defeated at the Battle of Chalons; and he drove the Western emperor Valentinian III from his capital at Ravenna in 452. He reached Constantinople and Rome but refrained from attacking either city.
In much of Western Europe, he is remembered as the epitome of cruelty and rapacity. In contrast, some histories and Chronicles lionize him as a great and noble king, and he plays major roles in three Norse sagas.
The origin of the Huns has been the subject of debate for centuries; however it can be said with general agreement that they were a confederation of Central Asian and European tribes, many of them horse nomads. Many experts think they were Turkic people, descended from the warlike Xiongnu tribes that menaced China as early as the 5th century BC. The first emperor of China, Qin Shi Huangdi, built part of the Great Wall to keep the Xiongnu out.
Their united power appeared or began to form in Europe in 5th century. They achieved military superiority over their neighbours by their readiness for battle, unusual mobility, and weapons including the composite bow.
The death of Rugila (also known as Rua or Ruga) in 434 left his nephews Attila and Bleda (the sons of his brother Mundzuk) in control over all the united Hun tribes. At the time of their accession, the Huns were bargaining with Byzantine emperor Theodosius II's envoys over the return of several renegades (possibly Hunnic nobles not in agreement with the brothers' leadership) who had taken refuge within the Byzantine Empire. The following year Attila and Bleda met with the imperial legation at Margus (present-day Požarevac) and, all seated on horseback in the Hunnic manner, negotiated a successful treaty: the Romans agreed not only to return the fugitives, but also to double their previous tribute of 350 Roman pounds (ca. 114.5 kg) of gold, open their markets to Hunnish traders, and pay a ransom of eight solidi for each Roman taken prisoner by the Huns. The Huns, satisfied with the treaty, decamped from the empire and returned to their home in the Hungarian Great Plain, perhaps to consolidate and strengthen their empire. Theodosius used this opportunity to strengthen the walls of Constantinople, building the city's first sea wall, and to build up his border defences along the Danube.
Huns remained out of Roman sight for the next few years as a Hunnic force invaded the Persian Empire. A defeat in Armenia by the Sassanid Persians caused them to abandon this attempt and return their attentions to Europe. In 440 they reappeared in force on the borders of the Roman Empire, attacking the merchants at the market on the north bank of the Danube that had been established by the treaty. Crossing the Danube they laid waste to Illyrian cities and forts on the river, among them, according to Priscus, Viminacium, which was a city of the Moesians in Illyria. Their advance began at Margus, for when the Romans discussed handing over the offending bishop, he slipped away secretly to the Huns and betrayed the city to them.
As Theodosius had conquered the river's defences, the Vandals, under the leadership of Geiseric, captured the Western Roman province of Africa with its capital of Carthage in 440 and the Sassanid Yazdegerd II invaded Armenia in 441. Stripping the Balkan defenses of forces requested by the West Romans, in order to launch an attack on the Vandals in Africa (which was the richest province of the Western empire and a main source of the food supply of Rome, left Attila and Bleda a clear path through Illyria into the Balkans, which they invaded in 441. The Hunnish army, having sacked Margus and Viminacium, took Singidunum (modern Belgrade) and Sirmium before halting. A lull followed in 442 and during this time Theodosius recalled his troops from Sicily and ordered a large new issue of coins to finance operations against the Huns. Having made these preparations, he thought it safe to refuse the Hunnish kings' demands.
Attila responded by their campaign in 443. Striking along the Danube, they overran the military centres of Ratiara and successfully besieged Naissus (modern Niš) with battering rams and rolling towers — military sophistication that was new to the Hun repertoire — then pushing along the Nisava they took Serdica (Sofia), Philippopolis (Plovdiv), and Arcadiopolis. They encountered and destroyed the Roman army outside Constantinople and were stopped by the double walls of the Eastern capital. A second army was defeated near Callipolis (modern Gallipoli) and Theodosius, now without any armed forces to respond, admitting defeat, sent the court official Anatolius to negotiate peace terms, which were harsher than the previous treaty: the Emperor agreed to hand over 6,000 Roman pounds (ca. 1,963 kg) of gold as punishment for having disobeyed the terms of the treaty during the invasion; the yearly tribute was tripled, rising to 2,100 Roman pounds (ca. 687 kg) in gold; and the ransom for each Roman prisoner rose to 12 solidi.
Their demands met for a time, the Hun kings withdrew into the interior of their empire. According to Jordanes (following Priscus), sometime during the peace following the Huns' withdrawal from Byzantium (probably around 445), Bleda died (killed by his brother, according to the classical sources), and Attila took the throne for himself.
In 450 Attila had proclaimed his intent to attack the powerful Visigoth kingdom of Toulouse, making an alliance with Emperor Valentinian III in order to do so. He had previously been on good terms with the Western Roman Empire and its de facto ruler Flavius Aëtius. Aetius had spent a brief exile among the Huns in 433, and the troops Attila provided against the Goths and Bagaudae had helped earn him the largely honorary title of magister militum in the west. The gifts and diplomatic efforts of Geiseric, who opposed and feared the Visigoths, may also have influenced Attila's plans.
However Valentinian's sister Honoria, in order to escape her forced betrothal to a Roman senator, had sent the Hunnish king a plea for help—and her engagement ring—in the spring of 450. Though Honoria may not have intended a proposal of marriage, Attila chose to interpret her message as such. He accepted, asking for half of the western Empire as dowry. When Valentinian discovered the plan, only the influence of his mother Galla Placidia convinced him to exile, rather than kill, Honoria. He also wrote to Attila strenuously denying the legitimacy of the supposed marriage proposal. Attila, not convinced, sent an emissary to Ravenna to proclaim that Honoria was innocent, that the proposal had been legitimate, and that he would come to claim what was rightfully his.
Meanwhile Chlodio the king of the Salian Franks had died, in battle against Aetius in 448 AD, and the succession struggle between his two sons drove a rift between Attila and Aetius; Attila supported the elder son, while Aetius supported the younger. Attila gathered his vassals—Gepids, Ostrogoths, Rugians, Scirians, Heruls, Thuringians, Alans, Burgundians, among others—and began his march west. In 451 he arrived in Belgica with an army exaggerated by Jordanes to half a million strong. J.B. Bury believes that Attila's intent, by the time he marched west, was to extend his kingdom—already the strongest on the continent—across Gaul to the Atlantic Ocean.
Gibbon states the majority view also quite eloquently: "(Attila's) retreat across the River Rhine confessed the last victory which was achieved in the name of the Western Roman Empire." The Visigothic-Roman alliance quickly dissolved.
Attila returned in 452 to claim his marriage to Honoria anew, invading and ravaging Italy along the way. The city of Venice was founded as a result of these attacks when the residents fled to small islands in the Venetian Lagoon. His army sacked numerous cities and razed Aquileia completely, leaving no trace of it behind. Legend has it he built a castle on top of a hill north of Aquileia to watch the city burn, thus founding the town of Udine, where the castle can still be found. Valentinian fled from Ravenna to Rome; Aetius remained in the field but lacked the strength to offer battle. Gibbon however says Aetius never showed his greatness more clearly than in managing to harass and slow Attila's advance with only a shadow force. Attila finally halted at the River Po. By this point disease may have broken out in Attila's camp, thus helping to stop his invasion.
At the wish of Emperor Valentinian III, Pope Leo I, accompanied by the Consul Avienus and the Prefect Trigetius, met Attila at Mincio in the vicinity of Mantua, and obtained from him the promise that he would withdraw from Italy and negotiate peace with the emperor. Prosper of Aquitaine gives a short reliable description of the historic meeting. The later anonymous account, a pious "fable which has been represented by the pencil of Raphael and the chisel of Algardi" (as Gibbon called it) says that the Pope, aided by Saint Peter and Saint Paul, convinced him to turn away from the city, promising Attila that in case he leaves in peace, one of his successor will receive a Holy Crown. Priscus reports that superstitious fear of the fate of Alaric—who died shortly after sacking Rome in 410—gave him pause.
After Attila left Italy and returned to his palace across the Danube, he planned to strike at Constantinople again and reclaim the tribute which Marcian had cut off. (Marcian was the successor of Theodosius and had ceased paying tribute in late 450 while Attila was occupied in the west; multiple invasions by the Huns and others had left the Balkans with little to plunder.) However Attila died in the early months of 453. The conventional account, from Priscus, says that at a feast celebrating his latest marriage to the beautiful and young Ildico (if uncorrupted, the name suggests a Gothic origin) he suffered a severe nosebleed and choked to death in a stupor. An alternative theory is that he succumbed to internal bleeding after heavy drinking.
Another story of his death, first recorded 80 years after the fact by the Roman chronicler Count Marcellinus, reports that "Attila, King of the Huns and ravager of the provinces of Europe, was pierced by the hand and blade of his wife." The Volsunga saga and the Poetic Edda also claim that King Atli (Attila) died at the hands of his wife, Gudrun. Most scholars reject these accounts as no more than romantic fables, preferring instead the version given by Attila's contemporary Priscus. The "official" account by Priscus, however, has recently come under renewed scrutiny by Michael A. Babcock. Based on detailed philological analysis, Babcock concludes that the account of natural death, given by Priscus, was an ecclesiastical "cover story" and that Emperor Marcian (who ruled the Eastern Roman Empire from 450-457) was the political force behind Attila's death.
Jordanes says, "the greatest of all warriors should be mourned with no feminine lamentations and with no tears, but with the blood of men." His horsemen galloped in circles around the silken tent where Attila lay in state, singing in his dirge, according to Cassiodorus and Jordanes, "Who can rate this as death, when none believes it calls for vengeance?" then celebrated a strava (lamentation) over his burial place with great feasting. Legend says that he was laid to rest in a triple coffin made of gold, silver, and iron, along with some of the spoils of his conquests. His men diverted a section of the Tisza, buried the coffin under the riverbed, and then were killed to keep the exact location a secret.
His sons Ellac (his appointed successor), Dengizich, and Ernakh fought over the division of his legacy, specifically which vassal kings would belong to which brother. As a consequence they were divided, defeated and scattered the following year in the Battle of Nedao by the Ostrogoths and the Gepids under Ardaric. According to Jordanes, Ardaric, who was once Attila's most prized chieftain, turned against the feuding brothers when he felt that they were treating the nations they ruled as slaves.
Attila's many children and relatives are known by name and some even by deeds, but soon valid genealogical sources all but dry up and there seems to be no verifiable way to trace Attila's descendants. This hasn't stopped many genealogists from attempting to reconstruct a valid line of descent for various medieval rulers. One of the most credible claims has been that of the tsars of Bulgaria (see Nominalia of the Bulgarian khans). A popular, but ultimately unconfirmed attempt tries to relate Attila to Charlemagne (see Attila the Hun to Charlemagne).
Attila is known in Western history and tradition as the grim FLAGELLUM DEI (Latin:"Scourge of God"), and his name has become a byword for cruelty and barbarism. Some of this may have arisen from confusion between him and later steppe warlords such as Genghis Khan and Tamerlane. All are considered to be cruel, clever, and blood-thirsty lovers of battle and pillage. The reality of his character is probably more complex. The Huns of Attila's era had been mingling with Roman civilisation for some time, largely through the Germanic foederati of the border, so that by the time of Theodosius's embassy in 448 Priscus could identify two primary languages among the Huns, Gothic and Hunnic, with some people knowing Latin and Greek. Priscus also recounts his meeting with an eastern Roman captive who had so fully assimilated into the Huns' way of life that he had no desire to return to his former country, and the Byzantine historian's description of Attila's humility and simplicity is unambiguous in its admiration.
The origin of Attila's name is not known with confidence, because very little is known about Hunnic names. In the Hunnic language Danube-Bulgarian, the etymology "oceanic (universal) [ruler]" has been proposed. Others believe that the name may be Gothic (or Gepid), from the word atta ("father") and the diminutive suffix -ila. Attila was not a rare name in Central Europe prior to Attila making his mark on history; the historical record shows numerous persons with the name preceding him. 'Attila' has many variants: Atli and Atle in Norse, Ætla, Attle and Atlee in English, Attila/Atilla/Etele in Hungarian (all the three name variants are used in Hungary; Attila is the most popular variant), Etzel in modern German or Attila, Atila or Atilla in modern Turkish. Also the word possibly originates from Turkic Atyl/Atal/Atil (ancient name of Volga river) with adjective suffix -ly. (Compare also Turkic medieval notable title atalyk - "senior as father").
Attila has been portrayed in various ways, sometimes as a noble ruler, sometimes as a cruel barbarian.


The Aegean Sea, Aigaío Pélagos;, Adalar Denizi) is a sea arm of the Mediterranean Sea located between the southern Balkan and Anatolian peninsulas, i.e. between the mainlands of Greece and Turkey respectively. In the north, it is connected to the Marmara Sea and Black Sea by the Dardanelles and Bosporus. The Aegean Islands are within the sea and some bound it on its southern periphery, including Crete and Rhodes. The Aegean Region, Turkey, consists of nine provinces in southwestern Turkey, in part bordering on the Aegean sea.
The sea was traditionally known as the Archipelago (Greek: Αρχιπέλαγος), the general sense of which has since changed to refer to the Aegean Islands and, generally, to any island group because the Aegean Sea is remarkable for its large number of islands.
In ancient times there were various explanations for the name Aegean. It was said to have been named after the Greek town of Aegae, or Aegea, a queen of the Amazons who died in the sea, or Aigaion, the "sea goat", another name of Briareus, one of the archaic Hecatonchires, or, especially among the Athenians, Aegeus, the father of Theseus, who drowned himself in the sea when he thought his son had died.
A possible etymology is a derivation from the Greek word (aiges) "waves" (Hesychius; metaphorical use of (aix) "goat"), hence "wavy sea", cf. also (aigialos) "coast".
In the Bulgarian language the sea is also known as White sea (Бяло море). According to legend, Bulgarian sailors and merchants in the Middle Ages found it a hospitable and timid sea to travel and called it White sea in contrast to the hostile and dangerous Black sea.
Aegean civilization is a general term for the Bronze Age civilizations of Greece and the Aegean; in ancient times the sea was the birthplace of two ancient civilizations – the Minoans of Crete, and the Mycenean Civilization of the Peloponnese. Later arose the city-states of Athens and Sparta among many others that constituted the Athenian Empire and Hellenic Civilization. Plato described the Greeks living round the Aegean "like frogs around a pond". The Aegean Sea was later invaded by Persians and the Romans, and inhabited by the Byzantine Empire, the Venetians, the Seljuk Turks, and the Ottoman Empire. The Aegean was the site of the original democracies, and its seaways were the means of contact among several diverse civilizations of the Eastern Mediterranean.
The Aegean Sea covers about 214,000 km² in area, and measures about 610 kilometres longitudinally and 300 kilometres latitudinally. The sea's maximum depth is 3,543 metres (11,624 ft), east of Crete. The Aegean Islands are found within its waters, with the following islands delimiting the sea on the south (generally from west to east): Kythera, Antikythera, Crete, Karpathos, and Rhodes.
The Greek Aegean Islands can be simply divided into seven groups: the Northeastern Aegean Islands, Euboea, the Northern Sporades, the Cyclades, the Saronic Islands (or Argo-Saronic Islands), the Dodecanese (or Southern Sporades), and Crete. The word archipelago was originally applied specifically to the Aegean Sea and its islands. Many of the Aegean Islands, or chains of islands, are actually extensions of the mountains on the mainland. One chain extends across the sea to Chios, another extends across Euboea to Samos, and a third extends across the Peloponnese and Crete to Rhodes, dividing the Aegean from the Mediterranean. Many of the islands have safe harbours and bays, but navigation through the sea is generally difficult. Many of the islands are volcanic, and marble and iron are mined on other islands. The larger islands have some fertile valleys and plains. In the Aegean Sea there are two islands belonging to Turkey: Bozcaada (Greek: Τένεδος Tenedos) and Gökçeada (Greek: Ίμβρος Imvros), while the rest belonging to Greece. The Aegean Sea has about 1,415 islands and islets, of which 1,395 belong to Greece.
The bays and gulfs of the Aegean beginning and the South and moving clockwise include on Crete, the Mirabelli, Almyros, Souda and Chania bays or gulfs, on the mainland the Myrtoan Sea to the west, the Saronic Gulf northwestward, the Petalies Gulf which connects with the South Euboic Sea, the Pagasetic Gulf which connects with the North Euboic Sea, the Thermian Gulf northwestward, the Chalkidiki Peninsula including the Cassandra and the Singitic Gulfs, northward the Strymonian Gulf and the Gulf of Kavala and the rest are in Turkey; Saros Gulf, Edremit Gulf, Dikili Gulf, Çandarlı Gulf, İzmir Gulf, Kuşadası Gulf, Gulf of Gökova, Güllük Gulf.


A Clockwork Orange is a speculative fiction novel by Anthony Burgess, published in 1962, and was later the basis for a 1971 film adaptation of the same name by Stanley Kubrick.
The novel was chosen by TIME Magazine as one of the 100 best English-language novels from 1923 to 2005.
Anthony Burgess wrote that the title was a reference to an alleged old Cockney expression "as queer as a clockwork orange".¹ Due to his time serving in the British Colonial Office in Malaysia, Burgess thought that the phrase could be used punningly to refer to a mechanically responsive (clockwork) human (orang, Malay for "man").
In his essay "Clockwork Oranges"², Burgess asserts that "this title would be appropriate for a story about the application of Pavlovian, or mechanical, laws to an organism which, like a fruit, was capable of colour and sweetness". This title alludes to the protagonist's positively conditioned responses to feelings of evil which prevent the exercise of his free will.
A Clockwork Orange is written in first person perspective from a seemingly biased and unreliable source. Alex never justifies his actions in the narration, giving a good sense that he is somewhat sincere; a narrator who, as unlikeable as he may attempt to seem, evokes pity from the reader through the telling of his unending suffering, and later through his realization that the cycle will never end. Alex's perspective is effective in that the way that he describes events is easy to relate to, even if the situations themselves are not. He uses words that are common in speech, as well as Nadsat, the speech of particular younger generation subcultures.
Set in a dystopian near future, the novel opens with the introduction of protagonist, fifteen-year-old Alex, who, with his gang members (known as "droogs") Pete, Georgie and Dim, roam the streets at night, committing violent crimes ("ultraviolence") for enjoyment.
Part 1 involves Alex reflecting on his illegal activity (such as beating strangers, the rape of two 10-year-old girls, and also the wife of writer F. Alexander). It describes the treachery of his droogs, resulting in Alex's capture and prison sentence for murder.
The use of lyrical language and Nadsat somewhat masks the horrible imagery of Alex's actions, and, to some extent, Alex is able to draw empathy from the reader, through his friendly nature towards his audience (referring to them as his "only friends," and to himself as "Your Humble Narrator," etc.).
After being caught for his crimes Alex is sentenced to 14 years for murder. Alex gets a job as an assistant to the prison chaplain. He feigns an interest in religion, and amuses himself by reading the Bible for its lurid descriptions of "the old yahoodies (Jews) tolchocking (beating) each other", imagining himself taking part in "the nailing-in" (the Crucifixion of Jesus). Alex hears about an experimental rehabilitation programme called "the Ludovico Technique", which promises that the prisoner will be released upon completion of the two-week treatment, and will not commit crimes afterwards.
Partially by taking part in the fatal beating of a cellmate, Alex manages to become the subject in the first full-scale trial of the Ludovico Technique. The technique itself is a form of aversion therapy, in which Alex is given a drug that induces extreme nausea while being forced to watch graphically violent films for two weeks. Among the films shown are propaganda films such as Triumph of the Will, which includes Alex's beloved Beethoven (last movement of the 9th symphony). He pleads with them to remove the music, but the clinicians refuse, saying it's "for his own good," and that the music may be the "punishment element". At the end of the treatment, Alex is unable to carry out or even contemplate violence without crippling nausea. He is also unable to listen to Beethoven's 9th Symphony without experiencing the same jarring physical reaction.
The third part of the novel concentrates mostly on the following punishment to which Alex is subjected after his treatment. Alex encounters many of his former victims, all of whom seek revenge upon him. He finds himself powerless to defend himself against them, due to feelings of sickness and fear of death, as a reaction to the violence. He finds that his parents have replaced him with a lodger in his own home, and wanders into the public library, only to be attacked by an aging old man whom he had beaten up with his droogs in chapter one. The police are called by the librarian and when they arrive, he sees that the police are no other than his old 'droog' Dim, and arch-enemy Billy Boy. Taking advantage of their positions, they take Alex into a rural part of town to beat him up, and then leave him to his own devices. While looking for solace, Alex falls into the hands of F. Alexander, the husband to the woman whom he earlier raped. Friends of the writer intend to use Alex as a weapon against the political party, exposing the terrible things that have been done to him. Although it is not clear whether the friends of F. Alexander intend it, their playing of Beethoven's 9th Symphony below Alex's locked room drives him to throw himself out of a window instead of enduring the sickness of the treatment's conditioning. Alex's suicide attempt fails, and leads to his being cured, after the bad publicity for the political party that follows.
Touching on themes of the power struggles between old and young generations, the corruption of the police, and also politics, and attempted (but failed) suicide, the third section of the novel is the most reflective of the troubles of future society, mostly shown through the final chapter, where Alex reflects that he and his friends have either been killed (Georgie), fallen victim to the state (Dim's becoming a police officer) or outgrown their destructive behaviour (Pete). Alex finds that he no longer finds pleasure in "ultra-violence" and yearns for a wife and a child of his own. Alex knows that the generation after his will probably be just as destructive, and the one after that,"..and nor would he be able to stop his own son, brothers. And it would itty (go) on till the end of the world.." — perhaps revealing Burgess's ultimate deliberation on the unruly youth.
Alex — The novel's anti-hero and leader among his "droogs,". Alex often refers to himself as "Your Humble Narrator". At the point of raping two ten year old girls, Alex reveals himself as "Alex The Large". This was later the basis for Alex's surname DeLarge in the 1971 film. However, following the attempted suicide the newspapers state his name as 'Alex Burgess' very clearly.
George or Georgie — A droog of Alex's. Georgie attempts to undermine Alex's status as leader of the gang.
Pete — A droog of Alex's. The more rational, democratic and least violent of the gang.
Dim — A slow-witted droog of Alex's. The real brute force of the gang.
P.R. Deltoid — A social worker assigned to Alex, who monitors his progress through reform schools.
The Prison Chaplain (also called the 'prison charlie', a take on Charlie Chaplin) — The character who first questions whether or not forced goodness is really better than chosen wickedness. The only character who is truly concerned about Alex's welfare; he is not taken seriously by Alex, though.
The Governor — The man who decides to let Alex "choose" to be the first reformed by the Ludovico Technique.
Dr. Brodsky — One of the co-founders of the Ludovico Technique. He at first seemed like a friend to Alex, and then introduced him to pain. Plays the "Bad Cop" role when talking to Alex before and after his sessions in the theater.
Dr. Branom — The other Co-Founder of the Ludovico Technique. He says much less than Brodsky and is interpreted as the "Good Cop" role when addressing Alex.
F. Alexander — An author writing, at the beginning of the novel, his own novel called A Clockwork Orange. His wife is raped by Alex and his droogs, and subsequently dies. He later takes Alex in and subjects him to his extremist friends. Shortly after meeting it is possible that they try to kill him using the weaknesses caused by the Ludovico Technique.
Although the book is divided into three parts, each containing seven chapters (7 being a reference to Shakespeare's seven stages of man and 21 being a symbolic reference to the British age of majority at the time the book was written), the 21st chapter was omitted from the versions published in the United States until 1986. The film adaptation, which was directed by Stanley Kubrick, follows the American version of the book, ending prior to the events of the 21st chapter. Kubrick claimed that he had not read the original version until he had virtually finished the screenplay, but that he certainly never gave any serious consideration to using it.
It has also been noted that Kubrick, on obtaining the novella, ripped it in half, kept one and gave the other half to Terry Southern, co-writer of the screenplay.
The book, narrated by Alex, contains many words in a slang dialect which Burgess invented for the book, called Nadsat. It is a mix of modified Slavic words, Cockney rhyming slang, derived Russian (like "baboochka"), and words invented by Burgess himself. For instance, the term 'droog' means 'friend' in Russian; 'korova' means 'cow'; 'golova'(gulliver) means 'head'; 'malchick' or 'malchickiwick' means 'boy'; 'soomka' means 'sack' or 'bag'; 'Bog' means 'God'; 'khorosho'(horrorshow) means good, 'prestoopnick' means 'criminal'; 'rooker' is 'hand', 'cal' is 'crap'; 'litso' is 'face'; and so on. One of Alex's doctors explains the language to a colleague as "Odd bits of old rhyming slang; a bit of gypsy talk, too. But most of the roots are Slav propaganda. Subliminal penetration." Some words are not derived from anything, but merely easy to guess, e.g 'in-out, in-out' or 'the old in-out' means sexual intercourse and 'cutter' means money.
In the first edition of the book, no key was provided, and the reader was left to infer the meaning from the context.
The term "Ultraviolence", referring to excessive and/or unjustified violence, was coined by Burgess in the book, which includes the phrase "do the ultra-violent." The term's association with aesthetic violence has led to its use in the media.
The best known adaptation of the novel to other forms is the 1971 film by Stanley Kubrick, but there have been others. The earlier 1965 film by Andy Warhol entitled Vinyl was an adaptation.
Excerpts from the first two chapters of the novel were dramatized and broadcast on BBC TV's programme Tonight, 1962 (now lost, believed wiped).
After Kubrick's film was released, Burgess wrote a Clockwork Orange stage play. In it, Dr. Branom defects from the psychiatric clinic when she grasps that the aversion treatment has destroyed Alex's ability to enjoy music. The play restores the novel's ending: Alex deciding to start a family. One of Alex's early victims, a bearded trumpeter who plays "Singin' in the Rain" at the Korova milkbar, is modeled on Stanley Kubrick.
In 1990, a second play, titled A Clockwork Orange 2004, was written for the Royal Shakespeare Company. It makes no references to the film version, yet does away with the novel's ending. The performance was scored by Bono and The Edge of U2.
In 2002, Godlight Theatre Company presented the New York Premiere adaptation of Anthony Burgess's 'A Clockwork Orange' at Manhattan Theatre Source. The production went on to play at the SoHo Playhouse (2002), Ensemble Studio Theatre (2004), 59E59 Theaters (2005) and the Edinburgh Festival Fringe (2005). While at Edinburgh, the production received rave reviews from the press while playing to sold-out audiences. The production was directed by Godlight's Artistic Director, Joe Tantalo.
In the 1995 film Tales from the Hood, A character undergoes a similar rehablitation technique.


Amsterdam () is the capital of the Netherlands. Its name is derived from "Amstel dam", pointing to the city's origin: a dam on the river Amstel. The city is known for its historic port, the Rijksmuseum, its red-light district (de Wallen), its liberal coffeeshops, and its many canals which have led to Amsterdam being called the "Venice of the North". During the Dutch Golden Age, Amsterdam was one of the most important ports in the world, with innovative developments in trade, and became the leading centre for finance and diamonds.
The city, founded in the late 12th century as a small fishing village, has grown to become the largest city in the Netherlands with a population of 743,104 inhabitants, containing at least 172 nationalities.
Amsterdam and its surrounding metropolitan area have a population of 1 million to about 1.5 million people, depending on definition, and is part of the Randstad conurbation, which has a population of 6,659,300.
The first known record of Amsterdam is 27 October 1275, when the inhabitants of a late 12th century fishing village who had built a bridge with a dam across the Amstel were granted freedom by count Floris V from paying a bridge toll. The certificate's wording (homines manentes apud Amestelledamme - people living near Amestelledamme) gives the first known use of the name Amsterdam, which by 1327 had developed into Aemsterdam. A local tradition has the city being founded by two Frisian fishermen, who landed on the shores of the Amstel in a small boat with their dog. In any case, Amsterdam's origin is relatively recent in comparison with other Dutch cities such as Nijmegen, Rotterdam and Utrecht.
Amsterdam was given city rights in 1300 or 1301. From the 14th century on, Amsterdam flourished, largely on the basis of trade with the cities of the Hanseatic League. In 1345 a Eucharistic miracle occurred near the Kalverstraat and Amsterdam would remain an important pilgrimage city until the Alteration to the protestant faith; today the Stille Omgang - a silent procession in civil dress - remains of the rich pilgrimage history.
The 17th century is considered Amsterdam's "Golden Age". In the early 17th century, Amsterdam became one of the wealthiest cities in the world. Ships sailed from Amsterdam to the Baltic Sea, North America, Africa and present-day Indonesia, India, Sri Lanka and Brazil, and formed the basis of a worldwide trading network. Amsterdam's merchants had the biggest share in the VOC and WIC. These companies acquired the overseas possessions which formed the seeds of the later Dutch colonies. Amsterdam was the most important point for the trans-shipment of goods in Europe, and it was the leading financial centre of the world. Amsterdam's stock exchange was the first to trade continuously.
The 18th and early 19th centuries saw a decline in Amsterdam's prosperity. The wars of the Dutch Republic with England (see Anglo-Dutch Wars) and France took their toll on Amsterdam. During the Napoleonic Wars, Amsterdam's fortunes reached their lowest point. However, with the establishment of the Kingdom of the Netherlands in 1815, things slowly began to improve. In Amsterdam new developments were started by people like city planner Samuel Sarphati, who found their inspiration in Paris.
The end of the 19th century is sometimes called Amsterdam's second Golden Age. New museums, a train station, and the Concertgebouw were built. At this time the Industrial Revolution reached Amsterdam. The Amsterdam-Rhine Canal was dug to give Amsterdam a direct connection to the Rhine, and the North Sea Canal to give the port a shorter connection to the North Sea. Both projects improved communication with the rest of Europe and the world dramatically. Joseph Conrad gives a brief description of Amsterdam, seen from the sea at this period, in The Mirror of the Sea (1906). Shortly before the World War I the city began expanding and new suburbs were built. During the war, the Netherlands remained neutral. Amsterdam suffered a food shortage, and heating fuel became scarce. The shortages sparked riots in which several people were killed.
Germany invaded the Netherlands on 10 May 1940, taking control of the country after five days of fighting. The Germans installed a Nazi civilian government in Amsterdam that cooperated in the persecution of Jews. Many Amsterdammers sheltered Jews at a high risk to themselves and their families and those that were discovered were also sent to the concentration camps. After the war approximately 120,000 Dutch were prosecuted as collaborators. More than 103,000 to 105,000 Jews were deported from the Netherlands to concentration camps, of whom perhaps the most famous was a young German girl, Anne Frank. Only 5,000 Dutch Jews survived the war. In the last months of the war, communication with the rest of the country broke down, and food and fuel became scarce. Many inhabitants of the city had to travel to the countryside to collect food. Dogs, cats, and raw sugar beets were consumed to stay alive. Tulip bulbs - cooked to a pulp - were a common food as well. Most of the trees in Amsterdam were cut down for fuel, and all the wood was taken from the apartments of deported Jews.
Amsterdam fans out south from Amsterdam Centraal railway station. The main street is Damrak which leads into Rokin. The area to the east of Damrak is the oldest area and is known as de Wallen ("the walls") after the medieval walls of the city - this area contains the city's red light area. To the south of de Wallen is the old Jewish quarter of Waterlooplein. The 17th century girdle of concentric canals, known as the "grachtengordel", embraces the heart of the city. Beyond the grachtengordel are the formerly working class areas of Jordaan and de Pijp, Museumplein, containing the city's major museums, and Vondelpark, the 19th century park named after the Dutch writer Joost van den Vondel.
Several parts of the city and of the urban area are polders, recognisable by their postfix -meer meaning 'lake', such as Aalsmeer, Bijlmermeer, Haarlemmermeer, and Watergraafsmeer.
Much of the Amsterdam canal system is the successful outcome of city planning. In the early part of the 17th century, with immigration at a height, a comprehensive plan was put together, calling for four main, concentric half-circles of canals with their ends resting on de IJ bay. Known as the "grachtengordel", three of the canals are mostly for residential development (Herengracht or ‘’Gentleman's Canal’’; Keizersgracht or ‘’Emperor's Canal’’; and Prinsengracht or ‘’Prince's Canal’’), and a fourth, outer canal, the present Nassau/Stadhouderskade, for purposes of defense and water management. The plan also envisaged interconnecting canals along radii; a set of parallel canals in the Jordaan quarter (primarily for the transportation of goods, for example, beer); the conversion of an existing, inner perimeter canal (Singel) from a defensive purpose to residential and commercial development; and more than one hundred bridges. The defensive purpose of the Nassau/Stadhouderskade was served by moat and earthen dikes, with gates at transit points but otherwise no masonry superstructures.
Construction proceeded from west to east, across the breadth of the lay-out, like a gigantic windshield wiper as the historian Geert Mak calls it – not from the center outwards as a popular myth has it. Construction of the north-western sector was started in 1613. After 1656, with the canals in the southern sector also already finished for some time, building in that sector too was started, although slowly. The eastern part of the concentric canal plan, covering the area between the Amstel river and the IJ bay, was never implemented. In the following centuries, the land went mostly for parks, old age homes, theaters and other public facilities – and for waterways without much plan.
Over the years, several canals have been filled up and are now streets or squares, such as Nieuwezijds Voorburgwal and Spui.
Amsterdam enjoys a moderate temperate climate, with the weather patterns being strongly influenced by Amsterdam's proximity to the North Sea to the west and its prevailing north-western winds and gales. Winter temperatures are mild: on average above freezing, although frosts are not uncommon during spells of easterly or northeasterly winds blowing in from the inner European continent, i. e. from Scandinavia, Russia and even Siberia. Summers are warm but rarely hot. Days with measurable precipitation are common, but still Amsterdam averages less than 760 mm of precipitation annually. Most of it falls as protracted drizzle or light rain. But the occasional Western storm may bring a lot of water at once, and all of it has to be pumped out to higher ground and to the seas around the city. These bodies of water make cloudy and damp days common, particularly in cooler months, October through March.
Amsterdam is the financial and business capital of the Netherlands and one of the most important cities in Europe in which to do business. Many large Dutch corporations and banks have their headquarters in Amsterdam, including ABN Amro, Akzo Nobel, Heineken International, ING Group, Ahold, TomTom, Delta Lloyd Group and Philips. KPMG International's global headquarters is located in nearby Amstelveen, as is the European headquarters of Cisco Systems.
Though many subsidiaries are located along the old canals, companies are increasingly relocating outside the city centre. The South Axis (Dutch: Zuidas) is increasingly a financial and legal center, and is intended to become the new business-face of the Netherlands.The five largest legal companies of the Netherlands have settled down in the South Axis, and also the Dutch subsidiaries of large consulting firms like Boston Consulting Group, McKinsey & Co and Accenture. In this financial quarter the recently expanded World trade centre also has its location.
The Amsterdam Stock Exchange (AEX), nowadays part of Euronext, is the world's oldest stock exchange and still one of the most important in Europe.
Amsterdam is the 5th busiest tourist destination in Europe with more than 4.2 million international visitors. The room occupation rate is the 2nd highest in Europe in 2007. Tourists can choose from 350 Hotels, 17 of which are fivestar hotels. 18,000 rooms and almost 45,000 beds are provided.
Amsterdam shops range from large department stores such as Metz & Co, founded in 1740, Maison de Bonneterie a Parisian style store founded in 1889, and De Bijenkorf founded in 1870, to small specialty shops. The most luxurious shopping street is P.C. Hooftstraat, the busiest high street is Kalverstraat.
In the 16th and 17th century non-Dutch immigrants to Amsterdam were mostly Huguenots, Flemings, Sephardi Jews and Westphalians. Hugenots came after 1685's Edict of Fontainebleau, while the Flemish Protestants came during the Eighty Years' War. The Westphalians came to Amsterdam mostly for economic reasons – their influx continued through the 18th and 19th centuries.
The first mass immigrants in the 20th century were people from Indonesia, who came to Amsterdam after the independence of the Dutch East Indies in the 1940s and 1950s. In the 1960s guest workers from Turkey, Morocco, Italy and Spain migrated to Amsterdam. After the independence of Suriname in 1975 a large wave of Surinamese settled in Amsterdam, mostly in the Bijlmer area. Other immigrants, among which asylants and illegals, come from Europe, America, Asia and Africa. In the seventies and eighties many 'old' Amsterdammers moved to 'new' cities like Almere and Purmerend, prompted by the third planological bill of the Dutch government. This bill promoted suburbanization and arranged for new developments in so called "groeikernen", lit. "cores of growth". Young professionals and artists moved into neighbourhoods the Pijp and the Jordaan abandoned by these Amsterdammers. The non-Western immigrants settled mostly in the social housing projects in Amsterdam-West and the Bijlmer.
In 1578 the previously Roman Catholic city of Amsterdam joined the revolt against Spanish rule, late in comparison to other major northern Dutch cities. In line with Protestant procedure of that time, all churches were "reformed" to the Protestant worship. Calvinism became the dominant religion and although Catholicism was not forbidden and priests allowed to serve, the Catholic hierarchy was prohibited. This led to the establishment of schuilkerken, covert churches, behind seemingly ordinary canal side house fronts, one of them the current debate center de Rode Hoed.
A large influx of foreigners of many religions into 17th-century Amsterdam, in particular Sefardic Jews from Spain and Portugal, Huguenots from France, and Protestants from the Southern Netherlands, led to the establishment of many non-Dutch-speaking religious churches. In 1603 the first notification is made of Jewish religious service. In 1639 the first Jewish synagogue was consecrated.
As they became established in the city, other Christian denominations used converted Catholic chapels to conduct their own services. The oldest Church of England building outside the United Kingdom is found at the Begijnhof. Regular services there are still offered in English. The Huguenots accounted for nearly 20% of Amsterdam's inhabitants in 1700; being Calvinists, they soon integrated into the Dutch Reformed Church, though often retaining their own congregations. Some, commonly referred by the moniker 'Walloon', and are recognisable today as they offer occasional services in French.
In the second half of the 17th century, Amsterdam experienced an influx of Ashkenazim, Jews from Central and Eastern Europe, which continued into the 19th century. Jews often fled the pogroms in those areas. They not only founded their own synagogues, but had a strong influence on the 'Amsterdam dialect' adding a large Yiddish local vocabulary. Amsterdam's nickname of Mokum, the Yiddish word for the Hebrew makom ("town"), stems from this immigration. Despite an absence of an official Jewish ghetto, most Jews preferred to settle in the Jordaan neighbourhood, the north western part of the Amsterdam canal girdle.
Catholic churches in Amsterdam have been constructed since the restoration of the bishopric hierarchy in 1853. One of the principal architects behind the city's Catholic churches, Cuypers, was also responsible for the Amsterdam Central Station and the Rijksmuseum, which led to a refusal of Protestant King William III to open 'that monastery'.
In 1924 the Roman Catholic Church of the Netherlands hosted the International Eucharistic Congress in Amsterdam, and numerous Catholic prelates visited the city, where numerous festivities were held in churches and stadiums; Catholic processions on the public streets however were still forbidden under law at the time. Only in the twentieth century was Amsterdam's relation to Catholicism normalised, but despite its far larger population size, the Catholic clergy chose to place its bishopric seat of the city in the nearby provincial town of Haarlem.
The most recent religious changes in Amsterdam are due to large-scale immigration from former colonies. Immigrants from Suriname have introduced Evangelical Protestantism and Lutheranism, from the Hernhutter variety, Hinduism, and a liberal branch of Islam. Turks, Kurds and Moroccans have introduced other Islamic sects. The large community of Ghanaian and Nigerian immigrants have established African churches, often in parking garages in the Bijlmer area, where many have settled. In addition, a broad array of other religious movements have been established congregations, including Buddhism, Confucianism, Hare Krishna, Bhagwan and Scientology.
During the later part of the 16th century Amsterdams Rederijkerskamer (Chamber of Rhetoric) organized contests between different Chambers in the reading of poetry and drama. In 1638 Amsterdam got its first theatre. Ballet performances were given in this theatre as early as 1642. In the 18th century French theatre became popular. Opera could be seen in Amsterdam from 1677, first only Italian and French operas, but in the 18th century German operas. In the 19th century popular culture was centered around the Nes area in Amsterdam (mainly vaudeville and music-hall). The metronome, one of the most important advances in European classical music was invented here in 1812 by Dietrich Nikolaus Winkel. At the end of this century the Rijksmuseum and Gemeentelijk Museum were built. In 1888 the Concertgebouworkest was established. With the 20th century came cinema, radio and television. Though the studios are in Hilversum and Aalsmeer, Amsterdam's influence on programming is very strong.
The artist most associated with Amsterdam is Rembrandt, whose work, and the work of his pupils, is displayed in the Rijksmuseum. Van Gogh lived in Amsterdam for a short while, so there is a museum dedicated to his early work.
Amsterdam has a world-class symphony orchestra, the Royal Concertgebouw Orchestra, the home base of which is the Concertgebouw.
Amsterdam has developed itself into a European fashion capital. Big fashion brands like G-star,Gsus,BlueBlood,10 feet and Warmenhoven & Venderbos and fashion designers like Mart Visser Viktor & Rolf, Marlies Dekkers and Frans Molenaar are headquartered in Amsterdam. Also model agencies like Elite Models, Touche models and Tony Jones have opened departments in Amsterdam. Supermodels like Yfke Sturm, Doutzen Kroes and Kim Noorda started their career in Amsterdam. Amsterdam is also known for its World Fashion Centre.
Visitors are attracted to Amsterdam for its reputation as a liberal city; its relaxed charm emphasised by elegant, narrow fronted merchant's houses and enchanting canals; and the reputation of its museums.
The major museums are the Rijksmuseum, the Stedelijk Museum, the Rembrandt House Museum, and the Van Gogh Museum, which houses the largest collection of Van Gogh's paintings and drawings in the world. The Anne Frank House, a museum dedicated to the story of Anne Frank, is also a popular tourist attraction.
The liberal nature of Amsterdam is not only physically embodied in the layout of the city, such as the de Wallen area which contains the red-light district and many cannabis-selling coffeeshops, but it is also embodied in the well-rounded, prevailing attitudes of its residents, government and businesses. Amsterdam's red-light district is located in the centre of the city and is clearly marked on maps. Window prostitution in the Netherlands is legal at specific places. Cannabis selling, however, is not - but it is tolerated when small quantities of cannabis (up to 5 grams) are involved. Previously in Amsterdam a handful of smart shops sold psilocybin mushrooms and drug paraphernalia. However psilocybin mushrooms have recently been made illegal. Though illegal to consume in public, these mushrooms are still sold by several smart shops.
Amsterdam, a major tourist attraction. It is a network of alleys containing several hundred tiny one-room apartments rented by female prostitutes (and some ladyboys) who offer their services from behind a window or glass door, typically illuminated with red lights. The area also has a number of sex shops, sex theatres, peep shows, a sex museum, a cannabis museum, and a number of coffee shops offering various cannabis products.
Amsterdam is the hometown of Eredivisie football club Ajax. Its home base is the modern stadium Amsterdam ArenA, located in the south-east of the city.
In 1928, Amsterdam hosted the Games of the IXth Olympiad. The Olympic Stadium built for the occasion has been completely restored and is now used for cultural and sporting events, such as the Amsterdam Marathon.
Amsterdam also is home to a famous ice rink, the Jaap Eden baan. The Amstel Tijgers play in this arena in the Dutch ice hockey premier league. In speed skating many international championships have been fought in the 400 m lane of this ice rink.
The city also has a baseball team, the Amsterdam Pirates, who play in the Dutch Major League. There are three field hockey teams, Amsterdam, Pinoké and Hurley, who play their matches around the Wagener Stadium. These teams are often referred to as playing in Amsterdam; however, all of them (even Amsterdam) play their matches in the neighbouring city of Amstelveen. There is also a basketball team, the Amsterdam Astronauts, who compete in the Dutch premier division and play their games in the Sporthallen Zuid, near the Olympic Stadium.
Since 1999 the city of Amsterdam has honoured its best sportsmen and -women at the Amsterdam Sports Awards. Boxer Raymond Joval and field hockey midfielder Carole Thate were the first to receive the awards in 1999.
Amsterdam is one of the most bicycle-friendly cities in the world and is a centre of bicycle culture with good provision for cyclists such as bike paths and bike racks, which are ubiquitous throughout the city. There are an estimated one million bicycles in the city. However, bike theft is common, so cyclists use large secure locks.
Public transport in Amsterdam mainly consists of bus and tram lines, operated by Gemeentelijk Vervoerbedrijf, Connexxion and Arriva; however, there are four metro lines; with a fifth line, the North/South line, under construction. Three free ferries carry pedestrians and cyclists across the IJ to Amsterdam-Noord, and two fare charging ferries go east and west along the harbour. There are also water taxis and a water bus, in addition to the canal cruises, that transport people along Amsterdam's waterways.
The A10 Ringroad surrounding the city connects Amsterdam with the Dutch national network of freeways. Interchanges on the A10 allow cars to enter the city by transferring to one of the eighteen city roads, numbered s101 through s118. These city roads are regional roads without grade separation, and sometimes without a central reservation. Most are accessible by cyclists. The s100 is called the centrumring, a smaller ringroad circumnavigating the city centre.
Amsterdam was intended in 1932 to be a major hub of the highway system of the Netherlands, with freeways numbered one through eight planned to originate from the city. However, the outbreak of the Second World War and shifting priorities led to the current situation, where only roads A1, A2, and A4 originate from Amsterdam according to the original plan. The A3 road to Rotterdam was cancelled in 1970 in order to conserve the Groene Hart. Road A8, leading north to Zaandam and the A10 Ringroad were opened between 1968 and 1974. Besides the A1, A2, A4 and A8, several freeways, such as the A7 and A6, carry traffic mainly bound for Amsterdam.
Amsterdam is served by eight stations of the Nederlandse Spoorwegen (Dutch Railways). Five are intercity stops: Sloterdijk, Zuid, Amstel, Bijlmer ArenA and Amsterdam Centraal. Many other stations exist in the Amsterdam urban area.
Eurolines has coaches from Amsterdam to destinations all over Europe.
Amsterdam Centraal is an international train station. From the station there are regular services with destinations in Belgium, France, Germany, and Switzerland. Among these trains are international trains of the Nederlandse Spoorwegen and the Thalys, CityNightLine, and InterCityExpress.
Amsterdam Schiphol Airport is less than 20 minutes by train from Amsterdam Central Station. It is the biggest airport in the Netherlands, the fourth largest in Europe and the tenth largest in the world. It handles about 44 million passengers a year and is home base to KLM. Schiphol is the third busiest airport in the world measured by international passengers.
Amsterdam has two universities: the University of Amsterdam (Universiteit van Amsterdam), and the VU University Amsterdam (Vrije Universiteit or "VU"). Other institutions for higher education include an art school, De Rietveldacademie, the Hogeschool van Amsterdam and the Amsterdamse Hogeschool voor de Kunsten. Amsterdam's International Institute of Social History is one of the world's largest documentary and research institutions concerning social history, and especially the history of the labour movement. Amsterdam's Hortus Botanicus, founded in the early 1600s, is one of the oldest botanical gardens in the world, with many old and rare specimens, amongst them the coffee plant that served as the parent for the entire coffee culture in Central and South America.
Amsterdam is thought to have excellent primary schools. Some of these schools base their teachings on particular pedagogic theories like the various Montessori schools. Many however are based on religion. This used to be primarily Roman Catholicism and various Protestant denominations, but with the influx of Muslim immigrants there is a rise in the number of Muslim schools. In addition to these schools based on distinct beliefs there are public schools.
The same goes for secondary education. Amsterdam is noted for having 3 independent grammar schools (Dutch: gymnasia), the Vossius Gymnasium, Barlaeus Gymnasium and St. Ignatius Gymnasium, where a classical curriculum including Latin and classical Greek is taught. Though believed until recently by many to be an anachronistic and elitist concept that would soon die out, the gymnasia have recently experienced a revival leading to the formation of a fourth grammar school in which the three aforementioned schools participate.
The administration of the municipality of Amsterdam is divided into 15 boroughs or stadsdelen; the central one, Centrum, being circled by Westerpark, Bos en Lommer, De Baarsjes, Oud-West, Oud-Zuid, Oost/Watergraafsmeer, Zeeburg and Amsterdam-Noord, with the six outer boroughs creating a further encirclement.
Amsterdam is usually understood to be the municipality of Amsterdam. Colloquially, some areas within the municipality, such as the village of Durgerdam, may not be considered part of Amsterdam. Statistics Netherlands uses three other definitions of Amsterdam: metropolitan agglomeration Amsterdam (Grootstedelijke Agglomeratie Amsterdam, not to be confused with Grootstedelijk Gebied Amsterdam, a synonym of Groot Amsterdam), Greater Amsterdam (Groot Amsterdam, a COROP region) and the urban region Amsterdam (Stadsgewest Amsterdam). These definitions are not synonymous with the terms urban area and metropolitan area, which are commonly used in English speaking countries for the purpose of defining large conurbations. The Amsterdam Department for Research and Statistics uses a fourth conurbation, namely the City region Amsterdam. This region is similar to Greater Amsterdam, but includes the municipalities Zaanstad and Wormerland. It excludes Graft-De Rijp.
The smallest of these areas is the municipality, with a population of 742,981 in 2006. The metropolitan agglomeration had a population of 1,021,870 in 2006. It includes the municipalities of Zaanstad, Wormerland, Oostzaan, Diemen and Amstelveen only, as well as the municipality of Amsterdam. Greater Amsterdam includes 15 municipalities, and had a population of 1,211,503 in 2006. Though much larger in area, the population of this area is only slightly larger, because the definition excludes the relatively populous municipality of Zaanstad. The largest area by population, the urban region Amsterdam, has a population of 1,468,122. It includes Zaanstad, Wormerveer, Muiden and Abcoude, but excludes Graft De Rijp, Uithoorn and Aalsmeer. Amsterdam is also part of the conglomerate metropolitan area Randstad, with a total population of 6,659,300 inhabitants.
As all Dutch municipalities, Amsterdam is governed by a mayor, aldermen, and the municipal council. However, unlike most other Dutch municipalities, Amsterdam is subdivided into fifteen stadsdelen (boroughs), a system that was implemented in the 1980s to improve local governance. The stadsdelen are responsible for many activities that previously had been run by the central city. Fourteen of these have their own council, chosen by a popular election. The fifteenth, Westpoort, covers the harbour of Amsterdam, has very few inhabitants, and is governed by the central municipal council. Local decisions are made at borough level, and only affairs pertaining to the whole city, such as major infrastructure projects, are handled by the central city council.
The present version of the Dutch constitution mentions "Amsterdam" and "capital" only in one place, chapter 2, article 32: The king's confirmation by oath and his coronation take place in "the capital Amsterdam" ("de hoofdstad Amsterdam"). Previous versions of the constitution spoke of "the city of Amsterdam" ("de stad Amsterdam"), without mention of capital. In any case, the seat of the government, parliament and supreme court of the Netherlands is (and always has been, with the exception of a brief period between 1808 and 1810) located at The Hague. Foreign embassies too are in The Hague. Although capital of the country, Amsterdam is not the capital of the province in which it is located, North Holland, whose capital is located at Haarlem.
The coat of arms of Amsterdam is composed of several historical elements. First and centre are three St Andrew's crosses, aligned in a vertical band on the city's shield. These St Andrew's crosses can also be found on the cityshields of neighbours Amstelveen and Ouder-Amstel. This part of the coat of arms is the basis of the flag of Amsterdam, flown by the city government, but also as civil ensign for ships registered in Amsterdam. Second is the Imperial Crown of Austria — in 1489, out of gratitude for services and loans, Maximilian I awarded Amsterdam the right to adorn its coat of arms with the king's crown, in 1508 replaced with Maximilian's imperial crown when he was crowned Holy Roman Emperor. In the early years of the 17th century, Maximilian's crown in Amsterdam's coat of arms was replaced with the crown of Emperor Rudolph II, a crown that also would become the Imperial Crown of Austria. The lions date from the late 16th century, when city and province became part of the Republic of the Seven United Netherlands. Last came the city's official motto: Heldhaftig, Vastberaden, Barmhartig ("Valiant, Determined, Compassionate"), bestowed on the city in 1947 by Queen Wilhelmina, in recognition of the city's bravery during World War II.

The Museum of Work, or Arbetets museum, is a museum located in Norrköping, Sweden. The museum can be found in the 19th century building The Iron in the Motala ström river in central Norrköping.


Audi AG, more commonly known as Audi, is a German automobile manufacturer and one of the world's leading performance-luxury marque, with headquarters in Ingolstadt, Bavaria, and has been an almost wholly-owned (99.7%) subsidiary of the Volkswagen Group since 1964. The company evolved from VW's takeover of both Auto Union, and NSU, the former having incorporated the historic Audi company which was founded in 1910.
Audi's corporate tagline is Vorsprung durch Technik, meaning "Advancement through Technology" or "Head Start through Technology". This German-language tagline is also used in other European countries, including the UK, and in other markets, such as Latin America, Oceania and parts of Asia including Japan. The American and Canadian tagline is "Truth in Engineering".
The company traces its origins back to 1899 and August Horch. The first Horch automobile was produced in 1901 in Zwickau. In 1909, Horch was forced out of the company he had founded. He then started a new company in Zwickau and continued using the Horch brand. His former partners sued him for trademark infringement and a German court determined that the Horch brand belonged to his former company. August Horch was forced to refrain from using his own family name in his new car business. Horch immediately called a meeting at the apartment of Franz Fikentscher to come up with a new name for his company. During this meeting Franz's son was quietly studying Latin in a corner of the room. Several times he looked like he was on the verge of saying something but would just swallow his words and continue working, until he finally blurted out, "Father - audiatur et altera pars.. wouldn't it be a good idea to call it audi instead of horch?". "Horch!" in German means "Hark!" or "listen", which is "Audi" in Latin. The idea was enthusiastically accepted by everyone attending the meeting. It is also popularly (but incorrectly) believed that Audi is an acronym which stands for "Auto Union Deutschland Ingolstadt".
Audi started with a 2,612 cc (2.6 liter) four cylinder model followed by a 3564 cc (3.6 L) model, as well as 4680 cc (4.7 L) and 5720 cc (5.7L) models. These cars were successful even in sporting events. August Horch left the Audi company in 1920. The first six cylinder model, 4655 cc (4.7 L) appeared in 1924. In 1928, the company was acquired by Jørgen Rasmussen, owner of DKW. In the same year, Rasmussen bought the remains of the US automobile manufacturer, Rickenbacker, including the manufacturing equipment for eight cylinder engines. These engines were used in Audi Zwickau and Audi Dresden models that were launched in 1929. At the same time, six cylinder and four cylinder (licensed from Peugeot) models were manufactured. Audi cars of that era were luxurious cars equipped with special bodywork.
In 1932, Audi merged with Horch, DKW and Wanderer, to form Auto Union.
Before World War II, Auto Union used the four interlinked rings that make up the Audi badge today, representing these four brands. This badge was used, however, only on Auto Union racing cars in that period while the member companies used their own names and emblems. The technological development became more and more concentrated and some Audi models were propelled by Horch or Wanderer built engines. During World War II, the Horch/Auto Union produced the Sd-Kfz 222 armored car, which was used in the German army during the war. It was powered by an Horch/Auto Union V8 engine which had a top speed of 50 miles per hour.
Another vehicle which was used in World War II to shuttle German military officials safely was known as the Kraftfahrzeug (KFZ 11) or the Horch Type 80. The military used it as a light transport vehicle.
The Audi emblem is four overlapping rings that represent the four marques of Auto Union. The Audi emblem symbolizes Audi amalgamation of Audi with DKW, Horch and Wanderer: the first ring represents Audi, the second represents DKW, third is Horch, and the fourth and last ring Wanderer.
The Auto Union plants were heavily bombed and severely damaged during World War II. After the war Zwickau was located in the soviet occupied zone of Germany (Since 1949 German Democratic Republic). The Auto Union AG got broken up. The Audi factory became the socialist company "VEB Automobilwerk Zwickau" (AWZ). The new Auto Union was launched in Ingolstadt (Bavaria). Many employees of the destroyed factories in Zwickau came to Ingolstadt and restarted the production of cars under the DKW label. These cars were equipped with two stroke engines. They based on a pre-war construction and were also built in Zwickau in a very similar way.
In 1958, Daimler-Benz acquired 87% of Auto Union, and in the next year 100%. In 1964, Volkswagen bought the factory in Ingolstadt and the brands of the Auto Union. The time of two stroke engines came to an end in the middle of the 1960s. Customers were more attracted to the comfortable four stroke engines. In September 1965, the last DKW model, the DKW F102, got a four stroke engine implanted and some changes of front and rear. Volkswagen dumped the brand DKW because of its two stroke smell, "relaunching" the Audi brand. The model was classified internally as the F103 and sold as simply the "Audi" (the name being a model designation rather than the manufacturer, which was still officially Auto Union), but later came to be known as the Audi 72. Developments of the model were named for their horsepower ratings and sold as the Audi 60, 75, 80, and Super 90. These models sold until 1972.
In 1969, Auto Union merged with NSU, based in Neckarsulm near Stuttgart. In the 1950s, NSU had been the world's largest manufacturer of motorcycles, but had moved on to produce small cars like the NSU Prinz (the TT and TTS versions are still popular as vintage race cars). NSU then focused on new rotary engines according to the ideas of Felix Wankel. In 1967, the new NSU Ro 80 was a space-age car well ahead of its time in technical details such as aerodynamics, light weight, and safety, but teething problems with the rotary engines put an end to the independence of NSU. Today the Neckarsulm plant is used to produce the larger Audi models, the R8, and the "RS" model range.
The mid-sized car that NSU had been working on, the K70, was intended to slot between the rear-engined Prinz models and the futuristic Ro80. However, Volkswagen took the K70 for its own range, spelling the end of NSU as a separate brand.
The new merged company was known as Audi NSU Auto Union AG, and saw the emergence of Audi as a separate brand for the first time since the pre-war era. Volkswagen introduced the Audi brand to the United States for the 1970 model year.
The first new car of this regime was the Audi 100 of 1968. This was soon joined by the Audi 80/Fox (which formed the basis for the 1973 Volkswagen Passat) in 1972 and the Audi 50 (later rebadged as the Volkswagen Polo) in 1974. The Audi 50 was a seminal design in many ways, because it was the first incarnation of the Golf/Polo concept, one that led to a hugely successful world car.
The Audi image at this time was a conservative one, and so, a proposal from chassis engineer Jörg Bensinger was accepted to develop the four-wheel drive technology in Volkswagen's Iltis military vehicle for an Audi performance car and rally racing car. The performance car, introduced in 1980, was named the "Audi Quattro," a turbocharged coupé which was also the first German large-scale production vehicle to feature permanent all-wheel drive through a center differential (not counting the earlier British Jensen FF, produced in small numbers). Commonly referred to as the "Ur-Quattro" (the "Ur-" prefix is a German augmentative used, in this case, to mean "original" and is also applied to the first generation of Audi's S4 and S6 sport sedans, as in "UrS4" and "UrS6"), few of these vehicles were produced (all hand-built by a single team) but the model was a great success in rallying. Prominent wins proved the viability of all-wheel drive racecars, and the Audi name became associated with advances in automotive technology.
In 1985, with the Auto Union and NSU brands effectively dead, the company's official name was now shortened to simply Audi AG.
In 1986, as the Passat-based Audi 80 was beginning to develop a kind of "grandfather's car" image, the type 89 was introduced. This completely new development sold extremely well. However, its modern and dynamic exterior belied the low performance of its base engine, and its base package was quite spartan (even the passenger-side mirror was an option.) In 1987, Audi put forward a new and very elegant Audi 90, which had a much superior set of standard features. In the early 1990s, sales began to slump for the Audi 80 series, and some basic construction problems started to surface.
This decline in sales was not helped in the USA by a 60 Minutes report which purported to show that Audi automobiles suffered from "unintended acceleration". The 60 Minutes report was based on customer reports of acceleration when the brake pedal was pushed. Independent investigators concluded that this was most likely due to a close placement of the accelerator and brake pedals (unlike American cars), and the inability, when not paying attention, to distinguish between the two. (In race cars, when manually downshifting under heavy braking, the accelerator has to be used in order to match revs properly, so both pedals have to be close to each other to be operated by the right foot at once, toes on the brake, heel on the accelerator; a driving technique called heel-and-toe). This did not become an issue in Europe, possibly due to more widespread experience among European drivers with manual transmissions.
60 Minutes ignored this fact and rigged a car to perform in an uncontrolled manner. The report immediately crushed Audi sales, and Audi renamed the affected model (The 5000 became the 100/200 in 1989, as it was elsewhere). Audi had contemplated withdrawing from the American market until sales began to recover in the mid-1990s. The turning point for Audi was the sale of the new A4 in 1996, and with the release of the A4/A6/A8 series, which was developed together with VW and other sister brands (so called "platforms").
In the early part of the 21st century, Audi set forth on a German racetrack to claim and maintain several World Records, such as Top Speed Endurance. This effort was in-line with the company's heritage from the 1930s racing era "Silver Arrows".
Currently, Audi's sales are growing strongly in Europe. 2004 marked the 11th straight increase in sales, selling 779,441 vehicles worldwide. Record figures were recorded from 21 out of about 50 major sales markets. The largest sales increases came from Eastern Europe (+19.3%), Africa (+17.2%) and the Middle East (+58.5%). In March of 2005, Audi is building its first two dealerships in India following its high increase in sales in the region.
Their 2007 worldwide sales have been released as 964,151 vehicles sold, yet another record for the brand. It is predicted that in 2008, they will pass the 1 million unit mark.
MMI has been generally well-received, as it requires less menu-surfing with its mass of buttons around a central knob, with shortcuts to the radio or phone functions. The screen, either colour or monochrome, is mounted on the upright dashboard, and on the A4 (new), A5, A6, A8, and Q7, the controls are mounted horizontally. However, an "MMI like" system is also available on the Audi A3 and A4 models when equipped with the optional Navigation System.
Audi has competed in numerous forms of auto racing. Audi's rich tradition in motorsport began with the Auto Union in the 1930s. In the 1990s Audi dominated the Touring and Super Touring categories of motor racing after success in circuit racing Stateside.
In 1980 Audi released the Quattro, an all wheel drive turbocharged car that went on to win rallies and races worldwide. It is considered one of the most significant rally cars of all time because it was one of the first to take advantage of the then-recently changed rules which allowed the use of all-wheel-drive in competition racing. Many critics doubted the viability of all-wheel-drive racers, thinking them to be too heavy and complex, yet the Quattro was to become a successful car. Leading its first rally it went off the road, however the rally world had been served notice AWD was the future. It won competition after competition for the next two years.
In 1984 Audi launched the short-wheelbase Sport Quattro car which dominated races in Monte Carlo and Sweden with Audi taking all podium finishes but succumbed to problems further into World Rally Championship contention. After another season mired in mediocre finishes, Walter Röhrl finished the season in his Sport Quattro S1 and helped place Audi second in the manufacturer's points. Audi also received rally honors in the Hong Kong to Beijing rally in that same year. Michèle Mouton, the first female WRC driver to win a round of the World Rally Championship and a driver for Audi, took the Sport Quattro S1, now simply called the S1 and raced in the Pikes Peak Hill Climb. The climb race pits a driver and car to drive up a 4,302 meter high mountain in Colorado and in 1985, Michèle Mouton set a new record of 11:25.39 and being the first woman to set a Pikes Peak record. In 1986, Audi formally left international rally racing following an accident in Portugal involving driver Joaquim Santos in his Ford RS200. Santos swerved to avoid hitting spectators in the road, and left the track into the crowd of spectators on the side, killing three and injuring 30. Bobby Unser used an Audi in that same year to claim a new record for the Pikes Peak Hill Climb at 11:09.22.
In 1987, Walter Röhrl claimed the title for Audi setting a new Pikes Peak record of 10:47.85 in his Audi S1 which he retired from the WRC two years earlier. The Audi S1 employed Audi's time-tested 5-cylinder turbo charged engine and generated over 600 hp (447 kW). The engine was mated to a 6-speed gearbox and ran on Audi's famous all-wheel drive system. All of Audi's top drivers drove this beast, Hannu Mikkola, Stig Blomqvist, Walter Röhrl and the female driver, Michèle Mouton. The Audi S1 enjoys a 0-60 mph (0-100 km/h) time of 2.3 s. This Audi S1 started the S-series of cars for Audi which now represents an increased level of sports options and quality in the Audi line-up.
As Audi moved away from rallying and into circuit racing, they chose to move first into America with the Trans-Am in 1988.
In 1989, Audi moved to IMSA GTO with the 90, however as they avoided the two major endurance events (Daytona and Sebring) despite winning on a regular basis, they would lose out on the title.
In 1990, having completed their objective to market cars in the United States, Audi returned to Europe turning first to the DTM series with the Audi V8, then in 1993, being unwilling to build cars for the new formula, they turned their attention to the fast growing Supertouring series, which took place nationally, first in the French Supertourisme and Italian Superturismo. In the following year, Audi would switched to the German Super Tourenwagen (known as STW) and then to British Touring Car Championship (BTCC) the year after that.
The FIA, having difficulty regulating the quattro system and what impact it had on the competitors, would eventually ban all four wheel drive cars from competing in 1998, by then Audi switched all their works efforts to sports car racing.
By 2000, Audi would still compete in the US with their RS4 for the SCCA Speed World GT Challenge, through dealer/team Champion Racing competing against Corvettes, Vipers, and smaller BMWs (where it is one of the few series to permit 4WD cars). In 2003, Champion Racing entered an RS6. Once again, the quattro all wheel drive was superior and Champion Audi won the championship. They returned in 2004 to defend their title but a newcomer, Cadillac with the new Omega Chassis CTS-V, gave them a run for their money. After four victories in a row, the Audis were sanctioned with several negative changes that deeply affected the car's performance. Namely, added ballasts and Champion Audi deciding to go with different tires and backing off the turbos boost pressure.
In 2004, after years of competing with the TT-R in the revitalized DTM series, with privateer team Abt Racing/Christian Abt taking the 2002 title with Laurent Aïello, Audi returned as a full factory effort to touring car racing by entering two factory supported Joest Racing A4s.
Beginning in 1999, Audi built the Audi R8 LMP to compete in sports car racing, including the LMP900 class at the 24 hours of Le Mans. The factory-supported Joest Racing team won at Le Mans three times in a row (2000 — 2002), as well as winning every race in the American Le Mans Series in its first year. Audi also sold the car to customer teams such as Champion Racing. In 2003, two Bentley Speed 8s, with engines designed by Audi and driven by Joest drivers loaned to the fellow VW company, competed in the GTP class and finished the race in the top two positions, while the Champion Racing R8 finished third overall and first in the LMP900 class. Audi returned to the winner's circle at the 2004 race, with the top three finishers all driving R8s: Audi Sport Japan Team Goh finished first, Audi Sport UK Veloqx second, and Champion Racing third.
At the 2005 24 Hours of Le Mans, Champion Racing entered two R8s along with an R8 from the Audi PlayStation Team Oreca. The R8s (which were built to old LMP900 regulations) received a more narrow air inlet restrictor, cutting power, and an additional 50 kg of weight compared to the newer LMP1 chassis. On average, the R8s were about 2-3 seconds off pace compared to the Pescarolo-Judd. But with a team of excellent drivers and experience, both Champion R8s were able to take first and third while the ORECA team took fourth. The Champion team was also the first American team to win Le Mans since the Gulf Ford GT's in 1967. This also ends the long era of the R8; however, its replacement for 2006, called the Audi R10, was unveiled on December 13, 2005.
The R10 employs many new features, including a twin-turbocharged diesel engine. Its first race was the 2006 12 Hours of Sebring as a race-test for the 2006 24 Hours of Le Mans, which it later went on to win. Audi has been on the forefront of motorsports, claiming a historic win in the first ever diesel sports car at 12 Hours of Sebring. Audi has achieved the title as the most dominant motor sport power since the start of the 21st century, continuing its long and storied motor sport heritage.
Audi produces 100% galvanized vehicles to prevent corrosion, and was the first mass-market vehicle to do so, following introduction of the process by Porsche, c.1978. Along with other precautionary measures, the thus achieved full-body zinc coating has proved to be very effective in preventing rust and corrosion perforation. The body's resulting durability even surpassed Audi's own expectations, causing the manufacturer to extend its original 10-year warranty against corrosion perforation to currently 12 years.
An all-aluminium car was brought forward by Audi, and in 1994 the Audi A8 was launched, which introduced aluminum space frame technology (called Audi Space Frame). Audi introduced a new series of vehicles in the mid-nineties and continues to pursue leading-edge technology and high performance. Prior to that effort, Audi used examples of the Type 44 chassis fabricated out of aluminum as test-beds for the technique. At one time, a copy of this body was fitted with a turbine engine, gaining a World record for mpg in a full-sized car, approximately 200mpg.
In all its post Volkswagen-era models, Audi has firmly refused to adopt the traditional rear wheel drive layout favoured by its two arch rivals Mercedes-Benz and BMW, favouring either front wheel drive or all wheel drive. To achieve this, Audi has usually engineered its cars with a longitudinally mounted engine mounted in an "overhung" position over the front wheels - in front of the axle line. While this allows for equal length driveshafts (therefore combatting torque steer), and the easy adoption of all-wheel drive, it goes against the ideal 50:50 weight distribution. For this reason, most still believe that BMW has the edge over Audi in terms of dynamic prowess, although this will be addressed with the forthcoming A5 coupe in 2007, and the B8 A4 range, which will feature the engine mounted behind the front wheels.
In the 1970s, two vehicle manufacturers Audi and Subaru designed their own all wheel drive systems in passenger vehicles. In the 1980s, all-wheel drive systems in cars became a fad, and other German manufacturers like Porsche, BMW and Mercedes-Benz offered all-wheel drive systems in their cars to compete in the marketplace, along with GM, Ford, Toyota and others. The all-wheel drive system in the Mercedes-Benz vehicles were riddled with problems right from the design sheet. The system also was not popular in Porsche vehicles because owners wanted the traditional performance of the rear wheel drive they got used to in older Porsches. Although Porsche and Mercedes-Benz offer all-wheel-drive systems in some cars and trucks today, neither manufacturer is as well-known for all-wheel-drive technology as is Audi. Audi has recently applied the quattro badge to models such as the A3 and TT which do not actually use the quattro system as in prior years, with a mechanical center differential, but with the Swedish Haldex electromechanical clutch AWD system.
In the 1980s, Audi was the champion of the inline 5 cylinder, 2.1/2.2 L engine as a longer lasting alternative to more traditional 6 cylinder engines. This engine was used not only in production cars but also in their race cars. The 2.1L inline 5 cylinder engine was used as a base for the rally cars in the 1980s, providing well over 400 horsepower (298 kW) after modification. Before 1990, there were engines produced with a displacement between 2.0L and 2.3L. This range of engine capacity was a good combination of good fuel economy (which was on the mind of every motorist in the 1980s) and, of course, a good amount of power.
Through the early 1990s, Audi began to move more towards the position of being a real competitor in its target market against global luxury leaders Mercedes-Benz and BMW. This began with the release of the Audi V8 in 1990. It was essentially a new engine fitted to the Audi 100/200, but with noticeable bodywork differences. Most obvious was the new grille that was now incorporated in the bonnet.
By 1991, Audi had the 4 cylinder Audi 80, the 5 cylinder Audi 90 and Audi 100, the turbocharged Audi 200 and the Audi V8. There was also a coupe version of the 80/90 with both 4 and 5 cylinder engines.
Although the five cylinder engine was a successful and very robust powerplant, it was still a little too different for the target market. With the introduction of an all-new Audi 100 in 1992, Audi introduced a 2.8L V6 engine. This engine was also fitted to a face-lifted Audi 80 (all 80 and 90 models were now badged 80 except for the USA), giving this model a choice of 4, 5 and 6 cylinder engines, in sedan, coupe and cabriolet body styles.
The 5 cylinder was soon dropped as a major engine choice; however, a turbocharged 230 hp (169 kW) version remained. The engine, initially fitted to the 200 quattro 20V of 1991, was a derivative of the engine fitted to the Sport Quattro. It was fitted to the Audi Coupe and named the S2 and also to the Audi 100 body, and named the S4. These two models were the beginning of the mass-produced S series of performance cars.
The Audi A8 replaced the V8 in 1994, with a revolutionary aluminium "Audi Space Frame" (ASF) to save weight. The weight reduction was offset by the quattro all-wheel drive system. It meant the car had similar performance to its rivals, but superior roadholding.
The next major model change was in 1995 when the Audi A4 replaced the Audi 80. The new nomenclature scheme was applied to the Audi 100 to become the Audi A6 (with a minor facelift). This also meant the S4 became the S6 and a new S4 was introduced in the A4 body. The S2 was discontinued. The Audi Cabriolet continued on (based on the Audi 80 platform) until 1999, gaining the engine upgrades along the way. A new A3 hatchback model (sharing the Volkswagen Golf Mk.4's platform) was introduced to the range in 1996, and the radical TT coupe and roadster were debuted in 1998 based on the same underpinnings. Another interesting model introduced was the Mercedes-Benz A-Class competitor, the Audi A2. The model sold relatively well in Europe, however, the A2 was discontinued in 2005 and Audi decided not to develop an immediate replacement.
The engines available throughout the range were now a 1.4L, 1.6L and 1.8L 4 cylinder, 1.8L 4-cylinder turbo, 2.6L and 2.8L V6, 2.2L turbo-charged 5 cylinder and the 4.2L V8. The V6s were replaced by new 2.4L and 2.8L 30V V6s in 1998, with marked improvement in power, torque and smoothness. Further engines were added along the way, including a 3.7L V8 and 6.0L W12 for the A8.
At the turn of the century, Audi introduced the direct-shift gearbox, or DSG, a manual transmission drivable like an automatic transmission. The system includes dual electrohydraulically controlled clutches instead of a torque converter. This is implemented in some VW Golfs, Audi A3 and TT models. The engine range was continually upgraded, with a 2.7L twin turbo V6 being offered in the Audi S4, A6 and allroad, while the 2.8L V6 was replaced by a 3.0L unit.
In 2001, Audi released a high performance version of the A8, dubbed S8. It featured a 4.2L V8 with 317 torque.
All TDI models are diesels.
As a premium member of the VW Group, technologies are frequently first introduced to the mass market in Audi vehicles before being 'trickled down' to more value oriented brands such as VW, SEAT and Škoda. Recent examples of this include a number of the FSI engines mentioned above, as well as the quick-shifting DSG dual-clutch gearbox option.
TSI® technology was introduced to the Volkswagen Golf early in 2006. These engines use, initially at least, a capacity of 1.4 litres combined with both a turbo- and super-charger to produce a high power output, with lower levels of harmful carbon dioxide emissions and improved fuel economy when compared with a non-turbo or super-charged engine of a high capacity, such as 2.0 litres. The 1.4 litre TSI engine currently on sale in VW's Golf produces outputs of 140 and. These engines have proved popular amongst the motoring press in Britain and could soon be filtered into the Audi range, with a possibility of featuring in the A3 and A4 models, as well as maybe featuring in SEAT and Skoda's model ranges sometime soon.
Audi has publicly set a goal to surpass BMW and the luxury and safety leaders Mercedes-Benz in global sales by 2015 and have made giant strides to the achievement of this goal since.


An aircraft is a vehicle which is able to fly through the air (or through any other atmosphere). All the human activity which surrounds aircraft is called aviation. (Most rocket vehicles are not aircraft because they are not supported by the surrounding air).
Manned aircraft are flown by a pilot. Until ca. the 1960s, unmanned aircraft were called drones. During the 1960s, the US military brought the term remotely piloted vehicles (RPV) into use. More recently the term Unmanned Aerial Vehicle (UAV) has become common.
Aircraft fall into two broad categories: Lighter-than-air, called aerostats, and heavier-than-air, called aerodynes.
Aerostats use buoyancy to float in the air in much the same way that ships float on the water. They are characterized by one or more large gasbags or canopies, filled with a relatively low density gas such as helium, hydrogen or hot air, which is lighter than the surrounding air. When the weight of this is added to the weight of the aircraft structure, it adds up to the same weight as the air that the craft displaces.
Small hot air balloons called sky lanterns date back to the 3rd century BC and were only the second type of aircraft to fly, the first being kites.
Originally a "balloon" was any aerostat, while the term "airship" was used for large powered aircraft — usually fixed-wing — though none had yet been built. The advent first of powered balloons, called dirigible balloons, and later of rigid hulls allowing a vast increase in size, began to change things. Huge powered aerostats, characterized by a rigid outer framework and separate aerodynamic skin surrounding the gas bags, came to dominate the skies, the Zeppelins being the largest and most famous. There were still no aeroplanes or non-rigid balloons large enough to be called airships, so "airship" came to be synonymous with these great monsters. Then several accidents, such as the Hindenburg disaster in 1937, led to the demise of these large rigid airships due to safety fears. Nowadays we say that a balloon is an unpowered aerostat, whilst an airship is a powered one.
A powered, steerable aerostat is called a dirigible. Sometimes this term is applied only to non-rigid balloons, and sometimes dirigible balloon is regarded as the definition of an airship (which may then be rigid or non-rigid). Non-rigid dirigibles are characterized by a moderately aerodynamic gasbag with stabilizing fins at the back. These soon became known as blimps. During the Second World War, this shape was widely adopted for tethered balloons; in windy weather this both reduces the strain on the tether and stabilizes the balloon. The nickname blimp was adopted along with the shape. In modern times we tend to call any small dirigible or airship a blimp, though a blimp may be unpowered as well as powered.
Heavier-than-air aircraft must find some way to push air or gas downwards, so that a reaction occurs (by Newton's laws of motion) to push the aircraft upwards. This dynamic movement through the air is the origin of the term aerodyne. There are two ways to produce dynamic upthrust: aerodynamic lift, and powered lift in the form of engine thrust.
Aerodynamic lift is the most common, with aeroplanes kept in the air by the forward movement of wings, and rotorcraft by spinning wing-shaped rotors. A wing or a rotor blade is a flat, horizontal surface, usually shaped in cross-section as an aerofoil. To fly it must move forwards through the air; this movement of air over the aerofoil shape deflects air downward to create an equal and opposite upward force, called lift, according to Newton's third law of motion.
With powered lift, the aircraft directs its engine thrust vertically downwards. A pure rocket is not usually regarded as an aerodyne, because it does not depend on the air for its lift (and can even fly into space), however many aerodynamic lift vehicles have been powered or assisted by rocket motors. Rocket-powered missiles which obtain aerodynamic lift at very high speed due to airflow over their bodies, are a marginal case.
The initialism VTOL (vertical take off and landing) is applied to aircraft that can take off and land vertically. Most are rotorcraft. Others, such as the Hawker Siddeley Harrier, take off and land vertically using powered lift and transfer to aerodynamic lift in steady flight. STOL stands for short take off and landing.
Aeroplanes or airplanes are technically called fixed-wing aircraft.
Aeroplanes are generally characterized by their wing configuration.
In a conventional configuration, the main wings are placed in front of a smaller stabilizer surface or tailplane. The canard reverses this, placing a small foreplane stabilizer forward of the wings, near the nose of the aircraft. Canards are becoming more common as supersonic aerodynamics grows more mature and because the forward surface contributes lift during straight-and-level flight. The tandem wing type has two wings of similar size, one at the front and one at the back. In a tailless design, the lift and horizontal control surfaces are combined. The ultimate expression of this is the flying wing, where there is no central fuselage, and perhaps even no separate vertical control surface (e.g. the B-2 Spirit).
Sometimes two or more wings are stacked one above the other. A biplane has two wings and a triplane three, while quadruplanes (four) and above have been tried but have never been successful. Up until the 1930's, biplanes were the most common. Triplanes were only occasionally made, especially for a brief period during the First World War due to their high manoeuvrability as fighters. Since the Second World War, most aeroplanes have been monoplanes. A sesquiplane is similar to a biplane, but with the lower wing much reduced in size. A monoplane has only one wing. Monoplanes are further classified as high-wing, mid-wing or low-wing, according to where on the fuselage the wing is attached.
Most multi-plane designs are braced, with struts and/or wires holding the wings in place. Some monoplanes, especially early designs, are also braced, because this allows a much lighter weight than a clean, unbraced cantilever design. But bracing causes a large amount of drag at higher speeds, so it is no longer used for faster designs.
Most low-speed aeroplanes have a straight wing, which may be constant-chord, or tapered so that it decreases in chord towards the tip. For flight near or above the speed of sound, a swept wing is usually used, where the wing angles backwards towards the tips (though forward sweep is occasionally experimented with, and M-wing designs which reverse direction half way along have been suggested). A notable variation is the delta wing, which is shaped like a triangle: the leading edge is sharply swept, but the trailing edge is straight; one common form is the cropped delta, which merges into the tapered swept category, and an especially graceful form is the double-curved ogival delta found for example on Concorde. Another variation is the crescent wing, seen for example on the Handley Page Victor, which is sharply swept inboard, with reduced sweep for the outboard section. A variable-geometry wing, or swing-wing, can change the angle of sweep in flight. It has been employed in a few examples of combat aircraft, the first production type being the General Dynamics F-111.
Seaplanes and Floatplanes differ in that a seaplane has the bottom of its fuselage shaped hydrodynamically and it sits directly on the water when at rest, while a floatplane has two or more floats attached below the rest of the aircraft so that the fuselage remains clear of the water at all times.
Some people consider wing-in-ground-effect vehicles to be aeroplanes, others do not. These craft "fly" close to the surface of the ground or water. An example is the Russian ekranoplan also nicknamed the "Caspian Sea Monster". Landings of large propeller or jet-engined aircraft or a hang glider invovles a flight sector where ground-effect flying occurs (same for many bird landings); such ground-effecting does not stop the aircraft from being aeroplanes. Man-powered aircraft also rely on ground effect to remain airborne, but this is only because they are so underpowered - the airframe is theoretically capable of flying much higher. (Hovercraft are not considered to be aircraft, since they rely wholly on the pressure of air on the ground beneath, and have no aerodynamic lifting surface).
Rotorcraft, or rotary-wing aircraft, use a spinning rotor with aerofoil section blades (a rotary wing) to provide lift. Types include helicopters, autogyros and various hybrids such as gyrodynes and compound rotorcraft.
Helicopters have powered rotors. The rotor is driven (directly or indirectly) by an engine and pushes air downwards to create lift. By tilting the rotor forwards, the downwards flow is tilted backwards, producing thrust for forward flight.
Autogyros or gyroplanes have unpowered rotors, with a separate power plant to provide thrust. The rotor is tilted backwards. As the autogyro moves forward, air blows upwards through it, making it spin.(cf. Autorotation) This spinning dramatically increases the speed of airflow over the rotor, to provide lift. Juan de la Cierva (a Spanish civil engineer) used the product name autogiro, and Bensen used gyrocopter. Rotor kites, such as the Focke Achgelis Fa 330 are unpowered autogyros, which must be towed by a tether to give them forward ground speed or else be tether-anchored to a static anchor in a high-wind situation for kited flight.
Gyrodynes are a form of helicopter, where forward thrust is obtained from a separate propulsion device rather than from tilting the rotor. The definition of a 'gyrodyne' has changed over the years, sometimes including equivalent autogyro designs. The most important characteristic is that in forward flight air does not flow significantly either up or down through the rotor disc but primarily across it. The Heliplane is a similar idea.
Some rotorcraft have reaction-powered rotors with gas jets at the tips, but most have one or more lift rotors powered from engine-driven shafts.
Some types of aircraft, such as balloons, kites, hang glider, andgliders, do not have any propulsion (although, the same crafts frequently are used as the base of a powered situation: powered Goodyear blimp, motorized Rogallo hang glider, motorglider, etc.).
Kites are tethered to the ground or other object (fixed or mobile) or other means that maintains tension in the kite line; and rely on virtual or real wind blowing over and under them to generate lift and drag.
Kytoons can be lighter-than-air, neutrally buoyant, or heavier-than air--they are balloon kites that are shaped and tethered to obtain kiting deflections.
Paragliders are true free-flight kite systems; the many kite lines to the wing maintain tension by the mobile falling hanging pilot. The wing may also be kited by way of powering the anchor; this does not alter that the wing remains unpowered; the wing and lines are unpowerd, but the total in-air system has an active powering.
Gliders gain their initial thrust from some launch mechanism, and then gain energy from gravity and thermal currents. Takeoff takes place from a high location, or the aircraft is pulled into the air by a ground-based winch or vehicle, or towed aloft by a powered "tug" aircraft. For a glider to maintain its forward air speed and lift, it must descend in relation to the air (but not necessarily in relation to the ground). The first practical example was designed and built by the British scientist and pioneer George Cayley who is universally recognised as the first aeronautical engineer.
A propeller comprises a set of small, wing-like aerofoils set around a central hub and aligned in the direction of travel. Spinning the propeller creates aerodynamic lift, or thrust, in a forward direction. A contra-prop arrangement has a second propeller close behind the first one on the same axis, which rotates in the opposite direction.
Some very early attempts were made to make lightweight steam engines capable of powering an aircraft. There is some evidence that (name needed) may have succeeded in making a flying model, but this has never been confirmed.
Turbine engines need not be used as jets (see below), but may be geared to drive a propeller in the form of a turboprop. Modern helicopters also typically use turbine engines to power the rotor.
A variation on propellers is to use many broad blades to create a fan. These fans are traditionally surrounded by a ring-shaped fairing or duct, as ducted fans. Some experimental designs do not use a duct, and are sometimes called propfans. How to tell whether it's a propellor or a fan? Look at it from the front when stationary: if you can see in between the blades then it is a propellor, while if the blades pretty much block the view it is a fan.
During the 1940's and especially following the 1973 energy crisis, development work was done on propellers and propfans with swept tips or even curved "scimitar-shaped" blades for use in high-speed commercial and military transports.
Jet engines provide thrust by taking in air, burning it with fuel, and accelerating the exhaust rearwards so that it ejects at high speed. The reaction against this acceleration provides the engine thrust.
Jet engines can provide much higher thrust than propellers, and are naturally efficient at higher altitudes, being able to operate above 40000 ft. They are also much more fuel-efficient than rockets. Consequently, nearly all high-speed and high-altitude aircraft use jet engines.
The early turbojet and modern turbofan (frequently a bypass turbofan) use a spinning turbine to create airflow for takeoff and to provide thrust, but this is not absolutely necessary. Many, mostly in military aviation, use afterburners. Other designs include the crude pulse jet, high-speed ramjet and the still-experimental supersonic-combustion ramjet or scramjet. These designs require an existing airflow to work and cannot work when stationary, so they must be launched by a catapult or rocket booster, or dropped from a mother ship. The bypass turbofan engines of the Lockheed blackbird were a hybrid design - the aircraft took off and landed in jet turbine configuration, and for high-speed flight the turbine was bypassed and the afterburners used in order to form a ramjet. The motorjet used a piston engine in place of the turbine - it was superseded by the turbojet and remained a curiosity.
The major distinction in aircraft usage is between military aviation, which includes all uses of aircraft for military purposes (such as combat, patrolling, search and rescue, reconnaissance, transport, and training), and civil aviation, which includes all uses of aircraft for non-military purposes.
Combat aircraft like fighters or bombers represent only a minority of the category. Many civil aircraft have been produced in separate models for military use, such as the civil Douglas DC-3 airliner, which became the military C-47/C-53/R4D transport in the U.S. military and the "Dakota" in the UK and the Commonwealth. Even the small fabric-covered two-seater Piper J3 Cub had a military version, the L-4 liaison, observation and trainer aircraft. In the past, gliders and balloons have also been used as military aircraft; for example, balloons were used for observation during the American Civil War and World War I, and cargo gliders were used during World War II to land troops.
Combat aircraft themselves, though used a handful of times for reconnaissance and surveillance during the Italo-Turkish War, did not come into widespread use until the Balkan War.
During World War I many types of aircraft were adapted for attacking the ground or enemy vehicles/ships/guns/aircraft, and the first aircraft designed as bombers were born. In order to prevent the enemy from bombing, fighter aircraft were developed to intercept and shoot down enemy aircraft. Tankers were developed after World War II to refuel other aircraft in mid-air, thus increasing their operational range. By the time of the Vietnam War, helicopters had come into widespread military use, especially for transporting, supplying, and supporting ground troops.
Civil aviation broadly divides into commercial and general activities, however there can be some overlap in practice.
Commercial aviation includes scheduled and charter airline flights. It also overlaps with a certain amount of general aviation activity where aircraft are offered for hire.
General aviation is a catch-all covering other kinds of private and commercial use. The vast majority of flights flown around the world each day belong to the general aviation category, which covers a wide range of activities such as business trips, civilian flight training, recreational balloon flying, firefighting, medical transport (medevac) flights, and cargo transportation on freight aircraft, to name a few. Within general aviation, the major distinction is between private flights (where the pilot is not paid for time or expenses) and commercial flights (where the pilot is paid by a customer or employer). Private pilots use aircraft primarily for personal travel, business travel, or recreation. Usually these private pilots own their own aircraft and take out loans from banks or specialized lenders to purchase them. Commercial general aviation pilots use aircraft for a wide range of tasks, such as flight training, pipeline surveying, passenger and freight transport, policing, crop dusting, and medevac flights. Piston-powered propeller aircraft (single-engine or twin-engine) are especially common for both private and commercial general aviation, but even private pilots occasionally own and operate helicopters like the Bell JetRanger or turboprops like the Beechcraft King Air. Business jets are typically flown by commercial pilots, although there is a new generation of small jets arriving soon for private pilots.
In layman's terms, experimental aircraft are one-off specials, built to explore some aspect of aircraft design and with no other useful purpose. The Bell X-1 rocket plane, which first broke the sound barrier in level flight, is a famous example.
The formal designation of "Experimental aircraft" also includes other types which are "not certified for commercial applications", including one-off modifications of existing aircraft such as the modified Boeing 747 which NASA uses to ferry the space shuttle from landing site to launch site, and aircraft homebuilt by amateurs for their own personal use.
A model aircraft is a small copy of some larger aircraft design. Models may be made to fly for fun, for static display, or for serious aerodynamic research (cf Reynolds number).
Aircraft builders frequently build small aircraft that are not simply small copies of some larger aircraft--both in hobby and in industrial exploratory efforts. Rather, they just build aircraft. The group of inventors (Inventors: Tyler MacCready, Martyn B. Cowley, Taras Kiceniuk, Jr. Parker MacCready, Walter R. Morgan, Matthew R. Kruse) together came up with the WalkAlong Glider which is not a model for any larger aircraft. Tyler MacCready's Walkalong Glider and US Patent 5100357.
Within any general category, aircraft are usually listed according to manufacturer and production type.
Aircraft generate considerable amounts of noise pollution and air pollution emissions. Since the 1960s the U S Environmental Protection Agency has developed emissions factors for the most commonly used aircraft; in 1972 the Federal Aviation Administration developed a computer model for prediction of air pollution concentrations produced by aircraft in flight.


Rephlex Records was co-founded by Aphex Twin with his friend Grant Wilson-Claridge in 1991.
Richard David James was born of Welsh parents Lorna and Derek James at 5:00 AM on August 18, 1971 in St. Munchins Limerick Regional Maternity Hospital, Ireland. James grew up in Lanner, Cornwall, England, enjoying, along with two older sisters a "very happy" childhood during which they, according to James, "were pretty much left to do what [they] wanted." He "liked growing up there, being cut off from the city and the rest of the world." James was educated at the Redruth School located in Redruth, Cornwall.
As a child he experimented on the strings and hammers of the family piano. According to Benjamin Middleton, James started producing music at the age of 12. As a teenager he DJed at the Shire Horse in St Ives, with Tom Middleton at the Bowgie Inn in Crantock, and also along the numerous beaches around Cornwall. From age 16 to 18 James studied for a National Diploma in Engineering from 1988 to 1990 in Cornwall College. James describing his course has said "music and electronics went hand in hand". According to his teachers he passed the course, although he listened to his mixes on his headphones during practical lessons.
James met Grant Wilson-Claridge in 1989, while they were DJing on alternate weeks at the Bowgie in Newquay, Cornwall. Wilson-Claridge was intrigued by James' sets and was later surprised to discover that James was playing tapes of his own music.
Richard James's first record was the 12-inch EP Analogue Bubblebath released as AFX, the track "En Trance to Exit" was made with Tom Middleton aka Schizophrenia.
It was played on the KISS FM playlist, an influential London pirate station, which helped the EP become a success.
Between 1991 and 1993, James released two Analogue Bubblebath EPs under the name of AFX and a Bradley Strider EP under "Bradley Strider". He would also record tracks during this time that appeared on his later releases,.I Care Because You Do and GAK. Early in his career, James moved to London to take an electronics course at Kingston Polytechnic, but at the time admitted to David Toop that his "electronics studies were already slipping away as a career in the techno business took precedence". After quitting his course, James remained in London and released a number of albums and EPs on Warp Records and other labels under many aliases, including AFX, Polygon Window, and Power-Pill. A number of Richard's tracks (released under the aliases Blue Calx, The Dice Man, and others) were also included in various compilations during this time. Local legend has it that James lived on the roundabout in Elephant and Castle, South London during his early years in the capital.
The first full-length Aphex Twin album, Selected Ambient Works 85-92, was released in 1992 on R&S Records. John Bush of the All Music Guide described it as a "watershed of ambient music". Rolling Stone magazine wrote of the album: "Aphex Twin expanded way beyond the ambient music of Brian Eno by fusing lush soundscapes with oceanic beats and bass lines". Critics also noted that the songs were recorded on cassette and that the sound quality was "relatively poor". Warp Records has billed the album as "both the birthplace and the benchmark of modern electronic music.. every home should have a copy." In 1992, he also released the Xylem Tube EP and Digeridoo as Aphex Twin, as Power-Pill the Pac-Man EP based on the arcade game Pac-Man, and two of his four Caustic Window EPs. Digeridoo reached #55 on the UK charts, and was later described as forshadowing drum and bass by Rolling Stone. Digeridoo was recorded initially for the benefit of FIZZ-BOMB (at the Shire Horse, St Ives, Cornwall). These early releases came out on Rephlex Records, Mighty Force of Exeter, and R&S Records of Belgium.
In 1993, Aphex released his third installment in the Analogue Bubblebath series, an ambient single On, his second Bradley Strider EP, two more Caustic Window EPs, and his first releases on Warp Records, Surfing on Sine Waves and Quoth under the alias Polygon Window.
Warp Records pressed and released a follow-up to SAW85-92, Selected Ambient Works Volume II in 1994. The sound was much less beat-driven than the previous volume. Except for one song explicitly named "Blue Calx", all of the track names were described with pie chart symbols, each of which was meant to be paired with a corresponding image in the album jacket. To decipher song titles, listeners had to pair each numbered symbol with the correct image (for example, the first title, which is often labeled "cliffs", is realized by pairing the first symbol with the first image, which is that of a rocky cliffside). James stated in The Wire magazine and other media that these songs were inspired by lucid dreams and synesthesia. 1994 would also include a string of other releases including his fourth Analogue Bubblebath, GAK, derived from early demos sent to Warp Records and Classics, a compilation album that includes the Digeridoo single, the Xylem Tube EP, along with some other previously unreleased tracks.
For his 1995 release,.I Care Because You Do, James used an image of his face for the album cover; a motif that would continue on many of his later records. The album was a compilation of songs composed between 1990 and 1994, and represented a mish-mash of Aphex Twin's various music styles. This was Aphex Twin's last record of the 1990s to use mostly analogue synthesizers. Aphex Twin collaborated with minimalist composer Philip Glass to make an orchestral version of one of the songs from this album, "Icct Hedral", which appeared on the Donkey Rhubarb EP. In 1995, two releases Melodies from Mars and Analogue Bubblebath 5 were recorded but not released.
In 1995 (primarily with Hangable Auto Bulb, a near anagram of Analogue Bubblebath), he began releasing more material composed on computers, combining a jungle sound with nostalgic childhood themes and strange computer-generated acid lines. Aphex Twin's early adoption of software synthesizers predated the later popularity of using computers to make music. The late 1990s saw his music become more popular and mainstream, as he released the Richard D. James Album (which included the previously released Girl/Boy EP), and Expert Knob Twiddlers (a collaboration with fellow dance producer u-ziq) in 1996, "Come to Daddy" in 1997 (#36 on UK charts) and "Windowlicker" in 1998 (#16 on UK charts), both of which were shown on MTV and became cover features for music magazines such as NME. The videos for both singles were directed by British artist Chris Cunningham and caused controversy on their release due to disturbing images and themes.
In 1997, a companion to Analogue Bubblebath 3 was released, Analogue Bubblebath 3.1.
In 2001 Aphex Twin released his most personal album yet, drukqs, a 2-CD album which featured prepared piano songs influenced by Erik Satie and John Cage. It is notable that many of the tracks names are written in the Cornish language (e.g. 'jynweythek' translatable as 'machinemusic'). Also included were abrasive, fast and meticulously programmed computer-made songs. Rolling Stone described the piano songs as "aimlessly pretty". Some reviewers concluded that drukqs was released as a contract breaker with Warp Records—a credible guess, as James' next big release came out on his own Rephlex label. Richard told the interviewers he had left almost all the album's tracks on an MP3 player that he accidentally left on a plane with "Aphex Twin - unreleased tracks" written on it, and rushed its release to pre-empt an Internet leak.
In late 2004, rumours of James' return to an acid techno based sound were realised with the Analord series. This series concentrated on producing fully analogue pieces of music, written and recorded on analogue equipment and pressed to vinyl. James was very meticulous about the whole process of recording, mastering and pressing. However, label co-owner Grant Wilson-Claridge convinced James to release a digital CD, Chosen Lords, which included a selection from the Analord series, with some tracks slightly altered to improve the flow of the album.
For the Analord records, James used his extensive collection of Roland drum machines which he bought when they were still at bargain prices. He also used one of the rarest and most desirable synthesizers of his generation, the Synton Fenix, and the notoriously difficult to program Roland MC-4 sequencer (a sequencer with a reputation for excellent timing), as well as the famous Roland TB-303 for his trademark acid melodies.
Recently, rumors in the media suggest Aphex Twin is now recording under one or more secret new aliases, such as The Tuss.
In late February 2008 it was confirmed that James would be headlining Ireland's very own Oxegen Festival. This has led to a mass registration on the festival website with demand for tickets reaching a new high. It was also announced that Aphex Twin is part of the confirmed lineup for T in the Park 2008. He will also be playing the Bestival in September this year. Aphex Twin was a late addition to perform at the 2008 Coachella Valley Music and Arts Festival.
The name "Aphex Twin" is derived from Aphex Systems Limited, a brand of audio signal processing equipment. It is used with permission, as was recognized on the back sleeve of his Richard D. James and Drukqs albums. He has explained in interviews that the 'Twin' is in memory of his brother, also named Richard James, who died at birth.
James usually creates his own photography for his releases' artwork. Many of these photos show James' own face, grinning or slightly distorted in some way, as it can be seen in some of his videoclips ("Come to Daddy", for example). Towards the end of the second track on the "Windowlicker" single (commonly referred to as "Equation") a photo of James' face is revealed when run through spectral analysis. The picture illustrates his famous toothy, evil grin (with a spiral also visible at the end of "Windowlicker").
At age 17, Richard D. James mentioned these influences: "Phonic Bod, Computer World, Mental Telepathy, Industrial Inc, Tomita, Tangerine Dream". Of note regarding this is that Mixmaster Morris mentions on the "I Luv AFX" BBC Radio 1 Breezeblock session that James' preferred moniker whilst DJ'ing in Cornwall was Phonic Boy on Dope. More recently, he has said that he gets inspiration from "everyday sounds that can be emulated / reconstructed electronically, quality techno, especially from Europe which overshadows the current hardcore pop crap". When asked about what is next for electronic music, he said "acid-techno, ambient-techno".
James was influenced by Chicago house and Detroit techno pioneers like Derrick May and Kevin Saunderson. Other house and acid house influences include A Guy Called Gerald, Mr. Fingers, 808 State, Lil Louis.
Avante Garde music is a big influence for James as well, including Brian Eno, Kraftwerk, Can, Neu! Tangerine Dream, Karlheinz Stockhausen, Tod Dockstader, Xenakis, Piero Umiliani, Bernard Parmegiani, John Cage, the French composer Erik Satie for his piano works and his innovation ideas for furniture music (a precursor to ambient music).
The BBC Radiophonic workshop influenced Aphex Twin, and he released a compilation of music recorded by the pioneers of that studio, for example Delia Derbyshire, called Music from the BBC Radiophonic Workshop on his own Rephlex Records label.
Many songs include sounds from and references to the ZX Spectrum. For instance, "Carn Marth" from the Richard D. James Album includes the tape loading noise of the game Sabre Wulf.
Richard has stated in many interviews that he listens to the Japanese experimental musician Merzbow.
Future Music: What pisses you off about the current music scene?
Aphex Twin: Too many sheep and not enough shephards. Let's all sit back and have a long hard think, then make something different! We can all do it, surely?
The London Sinfonietta has performed arrangements of Aphex Twin. In 2005, the orchestra Alarm Will Sound released Acoustica: Alarm Will Sound Performs Aphex Twin. The album consists of acoustic arrangements of some of James' electronic tracks.
The mathcore band The Dillinger Escape Plan has covered "Come to Daddy" on one of their EPs, Irony is a Dead Scene, that featured Mike Patton as vocalist. The jazz ensemble The Bad Plus covered "Flim" on their album These Are the Vistas. Additionally, Future Rock has performed "Alberto Balsalm" (from..I Care Because You Do") live as a multi-instrumental set.
Richard's own Rephlex Records label, which he co-owns with Grant Wilson-Claridge, created the term "Braindance" to describe Aphex Twin's music beginning in 1991. "Braindance" applies to "forward-thinking" electronic music that can appeal to the listener's brain as well as their desire to dance and party. Examples including Ed-DMX's Breakin' records label, µ-Ziq's Planet-mu label, the Aphex Twin EP Come To Daddy and Astrobotnia Parts 1, 2 & 3. It encompasses elements of a variety of genres, including traditional, classical, electronic music, popular, modern, industrial, ambient, hip hop, electro, house, techno, breakbeat, hardcore, ragga, garage, drum and bass, etc.
Aphex Twin said he composed ambient techno music at the age of 13; he has "over 100 hours" of unreleased music; he made his own software to compose with, including algorithmic processes which automatically generate beats and melodies; he experiences synesthesia; and he is able to incorporate lucid dreaming into the process of making music.
James owns a 1950s armoured scout car, the Daimler Ferret Mark 3, and a submarine bought from Russia. He lives in southeast London in a converted bank, which was formerly the Bank of Cyprus and then HSBC. Contrary to popular opinion, however, he does not own the silver structure in the centre of the roundabout at Elephant and Castle. This is, in fact, the Michael Faraday Memorial, containing a power transformer for the Northern Line, which James jokingly claimed to be buying in an interview with The Face magazine in 2001.
He was called by some "a child prodigy" and has been raised to a mythical status with these and other types of stories, including that he nearly precluded John Cage with his youthful experimentation using a piano in his own tunings or plucking the strings instead. Some of these rumors are hard to confirm as he has been known to spread mistruths in the prankster tradition making such claims as only sleeping two to three hours a night.
Aphex Twin provided all 3 of the tracks, [rhubarb] (SAW II), Xtal (SAW 85-92), and [parallel stripes] (SAW II), in the BBC's digital widescreen test transmission, broadcast on a loop in the UK during November 1998 and early 2002.
In November of 1995, "The Wire" wrote an article entitled "Advice to Clever Children".
A package of tapes containing music from several artists, including Aphex Twin, was sent to the German composer Karlheinz Stockhausen.
By displaying changing patterns of color on the monitor (in the case of the Spectrum, as with many early personal computers, the display monitor was a television), the natural hum from the cathode ray tube was modulated, producing a semblance of melody.
In May 2006 the artist Tahnaiya Russell (a surreal artist who cites Aphex Twin as an influence in her biography ) won the remix competition in Future Music magazine. Tahnaiya Russell's remix of the Luke Vibert track was deemed by Vibert himself to be the best of the submissions ("Relaxed and sophisticated, but with large balls and huge bass"). Richard James revealed to the magazine that he had entered under the alias, but was unaware he had actually won, and the prize of sample CDs was instead awarded to runner-up Michael Stephens. This might be another confusion as Tahnaiya Russell's website seems to belong to a real person who is also a photographer.
In an interview with Japan's Snoozer magazine in 2001, James stated that his favorite instruments were his piano, laptop computer, and the Synton Fenix.
In one of his older interviews in the nineties, Richard said he used Pro Tools and "stuff like that", though he is known to have used Cubase around the time of the "Richard D James" album. In the same interview, he reveals that he has "homemade" equipment which covered software programs written by himself and synthesisers and various hardware devices he built when he was younger.
Richard D. James studied electronics in Cornwall College and Kingston Polytechnic in London. He built his own synthesizers and samplers in his early years, he has also modified and circuit bent his equipment. James also programmed his personal music software algorithm.


Alfred Bernhard Nobel (October 21, 1833, Stockholm, Sweden – December 10, 1896, Sanremo, Italy) was a Swedish chemist, engineer, innovator, armaments manufacturer and the inventor of dynamite. He owned Bofors, a major armaments manufacturer, which he had redirected from its previous role as an iron and steel mill. In his last will, he used his enormous fortune to institute the Nobel Prizes. The synthetic element nobelium was named after him.
Nobel was the third son of Immanuel Nobel (1801-1872) and Andriette Ahlsell Nobel (1805-1889). Born in Stockholm on October 21 1833, he went with his family in 1842 to St. Petersburg, where his father (who had invented modern plywood) started a "torpedo" works. Alfred studied chemistry with Professor Nikolay Nikolaevich Zinin. In 1859, the factory was left to the care of the second son, Ludvig Nobel (1831-1888), who greatly enlarged it. Alfred, returning to Sweden with his father after the bankruptcy of their family business, devoted himself to the study of explosives, and especially to the safe manufacture and use of nitroglycerine (discovered in 1847 by Ascanio Sobrero, one of his fellow students under Théophile-Jules Pelouze at the University of Torino). Several explosions occurred at their family-owned factory in Heleneborg; one disastrous one killed Alfred's younger brother Emil and several other workers in 1864.
The foundations of the Nobel Prize were laid in 1895 when Alfred Nobel wrote his last will, leaving much of his wealth for its establishment. Since 1901, the prize has honored men and women for outstanding achievements in physics, chemistry, medicine, literature, and for work in peace.
In 1876 Bertha von Suttner became Alfred Nobel's secretary but after only a brief stay, left and married Baron Arthur Gundaccar von Suttner. Though her personal contact with Alfred Nobel had been brief, she corresponded with him until his death in 1896, and it is believed that she was a major influence in his decision to include a peace prize among those prizes provided in his will, which she won in 1905.
Nobel also wrote Nemesis, a prose tragedy in four acts about Beatrice Cenci, partly inspired by Percy Bysshe Shelley's The Cenci, was printed while he was dying. The entire stock except for three copies was destroyed immediately after his death, being regarded as scandalous and blasphemous. The first surviving edition (bilingual Swedish-Esperanto) was published in Sweden in 2003. The play has been translated to Slovenian via the Esperanto version.
Alfred Nobel is buried in Norra begravningsplatsen in Stockholm.
Nobel found that when nitroglycerin was incorporated in an absorbent inert substance like kieselguhr (diatomaceous earth) it became safer and more convenient to handle, and this mixture he patented in 1867 as dynamite. Nobel demonstrated his explosive for the first time that year, at a quarry in Redhill, Surrey, England.
Nobel later on combined nitroglycerin with another explosive, gun-cotton, and obtained a transparent, jelly-like substance, which was a more powerful explosive than dynamite. Gelignite, or blasting gelatin as it was branded, was patented in 1876, and was followed by a host of similar combinations, modified by the addition of potassium nitrate and various other substances.
The erroneous publication in 1888 of a premature obituary of Nobel by a French newspaper, condemning him for his invention of dynamite, is said to have brought about his decision to leave a better legacy after his death. The obituary stated Le marchand de la mort est mort ("The merchant of death is dead") and went on to say, "Dr. Alfred Nobel, who became rich by finding ways to kill more people faster than ever before, died yesterday." On November 27, 1895, at the Swedish-Norwegian Club in Paris, Nobel signed his last will and testament and set aside the bulk of his estate to establish the Nobel Prizes, to be awarded annually without distinction of nationality. He died of a stroke on December 10, 1896 at Sanremo, Italy. He left 31 million kronor (4,223,500 USD1896~103,931,888 USD2007) to fund the prizes.
The first three of these prizes are awarded for eminence in physical science, chemistry and medical science or physiology; the fourth is for literary work "in an ideal direction" and the fifth is to be given to the person or society that renders the greatest service to the cause of international fraternity, in the suppression or reduction of standing armies, or in the establishment or furtherance of peace congresses.
The formulation about the literary prize, "in an ideal direction" (i idealisk riktning in Swedish), is cryptic and has caused much confusion. For many years, the Swedish Academy interpreted "ideal" as "idealistic" (idealistisk) and used it as a pretext to not give the prize to important but less romantic authors, such as Henrik Ibsen, August Strindberg and Leo Tolstoy. This interpretation has since been revised, and the prize has been awarded to, for example, Dario Fo and José Saramago, who definitely do not belong to the camp of literary idealism.
There was also quite a lot of room for interpretation by the bodies he had named for deciding on the physical sciences and chemistry prizes, given that he had not consulted them before making the will. In his one-page testament, he stipulated that the money go to discoveries or inventions in the physical sciences and to discoveries or improvements in chemistry. He had opened the door to technological awards, but had not left instructions on how to deal with the distinction between science and technology. Since the deciding bodies he had chosen were more concerned with the former, it is not surprising that the prizes went to scientists and not to engineers, technicians or other inventors. In a sense, the technological prizes announced recently by the World Technology Network (not funded by the Nobel foundation) indirectly fill this gap.
In 2001, his great-grandnephew, Peter, asked the Bank of Sweden to differentiate its award to economists given "in Alfred Nobel's memory" from the five other awards. This has caused much controversy whether the prize for Economics is actually a "Nobel Prize" (see Bank of Sweden Prize in Economic Sciences in Memory of Alfred Nobel).


Alexander Graham Bell (3 March 1847 – 2 August 1922) was an eminent scientist, inventor and innovator who is often associated with the invention of the telephone. His father, grandfather and brother had all been associated with work on elocution and speech, and both his mother and wife were deaf, profoundly influencing Bell's life's work. His research on hearing and speech further led him to experiment with hearing devices that eventually culminated in Bell being awarded the first U.S. patent for the invention of the telephone in 1876.
Alexander Bell was born in Edinburgh, Scotland on 3 March 1847. Throughout his early life, Bell was a British subject. The family home was at 16 South Charlotte Street, Edinburgh and has a commemorative marker at the doorstep, marking this as Alexander Graham Bell's birthplace. He had two brothers: Melville James Bell (1845–1870) and Edward Charles Bell (1848–1867). Both of his brothers died of tuberculosis, Edward in 1867 and Melville in 1870. His father was Professor Alexander Melville Bell, and his mother was Eliza Grace (nee Symonds). Although he was born "Alexander", at age ten he made a plea to his father to have a middle name like his two brothers. For his 11th birthday, his father acquiesced and allowed him to adopt the middle name "Graham" chosen out of admiration for Alexander Graham, a Canadian being treated by his father and boarder who had become a family friend. To close relatives and friends he remained "Aleck" which his father continued to call him into later life.
From his early years, Bell showed a sensitive nature and a talent for art, poetry and music that was encouraged by his mother. With no formal training, he mastered the piano and became the family's pianist. Despite being normally quiet and introspective, he revelled in mimicry and "voice tricks" akin to ventriloquism that constantly entertained family guests. Bell was also deeply affected by his mother's gradual deafness (she began to lose her hearing when he was 12) and learned a manual finger language so he could sit at her side and tap out silently the conversations swirling around the family parlour. He also developed a technique of speaking in clear, modulated tones directly into his mother's forehead wherein she would hear him with reasonable clarity. Bell's preoccupation with his mother's deafness led him to study acoustics.
His family was associated with the teaching of elocution: his grandfather, Alexander Bell, in London, his uncle in Dublin, and his father, in Edinburgh, were all elocutionists. His father published a variety of works on the subject, several of which are still well known, especially his The Standard Elocutionist (1860) and treatise on Visible Speech, which appeared in Edinburgh in 1868. The Standard Elocutionist appeared in 168 British editions and sold over a quarter of a million copies in the United States alone. In this treatise, he explains his methods of how to instruct deaf-mutes (as they were then known) to articulate words and read other people's lip movements to decipher meaning. Aleck's father taught him and his brothers not only to write Visible Speech but also to identify any symbol and its accompanying sound. Aleck became so proficient that he became part of his father's public demonstrations and astounded audiences with his abilities in deciphering Latin, Gaelic and even Sanskrit symbols.
As a young child Bell, like his brothers, received his early schooling at home from his father. At an early age, however, he was enrolled at the Royal High School, Edinburgh, Scotland, which he left at age 15, completing the first four forms only. His school record was undistinguished, marked by absenteeism and lacklustre grades. His main interest remained in the sciences, especially biology with other school subjects treated with indifference, to the dismay of his demanding father. Upon leaving school, Bell went to London to live with his grandfather, Alexander Bell. During the year he spent with his grandfather, a love of learning was born, with long hours spent in serious discussion and study. The elder Bell took great efforts to have his young pupil learn to speak clearly and with conviction, the attributes that his pupil would need to become a teacher himself. At age 16, Bell secured a position as a "pupil-teacher" of elocution and music, in Weston House Academy, at Elgin, Moray, Scotland. Although he was enrolled as a student in Latin and Greek, he instructed in return for board and £10 per session. The following year he attended the University of Edinburgh; joining his older brother Melville who had enrolled there the previous year, and where Aleck intended to write exams but later graduated from the University of Toronto.
Bell's father encouraged Aleck's interest in speech and in 1863, took his sons to see a unique automaton, developed by Sir Charles Wheatstone based on the earlier work of Baron Wolfgang von Kempelen. The rudimentary "mechanical man" simulated a human voice. Aleck was fascinated by the machine and after he obtained a copy of von Kempelen's book published in Germany and had laboriously translated it, Aleck and his older brother Melville built their own automaton head. Their father, highly interested in their project, offered to pay for any supplies and spurred the boys on with the enticement of a "big prize" if they were successful. While his brother constructed the throat and larynx, Aleck tackled the more difficult task of recreating a realistic skull. His efforts resulted in a remarkably lifelike head that could "speak," albeit only a few words. The boys would carefully adjust the "lips" and when a bellows forced air through the windpipe, a very recognizable "Mama" ensued, to the delight of neighbors who came to see the Bell invention.
In 1865, when the Bell family moved to London, Bell returned to Weston House as an assistant master and in his spare hours, continued experiments on sound using a minimum of laboratory equipment. Bell concentrated on experimenting with electricity to convey sound and later installed a telegraph wire from his room in Somerset College to that of a friend. Throughout the fall and winter, his health faltered mainly through exhaustion. His younger brother, Edward "Ted" was similarly bed-ridden, suffering from tuberculosis. While Bell recovered (now referring to himself in correspondence as "A.G. Bell") and served the next year as an instructor at Somerset College, Bath, Somerset, England, his brother's condition deteriorated. Edward would never recover. Upon his brother's passing, Bell returned home in 1867. His older brother, "Melly" had married and moved out. With aspirations to obtain a degree at the University of London, Bell considered his next years as preparation for the degree examinations, devoting his spare time at his family's residence to studying.
Helping his father in Visible Speech demonstrations and lectures brought Bell to Susanna E. Hull's private school for the deaf in South Kensington, London. His first two pupils were "deaf mute" girls who made remarkable progress under his tutelage. While his older brother seemed to achieve success on many fronts including setting up his own school for elocution, applying for a patent on an invention, and beginning a family, Bell continued as a teacher. In May 1870, Melville died from complications of tuberculosis, causing a family crisis. His father had also suffered a debilitating illness earlier in life and had been restored to health by a convalescence in Newfoundland. Bell's parents precipitated a long-planned move when they realized that their remaining son was also sickly. Making a swift judgement, Alexander Melville Bell asked Bell to arrange for the sale of all the family property, conclude all of his brother's affairs (Bell took over a last student, curing a pronounced lisp) and join his father and mother in setting out for the "New World." Reluctantly, Bell also had to conclude a relationship with Marie Eccleston, whom he surmised was not prepared to leave England with him.
In 1870, at age 23, Bell, his brother's widow, Caroline (Margaret Ottaway), and his parents travelled on the SS Nestorian to Canada. After landing at Quebec City, the Bells boarded a train to Montreal and later to Paris, Ontario to stay with the Reverend Thomas Henderson, a family friend. After a brief stay with the Hendersons, the Bell family purchased a ten and a half acre farm at Tutelo Heights (now called Tutela Heights), near Brantford, Ontario. The property consisted of an orchard, larger farm house, stable, pigsty, hen-house and carriage house, bordering the Grand River.
At the homestead, Bell set up his own workshop in the converted carriage house near to what he called his "dreaming place," a large hollow nestled in trees at the back of the property above the river. Despite his frail condition upon arriving in Canada, Bell found the climate and environs to his liking, and rapidly improved. He continued his interest in the study of the human voice and when he discovered the Six Nations Reserve across the river at Onondaga, he learned the Mohawk language and translated its unwritten vocabulary into Visible Speech symbols. For his work, Bell was awarded the title of honorary chief and participated in a ceremony where he donned a Mohawk headdress and danced traditional dances.
After setting up his workshop, Bell continued experiments based on Helmholtz's work with electricity and sound. He designed a piano which, by means of electricity, could transmit its music at a distance. Once the family was settled in, both Bell and his father made plans to establish a teaching practice and in 1871, he accompanied his father to Montreal, where Melville was offered a position to teach his System of Visible Speech.
Subsequently, his father was invited by Sarah Fuller, principal of the Boston School for Deaf Mutes (which continues today as the Horace Mann School for the Deaf and Hard of Hearing), in Boston, Massachusetts, United States, to introduce the Visible Speech System by providing training for Fuller's instructors but he declined the post, in favor of his son. Travelling to Boston in April 1871, Bell provided a successful inservicing of the school's instructors. He was subsequently asked to repeat the program at the American Asylum for Deaf-mutes in Hartford and the Clarke School for the Deaf in Northampton.
In the following year, Bell became professor of Vocal Physiology and Elocution at the Boston University School of Oratory. During this period, he alternated between Boston and Brantford, spending summers in his Canadian home. At Boston University, Bell was "swept up" by the excitement engendered by the many scientists and inventors resident in the city. He continued his research in sound and endeavoured to find a way to transmit musical notes and articulate speech, but although absorbed by his experiments, he found it difficult to devote enough time to experimentation. While days and evenings were occupied by his teaching and private classes, Bell began to stay awake late into the night, running experiment after experiment in rented facilities at his boarding house. Keeping up "night owl" hours, he worried that his work would be discovered and took great pains to lock up his notebooks and laboratory equipment. Bell had a specially made table where he could place his notes and equipment inside a locking cover. Worse still, his health deteriorated as he suffered severe headaches. Returning to Boston in fall 1873, Bell made a fateful decision to concentrate on his experiments in sound.
Deciding to give up his lucrative private Boston practise, Bell only retained two students, six-year old "Georgie" Sanders, deaf from birth and 15-year old Mabel Hubbard. Each pupil would serve to play an important role in the next developments. George's father, Thomas Sanders, a wealthy businessman, offered Bell a place to stay at nearby Salem with Georgie's grandmother, complete with a room to "experiment." Although the offer was made by George's mother and followed the year-long arrangement in 1872 where her son and his nurse had moved to quarters next to Bell's boarding house, it was clear that Mr. Sanders was backing the proposal. The arrangement was for teacher and student to continue their work together with free room and board thrown in. Mabel was a bright, attractive girl who was ten years his junior but became the object of Bell's affection. Losing her hearing after a bout of scarlet fever at age five, she had learned to read lips but her father, Gardiner Greene Hubbard, Bell's benefactor and personal friend, wanted her to work directly with her teacher.
By 1874, Bell's initial work on the harmonic telegraph had entered a formative stage with progress made both at his new Boston "laboratory" as well as at his family home in Canada.
While working that summer in Brantford, Bell experimented with a "phonautograph," a pen-like machine that could draw shapes of sound waves on smoked glass by tracing their vibrations. Bell thought it might be possible to generate undulating electrical currents that corresponded to sound waves. Bell also thought that multiple metal reeds tuned to different frequencies like a harp would be able to convert the undulatory currents back into sound. But he had no working model to demonstrate the feasibility of these ideas.
In 1874, telegraph message traffic was rapidly expanding and in the words of Western Union President William Orton, had become "the nervous system of commerce." Orton had contracted with inventors Thomas Edison and Elisha Gray to find a way to send multiple telegraph messages on each telegraph line to avoid the great cost of constructing new lines. When Bell mentioned to Gardiner Hubbard and Thomas Sanders that he was working on a method of sending multiple tones on a telegraph wire using a multi-reed device, the two wealthy patrons began to financially support Bell's experiments. Patent matters would be handled by Hubbard's patent attorney Anthony Pollok.
In March 1875, Bell and Pollok visited the famous scientist Joseph Henry, who was then director of the Smithsonian Institution, and asked Henry's advice on the electrical multi-reed apparatus that Bell hoped would transmit the human voice by telegraph. Henry replied that Bell had "the germ of a great invention". When Bell said that he did not have the necessary knowledge, Henry replied, "Get it!" That declaration greatly encouraged Bell to keep trying. Bell did not have the equipment needed to continue his experiments, nor the ability to create a working model of his ideas. A chance meeting in 1874 between Bell and Thomas A. Watson, an experienced electrical designer and mechanic at the electrical machine shop of Charles Williams, changed all that.
With financial support from Sanders and Hubbard, Bell was able to hire Thomas Watson as his assistant and Bell and Watson experimented with acoustic telegraphy. On 2 June 1875, Watson accidentally plucked one of the reeds and Bell at the receiving end of the wire, heard the overtones of the reed, overtones that would be necessary for transmitting speech. That demonstrated to Bell that only one reed or armature was needed, not multiple reeds. This led to the "gallows" sound-powered telephone, which was able to transmit indistinct voice-like sounds but not clear speech.
Meanwhile, Elisha Gray was also experimenting with acoustic telegraphy and thought of a way to transmit speech using a water transmitter. On 14 February 1876, Gray filed a caveat with the U.S. patent office for a telephone design that used a water transmitter. That same morning, Bell's lawyer filed an application with the patent office for the telephone. There is a debate about who arrived first and Gray later challenged the primacy of Bell's patent.
Three days after his patent was issued, Bell experimented with a water transmitter, using an acid-water mixture. Vibration of the diaphragm caused a needle to vibrate in the water which varied the electrical resistance in the circuit. When Bell spoke the famous sentence "Mr Watson — Come here — I want to see you" into the liquid transmitter, Watson, listening at the receiving end in an adjoining room, heard the words clearly.
Bell's successful test of Gray's water transmitter design provided a proof of concept experiment that proved to Bell's satisfaction that clear human voice sounds could be electrically transmitted. After that, Bell focused on improving the electromagnetic telephone and he did not use a water transmitter in public demonstrations or in commercial applications.
Continuing his experiments in Brantford, Bell brought a working model of his telephone home. On 3 August 1876, from the telegraph office in Mount Pleasant five miles (eight km) away from Brantford, Alexander sent a tentative telegram indicating he was ready. With curious onlookers packed into the office as witnesses, faint voices were heard replying. The following night, he amazed his family and guests when a message was received at the Bell home from Brantford, four miles (six km) distant along an improvised wire strung up along telegraph lines, fences and ending up being laid through a tunnel. This time guests at the household distinctly heard people in Brantford reading and singing. These first long-distance transmissions clearly proved that the telephone could work over long distances.
Bell and his partners, Hubbard and Sanders, offered to sell the patent outright to Western Union for $100,000. The president of Western Union balked, countering that the telephone was nothing but a toy. Two years later, he told colleagues that if he could get the patent for $25 million he would consider it a bargain. By then the Bell company no longer wanted to sell the patent. Bell's investors would become millionaires while he fared well from residuals and at one point, had assets nearly reaching one million dollars.
Bell began a series of public demonstrations and lectures in order to introduce the new invention to the scientific community as well as the general public. His demonstration of an early machine at the 1876 Centenary Exhibition in Philadelphia, the following day, made the telephone the featured headline worldwide. Influential visitors to the exhibition included Emperor Pedro II of Brazil, and later Bell had the opportunity to personally demonstrate the invention to William Thomson, a renowned Scottish scientist and even Queen Victoria who had requested a private audience at Osborne House, her Isle of Wight home; she called the demonstration "most extraordinary." The enthusiasm that surrounded Bell's public displays laid the groundwork for acceptance of the revolutionary device.
As is sometimes common in scientific discoveries, simultaneous developments can occur, as evidenced by a number of inventors who were at work on the telephone. Although many of these devices had common features that were incorporated in Bell's machine, none were successful in establishing priority over the original Bell patent. The Bell company lawyers successfully fought off a myriad of lawsuits generated initially around the challenges by Elisha Gray and Amos Dolbear. In personal correspondence to Bell, both Gray and Dolbear had acknowledged his prior work which considerably weakened their later claims. On 13 January 1887, the Government of the United States moved to annul the patent issued to Bell on the grounds of fraud and misrepresentation. The prosecuting attorney was the Hon. George M. Stearns under the direction of the Solicitor General George A. Jenks. The Bell company decisively won the landmark case. Bell's direct and cross-examination testimony alone filled 445 pages but was the key to the decision against the government.
Over a period of 18 years, the Bell Telephone Company faced over 600 litigations from inventors claiming to have invented the telephone, never once losing a case. Bell's laboratory notes and family letters were the key to establishing a long lineage to his experiments. One example of the legal action was by Italian inventor Antonio Meucci who claimed in 1834 to have created the first working model of a telephone in Italy. In 1876, Meucci took Bell to court in order to establish his priority. Meucci lost his case due to lack of material evidence of his inventions. Meucci's work, like many other inventors of the period, was based around earlier acoustic principles. However, due to the efforts of Congressman Vito Fossella, Resolution 269 the U.S. House of Representatives on 11 June 2002 stated that Meucci's "work in the invention of the telephone should be acknowledged," even though this did not put an end to a still contentious issue. Overwhelmingly, modern scholars do not recognize the claims of acoustic devices such as Meucci's had any bearing on the development of the telephone.
The value of the Bell patent was acknowledged throughout the world, and when Bell had delayed the German patent application, the electrical firm of Siemens & Halske (S&H) managed to set up a rival manufacturer of Bell telephones under their own patent. The Siemens company produced near-identical copies of the Bell telephone without paying royalties. A series of agreements in other countries eventually consolidated a global telephone operation. The strain on Bell by his constant appearances in court necessitated by the legal battles, eventually resulted in his resignation from the company.
On 11 July 1877, a few days after the Bell Telephone Company began, Bell married Mabel Hubbard (1857–1923) at the Hubbard estate in Cambridge, and shortly after, embarked on a year-long honeymoon in Europe. During the Bells' European honeymoon, Alec brought a handmade model of his telephone with him, making it a "working holiday." Although the courtship had begun years earlier, Alexander waited until he was financially secure before marrying. Although the telephone appeared to be an "instant" success, it was not initially a profitable venture and Bell's main sources of income were from lectures until after 1897. One unusual request exacted by his fiancée was that he use "Alec" rather than the family's earlier familiar name. From 1876, he would sign his name "Alec Bell." They had four children: Elsie May Bell (1878–1964) who married Gilbert Grosvenor of National Geographic fame, Marian Hubbard Bell (1880–1962) who was referred to as "Daisy", and two sons who died in infancy.
In 1882, Bell became a naturalized citizen of the United States. The Bell family maintained a residence in Washington, DC, where Alec set up a laboratory. In 1915, he characterized his status as: "I am not one of those hyphenated Americans who claim allegiance to two countries." Despite this declaration, Bell has been claimed as a "native son" by Canada, Scotland and the United States. By 1885, a new summer retreat was contemplated. That summer, the Bells had a vacation on Cape Breton Island in Nova Scotia, spending time at the small village of Baddeck. Returning in 1886, Bell started building an estate on a point across from Baddeck, overlooking Bras d'Or Lake. By 1889, a large house, christened "The Lodge" was completed and two years later, a larger complex of buildings were begun that the Bells would name Beinn Bhreagh(Gaelic: beautiful mountain) after Alec's ancestral Scottish highlands. Bell would spend his final, and some of his most productive years in residence in both Washington, D.C. and Beinn Bhreagh.
Until the end of his life Bell and his family would alternate between the two homes, but Beinn Bhreagh would, over the next 30 years, become more than a summer home as Bell became so absorbed in his experiments that annual stays lengthened. Both Mabel and Alec became immersed in the Baddeck community and were accepted by the villagers as "their own." The Bells were still in residence at Beinn Bhreagh when the Halifax Explosion occurred on 6 December 1917. Mabel and Alec mobilized the community to help victims in Halifax.
Although Alexander Graham Bell is most often associated with the invention of the telephone, his interests were extremely varied. According to his biographer, Charlotte Gray, Bell's work ranged "unfettered across the scientific landscape" and he often went to bed voraciously reading the Encyclopaedia Britannica, scouring it for new areas of interest. The range of Bell's inventive genius is represented only in part by the 18 patents granted in his name alone and the 12 he shared with his collaborators. These included 14 for the telephone and telegraph, four for the photophone, one for the phonograph, five for aerial vehicles, four for "hydroairplanes" and two for selenium cells. Bell's inventions spanned a wide range of interests and included a metal jacket to assist in breathing, the audiometer to detect minor hearing problems, a device to locate icebergs, investigations on how to separate salt from seawater, and work on finding alternative fuels.
Bell worked extensively in medical research and invented techniques for teaching speech to the deaf. During his Volta Laboratory period, Bell and his associates considered impressing a magnetic field on a record as a means of reproducing sound. Although the trio briefly experimented with the concept, they were unable to develop a workable prototype. They abandoned the idea, never realizing they had glimpsed a basic principle which would one day find its application in the tape recorder, the hard disc and floppy disc drive and other magnetic media.
Bell's own home used a primitive form of air conditioning, in which fans blew currents of air across great blocks of ice. He also anticipated modern concerns with fuel shortages and industrial pollution. Methane gas, he reasoned, could be produced from the waste of farms and factories. At his Canadian estate in Nova Scotia, he experimented with composting toilets and devices to capture water from the atmosphere. In a magazine interview published shortly before his death, he reflected on the possibility of using solar panels to heat houses.
Bell is also credited with the invention of the metal detector in 1881. The device was hurriedly put together in an attempt to find the bullet in the body of U.S. President James Garfield. The metal detector worked flawlessly in tests but did not find the assassin's bullet partly because the metal bed frame the President was lying on disturbed the instrument, resulting in static. The president's surgeons, who were sceptical of the device, ignored Bell's requests to move the president to a bed not fitted with metal springs. Alternately, although Bell had detected a slight sound on his first test, the bullet may have lodged too deeply to be detected by the crude apparatus. Bell gave a full account of his experiments in a paper read before the American Association for the Advancement of Science(AAAS) in August 1882.
The March 1906 Scientific American article by American hydrofoil pioneer William E. Meacham explained the basic principle of hydrofoils and hydroplanes. Bell considered the invention of the hydroplane as a very significant achievement. Based on information gained from that article he began to sketch concepts of what is now called a hydrofoil boat. Bell and assistant Frederick W. "Casey" Baldwin began hydrofoil experimentation in the summer of 1908 as a possible aid to airplane takeoff from water. Baldwin studied the work of the Italian inventor Enrico Forlanini and began testing models. This led him and Bell to the development of practical hydrofoil watercraft.
During his world tour of 1910–1911, Bell and Baldwin met with Forlanini in France. They had rides in the Forlanini hydrofoil boat over Lake Maggiore. Baldwin described it as being as smooth as flying. On returning to Baddeck, a number of initial concepts were built as experimental models, including the Dhonnas Beag, the first self-propelled Bell-Baldwin hydrofoil. The experimental boats were essentially proof-of-concept prototypes that culminated in the more substantial HD-4, powered by Renault engines. A top speed of 54 miles per hour (87 km/h) was achieved, with the hydrofoil exhibiting rapid acceleration, good stability and steering along with the ability to take waves without difficulty. In 1913, Dr. Bell hired Walter Pinaud, a Sydney yacht designer and builder as well as the proprietor of Pinaud's Yacht Yard in Westmount, Nova Scotia to work on the pontoons of the HD-4. Pinaud soon took over the boatyard at Bell Laboratories on Beinn Bhreagh, Bell's estate near Baddeck, Nova Scotia. Pinaud's experience in boat-building enabled him to make useful design changes to the HD-4. After the First World War, work began again on the HD-4. Bell's report to the U.S. Navy permitted him to obtain two 350 horsepower (260 kW) engines in July 1919. On 9 September 1919, the HD-4 set a world's marine speed record of 70.86 miles per hour (114.04 km/h). This record stood for ten years.
Bell was a supporter of aerospace engineering research through the Aerial Experiment Association (AEA), officially formed at Baddeck, Nova Scotia, in October 1907 at the suggestion of Mrs. Mabel Bell and with her financial support. The AEA was headed by Bell and the founding members were four young men: American Glenn H. Curtiss, a motorcycle manufacturer who later was awarded the Scientific American Trophy for the first official one-kilometre flight in the Western hemisphere and became a world-renowned airplane manufacturer; Frederick W. Baldwin, the first Canadian and first British subject to pilot a public flight in Hammondsport, New York; J.A.D. McCurdy; and Lieutenant Thomas Selfridge, an official observer from the U.S. government.
In 1891, Bell began experiments to develop motor-powered heavier-than-air aircraft.
In 1898, Bell experimented with tetrahedral box kites and wings constructed of multiple compound tetrahedral kites covered in silk. The tetrahedral wings were named Cygnet I, II and III, and were flown both unmanned and manned (Cygnet I crashed during a flight carrying Selfridge) in the period from 1907–1912. Some of Bell's kites are on display at the Alexander Graham Bell National Historic Site.
The AEA's work progressed to heavier-than-air machines, applying their knowledge of kites to gliders. Moving to Hammondsport, the group then designed and built the Red Wing, framed in bamboo and covered in red silk and powered by a small air-cooled engine. On 12 March 1908, over Keuka Lake, the biplane lifted off on the first public flight in North America. The innovations that were incorporated into this design included a cockpit enclosure and tail rudder (later variations on the original design would add ailerons as a means of control). One of the AEA project's inventions, the aileron, is a standard component of aircraft today. (The aileron was also invented independently by Robert Esnault-Pelterie.) The White Wing and June Bug were to follow and by the end of 1908, over 150 flights without mishap had been accomplished. However, the AEA had depleted its initial reserves and only a $10,000 grant from Mrs. Bell allowed it to continue with experiments.
Their final aircraft design, the Silver Dart embodied all of the advancements found in the earlier machines. On 23 February 1909, Bell was present as the Silver Dart flown by J.A.D. McCurdy from the frozen ice of Lake Baddeck, made the first aircraft flight in Canada (and the British Empire). Bell had worried that the flight was too dangerous and had arranged for a doctor to be on hand. With the successful flight, the AEA disbanded and the Silver Dart would revert to Baldwin and McCurdy who began the Canadian Aerodrome Company and would later demonstrate the aircraft to the Canadian Army.
Along with many very prominent thinkers and scientists of the time, Bell was connected with the eugenics movement in the United States. In his lecture Memoir upon the formation of a deaf variety of the human race presented to the National Academy of Sciences on 13 November 1883 he noted that congenitally deaf parents were more likely to produce deaf children and tentatively suggested that couples where both parties were deaf should not marry. However, it was his hobby of livestock breeding which led to his appointment to biologist David Starr Jordan's Committee on Eugenics, under the auspices of the American Breeders Association. The committee unequivocally extended the principle to man. From 1912 until 1918 he was the chairman of the board of scientific advisers to the Eugenics Record Office associated with Cold Spring Harbor Laboratory in New York, and regularly attended meetings. In 1921, he was the honorary president of the Second International Congress of Eugenics held under the auspices of the American Museum of Natural History in New York. Organisations such as these advocated passing laws (with success in some states) that established the compulsory sterilization of people deemed to be, as Bell called them, a "defective variety of the human race". By the late 1930s, about half the states in the U.S. had eugenics laws, and the California laws were used as a model for eugenics laws in Nazi Germany.
His ideas about people he considered defective centered on the deaf. This was because of his feelings for his deaf family and his contact with deaf education. In addition to advocating sterilization of the deaf, Bell wished to prohibit deaf teachers from being allowed to teach in schools for the deaf. He worked to outlaw the marriage of deaf individuals to one another, and he was an ardent supporter of oralism over the use of sign language to educate deaf students. His avowed goal was to eradicate the language and culture of the deaf so as to encourage them to assimilate into the hearing culture, for their own long-term benefit and for the benefit of society at large.
Although he supported what some consider harsh and inhumane policies today, he was not unkind to deaf individuals who supported his theories of oralism. He was a personal and longtime friend of Helen Keller, and his wife Mabel was deaf (though none of their children were).
The bel (B) is a unit of measurement invented by Bell Labs and named after Bell. The bel was too large for everyday use, so the decibel (dB), equal to 0.1 B, became more commonly used as a unit for measuring sound intensity.
The IEEE's Alexander Graham Bell Medal has been presented since 1976 to an individual or team, honoring outstanding contributions in the field of telecommunications.
A large number of Bell's writings, notebooks, papers and other documents rest at the United States Library of Congress Manuscript Devision, as the Alexander Graham Bell Family Papers; the collection is available for online viewing. Another large collection of Bell's documents resides at the Alexander Graham Bell Institute.
Bell died of pernicious anemia on 2 August 1922, at his private estate, Beinn Bhreagh, Nova Scotia, at age 75. While tending to her husband after a long illness, Mabel whispered, "Don't leave me." By way of reply, Bell traced the sign for "No" – and promptly expired.
Dr. Alexander Graham Bell was buried atop Beinn Bhreagh mountain overlooking Bras d'Or Lake. He was survived by his wife and his two daughters, Elisa May and Marion.


Amhrán na bhFiann (pronounced /ˈəuɾˠaːn̪ˠ nˠə ˈvʲiːən̪ˠ/) is the national anthem of Ireland. The song is also known by its English language title, ""'The Soldier's Song", and as The National Anthem of Ireland (). Nowadays, the Irish language version of the song is usually sung. The Irish version is a translation of the earlier English version. The music was composed (as A Soldier's Song') by Peadar Kearney and Patrick Heeney, and the original English lyrics were authored by Kearney and subsequently translated into Irish by Liam Ó Rinn. The national anthem consists of the chorus only of Amhrán na bhFiann; the original also has several verses. The Presidential Salute played when the President of Ireland arrives at an official engagement, consists of the first four bars of the national anthem immediately followed by the last five. It is played without lyrics.
The Soldier's Song was composed in 1907, with lyrics by Peadar Kearney and music by Kearney and Patrick Heeney. The lyrics were first published in Irish Freedom by Bulmer Hobson in 1912. The Irish language lyrics were the work of Liam Ó Rinn (1888 - 1950), who was also involved in drafting the Irish language version of both the 1922 Irish Free State Constitution and the 1937 Irish Constitution. The Irish lyrics were first published in An tÓglach (the magazine of the Irish Defence Forces) on 3 November 1923. The Soldier's Song/Amhrán na bhFiann was popular among Irish republicans, and was sung by rebels in the General Post Office (GPO) during the Easter Rising of 1916, and afterwards in British internment camps. The song became the official state anthem in 1926.
God Save the King was the official anthem of the United Kingdom of Great Britain and Ireland until the independent Irish Free State was established in 1922. The continued use of God Save the King by some Irish people caused annoyance to the new Irish state and, on one occasion, Governor-General James McNeill refused to attend a public function in Trinity College when he learned that the university intended to play the anthem during his visit. Even after the adoption of Amhrán na bhFiann as the official anthem of the Irish Free State in July 1926, a minority continued to sing the British anthem, and to pray for the King and Queen in Church of Ireland services, for a number of years.
In 1934, the Irish state acquired the copyright of the song for the sum of £1,200.
The song is regarded by many nationalists as the national anthem of the whole island of Ireland, and it is therefore sung, for example, at Gaelic Athletic Association matches held in Northern Ireland as well as in the Republic of Ireland. Unionists, however, reject this use of Amhrán na bhFiann. At international games played by the all-island rugby union team, the specially-commissioned song Ireland's Call is used; Amhrán na bhFiann is only used within the Republic. Ireland's Call has also been adopted by all-Ireland teams in some other sports.
The Irish version is a free translation of the English; in particular, "Sinne Fianna Fáil" is not a literal translation of "Soldiers are we". Fianna Fáil — literally the Fianna (band of warriors) of Fál, but variously translated as "Soldiers of Destiny", "Warriors of Destiny" or "Soldiers of Ireland" — was an alternative name given to the Irish Volunteers in the 1913 – 1922 period. The initials "FF" appeared on the Volunteer badge, and were adopted by the Army of the Irish Free State. Fianna Fáil was later chosen by Éamon de Valera as the name of his new political party in 1926. Some versions of Amhrán na bhFiann substitute "Sinne Laochra Fáil" for "Sinne Fianna Fáil" (laochra also translates as warriors) in order to avoid any association of the anthem with the political party.
In recent years, a number of Irish newspapers and columnists have proposed replacing Amhrán na bhFiann with a new national anthem, arguing that the current wording is excessively militant and anti-British. Those who favour its retention argue that it is no more militant than the British, French or American national anthem.
Amhrán na bhFiann" is usually sung or played in march time. Different tempos may be used, however, and the verse and chorus are occasionally played. Radio Telefís Éireann (RTÉ), the Irish national broadcasting company, played an orchestral version in a slow tempo at the close of transmission from 1962 onwards. At the 1996 Summer Olympics in Atlanta, when Michelle Smith won three gold medals in swimming, the verse and chorus were played in a lively tempo.


Anatolia (, Anatolía) () is a geographic region bounded by the Black Sea to the north, the Mediterranean Sea to the south, the Aegean Sea to the west, and the bulk of the Asian mainland to the east.
The name Anatolia comes from the Greek Aνατολή (Αnatolí), "(sun)Rise," or Ανατολία (Anatolía), "(land) of the sunrise" or simply the "East." It likely dates back at least 3000 years, from the Ionian settlement period circa the 1st millennium BC. (See also Ionian League). The Byzantine Greek term Anatolikon (the "Eastern One") signified the lands to the East of Europe and of the Byzantine Empire's capital city of Constantinople (now Istanbul). The etymology of the word supports the idea that Anatolia was a peninsula bordered by the Black Sea, the Mediterranean Sea, and the Eastern Taurus Range.
The Anatolian peninsula is bounded by the Black Sea to the north, the Mediterranean Sea to the south, the Aegean Sea (itself an arm of the Mediterranean) to the west, and the bulk of the Asian mainland to the east.
Anatolia's terrain is structurally complex. A central massif composed of uplifted blocks and downfolded troughs, covered by recent deposits and giving the appearance of a plateau with rough terrain, is wedged between two folded mountain ranges that converge in the east. True lowland is confined to a few narrow coastal strips along the Black Sea and Mediterranean Sea coasts. Flat or gently sloping land is rare and largely confined to the deltas of the Kızıl River, the coastal plains of Çukurova, and the valley floors of the Gediz River and the Büyük Menderes River, and some interior high plains in Anatolia, mainly around Tuz Gölü (Salt Lake) and Konya Ovası (Konya Basin).
The Black Sea region has a steep, rocky coast with rivers that cascade through the gorges of the coastal ranges. The North Anatolian mountains are an interrupted chain of folded highlands that generally parallel the Black Sea coast. A few larger rivers, those cutting back through the Pontic Mountains (), have tributaries that flow in broad, elevated basins. Rivers flow from the mountains toward the Black Sea trough in lengthy valleys.
Access inland from the coast is limited to a few narrow valleys because mountain ridges, with elevations of 1,525 to 1,800 metres (5,000 to 5,900 ft) in the west and 3,000 to 4,000 metres (10000 to 13000 ft) in the east in Kaçkar Mountains, form an almost unbroken wall separating the coast from the interior. The higher slopes facing southwest tend to be densely wet. Because of these natural conditions, the Black Sea coast historically has been isolated from Anatolia. The southern slopes—facing the Anatolian Plateau—are mostly unwooded, but the northern slopes contain dense growths of both deciduous and evergreen trees.
The narrow coastal plains of the Mediterranean region, separated from the Anatolian plateau by the Taurus Mountains, which reach elevations of 2,000 to 2,750 metres (6600 to 9000 ft), are cultivated intensively. Fertile soils and a warm climate make the Mediterranean coast ideal for growing citrus fruits, grapes, figs, bananas, various vegetables, barley, wheat, and, in irrigated areas, rice and cotton. The Çukurova in the east is a plain that is the most developed agricultural area of the Mediterranean region.
Stretching inland from the Aegean coastal plain, Central Anatolia occupies the area between the two zones of the folded mountains, extending east to the point where the two ranges converge. The plateau-like, semiarid highlands of Anatolia are considered the heartland of the country. The region varies in elevation from 600 to 1,200 metres (2000 to 4000 ft) from west to east. The two largest basins on the plateau are the Konya Ovası and the basin occupied by the large salt lake, Tuz Gölü. Both basins are characterized by inland drainage. Wooded areas are confined to the northwest and northeast of the plateau.
Mountains close to the coast prevent Mediterranean influences from extending inland, giving the interior of Turkey a continental climate with distinct seasons. The Anatolian Plateau is much more subject to extremes than are the coastal areas. Winters on the plateau are especially severe. Temperatures of -30 °C to -40 °C (-22 °F to -40 °F) can occur in the mountainous areas in the east, and snow may lie on the ground 120 days of the year. In the west, winter temperatures average below 1 °C (34 °F). Summers are hot and dry, with temperatures above 30 °C (86 °F). Annual precipitation averages about 400 mm (15.7 inches), with actual amounts determined by elevation. The driest regions are the Konya Ovası and the Malatya Ovası, where annual rainfall frequently is less than 300 mm (11.8 inches). May is generally the wettest month and July and August are the driest.
Eastern Anatolia where the Pontus and Taurus mountain ranges converge, is rugged country with higher elevations, a more severe climate, and greater precipitation than are found on the Anatolian Plateau. The region is known as the Anti-Taurus, and the average elevation of its peaks exceeds 3,000 m. Mount Ararat, at 5,137 metres (16854 ft) the highest point in Turkey, is located in the Anti-Taurus. Lake Van is situated in the mountains at an elevation of 1,546 metres (5072 ft). The headwaters of three major rivers arise in the Anti-Taurus: the east-flowing Aras River, which empties into the Caspian Sea; the south-flowing Euphrates and Tigris join in Iraq before emptying into the Persian Gulf. Several small streams that empty into the Black Sea or landlocked Lake Van also originate in these mountains.
Southeast Anatolia lies south of the Anti-Taurus Mountains. It is a region of rolling hills and a broad plateau surface that extends into Syria. Elevations decrease gradually, from about 800 metres (2600 ft) in the north to about 500 metres (1600 ft) in the south. Traditionally, wheat and barley were the main crops of the region, but the inauguration of major new irrigation projects in the 1980s has led to greater agricultural diversity and development.
Anatolia's diverse topography and climate has encouraged a similar diversity of plant and animal communities. The mountains and coastal plain of northern Anatolia, with its humid and mild climate, is home to temperate broadleaf, mixed, and coniferous forests. The central and eastern plateau, with its drier continental climate, is home to deciduous forests and forest steppes. Western and southern Anatolia, which have a Mediterranean climate, are home to Mediterranean forests, woodlands, and shrub ecoregions.
Because of its strategic location at the intersection of Asia and Europe, Anatolia has been the center of several civilizations since prehistoric times. Neolithic settlements such as Çatalhöyük, Çayönü, Nevali Cori, Hacilar, Göbekli Tepe, and Mersin are being explored by archaeologists. Through recorded history, Anatolians have spoken both Indo-European and Semitic languages, as well as many languages of uncertain affiliations. In fact, given the antiquity of the Indo-European Hittite and Luwian languages, some scholars have proposed Anatolia as the hypothetical center from which the Indo-European languages originated.
The earliest definitive record of rule in Anatolia is from the Akkadian Empire under Sargon in the 24th century BCE. The region was famous for exporting various raw materials. Akkad suffered problematic climate changes in Mesopotamia, as well as a reduction in available manpower that affected trade. This led to the fall of the Akkadians around 2150 BCE at the hands of the Gutians.
After the Gutians were vanquished, the Assyrian Empire claimed the resources, notably silver. One of the numerous Assyrian cuneiform records found in Anatolia at Kanesh uses an advanced system of trading computations and credit lines.
More than 2500 years ago, the area was home for Armenians. In the first century BC, it was one small part of Tigran, the King of Armenia, whose kingdom was spread among Caspian, Black and Mediterranean seas.


Apple Inc. (, ), formerly Apple Computer Inc. is an American multinational corporation with a focus on designing and manufacturing consumer electronics and closely related software products. Established in Cupertino, California on April 1 1976, Apple develops, sells, and supports a series of personal computers, portable media players, mobile phones, computer software, and computer hardware and hardware accessories. As of September 2007, the company operates about 200 retail stores in five countries and an online store where hardware and software products are sold. The iTunes Store provides music, audiobooks, iPod games, music videos, episodes of television programs, and movies which can be downloaded using iTunes on Mac or Windows (and in Linux under Wine), and also on the iPod touch and the iPhone. The company's best-known hardware products include the Macintosh line of personal computers, the iPod line of portable media players, and the iPhone. Apple's software products include the Mac OS X operating system, the iLife suite of multimedia and creativity software, and Final Cut Studio, a suite of professional audio- and film-industry software products.
The company, incorporated January 3 1977, was known as "Apple Computer, Inc." for its first 30 years. On January 9 2007, the company dropped "Computer" from its corporate name, reflecting the company's ongoing expansion into the consumer electronics market in addition to its traditional focus on personal computers.
Apple employs over 20,000 permanent and temporary workers worldwide and had worldwide annual sales in its fiscal year 2007 (ending September 29 2007) of US$24.01 billion.
For a variety of reasons, ranging from its philosophy of comprehensive aesthetic design to their advertising campaigns, Apple has engendered a distinct reputation in the consumer electronics industry and has cultivated a customer base that is unusually devoted to the company and its brand, particularly in the United States.
The company introduced the Apple II microcomputer in March 1977. A few years later, in 1983, it introduced the Lisa, the first commercial personal computer to employ a graphical user interface (GUI), which was influenced in part by the Xerox Alto. Lisa was also the first personal computer to have the mouse. In 1984, the Macintosh was introduced, which arguably advanced the concept of a new user-friendly graphical user interface. Apple's success with the Macintosh became a major influence in the development of graphical interfaces elsewhere, with major computer operating systems, such as the Commodore Amiga, and Atari ST, appearing on the market within two years of the introduction of the Macintosh.
In 1991, Apple introduced the PowerBook line of portable computers. The 1990s also saw Apple's market share fall as competition from Microsoft Windows and the comparatively inexpensive IBM PC compatible computers that would eventually dominate the market. In the 2000s, Apple expanded its focus on software to include professional and prosumer video, music, and photo production solutions, with a view to promoting their products as a "digital hub". It also introduced the iPod, the most popular digital music player in the world.
Apple was founded on April 1 1976 by Steve Jobs, Steve Wozniak, and Ronald Wayne to sell the Apple I personal computer kit. They were hand-built by Steve Wozniak in the living room of Jobs' parents' home, and the Apple I was first shown to the public at the Homebrew Computer Club. Eventually 200 computers were built. The Apple I was sold as a motherboard (with CPU, RAM, and basic textual-video chips) — not what is today considered a complete personal computer. The user was required to provide two different AC input voltages (the manual recommended specific transformers), wire an ASCII keyboard (not provided with the computer) to a DIP connector (providing logic inverter and alpha lock chips in some cases), and to wire the video output pins to a monitor or to an RF modulator if a TV set was used. The Apple I went on sale in July 1976 and was market-priced at $666.66.
Jobs approached a local computer store, The Byte Shop, which ordered fifty units and paid US$500 for each unit after much persuasion. He then ordered components from Cramer Electronics, a national electronic parts distributor. Using a variety of methods, including borrowing space from friends and family and selling various items including a Volkswagen Type 2 bus, Jobs managed to secure the parts needed while Wozniak and Ronald Wayne assembled the Apple I.
Apple was incorporated January 3 1977 without Wayne, who sold his share of the company back to Jobs and Wozniak, and with Mike Markkula, who provided essential business expertise and funding of US $250,000 during the formation of Apple.
The Apple II was introduced on April 16 1977 at the first West Coast Computer Faire. It differed from its major rivals, the TRS-80 and Commodore PET, because it came with color graphics and an open architecture. While early models used ordinary cassette tapes as storage devices, this was quickly superseded by the introduction of a 5 1/4 inch floppy disk drive and interface, the Disk II.
By the end of the 1970s, Jobs and his partners had a staff of computer designers and a production line. The Apple II was succeeded by the Apple III in May 1980 as the company struggled to compete against IBM and Microsoft in the lucrative business and corporate computing market. The designers of the Apple III were forced to comply with Jobs' request to omit the cooling fan, and this ultimately resulted in thousands of recalled units due to overheating. An updated version, the Apple III+, was introduced in 1983, but it was also a failure due to bad press and wary buyers.
Apple's sustained growth during the early 1980s was partly due to its leadership in the education sector, attributed to their adaptation of the programming language LOGO, used in many schools with the Apple II. The drive into education was accentuated in California with the donation of one Apple II and one Apple LOGO software package to each public school in the state. The deal concluded between Steve Jobs and Jim Baroux of LCSI, and having required the support of Sacramento, established a strong and pervasive presence for Apple in all schools throughout California. The initial conquest of education environments was critical to Apple's acceptance in the home where the earliest purchases of computers by parents was in support of children's continued learning experience.
Jobs and several other Apple employees including Jef Raskin visited Xerox PARC in December 1979 to see the Alto computer. Xerox granted Apple engineers three days of access to the PARC facilities in return for selling them US$1 million in pre-IPO Apple stock (approximately US$18 million net).
It is said that Jobs was immediately convinced that all future computers would use a GUI, and decided to turn over design of Apple's next project, the Apple Lisa, to produce such a device. The Lisa was named after Jobs' daughter (however, a bacronym, Local Integrated Software Architecture, was coined). He was eventually pushed from the group due to infighting, and instead took over Jef Raskin's low-cost computer project, the Macintosh. Branding the new effort as the product that would "save Apple", an intense turf war broke out between the Lisa's "corporate shirts" and Jobs' Macintosh "pirates", both teams claiming they would ship first and be more successful. In 1983 the Lisa team won the race and Apple introduced the first personal computer to be sold to the public with a GUI. However, the Lisa was a commercial failure as a result of its high price tag (US$9,995) and limited software titles.
In 1984, drawing upon its experience with the Lisa, Apple next launched the Macintosh. Its debut was announced by a single national broadcast of the now famous US$1.5 million television commercial, "1984", based on George Orwell's novel Nineteen Eighty-Four. The commercial was directed by Ridley Scott and aired during Super Bowl XVIII on January 22 1984. Jobs' intention with the ad was to represent the IBM PC as Big Brother, and the Macintosh as a nameless female action hero portrayed by Anya Major. While the Macintosh initially sold well, follow-up sales were not particularly strong. The machine's fortunes changed with the introduction of the LaserWriter, the first laser printer to be offered at a reasonable price point, and PageMaker, an early desktop publishing (DTP) package. The Mac was particularly powerful in this market due to its advanced graphics capabilities, which were already necessarily built-in to create the intuitive Macintosh GUI. It has been suggested that the combination of these three products was responsible for the creation of the DTP market. As DTP became widespread, Apple's sales reached a series of new highs, and the company had its initial public offering on September 7, 1984.
An internal power struggle developed between Jobs and new CEO John Sculley in 1985. Apple's board of directors sided with Sculley and Jobs was removed from his managerial duties. Jobs later resigned from Apple and founded NeXT Inc. a computer company that built machines with futuristic designs and ran the UNIX-derived NeXTStep operating system. Although powerful, NeXT computers never caught on with buyers, due in part to their high purchase price.
Having learned several painful lessons after introducing the bulky Macintosh Portable in 1989, Apple introduced the PowerBook in 1991, which established the modern form and ergonomic layout of the laptop computer. The same year, Apple introduced System 7, a major upgrade to the operating system which added color to the interface, and introduced a number of new networking capabilities. It would remain the architectural basis for Mac OS until 2001.
The success of the PowerBook and several other Apple products during this period led to increasing revenue. For some time, it appeared that Apple could do no wrong, introducing fresh new products and generating increasing profits in the process. The magazine MacAddict named the period between 1989 to 1991 the "first golden age" of the Macintosh. However, the continuing development of Microsoft Windows had given birth to an interface that was competitive with Apple's. Combined with a huge base of low-cost computers and peripherals and an improving software suite, an increasing number of potential customers turned to the "Wintel" standard.
Apple, relying on high profit margins to maintain their massive R&D budget, never developed a clear response. Instead they sued Microsoft for theft of intellectual property, in Apple Computer, Inc. v. Microsoft Corporation. The lawsuit dragged on for years before finally being thrown out of court. A series of major product flops and missed deadlines destroyed Apple's reputation of invincibility, and consequently their market share dropped, particularly after the release of Windows 95.
During this time, Apple branched out into consumer electronics. One example of this product diversification was the Apple QuickTake digital camera, one of the first digital cameras brought to the consumer market. A more famous example was the Newton, termed a "Personal digital assistant" or "PDA" by Sculley, that was introduced in 1993. Though it failed commercially, it defined and launched a new category of computing and was a forerunner of devices such as Palm Pilot, PocketPC, and eventually the iPhone.
By the mid-90s, Apple realized that it had to reinvent the Macintosh in order to stay competitive in the market. The needs of both computer users and computer programs were becoming, for a variety of technical reasons, harder for the existing hardware and operating system to address.
In 1994 Apple allied with long-time competitor IBM and CPU maker Motorola in the so-called AIM alliance. This was a bid to create a new computing platform (the PowerPC Reference Platform or PReP), which would use IBM and Motorola hardware coupled with Apple's software. The AIM alliance hoped that PReP's performance and Apple's software would leave the PC far behind, thus countering Microsoft, which had become Apple's chief competitor. That year, Apple introduced the Power Macintosh using IBM's PowerPC processor. This processor utilized a RISC architecture, which differed substantially from the Motorola 68k series that had been used by all previous Macs.
Throughout the mid to late 1990s, Apple tried to improve its operating system's multitasking and memory management. After multiple failed attempts to improve the existing Mac OS, first with the Taligent project, then later with Copland and Gershwin, the company chose to purchase NeXT and its NeXTSTEP operating system, bringing Steve Jobs back to Apple in the process. On July 9 1997, Gil Amelio was ousted as CEO of Apple by the board of directors after overseeing a 3-year record-low stock price and crippling financial losses. Jobs stepped in as the interim CEO and began a restructuring of the company's product line.
At the 1997 Macworld Expo, Steve Jobs announced that Apple would be entering into a partnership with Microsoft to release new versions of Microsoft Office for the Macintosh as well as a US$150 million investment in non-voting Apple stock.
On November 10 1997, Apple introduced the Apple Store, an online retail store based upon the WebObjects application server the company had acquired in its purchase of NeXT. The new direct sales outlet was also tied to a new build-to-order manufacturing strategy and announced at the same time as new machines using the PowerPC processor.
On August 15 1998, Apple introduced a new all-in-one Mac computer reminiscent of the original Macintosh 128K: the iMac. The iMac design team was led by Jonathan Ive, who would later design the iPod and the iPhone. While not groundbreaking from a technological standpoint, the iMac featured an innovative new translucent plastic exterior, originally in Bondi Blue, but later many other colors. The iMac sold close to 800,000 units in its first five months and helped return the company to sustained profitability for the first time since 1993.
Through this time period, Apple purchased several companies in a move to create a portfolio of professional and consumer-oriented digital production software. In 1998, Apple announced the purchase of Macromedia's Final Cut software, signalling its expansion into the digital video editing market. The following year, Apple released two video editing products: iMovie for consumers, and Final Cut Pro for professionals, the latter of which has gone on to be a significant video-editing program, with 800,000 registered users in early 2007. In 2002 Apple purchased Nothing Real for their advanced digital compositing application Shake, as well as Emagic for their music productivity application Logic, which led to the development of their consumer-level GarageBand application. With iPhoto's release in 2002, this completed Apple's collection of consumer and professional level creativity software, with the consumer-level applications being collected together into the iLife suite.
Mac OS X, the operating system based on NeXT's OPENSTEP and BSD Unix was released on March 24 2001 after several years of development. Aimed at consumers and professionals alike, Mac OS X aimed to marry the stability, reliability and security of the Unix operating system with the ease of use afforded by a completely overhauled user interface. To aid users in moving their applications from Mac OS 9, the new operating system allowed the use of OS 9 applications through Mac OS X's Classic environment.
On May 19 2001, Apple opened its first official Apple Retail Stores in Virginia and California, and has since continued to open more stores in the United States and other countries.
Later the same year, Apple introduced its first iPod portable digital audio player. The product has proven phenomenally successful; over 100 million units have been sold in the six years since its introduction. In 2003, Apple's iTunes Store was introduced, offering online music downloads for US 99¢ a song and integration with the iPod. The service quickly became the market leader in online music services, with over 3 billion downloads by August 2007. Steve Jobs announced that iTunes had reached 4 billion downloads during his keynote address at the 2008 Macworld Conference & Expo.
As for the Macintosh, Apple's design team progressively abandoned the flashy colors of the iMac G3 era in favor of white polycarbonate for consumer lines such as the iMac and iBook, as well as the educational eMac, and metal enclosures for the professional lines. This began with the 2001 release of the titanium PowerBook and was followed by the 2001 white iBook, the 2002 flat-panel iMac, the 2003 Power Mac G5, and the 2004 Apple Cinema Displays.
In the Worldwide Developers Conference (WWDC) keynote address on June 6 2005, Steve Jobs announced that Apple would begin producing Intel-based Mac computers beginning in 2006.
On January 10 2006, Apple released its first Intel chip computers, a new notebook computer known as the MacBook Pro (with a 15.4" screen) and a new (though cosmetically identical) iMac with purportedly two to three times faster performance compared with its predecessor. Both used Intel's Core Duo chip technology. Through 2006, Apple transitioned the entire Mac product line to Intel chips, retaining the enclosure design while replacing its internal components. The Power Mac brand was retired, with Mac Pro being its successor. Apple also introduced a new piece of software called Boot Camp that helps users install Windows XP on their Intel Mac alongside Mac OS X.
Delivering his keynote at Macworld 2007 (January 9 2007), Steve Jobs announced a change of name: Apple Computer Inc. would from that point be known as Apple Inc. The event also saw the announcement of the iPhone, and the Apple TV. The following day, Apple shares hit US$97.80, then an all-time high. In May 2007, Apple's share price passed the US$100 mark.
On February 7 2007, Apple indicated that it would be willing to sell music on the iTunes store without digital rights management protection (allowing tracks to be played on any compatible player) if major record labels would agree to drop that anti-piracy technology. On April 2 2007, Apple and record label EMI jointly announced the removal of anti-piracy technology from EMI's catalog in the iTunes Store, effective in May.
Apple introduced the Apple Macintosh family in 1984 and today makes consumer, professional, and educational computers. The Mac mini is the company's consumer sub-desktop computer, introduced in January 2005 and designed to motivate Windows users to switch to the Mac computer platform. The iMac is a consumer desktop computer that was first introduced by Apple in 1998, and its popularity helped revive the company's fortunes. The iMac is similar in concept to the original Macintosh in that the monitor and computer are housed in a single unit. It is now in its third major design iteration, and has been upgraded many times (including a switch to Intel processors) using the same design. Apple sells three lines of portable computers: the MacBook which includes a 13 inch widescreen, and is available in white and black variants, the MacBook Air, an ultra-thin, ultra-portable notebook with a 13.3 inch LED backlit widescreen and the MacBook Pro, a professional portable computer alternative to the MacBook. The MacBook Pro is marketed as being intended for professional and creative users, and offers configurations with 15-inch and 17-inch displays. The Mac Pro is Apple's workstation-class desktop computer offering, which is housed in an aluminum enclosure that matches the design aesthetic of the Apple Cinema Display. Apple's rack mount offerings include the Xserve, a dual core, dual processor 1U server, and the Xserve RAID for large-scale storage options.
Apple sells a variety of computer accessories for Mac computers including the AirPort wireless networking products, Time Capsule, Apple Cinema Display, Mighty Mouse, the Apple Wireless Keyboard computer keyboard, and the Apple USB Modem.
On October 23 2001, Apple introduced the iPod digital music player. Initially equipped with a 5 GB hard drive and a monochrome screen, models today can store up to 160 GB and display video, play games, and support a wide range of third-party add-on devices. As of September 2007, Apple sells four variants of the iPod: the iPod shuffle, iPod nano, iPod classic and iPod touch. The iPod is the market leader in portable music players by a significant margin, with more than 100 million units shipped as of April 9 2007. Apple has partnered with Nike to introduce the Nike+iPod Sports Kit enabling runners to sync and monitor their runs with iTunes and the Nike+ website.
At the Macworld Conference & Expo in January 2007, Steve Jobs revealed the long anticipated iPhone, a convergence of an Internet-enabled smartphone and video iPod. The iPhone combines a 2.5G quad band GSM and EDGE cellular phone with features found in hand held devices, running a scaled-down versions of Apple's Mac OS X, with various applications such as Safari web browser, e-mail, and navigation. The iPhone features a 3.5 inch touch screen display, 8 GB of memory, Bluetooth, and WiFi (both "b" and "g"). The iPhone first became available on June 29 2007.
Additionally at the conference, Jobs demonstrated the Apple TV, (previously known as the iTV), a set-top video device intended to bridge the sale of content from iTunes with high-definition televisions. The device links up to a user's TV and syncs, either via WiFi or a wired network, with one computer's iTunes library and streams from an additional four. The Apple TV incorporates a 40 GB hard drive for storage, includes outputs for HDMI and component video, and plays video at a maximum resolution of 720p. It was later updated to include a 160 GB drive for even more space for media.
In 2008 Apple presented trackpad, which is based on the multi-touch technology. The latter was being designed exclusively for the new series of Apple laptops. For the first time this technology was applied in the iPhone and the iPod Touch. The trackpad can interpret a variety of combinations of three-finger manipulations.
The highest functionality of the new trackpad is achieved by combining the motions of three fingers. Users can apply different combinations for such functions as: scrolling, zooming pictures in and out and rotating objects. Applications including Finder, iPhoto and Safari possess their personal sets of combinations.
The multi-touch trackpad is created according to the gesture language developed by Fingerworks, a company that is part of Apple.
A study in January 2006 by the United States Environmental Protection Agency found that Apple's hardware compares favorably with that of its major competitors on environmental friendliness.
On June 5 2007, Apple updated their MacBook Pro product line. This hardware update is environmentally notable because LEDs fully replaced cold cathode lamps in the 15 inch MacBook Pro's display backlighting, a first for Apple laptops (the iPod has had LED backlighting since its creation in 2001). This ameliorates Apple's environmental stance, as cold cathode lamps contain mercury, whereas LEDs do not.
Former Vice President of the United States and environmentalist Al Gore is a member of Apple's board of directors.
Apple develops its own operating system to run on Macs, Mac OS X, the latest version being Mac OS X v10.5 Leopard. Apple also independently develops computer software titles for its Mac OS X operating system. Much of the software Apple develops is bundled with its computers. An example of this is the consumer-oriented iLife software package which bundles iDVD, iMovie, iPhoto, iTunes, GarageBand, and iWeb. For presentation, page layout and word processing, iWork is available, which includes Keynote, Pages, and Numbers. iTunes, QuickTime media player, and Safari web browser are available as free downloads for both Mac OS X and Windows.
Apple also offers a range of professional software titles. Their range of server software includes the operating system Mac OS X Server; Apple Remote Desktop, a remote systems management application; WebObjects, Java Web application server; and Xsan, a Storage Area Network file system. For the professional creative market, there is Aperture for professional RAW-format photo processing; Final Cut Studio, a video production suite; Logic, a comprehensive music toolkit and Shake, an advanced effects composition program.
Apple also offers online services with.Mac which bundles.Mac HomePage,Mac Mail,Mac Groups,Mac iDisk,Mac Backup,Mac Sync, and Learning Center online tutorials.
Critics of Apple commonly point to their vertically integrated business model, where all the hardware and operating system software comes from one company. Although the Apple II was very open, the Macintosh was originally closed and proprietary, and during the Mac's early history Apple generally refused to adopt prevailing industry standards for hardware, instead creating and implementing their own (for example, The Lisa's FileWare drive, and the ADB).
This trend was largely reversed in the late 1990s beginning with Apple's adoption of the PCI bus in the 7500/8500/9500 Power Macs. Apple has since adopted USB, AGP, HyperTransport, Wi-Fi, and other industry standards in its computers and was in some cases a leader in the adoption of such standards. FireWire is an Apple-originated standard which has seen widespread industry adoption after it was standardized as IEEE 1394.
However, the iPod remains a mostly closed and vertically integrated platform. Although Apple provides documented interfaces for hardware accessories, developers have no supported way to add features to the software (such as decoding of additional formats). Although the iPod supports the mainstream MP3 and AAC formats, there is not support for other proprietary formats, like Windows Media (this can be converted to AAC with iTunes on Windows), RealAudio and the open Ogg Vorbis format. Apple has refused to license its FairPlay DRM system to other online music vendors. The company added Windows PC support with their second generation iPod series.
Ever since the first Apple store opened, Apple has wanted third parties to sell their products and software inside their stores. This allows, for instance, Nikon and Canon to sell their Mac-compatible digital cameras and camcorders inside the store. Adobe, the largest Apple software partner, also sells its Mac-compatible software, as does Microsoft, who sells Microsoft Office for the Mac. A notable exception are books published by John Wiley & Sons, who publishes the For Dummies series of instructional books. The publisher's line of books were banned from Apple Stores in 2005 because Steve Jobs disagreed with their editorial policy.
Apple Inc.'s world corporate headquarters are located in the middle of Silicon Valley, at 1 Infinite Loop, Cupertino, California. This Apple campus has six buildings which total 850,000 sq ft (79,000 m²). and was built in 1993 by Sobrato Development Cos.
In 2006, Apple announced its intention to build a second campus on 50 acres assembled from various contiguous plots. The new campus, also in Cupertino, will be about one mile east of the current campus.
Since the introduction of the Macintosh in 1984 with the 1984 Super Bowl commercial to the more modern 'Get a Mac' adverts, Apple has been recognized for its efforts towards effective advertising and marketing for its products, though it has been criticized for the content of more recent campaigns.
Apple’s first logo, designed by Jobs and Wayne, depicts Sir Isaac Newton sitting under an apple tree. Almost immediately, though, this was replaced by Rob Janoff’s "rainbow Apple," the now-familiar rainbow-colored silhouette of an apple with a bite taken out of it, possibly as a tribute to Isaac Newton's discoveries of the gravity (the apple), and the separation of light by prisms (the colors). This was one of several designs Janoff presented to Jobs in 1976.
While it is generally accepted to have been in reference to Isaac Newton, a curious urban legend exists that the bitten apple is a homage to the mathematician Alan Turing, who committed suicide by eating an apple he had laced with cyanide. Turing is regarded as one of the fathers of the computer.
In 1998, with the roll out of the new iMac, Apple began enforcing the use of a strictly monochrome logo—supposedly at the insistence of a newly re-inaugurated Jobs—nearly identical in shape to its previous rainbow incarnation. However, no specific color is prescribed; for example, it is grey on the Power Mac G5, Mac Mini, and iMac, black on the Aluminum iMac, blue in the iPod's "legal" menu and (by default) in Mac OS X until 10.5 when it was changed to chrome on the 'About this Mac' panel and the boot screen in Mac OS X 10.3 and 10.4, red on many software packages, and white on the iBook, PowerBook G4, PowerBook G3 (late models), MacBook, and MacBook Pro. The logo's shape is one of the most recognized brand symbols in the world, identifies all Apple products and retail stores (the name "Apple" is usually not even present), and notably included as stickers in nearly all Macintosh and iPod packages through the years.
Apple's first slogan, "Byte into an Apple", was coined in the late 1970s. Once Apple started selling more than just computers, slogans were created for each individual product, rather than for the company itself. For example, the slogan "iThink, therefore iMac", was used in 1998 to promote the iMac. Several company-directed slogans are marketed today; however Apple tends to focus mainly on marketing its products individually.
Apple's earliest court action dates to 1978 when Apple Records, The Beatles-founded record label, filed suit against Apple Computer for trademark infringement. The suit settled in 1981 with an amount of US$80,000 being paid to Apple Corps. As a condition of the settlement, Apple Computer agreed to stay out of the music business. The case arose in 1989 again when Apple Corps sued over the Apple IIGS, which included a professional synthesizer chip, claiming violation of the 1981 settlement agreement. In 1991 another settlement of around US$26.5 million was reached. In September 2003 Apple Computer was sued by Apple Corps again, this time for introducing the iTunes Music Store and the iPod, which Apple Corps believed was a violation of the previous agreement by Apple Computer not to distribute music. The trial in the UK ended on May 8 2006 with victory for Apple Computer. The judge ruled the company's iTunes Music Store did not infringe on the trademark of Apple Corps and ordered Apple Corps to pay the legal costs. A new settlement was announced on February 5 2007 giving Apple, Inc. control over the Apple mark with Apple Corps licensed to use it. Portions of the settlement are confidential, but each side will pay its own legal costs. As the Beatles' songs are not available for download from any legal music download sites, including the iTunes Music Store, Jobs' highly public nod to the Beatles (playing "Lovely Rita" on the iPhone) during his January 9 2007 Macworld keynote fueled widespread speculation about a deal to sell Beatles songs on iTunes. A spokewoman for Apple Corps said the settlement had no bearing on any such matter.
In July 1998, Abdul Traya registered the domain name appleimac.com, shortly after Apple announced the iMac, in an attempt to draw attention to the web-hosting business he was running out of his parents' basement. After a legal dispute that lasted until April 1999, Traya and Apple settled out of court with Apple paying legal fees and giving Traya a "token payment" in exchange for the domain name.
In a more recent previously unrelated lawsuit, Apple entered into a class action settlement, upheld on December 20 2005 following an appeal, regarding the battery life of iPod music players sold prior to May 2004. Eligible members of the class are entitled to extended warranties, store credit, cash compensation, or battery replacement.
Creative also recently filed a patent dispute alleging that Apple infringed on one of Creative's patents for their Zen player with the iPod and iPod nano. On August 23 2006, Apple and Creative settled their patent disputes by paying Creative US$100 million.
On January 10 2007, Cisco sued Apple for the iPhone, since Cisco has held the trademark on the name "iPhone" since 2000. Cisco had refused rights to use the name "iPhone" on multiple occasions. Apple and Cisco had been in talks for a while about use of the name, though Apple had been denied the use of the name on several occasions leading up through January 9. Cisco alleged that Apple created a front company to attempt to acquire the name through other means, but failed also. During the 2007 Macworld Expo, Apple used Cisco's "iPhone" name anyway. On February 22 2007 Cisco and Apple announced an agreement under which both companies would be allowed to use the iPhone name worldwide.
In July 2007, Colorado-based photographer Louis Psihoyos filed suit against Apple for allegedly ripping his "wall of videos" imagery to advertise for Apple TV. According to Psihoyos, Apple had been negotiating with Psihoyos for rights to the imagery, but backed out and promptly used the imagery anyway.
On June 29 2006, Apple announced that an internal investigation "discovered irregularities related to the issuance of certain stock option grants made between 1997 and 2001." A Special Committee reported the findings of the stock backdating investigation three months later on October 4 2006, stating "the investigation found no misconduct by any member of Apple's current management team",. "the most recent evidence of irregularities relates to a January 2002 grant", and "stock option grants made on 15 dates between 1997 and 2002 appear to have grant dates that precede the approval of those grants". The Special Committee also reported that "in a few instances, Apple CEO Steve Jobs was aware that favorable grant dates had been selected, but he did not receive or otherwise benefit from these grants and was unaware of the accounting implications." Documents were subsequently faked to indicate a special board meeting had occurred and that the options had been granted on that day. The backdating gave Jobs a potential net gain of more than US$20 million had he exercised his options.
On April 24 2007, the SEC announced it had filed charges against former Apple chief financial officer Fred D. Anderson and former Apple general counsel Nancy R. Heinen for their alleged roles in backdating Apple options. Anderson immediately settled the charges for a payment of a civil penalty of US$150,000 and disgorgement of "ill-gotten gains" of approximately US$3.49 million. Heinen was charged with, among other things, violating the anti-fraud provisions of the Securities Act of 1933 and the Securities Exchange Act of 1934, lying to Apple's auditors, and violating prohibitions on circumventing internal controls, based on the options awarded to Steve Jobs (dated October 19 2001 but allegedly granted in December 2001) and also option grants awarded to top company executives, including Heinen (dated January 17 2001, but allegedly granted in February 2001.) The SEC is seeking injunctive relief, disgorgement, and money penalties against Heinen, in addition to an order barring her from serving as an officer or director of a public company. The charges against Heinen remain pending.
In late April 2007, the SEC announced that it would not bring action against Apple due to its "swift, extensive, and extraordinary cooperation in the Commission's investigation." Most analysts took this statement to mean that Apple was in the clear, and Steve Jobs personally read the statement to concerned shareholders at a meeting.
Apple was one of several highly successful companies founded in the 1970s that bucked the traditional notions of what a corporate culture should look like in terms of organizational hierarchy (flat versus tall, casual versus formal attire, etc). Other highly successful firms with similar cultural aspects from the same time period include Southwest Airlines and Microsoft. Originally, the company stood in opposition to staid competitors like IBM more or less by default, thanks to the influence of its founders; Steve Jobs often walked around the office barefoot even after Apple was a Fortune 500 company. By the time of the "1984" TV ad, this trait had become a key way the company differentiated itself from its competitors.
As the company has grown and been led by a series of chief executives, each with his own idea of what Apple should be, some of its original character has arguably been lost, but Apple still has a reputation for fostering individuality and excellence that reliably draws talented people into its employ, especially after Jobs' return. To recognize the best of its employees, Apple created the Apple Fellows program. Apple Fellows are those who have made extraordinary technical or leadership contributions to personal computing while at the company. The Apple Fellowship has so far been awarded to a few individuals including Bill Atkinson, Steve Capps, Rod Holt, Alan Kay, Guy Kawasaki, Don Norman, Rich Page, and Steve Wozniak.
According to surveys by J. D. Power, Apple has the highest brand and repurchase loyalty of any computer manufacturer. While this brand loyalty is considered unusual for any product, Apple appears not to have gone out of its way to create it. At one time, Apple evangelists were actively engaged by the company, but this was after the phenomenon was already firmly established. Apple evangelist Guy Kawasaki has called the brand fanaticism "something that was stumbled upon". Apple has, however, supported the continuing existence of a network of Mac User Groups in most major and many minor centers of population where Mac computers are available.
Mac users meet at the European Apple Expo and the San Francisco Macworld Conference & Expo trade shows where Apple introduces new products each year to the industry and public. Mac developers in turn gather at the annual Apple Worldwide Developers Conference.
Apple Store openings can draw crowds of thousands, with some waiting in line as much as a day before the opening or flying in from other countries for the event. The New York City Fifth Avenue "Cube" store had a line as long as half a mile; a few Mac fans took the opportunity of the setting to propose marriage. The Ginza opening in Tokyo was estimated in the thousands with a line exceeding eight city blocks.
Market research indicates that Apple draws its customer base from an unusually artistic, creative, and well-educated population, which may explain the platform’s visibility within certain youthful, avant-garde subcultures.
Apple has received criticism for not notifying users of system vulnerabilities until a fix is released, meaning users are vulnerable to known security flaws until the fix is released.
Longtime Apple consumers have claimed to observe a marked decline in the reliability and durability of the company's computing and iPod lines, particularly since Apple's migration to Intel processors in 2006. The Macbook and Macbook Pro series of laptop computers in particular drew considerable criticism for problems associated with malfunctioning fans, surface discolouration, excessive heat production, and warping cases and batteries,particularly among "revision A" models.The Dublin office of the European Consumer Centre (ECC) consumer body has reported a rise in complaints about products made by Apple, many of which relate to an alleged design fault in some Apple laptops that causes the computer to break down after a year's usage, just outside the company's warranty period. ECC Dublin claims there is a problem with "built-in obsolescence" in some well-known Apple products such as laptops and iPods. It is difficult to estimate the proportion of faults per unit shipped due to the naturally self-selecting tendency of the sample of a consumer base reporting faults. However, the existence of a website, AppleDefects.com, dedicated solely to the discussion of faults with Apple's post-Intel transition product portfolio would appear to vindicate some of the claims being made. In conjunction with the above, Apple has been criticised for treating early adopters of new hardware like "guinea pigs" - in effect using their experiences to iron out bugs in subsequent revisions. One website states that "The conventional wisdom is to not buy "Rev A" Apple hardware" The iPhone was particularly subject to this accusation after the price of the phone was reduced by $200 just two months after its release, resulting in a flood of complaints to Apple Apple did however attempt to rectify things by offering $100 store credit to early iPhone customers.
Apple has been accused of pressuring journalists to release their sources, with regards to leaked information about new Apple products, going as far as filing lawsuits against "John Does". In particular, Apple fought a protracted battle against the Think Secret web site, eventually ending in a settlement that closed the web site but maintained the anonymity of its sources.
Apple also has received criticism for its iPhone and iPod integration with iTunes for not facilitating creation of software to run and maintain those devices using different applications tools besides iTunes.
Similarly, Apple has not licensed its Fairplay DRM system to any other company, preventing users to listening to DRM protected music bought from sources other than the iTunes store. By not allowing other companies or individuals to interoperate with its DRM system, Apple prevents competition and divides the market. For that reason most other online music stores which use DRM use the Windows Media format, which is incompatible with Apple products.
Apple has been investigated and criticized for possible sweatshop conditions in factories in China where contract manufacturers make its iPod.
Apple also has received criticism and two class-action lawsuits at both state and federal level about its iPhone product only being allowed service through a single mobile service provider in each country it has been released in (AT&T in the US, O2 in the UK), citing monopolistic and antitrust allegations between the two companies. Software updates (maliciously or not) initially made unlocked iPhones unusable ("bricked"), however the most recent update revives the phone. Currently there is no official way to unlock an iPhone, and it cannot be bought unlocked for use on any network.
Another common criticism of Apple is that its products are often not user serviceable, instead requiring they be returned to Apple for repairs and upgrades. Typical examples include the batteries in the iPod, iPhone and MacBook Air which are non-user replaceable, and the difficulty of installing simple upgrades (HDD, RAM etc) in older MacBooks.


Aberdeenshire (Siorrachd Obar Dheathain in Gaelic) is one of the 32 unitary council areas in Scotland.
Present day Aberdeenshire does not include Aberdeen City which is a Council Area in its own right. However, Aberdeenshire Council has its headquarters at Woodhill House, in Aberdeen; the only Scottish council whose headquarters are based outwith its area's border. Aberdeenshire borders Angus and Perth and Kinross to the south, and Highland and Moray to the west.
Aberdeenshire has a rich prehistoric and historic heritage. It is the locus of a large number of Neolithic and Bronze Age archaeological sites. Since medieval times there have been a number of crossings of the Mounth (a spur of mountainous land that extends from the higher inland range to the North Sea slightly north of Stonehaven) through present day Aberdeenshire from the Scottish Lowlands to the Highlands. Some of the most well known and historically important trackways are the Causey Mounth and Elsick Mounth.
The present council area is named after the historic county of Aberdeen which had different boundaries and was abolished in 1975, under the Local Government (Scotland) Act 1973. Between 1975 and 1996 the area was incorporated within the region of Grampian, with local government functions being divided between the regional council and three district councils; Banff and Buchan, Gordon and Kincardine and Deeside. The region had also two other districts; Moray and the City of Aberdeen.
In 1996, under the Local Government etc (Scotland) Act 1994, the Banff and Buchan district, the Gordon district and the Kincardine and Deeside district were merged to form the Aberdeenshire council area, and the other two districts became autonomous council areas.
The Council's net expenditure is £399.1m a year (2003/04). Education takes the largest share of expenditure (55%), followed by Social Work and Housing (19%), Transportation and Infrastructure (11%), and Joint Services such as Fire and Police (10%). 22% of revenue is raised locally through the Council Tax. Average Band D Council Tax is the eighth lowest in mainland Scotland at £966 (2003/04).
The population has a higher proportion of younger age groups than the rest of Scotland, reflecting employment-driven in-migration in recent decades.
There are numerous rivers and burns in Aberdeenshire, including Cowie Water, Carron Water, Burn of Muchalls, River Dee, River Don, River Ythan, Feugh Water and Luther Water. Summers are mild and winters are typically cold in Aberdeenshire; Coastal temperatures are moderated by the North Sea such that coastal areas are typically cooler in the summer and warmer in winter than inland locations. Coastal areas are also subject to haar, or coastal fog.

Aztlan Underground is a fusion band from Los Angeles. Since early 1989, Aztlan Underground has played Rapcore. Indigenous drums, flutes, and rattles are commonplace in its musical compositions.
This unique sound is the backdrop for the band's message of dignity for indigenous people, all of humanity, and Earth. Aztlan Underground has been cultivating a grass roots audience across the country, which has become a large and loyal underground following. Their music includes spoken word pieces and elements of punk, hip hop, rock, funk, jazz, and indigenous music, among others.
The artists are Chenek "DJ Bean" (turntables, samples and percussion), Yaotl (vocals, indigenous percussion), Joe "Peps" (bass, rattles), Alonzo Beas (guitars, synth), Caxo (drums, indigenous percussion), and Bulldog (vocals, flute).
Aztlan Underground appeared on television on Culture Clash on Fox in 1993, was part of Breaking Out, a concert on pay per view in 1998, and was featured in the independent films Algun Dia and Frontierlandia.
The band has been mentioned or featured in various newspapers and magazines: the Vancouver Sun, Northshore News (Vancouver, Canada newspaper), New Times (Los Angeles weekly entertainment newspaper), BLU Magazine (underground hip hop magazine), BAM Magazine (Southern California), La Banda Elastica Magazine, and the Los Angeles Times Calendar section. It is also the subject of a chapter in "It's Not About A Salary, by Brian Cross. They also opened for Rage Against the Machine in Mexico City.
It was nominated in the New Times 1998 "Best Latin Influenced" category, the BAM Magazine 1999 "Best Rock en Español" category, and the LA Weekly 1999 "Best Hip Hop" category.
The band is currently in the studio completing their third album as of June 2006. The new album is due in early 2008.


The Anschluss (/ˈanʃlʊs/ German: link-up), also known as the Anschluss Österreichs, was the 1938 annexation of Austria into Greater Germany by the Nazi regime.
The events of March 12, 1938, marked the culmination of historical cross-national pressures to unify the German populations of Austria and Germany under one nation. However, the 1938 Anschluss, regardless of its popularity, was enacted by Germany. Earlier, Nazi Germany had provided support for the Austrian National Socialist Party (Austrian Nazi Party) in its bid to seize power from Austria's Austrofascist leadership. Fully devoted to remaining independent but amidst growing pressures, the chancellor of Austria, Kurt Schuschnigg, tried to hold a plebiscite.
Although he expected Austria to vote in favour of maintaining autonomy, a well-planned internal overthrow by the Austrian Nazi Party of Austria's state institutions in Vienna took place on March 11, prior to the vote. With power quickly transferred over to Germany, the Wehrmacht troops entered Austria to enforce the Anschluss. The Nazis held a plebiscite within the following month, where they received 99.73% of the vote. No fighting ever took place and the strongest voices against the annexation, particularly Fascist Italy, France and the United Kingdom (the "Stresa Front"), were powerless or, in the case of Italy, appeased. The Allies were, on paper, committed to upholding the terms of the Treaty of Versailles, which specifically prohibited the union of Austria and Germany.
Nevertheless, the Anschluss was among the first major steps in Adolf Hitler's long-desired creation of an empire including German-speaking lands and territories Germany had lost after World War I. Already prior to the 1938 annexation, the Rhineland was retaken and the Saar region was returned to Germany after fifteen years of occupation. After the Anschluss, the predominantly German Sudetenland of Czechoslovakia was taken, with the rest of the country becoming a protectorate to Germany in 1939. That same year, Memelland was returned from Lithuania, the final peaceful territorial aggrandizement before the start of World War II.
Austria ceased to exist as a fully independent nation until late 1945. A Provisional Austrian Government was set up on April 27, 1945 and was legally recognized by the Allies in the following months, but it was not until 1955 that Austria regained full sovereignty.
The idea of grouping all Germans into one state had been the subject of inconclusive debate since the end of the Holy Roman Empire in 1806. Before 1866, it was generally thought that the unification of the Germans could only succeed under Austrian leadership, but the rise of Prussia was largely unpredicted. This created a rivalry between the two that made unification through a Großdeutschland solution impossible. Also, due to the multi-ethnic composition of the Austro-Hungarian Empire centralized in Vienna, many rejected this notion and it was unthinkable that Austria would give up her "non-German" territories, let alone submit to Prussia. Nevertheless, a series of wars, including the Austro-Prussian War, led to the expulsion of Austria from German affairs, allowed for the creation of the North German Confederation and consolidated the German states through Prussia, enabling the creation of a German Empire in 1871. Otto von Bismarck played a fundamental role in this process, with the end result representing a Kleindeutsche solution that did not include the German-speaking parts of Austria-Hungary. The Emperor in Vienna did not want to become a member of Bismarck's Second Reich, because he would have been forced to be an Emperor of "second class" compared with the Emperor in Berlin. When Austria-Hungary broke up in 1918, many German-speaking Austrians hoped to join with Germany in the realignment of Europe, but the Treaty of Versailles (1919) and the Treaty of Saint-Germain of 1919 explicitly vetoed the inclusion of Austria within a German state, because France and the UK feared the power of a larger Germany, and had already begun to disempower the current one. Also Austrian particularism, especially among the nobility, played a huge role, as Austria was Roman Catholic, while Germany was dominated, especially in government, more by Protestants. Both constitutions, that of Weimar Republic and that of the First Austrian Republic, included the political aim of unification and this aim was widely supported also by democratic parties. In the early 1930s, popular support for union with Germany remained overwhelming, and the Austrian government looked to a possible customs union with Germany in 1931.
In early 1938, Hitler had consolidated his power in Germany and was ready to reach out to fulfill his long-planned expansion. After a lengthy period of pressure by Germany, Hitler met Kurt Schuschnigg, the Chancellor of Austria on 12 February 1938 in Berchtesgaden (Bavaria) and instructed him to lift the ban on political parties, reinstate full party freedoms, release all imprisoned members of the Nazi party and let them participate in the government. Otherwise, he would take military action. Schuschnigg complied with Hitler's demands and appointed Arthur Seyss-Inquart, a pro-Nazi lawyer, as Interior Minister and another Nazi, Edmund Glaise-Horstenau, as Minister, even without a portfolio.
Before the February meeting, Schuschnigg was already under considerable pressure from Germany. This may be seen in the demand to remove the chief of staff of the Austrian Army, Alfred Jansa, from his position in January 1938. Jansa and his staff had developed a scenario for Austria's defense against a German attack, a situation Hitler wanted to avoid at all costs. Schuschnigg subsequently complied with the demand.
During the following weeks, Schuschnigg realized that his newly appointed ministers were working to take over his authority. Schuschnigg tried to gather support throughout Austria and inflame patriotism among the people. For the first time since 12 February 1934 (the time of the Austrian Civil War), socialists and communists could legally appear in public again. The communists announced their unconditional support for the Austrian government, understandable in light of Nazi pressure on Austria. The socialists demanded further concessions from Schuschnigg before they were willing to side with him.
On 9 March, as a last resort to preserve Austria's independence, Schuschnigg scheduled a plebiscite on the independence of Austria for 13 March. To secure a large majority in the referendum, Schuschnigg set the minimum voting age at 24 in order to exclude younger voters who largely sympathized with Nazi ideology. Holding a referendum was a highly risky gamble for Schuschnigg, and, on the next day, it became apparent that Hitler would not simply stand by while Austria declared its independence by public vote. Hitler declared that the plebiscite would be subject to major fraud and that Germany would not accept it. In addition, the German Ministry of Propaganda issued press reports that riots had broken out in Austria and that large parts of the Austrian population were calling for German troops to restore order. Schuschnigg immediately responded publicly that reports of riots were false.
Hitler sent an ultimatum to Schuschnigg on 11 March, demanding that he hand over all power to the Austrian National Socialists or face an invasion. The ultimatum was set to expire at noon, but was extended by two hours. However, without waiting for an answer, Hitler had already signed the order to send troops into Austria at one o'clock, issuing it to Hermann Göring only hours later.
Schuschnigg desperately sought support for Austrian independence in the hours following the ultimatum, but, realizing that neither France nor the United Kingdom was willing to take steps, he resigned as Chancellor that evening. In the radio broadcast in which he announced his resignation, he argued that he accepted the changes and allowed the Nazis to take over the government in order to avoid bloodshed. Meanwhile, Austrian President Wilhelm Miklas refused to appoint Seyss-Inquart Chancellor and asked other Austrian politicians such as Michael Skubl and Sigismund Schilhawsky to assume the office. However, the Nazis were well organised. Within hours they managed to take control of many parts of Vienna, including the Ministry of Internal Affairs (controlling the Police). As Miklas continued to refuse to appoint a Nazi government and Seyss-Inquart still could not send a telegram in the name of the Austrian government demanding German troops to restore order, Hitler became furious. At about 10 PM, well after Hitler had signed and issued the order for the invasion, Göring and Hitler gave up on waiting and published a forged telegram containing a request by the Austrian Government for German troops to enter Austria. Around midnight, after nearly all critical offices and buildings had fallen into Nazi hands in Vienna and the main political party members of the old government had been arrested, Miklas finally conceded to appoint Seyss-Inquart Chancellor.
On the morning of 12 March, the 8th Army of the German Wehrmacht crossed the German-Austrian border. They did not face resistance by the Austrian Army—on the contrary, the German troops were greeted by cheering Austrians with Hitler salutes, Nazi flags and flowers. By this the NS invasion into Austria without one single shooting is also called "Blumenkrieg" (war of flowers). For the Wehrmacht this invasion was the first big test of its machinery. Although the invading forces were badly organized and coordination between the units was poor, it mattered little because no fighting took place. It did, however, serve as a warning to German commanders in future military operations, such as that against Czechoslovakia.
The Anschluss was given immediate effect by legislative act on 13 March, subject to ratification by a plebiscite. Austria became the province of Ostmark, and Seyss-Inquart was appointed Governor. The plebiscite was held on 10 April and officially recorded a support of 99.73% of the voters.
Hitler's brutal methods to emasculate any opposition were immediately implemented in the weeks preceding the referendum. Even before the first German soldier crossed the border, Heinrich Himmler and a few SS officers landed in Vienna to arrest prominent representatives of the First Republic such as Richard Schmitz, Leopold Figl, Friedrich Hillegeist and Franz Olah. During the few short weeks between the Anschluss and the plebiscite, Social Democrats, Communists, and other potential political dissenters, as well as Jews, were rounded up and either imprisoned or sent to concentration camps. Within only a few days of 12 March, 70,000 people had been arrested. The referendum itself was subject to large-scale propaganda and to the abrogation of the voting rights of around 400,000 people (nearly 10% of the eligible voting population), mainly former members of left-wing parties and Jews.
While historians concur that the result itself was not manipulated, the voting process was neither free nor secret. Officials were present directly beside the voting booths and received the voting ballot by hand (in contrast to a secret vote where the voting ballot is inserted into a closed box). In some remote areas of Austria the referendum on the independence of Austria on 13 March was held despite the Wehrmacht's presence in Austria (it took up to 3 days to occupy every part of Austria). For instance, in the village of Innervillgraten a majority of 95% voted for Austria's independence.
Austria remained part of the Third Reich until the end of World War II when a preliminary Austrian Government declared the Anschluss "null und nichtig" (null and void) on April 27 1945. After the war, then allied-occupied Austria was recognized and treated as a separate country, but was not restored to sovereignty until the Austrian State Treaty and Austrian Declaration of Neutrality, both of 1955, largely due to the rapid development of the Cold War and disputes between the Soviet Union and its former allies over its foreign policy.
The picture of Austria in the first days of its existence in the Third Reich is one of contradictions: at one and the same time, Hitler's terror regime began to tighten its grip in every area of society, beginning with mass arrests and thousands of Austrians attempting to flee in every direction; yet Austrians could be seen cheering and welcoming German troops entering Austrian territory. Many Austrian political figures did not hesitate to announce their support of the Anschluss and their relief that it happened without violence.
Cardinal Theodor Innitzer (a political figure of the CS) declared as early as 12 March: "The Viennese Catholics should thank the Lord for the bloodless way this great political change has occurred, and they should pray for a great future for Austria. Needless to say, everyone should obey the orders of the new institutions." The other Austrian bishops followed suit some days later. Vatican Radio, however, immediately broadcast a vehement denunciation of the German action, and Cardinal Pacelli, the Vatican Secretary of State, ordered Innitzer to report to Rome. Before meeting with the pope, Innitzer met with Pacelli, who had been outraged by Innitzer's statement. He made it clear that Innitzer needed to retract; he was made to sign a new statement, issued on behalf of all the Austrian bishops, which provided: ""The solemn declaration of the Austrian bishops.. was clearly not intended to be an approval of something that was not and is not compatible with God's law"". The Vatican newspaper also reported that the bishops' earlier statement had been issued without the approval from Rome.
Robert Kauer, President of the Protestants in Austria, greeted Hitler on 13 March as "saviour of the 350,000 German Protestants in Austria and liberator from a five-year hardship." Even Karl Renner, the most famous Social Democrat of the First Republic, announced his support for the Anschluss and appealed to all Austrians to vote in favour of it on 10 April.
His Majesty's Government have throughout been in the closest touch with the situation. The Foreign Secretary saw the German Foreign Minister on the 10th of March and addressed to him a grave warning on the Austrian situation and upon what appeared to be the policy of the German Government in regard to it.. Late on the 11th of March our Ambassador in Berlin registered a protest in strong terms with the German Government against such use of coercion, backed by force, against an independent State in order to create a situation incompatible with its national independence.
I imagine that according to the temperament of the individual the events which are in our minds to-day will be the cause of regret, of sorrow, perhaps of indignation. They cannot be regarded by His Majesty's Government with indifference or equanimity. They are bound to have effects which cannot yet be measured. The immediate result must be to intensify the sense of uncertainty and insecurity in Europe. Unfortunately, while the policy of appeasement would lead to a relaxation of the economic pressure under which many countries are suffering to-day, what has just occurred must inevitably retard economic recovery and, indeed, increased care will be required to ensure that marked deterioration does not set in. This is not a moment for hasty decisions or for careless words. We must consider the new situation quickly, but with cool judgement.. As regards our defence programmes, we have always made it clear that they were flexible and that they would have to be reviewed from time to time in the light of any development in the international situation. It would be idle to pretend that recent events do not constitute a change of the kind that we had in mind. Accordingly we have decided to make a fresh review, and in due course we shall announce what further steps we may think it necessary to take.
The moderate reaction to the Anschluss was the first major consequence of the strictly followed appeasement British foreign policy strategy. The international reaction to the events of March 12, 1938 led Hitler to conclude that he could use even more aggressive tactics in his roadmap to expand the Third Reich, as he would later in annexing the Sudetenland. The relatively bloodless Anschluss helped pave the way for the Treaty of Munich in September 1938 and the annexation of Czechoslovakia in 1939, because it reinforced appeasement as the right way for Britain to deal with Hitler's Germany.
The word "Anschluss" outside the context of March 1938 is properly translated as "joinder", "connection", "unification" or "political union". In contrast the German word "Annektierung" that would mean military annexation unambiguously was and is not commonly used in this context. The usage of the term "Anschluss" has been widespread before and in 1938 describing an incorporation of Austria into Germany. Calling the incorporation of Austria into Nazi Germany an "Anschluss", that is a unification or joinder, was however also part of the propaganda used in 1938 by Hitler and the Nazis to create the impression the events of March 1938 were not backed and enforced by miliary pressure. Hitler himself stressed the meaning of the events numerous times following the "Anschluss" and described the incorporation of Austria as the return of it to its original home (Heimkehr). The word Anschluss endured the years of the Second World War and the years thereafter, letting the term, despite its non-correlating to the actual events and propaganda usage in 1938 stand for the events that took place.
Some historical sources, for instance, Encyclopædia Britannica, describe the Anschluss as an "annexation" rather than a union. From a factual view of the events that were mainly driven by the German military power and political pressure within Austria and from the outside the term annexation is the closer description than the term "Anschluss". It however omits to present the differences between the "Anschluss" and other annexations of Nazi Germany backed by force, i.e. large parts of the Austrian population either supported or were indifferent to the incorporation of Austria into the Third Reich.
The Anschluss can be misunderstood as merely a military annexation. This invites confusion with other German military occupations of European countries. Adolf Hitler himself was an Austrian. Despite the subversion by Hitler's sympathisers, Austrian acceptance of direct government by Hitler's Germany was a different phenomenon from the administration of other collaborationist countries.
The governments of the United Kingdom, the Soviet Union and the United States of America are agreed that Austria, the first free country to fall a victim to Hitlerite aggression, shall be liberated from German domination.
They regard the annexation imposed on Austria by Germany on 15 March 1938, as null and void. They consider themselves as in no way bound by any charges effected in Austria since that date. They declare that they wish to see re-established a free and independent Austria and thereby to open the way for the Austrian people themselves, as well as those neighbouring States which will be faced with similar problems, to find that political and economic security which is the only basis for lasting peace.
Austria is reminded, however, that she has a responsibility, which she cannot evade, for participation in the war at the side of Hitlerite Germany, and that in the final settlement account will inevitably be taken of her own contribution to her liberation.
To judge from the last paragraph and subsequent determinations at the Nuremberg Trial, the Declaration was intended to serve as propaganda aimed at stirring Austrian resistance (although there are Austrians counted as Righteous Among the Nations, there never was an effective Austrian armed resistance of the sort found in other countries under German occupation) more than anything else, although the exact text of the declaration is said to have a somewhat complex drafting history. At Nuremberg Arthur Seyss-Inquart and Franz von Papen, in particular, were both indicted under count one (conspiracy to commit crimes against peace) specifically for their activities in support of the Austrian Nazi Party and the Anschluss, but neither was convicted of this count. In acquitting von Papen, the court noted that his actions were in its view political immoralities but not crimes under its charter. Seyss-Inquart was convicted of other serious war crimes, most of which took place in Poland and the Netherlands, was sentenced to death and executed.
After World War II, many Austrians sought comfort in the idea of Austria as "the Nazis' first victim". Although the Nazi party was promptly banned, Austria did not have the same thorough process of de-Nazification at the top of government which was imposed on Germany for a time. Lacking outside pressure for political reform, factions of Austrian society tried for a long time to advance the view that the Anschluss was only an annexation at the point of a bayonet.
This view of the events of 1938 has deep roots in the ten years of Allied occupation and the struggle to regain Austrian sovereignty: The victim theory played an essential role in the negotiations on the Austrian State Treaty with the Soviets, and by pointing to the Moscow Declaration, Austrian politicians heavily relied on it to achieve a solution for Austria different from the Germany's division into East and West. The State Treaty, alongside with the subsequent Austrian declaration of permanent neutrality, marked important milestones for the solidification of Austria's independent national identity during the course of following decades.
As Austrian politicians of the Left and Right attempted to reconcile their differences in order to avoid the violent conflict that had dominated the First Republic, discussions of both Austrian-Nazism and Austria's role during the Nazi-era were largely avoided. Still, the Austrian People's Party (ÖVP) had advanced, and still advances, the argument that the establishment of the Dollfuss dictatorship was necessary in order to maintain Austrian independence; while the Austrian Social Democratic Party, (SPÖ), argues that the Dollfuss dictatorship stripped the country of the democratic resources necessary to repel Hitler; yet it ignores that Hitler himself was indigenous to Austria.
For decades, the victim theory established in the Austrian mind remained largely undisputed. The Austrian public was only rarely forced to confront the legacy of the Third Reich (most notably during the events of 1965 concerning Taras Borodajkewycz, a professor of economic history notorious for anti-Semitic remarks, when Ernst Kirchweger, a concentration camp survivor, was killed by a right-wing protester during riots). It was not until the 1980s that Austrians were finally massively confronted with their past. The main catalyst for the start of a Vergangenheitsbewältigung was the so-called Waldheim affair. The Austrian reply to allegations during the 1986 Presidential election campaign that successful candidate and former UN Secretary-General Kurt Waldheim had been a member of the Nazi party and of the infamous SA (he was later absolved of direct involvement in war crimes) was that scrutiny was an unwelcome intervention in the country's internal affairs. Despite the politicians' reactions to international criticism of Waldheim, the Waldheim affair started the first serious major discussion on Austria's past and the Anschluss.
Another main factor for Austria and its coming to terms with the past emerged in the 1980s: Jörg Haider and the rise of the Freedom Party of Austria (FPÖ). The party had combined elements of the pan-German right with free-market liberalism since its foundation in 1955, but after Haider had ascended to the party chairmanship in 1986, the liberal elements became increasingly marginalized while Haider began to openly use nationalist and anti-immigrant rhetoric. He was often criticised for tactics such as the völkisch (ethnic) definition of national interest ("Austria for Austrians") and his apologism for Austria's past, notably calling members of the Waffen-SS "men of honour". Following an enormous electoral rise in the 1990s peaking in the 1999 elections, the FPÖ, now purged of its liberal elements, entered a coalition with the Austrian People's Party (ÖVP) led by Wolfgang Schüssel that met international condemnation in 2000. This coalition triggered the regular Donnerstagsdemonstrationen (Thursday demonstrations) in protest against the government, which took place on the Heldenplatz, where Hitler had greeted the masses during the Anschluss. Haider's tactics and rhetoric, which were often criticised as sympathetic to Nazism, again forced Austrians to reconsider their relationship to the past.
But Haider is not alone in making controversial remarks about Austria's past: Haider's coalition partner, former Chancellor Wolfgang Schüssel, in a 2000 interview with the Jerusalem Post stated that Austria was the first victim of Hitler-Germany.
Tearing into the simplism of the victim theory and the time of the Austrofascism, Thomas Bernhard's last play, Heldenplatz, was highly controversial even before it appeared on stage in 1988, fifty years after Hitler's visit. Bernhard's achievement was to make the elimination of references to Hitler's reception in Vienna emblematic of Austrian attempts to claim their history and culture under questionable criteria. Many politicians from all political factions called Bernhard a Nestbeschmutzer (so. damaging the reputation of his country) and openly demanded that the play should not be staged in Vienna's Burgtheater. Kurt Waldheim, who was at that time still Austrian president called the play a crude insult to the Austrian people.
I personally would like to know why the WJC World Jewish Congress has hardly put any pressure on Austria, even as leading Nazis and SS leaders were Austrians, Hitler included.. Immediately after the war, the US wanted to make the Russians withdraw from Austria, and the Russians wanted to keep Austria neutral, therefore there was a common interest to grant Austria victim status. And later Austria could cry poor - though its per capita income is as high as Germany's. And, most importantly, the Austrian PR machinery works better. Austria has the opera ball, the imperial castle, Mozartkugeln [a chocolate]. Americans like that. And Austrians invest and export relatively little to the US, therefore they are less vulnerable to blackmail. In the meantime, they set up a commission in Austria to clarify what happened to Jewish property. Victor Klima, the former chancellor, has asked me to join. My father fought for Austria in the First World War and in 1939 he was kicked out of Austria. After the war they offered him ten dollars per month as compensation. For this reason I told Klima, no thank you, this makes me sick.
Given the extensive participation of numerous Austrians, including at the highest levels, in the implementation of the Final Solution and other Nazi crimes, Austria should have been a leader in the prosecution of Holocaust perpetrators over the course of the past four decades, as has been the case in Germany. Unfortunately relatively little has been achieved by the Austrian authorities in this regard and in fact, with the exception of the case of Dr. Heinrich Gross which was suspended this year under highly suspicious circumstances (he claimed to be medically unfit, but outside the court proved to be healthy) not a single Nazi war crimes prosecution has been conducted in Austria since the mid-1970s.
In 2003, the Center launched a worldwide effort named "Operation: Last Chance" in order to collect further information about those Nazis still alive that are potentially subject to prosecution. Although reports issued shortly thereafter credited Austria for initiating large-scale investigations, there has been one case where criticism of Austrian authorities arose recently: The Center has put 92-year old Croatian Milivoj Asner on its 2005 top ten list. Asner fled to Austria in 2004 after Croatia announced it would start investigations in the case of war crimes he may have been involved in. In response to objections about Asner's continued freedom, Austria's federal government has deferred to either extradition requests from Croatia or prosecutorial actions from Klagenfurt, neither of which appears forthcoming (as of June 2005). Extradition is not an option since Asner also holds Austrian citizenship, having lived in the country from 1946 to 1991.


The American Civil War (1861–1865), which is also known by several other names, was a civil war between the United States of America (the "Union") and the Southern slave states of the newly formed Confederate States of America under Jefferson Davis. The Union included all of the free states and the five slaveholding border states and was led by Abraham Lincoln and the Republican Party. Republicans opposed the expansion of slavery into territories owned by the United States, and their victory in the presidential election of 1860 resulted in seven Southern states declaring their secession from the Union even before Lincoln took office. The Union rejected secession, regarding it as rebellion.
Hostilities began on April 12 1861, when Confederate forces attacked a U.S. military installation at Fort Sumter in South Carolina. Lincoln responded by calling for a large volunteer army, then four more Southern states declared their secession. In the war's first year, the Union assumed control of the border states and established a naval blockade as both sides massed armies and resources. In 1862, battles such as Shiloh and Antietam caused massive casualties unprecedented in U.S. military history. In September 1862, Lincoln's Emancipation Proclamation made ending slavery in the South a war goal, which complicated the Confederacy's manpower shortages.
In the East, Confederate commander Robert E. Lee won a series of victories over Union armies, but Lee's reverse at Gettysburg in early July, 1863 proved the turning point. The capture of Vicksburg and Port Hudson by Ulysses S. Grant completed Union control of the Mississippi River. Grant fought bloody battles of attrition with Lee in 1864, forcing Lee to defend the Confederate capital at Richmond, Virginia. Union general William Sherman captured Atlanta, Georgia, and began his famous March to the Sea, devastating a hundred-mile-wide swath of Georgia. Confederate resistance collapsed after Lee surrendered to Grant at Appomattox Court House on April 9, 1865.
The coexistence of a slave-owning South with an increasingly anti-slavery North made conflict inevitable. Lincoln did not propose federal laws against slavery where it already existed, but he had, in his 1858 House Divided Speech, expressed a desire to "arrest the further spread of it, and place it where the public mind shall rest in the belief that it is in the course of ultimate extinction". Much of the political battle in the 1850s focused on the expansion of slavery into the newly created territories. All of the organized territories were likely to become free-soil states, which increased the Southern movement toward secession. Both North and South assumed that if slavery could not expand it would wither and die.
Southern fears of losing control of the federal government to antislavery forces, and Northern fears that the slave power already controlled the government, brought the crisis to a head in the late 1850s. Sectional disagreements over the morality of slavery, the scope of democracy and the economic merits of free labor vs. slave plantations caused the Whig and "Know-Nothing" parties to collapse, and new ones to arise (the Free Soil Party in 1848, the Republicans in 1854, the Constitutional Union in 1860). In 1860, the last remaining national political party, the Democratic Party, split along sectional lines.
Both North and South were influenced by the ideas of Thomas Jefferson. Southerners emphasized the states' rights ideas mentioned in Jefferson's Kentucky and Virginia Resolutions and the right of revolution mentioned in the Declaration of Independence. Northerners ranging from the abolitionist William Lloyd Garrison to the moderate Republican leader Abraham Lincoln emphasized Jefferson's declaration that all men are created equal. Lincoln mentioned this proposition in his Gettysburg Address.
Historian Kenneth M. Stampp mentioned Confederate Vice President Alexander Stephens' A Constitutional View of the Late War Between the States as an example of a Southern leader who said that slavery was the "cornerstone of the Confederacy" when the war began and then said that the war was not about slavery but states' rights after Southern defeat. Stampp said that Stephens became one of the most ardent defenders of the Lost Cause.
All but one inter-regional crisis involved slavery, starting with debates on the three-fifths clause in the Constitutional Convention of 1787. Other factors include sectionalism (caused by the growth of slavery in the deep South while slavery was gradually phased out in Northern states) and economic differences between North and South, although most modern historians disagree with the extreme economic determinism of historian Charles Beard. The fact that seven immigrants out of eight settled in the North, plus the fact that twice as many whites left the South for the North as vice versa, contributed to the South's defensive-aggressive political behavior. There was controversy over adding the slave state of Missouri to the Union that led to the Missouri Compromise of 1820, the Nullification Crisis over the Tariff of 1828 (although the tariff was low after 1846), the Gag rule that prevented discussion in Congress of petitions for ending slavery from 1835–1844, the acquisition of Texas as a slave state in 1845 and Manifest Destiny as an argument for gaining new territories where slavery would become an issue after the Mexican-American War (1846–1848), which resulted in the Compromise of 1850. The Wilmot Proviso was an unsuccessful attempt by Northern politicians to exclude slavery from the territories conquered from Mexico. There were unsuccessful attempts to end controversy over slavery in the territories through popular sovereignty and Southern attempts to annex Cuba (including the Ostend Manifesto) and Nicaragua as slave states. The extremely popular antislavery novel Uncle Tom’s Cabin (1852) by Harriet Beecher Stowe greatly increased Northern opposition to the Fugitive Slave Law of 1850.
John Brown's raid in 1859 and the split in the Democratic Party in 1860 polarized the nation between North and South. The election of Lincoln in 1860 was the final trigger for secession. During the secession crisis, many sought compromise. Two of these attempts were the "Corwin Amendment" and the "Crittenden Compromise." All attempts at compromise failed.
Southern secession was triggered by the election of Republican Abraham Lincoln because regional leaders feared that he would stop the expansion of slavery and put it on a course toward extinction. Many Southerners thought either Lincoln or another Northerner would abolish slavery, and that it was time to secede. The slave states, which had already become a minority in the House of Representatives, were now facing a future as a perpetual minority in the Senate and Electoral College against an increasingly powerful North. Deep South states with the most slavery seceded first, followed by the secession of four more states following the Battle of Fort Sumter and Lincoln's subsequent call for each remaining state to provide troops to retake forts and suppress the insurrection. Upper South states refused to send troops against their neighbors in what they considered an invasion.
A strong correlation was shown between the degree of support for secession and the number of plantations in the region; states of the deep South which had the greatest concentration of plantations were the first to secede. The upper South slave states of Virginia, North Carolina, Arkansas, and Tennessee had fewer plantations and rejected secession until the Fort Sumter crisis forced them to choose sides. Border states had fewer plantations still and never seceded.
The percentage of Southern whites living in families that owned slaves was 36.7 percent in the lower South, 25.3 percent in the upper South and 15.9 percent in the border states that fought mostly for the Union. Ninety-five percent of blacks lived in the South, comprising one third of the population there as opposed to one percent of the population of the North. Consequently, fears of eventual emancipation were much greater in the South than in the North.
The Supreme Court decision of 1857 in Dred Scott v. Sandford added to the controversy. Chief Justice Roger B. Taney's decision said that slaves were "so far inferior that they had no rights which the white man was bound to respect", and that slavery could spread into the territories. Lincoln warned that "the next Dred Scott decision" could threaten northern states with slavery.
Northern politician Abraham Lincoln said, "this question of Slavery was more important than any other; indeed, so much more important has it become that no other national question can even get a hearing just at present." The slavery issue was related to sectional competition for control of the territories, and the Southern demand for a slave code for the territories was the issue used by Southern politicians to split the Democratic Party in two, which all but guaranteed the election of Lincoln and secession. When secession was an issue, South Carolina planter and state Senator John Townsend said that "our enemies are about to take possession of the Government, that they intend to rule us according to the caprices of their fanatical theories, and according to the declared purposes of abolishing slavery." Similar opinions were expressed throughout the South in editorials, political speeches and declarations of reasons for secession. Even though Lincoln had no plans to outlaw slavery where it existed, Southerners throughout the South expressed fears for the future of slavery.
Southern concerns included not only economic loss but also fears of racial equality. The Texas Declaration of Causes for Secession said that the non-slave-holding states were "proclaiming the debasing doctrine of equality of all men, irrespective of race or color", and that the African race "were rightfully held and regarded as an inferior and dependent race". Alabama secessionist E. S. Dargan said that emancipation would make Southerners feel "demoralized and degraded".
Beginning in the 1830s, the U.S. Postmaster General refused to allow mail which carried abolition pamphlets to the South. Northern teachers suspected of any tinge of abolitionism were expelled from the South, and abolitionist literature was banned. Southerners rejected the denials of Republicans that they were abolitionists. John Brown's raid on the federal Harpers Ferry Armory greatly increased Southern fears of slave insurrections. The North felt threatened as well, for as Eric Foner concludes, "Northerners came to view slavery as the very antithesis of the good society, as well as a threat to their own fundamental values and interests".
Before Lincoln took office, seven states had declared their secession from the Union. They established a Southern government, the Confederate States of America on February 9 1861. They took control of federal forts and other properties within their boundaries with little resistance from outgoing President James Buchanan, whose term ended on March 4 1861. Buchanan asserted, "The South has no right to secede, but I have no power to prevent them." One quarter of the U.S. Army—the entire garrison in Texas—was surrendered to state forces by its commanding general, David E. Twiggs, who then joined the Confederacy.
As Southerners resigned their seats in the Senate and the House, secession later enabled Republicans to pass bills for projects that had been blocked by Southern Senators before the war, including the Morrill Tariff, land grant colleges (the Morill Act), a Homestead Act, a trans-continental railroad (the Pacific Railway Acts), the National Banking Act and the authorization of United States Notes by the Legal Tender Act of 1862. The Revenue Act of 1861 introduced the income tax to help finance the war.
Seven Deep South cotton states seceded by February 1861, starting with South Carolina, Mississippi, Florida, Alabama, Georgia, Louisiana, and Texas. These seven states formed the Confederate States of America (February 4 1861), with Jefferson Davis as president, and a governmental structure closely modeled on the U.S. Constitution. Within two months of the first shots at Fort Sumter, four more slave states seceded and joined the Confederacy: Virginia, Arkansas, North Carolina and Tennessee. The northwestern portion of Virginia subsequently seceded from Virginia, joining the Union as the new state of West Virginia on June 20 1863.
Twenty-three states remained loyal to the Union: California, Connecticut, Delaware, Illinois, Indiana, Iowa, Kansas, Kentucky, Maine, Maryland, Massachusetts, Michigan, Minnesota, Missouri, New Hampshire, New Jersey, New York, Ohio, Oregon, Pennsylvania, Rhode Island, Vermont, and Wisconsin. During the war, Nevada and West Virginia joined as new states of the Union. Tennessee and Louisiana were returned to Union control early in the war.
The territories of Colorado, Dakota, Nebraska, Nevada, New Mexico, Utah, and Washington fought on the Union side. Several slave-holding Native American tribes supported the Confederacy, giving the Indian territory (now Oklahoma) a small bloody civil war.
The Border states in the Union were West Virginia (which was separated from Virginia and became a new state), and four of the five northernmost slave states (Maryland, Delaware, Missouri, and Kentucky).
Maryland had numerous pro-Confederate officials who tolerated anti-Union rioting in Baltimore and the burning of bridges. Lincoln responded with martial law and called for troops. Militia units that had been drilling in the North rushed toward Washington and Baltimore. Before the Confederate government realized what was happening, Lincoln had seized firm control of Maryland (and the separate District of Columbia), by arresting all the Maryland government members and holding them without trial.
In Missouri, an elected convention on secession voted decisively to remain within the Union. When pro-Confederate Governor Claiborne F. Jackson called out the state militia, it was attacked by federal forces under General Nathaniel Lyon, who chased the governor and the rest of the State Guard to the southwestern corner of the state. (See also: Missouri secession). In the resulting vacuum, the convention on secession reconvened and took power as the Unionist provisional government of Missouri.
Kentucky did not secede; for a time, it declared itself neutral. However, the Confederates broke the neutrality by seizing Columbus, Kentucky in September 1861. That turned opinion against the Confederacy, and the state reaffirmed its loyal status, while trying to maintain slavery. During a brief invasion by Confederate forces, Confederate sympathizers organized a secession convention, inaugurated a governor, and gained recognition from the Confederacy. The rebel government soon went into exile and never controlled the state.
After Virginia's 1861 declaration of secession from the U.S. Union supporters in fifty counties of northwestern Virginia voted on October 24, 1861 to approve the creation of the new state of West Virginia. The majority of the voters in what was to become West Virginia had voted against Virginia’s secession, although twenty six of the fifty counties had pro-secession majorities. About half of West Virginia's soldiers were Confederate. This new state was admitted to the Union on June 20, 1863.
Similar Unionist secessions attempts appeared in East Tennessee, but were suppressed by the Confederacy. Jefferson Davis arrested over 3000 men suspected of being loyal to the Union and held them without trial.
Over 10,000 military engagements took place during the war, 40% of them in Virginia and Tennessee. Since separate articles deal with every major battle and many minor ones, this article only gives the broadest outline. For more information see List of American Civil War battles and Military leadership in the American Civil War.
Lincoln's victory in the presidential election of 1860 triggered South Carolina's declaration of secession from the Union. By February 1861, six more Southern states made similar declarations. On February 7, the seven states adopted a provisional constitution for the Confederate States of America and established their temporary capital at Montgomery, Alabama. A pre-war February Peace Conference of 1861 met in Washington in a failed attempt at resolving the crisis. The remaining eight slave states rejected pleas to join the Confederacy. Confederate forces seized most of the Federal forts within their boundaries (they did not take Fort Sumter); President Buchanan protested but made no military response aside from a failed attempt to resupply Fort Sumter via the ship Star of the West (the ship was fired upon by Citadel cadets), and no serious military preparations. However, governors in Massachusetts, New York, and Pennsylvania quietly began buying weapons and training militia units.
On March 4 1861, Abraham Lincoln was sworn in as President. In his inaugural address, he argued that the Constitution was a more perfect union than the earlier Articles of Confederation and Perpetual Union, that it was a binding contract, and called any secession "legally void". He stated he had no intent to invade Southern states, nor did he intend to end slavery where it existed, but that he would use force to maintain possession of federal property. His speech closed with a plea for restoration of the bonds of union.
The South sent delegations to Washington and offered to pay for the federal properties and enter into a peace treaty with the United States. Lincoln rejected any negotiations with Confederate agents on the grounds that the Confederacy was not a legitimate government, and that making any treaty with it would be tantamount to recognition of it as a sovereign government. However, Secretary of State William Seward engaged in unauthorized and indirect negotiations that failed.
Fort Sumter in Charleston, South Carolina, Fort Monroe, Fort Pickens and Fort Taylor were the remaining Union-held forts in the Confederacy, and Lincoln was determined to hold Fort Sumter. Under orders from Confederate President Jefferson Davis, troops controlled by the Confederate government under P. G. T. Beauregard bombarded the fort with artillery on April 12, forcing the fort's capitulation. Northerners rallied behind Lincoln's call for all of the states to send troops to recapture the forts and to preserve the Union. With the scale of the rebellion apparently small so far, Lincoln called for 75,000 volunteers for 90 days. For months before that, several Northern governors had discreetly readied their state militias; they began to move forces the next day.
Four states in the upper South (Tennessee, Arkansas, North Carolina, and Virginia), which had repeatedly rejected Confederate overtures, now refused to send forces against their neighbors, declared their secession, and joined the Confederacy. To reward Virginia, the Confederate capital was moved to Richmond. The city was the symbol of the Confederacy; if it fell, the new nation would lose legitimacy. Richmond was in a highly vulnerable location at the end of a tortuous Confederate supply line. Although Richmond was heavily fortified, supplies for the city would be reduced by Sherman's capture of Atlanta and cut off almost entirely when Grant besieged Petersburg and its railroads that supplied the Southern capital.
Winfield Scott, the commanding general of the U.S. Army, devised the Anaconda Plan to win the war with as little bloodshed as possible. His idea was that a Union blockade of the main ports would weaken the Confederate economy; then the capture of the Mississippi River would split the South. Lincoln adopted the plan, but overruled Scott's warnings against an immediate attack on Richmond.
In May 1861, Lincoln enacted the Union blockade of all Southern ports, ending most international shipments to the Confederacy. Violators' ships and cargos could be seized and were often not covered by insurance. By late 1861, the blockade stopped most local port-to-port traffic. The blockade shut down King Cotton, ruining the Southern economy. British investors built small, fast "blockade runners" that traded arms and luxuries from Bermuda, Cuba and the Bahamas in return for high-priced cotton and tobacco. When captured, the blockade runners and cargo were sold and the proceeds given to the Union sailors, but the British crews were released. Shortages of food and other goods triggered by the blockade, foraging by Northern armies, and the impressment of crops by Confederate armies combined to cause hyperinflation and bread riots in the South.
On March 8, 1862, the Confederate Navy waged a fight against the Union Navy when the ironclad CSS Virginia attacked the blockade; it seemed unstoppable but the next day it had to fight the new Union warship USS Monitor in the Battle of the Ironclads. The battle ended in a draw, which was a strategic victory for the Union in that the blockade was sustained. The Confederacy lost the CSS Virginia when the ship was scuttled to prevent capture, and the Union built many copies of the USS Monitor. Lacking the technology to build effective warships, the Confederacy attempted to obtain warships from Britain. The Union victory at the Second Battle of Fort Fisher in January 1865 closed the last useful Southern port and virtually ended blockade running.
Because of the fierce resistance of a few initial Confederate forces at Manassas, Virginia, in July 1861, a march by Union troops under the command of Maj. Gen. Irvin McDowell on the Confederate forces there was halted in the First Battle of Bull Run, or First Manassas, whereupon they were forced back to Washington, D.C. by Confederate troops under the command of Generals Joseph E. Johnston and P. G. T. Beauregard. It was in this battle that Confederate General Thomas Jackson received the nickname of "Stonewall" because he stood like a stone wall against Union troops. Alarmed at the loss, and in an attempt to prevent more slave states from leaving the Union, the U.S. Congress passed the Crittenden-Johnson Resolution on July 25 of that year, which stated that the war was being fought to preserve the Union and not to end slavery.
Maj. Gen. George B. McClellan took command of the Union Army of the Potomac on July 26 (he was briefly general-in-chief of all the Union armies, but was subsequently relieved of that post in favor of Maj. Gen. Henry W. Halleck), and the war began in earnest in 1862. Upon the strong urging of President Lincoln to begin offensive operations, McClellan attacked Virginia in the spring of 1862 by way of the peninsula between the York River and James River, southeast of Richmond. Although McClellan's army reached the gates of Richmond in the Peninsula Campaign, Johnston halted his advance at the Battle of Seven Pines, then General Robert E. Lee and top subordinates James Longstreet and Stonewall Jackson defeated McClellan in the Seven Days Battles and forced his retreat. The Northern Virginia Campaign, which included the Second Battle of Bull Run, ended in yet another victory for the South. McClellan resisted General-in-Chief Halleck's orders to send reinforcements to John Pope's Union Army of Virginia, which made it easier for Lee's Confederates to defeat twice the number of combined enemy troops.
Emboldened by Second Bull Run, the Confederacy made its first invasion of the North, when General Lee led 45,000 men of the Army of Northern Virginia across the Potomac River into Maryland on September 5. Lincoln then restored Pope's troops to McClellan. McClellan and Lee fought at the Battle of Antietam near Sharpsburg, Maryland, on September 17 1862, the bloodiest single day in United States military history. Lee's army, checked at last, returned to Virginia before McClellan could destroy it. Antietam is considered a Union victory because it halted Lee's invasion of the North and provided an opportunity for Lincoln to announce his Emancipation Proclamation.
When the cautious McClellan failed to follow up on Antietam, he was replaced by Maj. Gen. Ambrose Burnside. Burnside was soon defeated at the Battle of Fredericksburg on December 13 1862, when over twelve thousand Union soldiers were killed or wounded during repeated futile frontal assaults against Marye's Heights. After the battle, Burnside was replaced by Maj. Gen. Joseph Hooker. Hooker, too, proved unable to defeat Lee's army; despite outnumbering the Confederates by more than two to one, he was humiliated in the Battle of Chancellorsville in May 1863. He was replaced by Maj. Gen. George Meade during Lee's second invasion of the North, in June. Meade defeated Lee at the Battle of Gettysburg (July 1 to July 3 1863), the bloodiest battle of the war, which is sometimes considered the war's turning point. Pickett's Charge on July 3 is often recalled as the high-water mark of the Confederacy, not just because it signaled the end of Lee's plan to pressure Washington from the north, but also because Vicksburg, Mississippi, the key stronghold to control of the Mississippi, fell the following day. Lee's army suffered 28,000 casualties (versus Meade's 23,000). However, Lincoln was angry that Meade failed to intercept Lee's retreat, and after Meade's inconclusive Fall campaign, Lincoln decided to turn to the Western Theater for new leadership.
While the Confederate forces had numerous successes in the Eastern theater, they were defeated many times in the West. They were driven from Missouri early in the war as a result of the Battle of Pea Ridge. Leonidas Polk's invasion of Columbus, Kentucky ended Kentucky's policy of neutrality and turned that state against the Confederacy.
Nashville, Tennessee, fell to the Union early in 1862. Most of the Mississippi was opened with the taking of Island No. 10 and New Madrid, Missouri, and then Memphis, Tennessee. The Union Navy captured New Orléans without a major fight in May 1862, allowing the Union forces to begin moving up the Mississippi as well. Only the fortress city of Vicksburg, Mississippi, prevented unchallenged Union control of the entire river.
General Braxton Bragg's second Confederate invasion of Kentucky ended with a meaningless victory over Maj. Gen. Don Carlos Buell at the Battle of Perryville, although Bragg was forced to end his attempt at liberating Kentucky and retreat due to lack of support for the Confederacy in that state. Bragg was narrowly defeated by Maj. Gen. William Rosecrans at the Battle of Stones River in Tennessee.
The one clear Confederate victory in the West was the Battle of Chickamauga. Bragg, reinforced by Lt. Gen. James Longstreet's corps (from Lee's army in the east), defeated Rosecrans, despite the heroic defensive stand of Maj. Gen. George Henry Thomas. Rosecrans retreated to Chattanooga, which Bragg then besieged.
The Union's key strategist and tactician in the West was Maj. Gen. Ulysses S. Grant, who won victories at Forts Henry and Donelson, by which the Union seized control of the Tennessee and Cumberland Rivers; the Battle of Shiloh; the Battle of Vicksburg, cementing Union control of the Mississippi River and considered one of the turning points of the war. Grant marched to the relief of Rosecrans and defeated Bragg at the Third Battle of Chattanooga, driving Confederate forces out of Tennessee and opening a route to Atlanta and the heart of the Confederacy.
Guerrilla activity turned much of Missouri into a battleground. Missouri had, in total, the third most battles of any state during the war. The other states of the west, though geographically isolated from the battles to the east, had a few small-scale military actions take place. Confederate incursions into Arizona and New Mexico were repulsed in 1862. Late in the war, the Union Red River Campaign was a failure. Texas remained in Confederate hands throughout the war, but was cut off from the rest of the Confederacy after the capture of Vicksburg in 1863 gave the Union control of the Mississippi River.
At the beginning of 1864, Lincoln made Grant commander of all Union armies. Grant made his headquarters with the Army of the Potomac, and put Maj. Gen. William Tecumseh Sherman in command of most of the western armies. Grant understood the concept of total war and believed, along with Lincoln and Sherman, that only the utter defeat of Confederate forces and their economic base would bring an end to the war. This was total war not in terms of killing civilians but rather in terms of destroying homes, farms and railroad tracks. Grant devised a coordinated strategy that would strike at the entire Confederacy from multiple directions: Generals George Meade and Benjamin Butler were ordered to move against Lee near Richmond; General Franz Sigel (and later Philip Sheridan) were to attack the Shenandoah Valley; General Sherman was to capture Atlanta and march to the sea (the Atlantic Ocean); Generals George Crook and William W. Averell were to operate against railroad supply lines in West Virginia; and Maj. Gen. Nathaniel P. Banks was to capture Mobile, Alabama.
Union forces in the East attempted to maneuver past Lee and fought several battles during that phase ("Grant's Overland Campaign") of the Eastern campaign. Grant's battles of attrition at the Wilderness, Spotsylvania, and Cold Harbor resulted in heavy Union losses, but forced Lee's Confederates to fall back again and again. An attempt to outflank Lee from the south failed under Butler, who was trapped inside the Bermuda Hundred river bend. Grant was tenacious and, despite astonishing losses (over 65,000 casualties in seven weeks), kept pressing Lee's Army of Northern Virginia back to Richmond. He pinned down the Confederate army in the Siege of Petersburg, where the two armies engaged in trench warfare for over nine months.
Grant finally found a commander, General Philip Sheridan, aggressive enough to prevail in the Valley Campaigns of 1864. Sheridan defeated Maj. Gen. Jubal A. Early in a series of battles, including a final decisive defeat at the Battle of Cedar Creek. Sheridan then proceeded to destroy the agricultural base of the Shenandoah Valley, a strategy similar to the tactics Sherman later employed in Georgia.
Meanwhile, Sherman marched from Chattanooga to Atlanta, defeating Confederate Generals Joseph E. Johnston and John Bell Hood along the way. The fall of Atlanta, on September 2 1864, was a significant factor in the reelection of Lincoln as president. Hood left the Atlanta area to menace Sherman's supply lines and invade Tennessee in the Franklin-Nashville Campaign. Union Maj. Gen. John M. Schofield defeated Hood at the Battle of Franklin, and George H. Thomas dealt Hood a massive defeat at the Battle of Nashville, effectively destroying Hood's army.
Leaving Atlanta, and his base of supplies, Sherman's army marched with an unknown destination, laying waste to about 20% of the farms in Georgia in his "March to the Sea". He reached the Atlantic Ocean at Savannah, Georgia in December 1864. Sherman's army was followed by thousands of freed slaves; there were no major battles along the March. Sherman turned north through South Carolina and North Carolina to approach the Confederate Virginia lines from the south, increasing the pressure on Lee's army.
Lee's army, thinned by desertion and casualties, was now much smaller than Grant's. Union forces won a decisive victory at the Battle of Five Forks on April 1, forcing Lee to evacuate Petersburg and Richmond. The Confederate capital fell to the Union XXV Corps, composed of black troops. The remaining Confederate units fled west and after a defeat at Sayler's Creek, it became clear to Robert E. Lee that continued fighting against the United States was both tactically and logistically impossible.
Lee surrendered his Army of Northern Virginia on April 9 1865, at Appomattox Court House. In an untraditional gesture and as a sign of Grant's respect and anticipation of folding the Confederacy back into the Union with dignity and peace, Lee was permitted to keep his officer's saber and his horse, Traveller. Johnston surrendered his troops to Sherman on April 26 1865, in Durham, North Carolina. On June 23 1865, at Fort Towson in the Choctaw Nations' area of the Oklahoma Territory, Stand Watie signed a cease-fire agreement with Union representatives, becoming the last Confederate general in the field to stand down. The last Confederate naval force to surrender was the CSS Shenandoah on November 4 1865, in Liverpool, England.
At the beginning of the war some Union commanders thought they were supposed to return escaped slaves to their masters. By 1862, when it became clear that this would be a long war, the question of what to do about slavery became more general. The Southern economy and military effort depended on slave labor. It began to seem unreasonable to protect slavery while blockading Southern commerce and destroying Southern production. As one Congressman put it, the slaves "…cannot be neutral. As laborers, if not as soldiers, they will be allies of the rebels, or of the Union." The same Congressman—and his fellow Radical Republicans—put pressure on Lincoln to rapidly emancipate the slaves, whereas moderate Republicans came to accept gradual, compensated emancipation and colonization. Copperheads, the border states and War Democrats opposed emancipation, although the border states and War Democrats eventually accepted it as part of total war needed to save the Union.
In 1861, Lincoln expressed the fear that premature attempts at emancipation would mean the loss of the border states, and that "to lose Kentucky is nearly the same as to lose the whole game." At first, Lincoln reversed attempts at emancipation by Secretary of War Simon Cameron and Generals John C. Fremont (in Missouri) and David Hunter (in South Carolina, Georgia and Florida) in order to keep the loyalty of the border states and the War Democrats.
Since the Emancipation Proclamation was based on the President's war powers, it only included territory held by Confederates at the time. However, the Proclamation became a symbol of the Union's growing commitment to add emancipation to the Union's definition of liberty. Lincoln also played a leading role in getting Congress to vote for the Thirteenth Amendment, which made emancipation universal and permanent.
Confederates enslaved captured black Union soldiers, and black soldiers especially were shot when trying to surrender at the Fort Pillow Massacre. This led to a breakdown of the prisoner exchange program and the growth of prison camps such as Andersonville prison in Georgia where almost 13,000 Union prisoners of war died of starvation and disease.
In spite of the South's shortage of manpower, most Southern leaders opposed arming slaves as soldiers until 1865. As Howell Cobb said, "If slaves will make good soldiers our whole theory of slavery is wrong." Confederate generals Patrick Cleburne and Robert E. Lee argued in favor of arming blacks late in the war, and Jefferson Davis was eventually persuaded into supporting plans for arming slaves in order to avoid military defeat. The Confederacy surrendered at Appomattox before this plan could be implemented.
A few Confederates had been discussing the possibility of arming slaves since the early stages of the war, and some free blacks had even offered to fight for the South. In 1862 Georgian Congressman Warren Akin supported the enrolling of slaves with the promise of emancipation, as did the Alabama legislature. Support for doing so also grew in other Southern states. In early March, 1865, Virginia endorsed a bill to enlist back soldiers, and on March 13 the Confederate Congress did the same.
The Emancipation Proclamation greatly reduced the Confederacy's hope of getting aid from Britain or France. Lincoln's moderate approach succeeded in getting border states, War Democrats and emancipated slaves fighting on the same side for the Union. The Union-controlled border states (Kentucky, Missouri, Maryland, Delaware and West Virginia) were not covered by the Emancipation Proclamation. All abolished slavery on their own, except Kentucky and Delaware. The great majority of the 4 million slaves were freed by the Emancipation Proclamation, as Union armies moved South. The 13th amendment, ratified December 6 1865, finally freed the remaining slaves in Kentucky and Delaware that numbered 225,000 for Kentucky and 1,800 in Delaware as of 1860.
Entry into the war by Britain and France on behalf of the Confederacy would have greatly increased the South's chances of winning independence from the Union. The Union, under Lincoln and Secretary of State William Henry Seward worked to block this, and threatened war if any country officially recognized the existence of the Confederate States of America (none ever did). In 1861, Southerners voluntarily embargoed cotton shipments, hoping to start an economic depression in Europe that would force Britain to enter the war in order to get cotton. Cotton diplomacy proved a failure as Europe had a surplus of cotton, while the 1860–62 crop failures in Europe made the North's grain exports of critical importance. It was said that "King Corn was more powerful than King Cotton", as US grain went from a quarter of the British import trade to almost half.
When the UK did face a cotton shortage, it was temporary, being replaced by increased cultivation in Egypt and India. Meanwhile, the war created employment for arms makers, iron workers, and British ships to transport weapons.
Charles Francis Adams proved particularly adept as minister to Britain for the Union, and Britain was reluctant to boldly challenge the Union's blockade. The Confederacy purchased several warships from commercial ship builders in Britain. The most famous, the CSS Alabama, did considerable damage and led to serious postwar disputes. However, public opinion against slavery created a political liability for European politicians, especially in Britain. War loomed in late 1861 between the U.S. and Britain over the Trent Affair, involving the Union boarding of a British mail steamer to seize two Confederate diplomats. However, London and Washington were able to smooth over the problem after Lincoln released the two.
In 1862, the British considered mediation—though even such an offer would have risked war with the U.S. Lord Palmerston reportedly read Uncle Tom’s Cabin three times when deciding on this. The Union victory in the Battle of Antietam caused them to delay this decision. The Emancipation Proclamation further reinforced the political liability of supporting the Confederacy. Despite sympathy for the Confederacy, France's own seizure of Mexico ultimately deterred them from war with the Union. Confederate offers late in the war to end slavery in return for diplomatic recognition were not seriously considered by London or Paris.
Since the war's end, it has been arguable whether the South could have really won the war. A significant number of scholars believe that the Union held an insurmountable advantage over the Confederacy in terms of industrial strength and population. Confederate actions, they argue, could only delay defeat. Southern historian Shelby Foote expressed this view succinctly in Ken Burns's television series on the Civil War: "I think that the North fought that war with one hand behind its back.… If there had been more Southern victories, and a lot more, the North simply would have brought that other hand out from behind its back. I don't think the South ever had a chance to win that War." The Confederacy sought to win independence by out-lasting Lincoln. However, after Atlanta fell and Lincoln defeated McClellan in the election of 1864, the hope for a political victory for the South ended. At that point, Lincoln had succeeded in getting the support of the border states, War Democrats, emancipated slaves and Britain and France. By defeating the Democrats and McClellan, he also defeated the Copperheads and their peace platform. Lincoln had also found military leaders like Grant and Sherman who would press the Union's numerical advantage in battle over the Confederate Armies. Generals who did not shy from bloodshed won the war, and from the end of 1864 onward there was no hope for the South.
On the other hand, James McPherson has argued that the North’s advantage in population and resources made Northern victory possible, but not inevitable. The American War of Independence and the Vietnam War are examples of wars won by the side with fewer numbers. Confederates did not need to invade and hold enemy territory in order to win, but only needed to fight a defensive war to convince the North that the cost of winning was too high. The North needed to conquer and hold vast stretches of enemy territory and defeat Confederate armies in order to win.
Also important were Lincoln's eloquence in rationalizing the national purpose and his skill in keeping the border states committed to the Union cause. Although Lincoln's approach to emancipation was slow, the Emancipation Proclamation was an effective use of the President's war powers.
The more industrialized economy of the North aided in the production of arms, munitions and supplies, as well as finances, and transportation. The table shows the relative advantage of the Union over the Confederate States of America (CSA) at the start of the war. The advantages widened rapidly during the war, as the Northern economy grew, and Confederate territory shrank and its economy weakened. The Union population was 22 million and the South 9 million in 1861; the Southern population included more than 3.5 million slaves and about 5.5 million whites, thus leaving the South's white population outnumbered by a ratio of more than four to one compared with that of the North. The disparity grew as the Union controlled more and more southern territory with garrisons, and cut off the trans-Mississippi part of the Confederacy. The Union at the start controlled over 80% of the shipyards, steamships, river boats, and the Navy. It augmented these by a massive shipbuilding program. This enabled the Union to control the river systems and to blockade the entire southern coastline. Excellent railroad links between Union cities allowed for the quick and cheap movement of troops and supplies. Transportation was much slower and more difficult in the South which was unable to augment its much smaller rail system, repair damage, or even perform routine maintenance. The failure of Davis to maintain positive and productive relationships with state governors (especially governor Joseph E. Brown of Georgia and governor Zebulon Vance of North Carolina) damaged his ability to draw on regional resources. The Confederacy's "King Cotton" misperception of the world economy led to bad diplomacy, such as the refusal to ship cotton before the blockade started.
The Emancipation Proclamation enabled African-Americans, both free blacks and escaped slaves, to join the Union Army. About 190,000 volunteered, further enhancing the numerical advantage the Union armies enjoyed over the Confederates, who did not dare emulate the equivalent manpower source for fear of fundamentally undermining the legitimacy of slavery. Emancipated slaves fought in several key battles in the last two years of the war. European immigrants joined the Union Army in large numbers too. 23.4% of all Union soldiers were German-Americans; about 216,000 were born in Germany.
Northern leaders agreed that victory would require more than the end of fighting. It had to encompass the two war goals: Secession had to be totally repudiated, and all forms of slavery had to be eliminated. They disagreed sharply on the criteria for these goals. They also disagreed on the degree of federal control that should be imposed on the South, and the process by which Southern states should be reintegrated into the Union.
Reconstruction, which began early in the war and ended in 1877, involved a complex and rapidly changing series of federal and state policies. The long-term result came in the three "Civil War" amendments to the Constitution (the XIII, which abolished slavery, the XIV, which extended federal legal protections to citizens regardless of race, and the XV, which abolished racial restrictions on voting). Reconstruction ended in the different states at different times, the last three by the Compromise of 1877. For details on why the Fourteenth Amendment and Fifteenth Amendment were largely ineffective until the American Civil Rights movement, see Jim Crow laws, Ku Klux Klan, Plessy v. Ferguson, United States v. Cruikshank, Civil Rights Cases and Reconstruction.
All slaves in the Confederacy were freed by the Emancipation Proclamation, which stipulated that slaves in Confederate-held areas, but not in border states or in Washington, D.C. were free. Slaves in the border states and Union-controlled parts of the South were freed by state action or by the Thirteenth Amendment, although slavery effectively ended in the U.S. in the spring of 1865. The full restoration of the Union was the work of a highly contentious postwar era known as Reconstruction. The war produced about 970,000 casualties (3% of the population), including about 620,000 soldier deaths—two-thirds by disease. The war accounted for more casualties than all other U.S. wars combined. The causes of the war, the reasons for its outcome, and even the name of the war itself are subjects of lingering controversy today. About 4 million black slaves were freed in 1865. Based on 1860 census figures, 8% of all white males aged 13 to 43 died in the war, including 6% in the North and an extraordinary 18% in the South.


Andrew Warhola (August 6, 1928 – February 22, 1987), better known as Andy Warhol, was an American artist and a central figure in the movement known as Pop art. After a successful career as a commercial illustrator, Warhol became famous worldwide for his work as a painter, an avant-garde filmmaker, a record producer, an author, and a public figure known for his membership in wildly diverse social circles that included bohemian street people, distinguished intellectuals, Hollywood celebrities and wealthy aristocrats.
A controversial figure during his lifetime (his work was often derided by critics as a hoax, or "put-on"), Warhol has been the subject of numerous retrospective exhibitions, books, feature and documentary films since his death in 1987.
Warhol's father migrated to the USA in 1914, while his mother joined him in 1921, after the death of Andy Warhol's grandparents. Warhol's father worked in a coal mine. The family lived at 55 Beelen Street and later at 3252 Dawson Street in the Oakland neighborhood of Pittsburgh. The family was Byzantine Catholic and attended St. John Chrysostom Byzantine Catholic Church. Andy Warhol has two older brothers John and Paul.
In third grade Warhol came down with St. Vitus' dance, an affliction of the nervous system causing involuntary movements which is believed to be a complication of scarlet fever. This disease led to a blotchiness in pigmentation of his skin and, as a child, he became somewhat of a hypochondriac developing a fear of hospitals and medical doctors. Because he was at times bed-ridden as a child he became an outcast among his school-mates and bonded with his mother very strongly (Guiles, 1989). When in bed he used to draw, listen to the radio and collect pictures of movie stars around his bed. Looking back later Warhol described the period of his sickness as very important in the development of his personality and in the forming of his skill-set and preferences.
Warhol showed an early artistic talent and studied commercial art at the School of Fine Arts at Carnegie Institute of Technology in Pittsburgh (now Carnegie Mellon University). In 1949, he moved to New York City and began a successful career in magazine illustration and advertising. During the 1950s, he became well-known mainly for his whimsical ink drawings of shoes for advertisements. These were done in a loose, blotted ink style, and figured in some of his earliest showings in New York at the Bodley Gallery. The music industry was expanding rapidly at this time with the introduction of the vinyl record, Hi-Fi, and stereophonic recordings. RCA Records hired Warhol, along with another freelance artist Sid Maurer to design album covers and promotional materials.
It was during the 1960s that Warhol began to make paintings of famous American products such as "Campbell's Soup Cans" from the Campbell Soup Company and Coca-Cola, as well as paintings of celebrities like Marilyn Monroe, Troy Donahue, and Elizabeth Taylor. He founded "The Factory", his studio during these years and gathered around himself a wide range of artists, writers, musicians, and underground celebrities. He switched to silkscreen prints which he produced serially, seeking not only to make art of mass-produced items but to mass produce the art itself. By minimizing the role of his own hand in the production of his work and declaring that he wanted to be "a machine", Warhol sparked a revolution in art. His work quickly became very controversial and popular.
This quotation both expresses his affection for popular culture, and evidences an ambiguity of perspective that cuts across nearly all of the artist's statements about his own work.
New York's Museum of Modern Art hosted a Symposium on pop art in December 1962 during which artists like Warhol were attacked for "capitulating" to consumerism. Critics were scandalized by Warhol's open embrace of market culture. This symposium set the tone for Warhol's reception. Throughout the decade it became more and more clear that there had been a profound change in the culture of the art world, and that Warhol was at the center of that shift.
A pivotal event was the 1964 exhibit "The American Supermarket" a show held in Paul Bianchini's Upper East Side gallery. The show was presented as a typical small supermarket environment, except that everything in it from the produce, canned goods, meat, posters on the wall, etc. were created by six prominent pop artists of the time including the controversial (and like-minded) Billy Apple, Mary Inman, and Robert Watts. Warhol's painting of a can of Campbell's soup cost $1,500 while each autographed can sold for $6. The exhibit was one of the first mass events that directly confronted the general public with both Pop Art and the perennial question of what is art.
As an advertisement illustrator in the 1950s, Warhol used assistants to increase his productivity. Collaboration would remain a defining (and controversial) aspect of his working methods throughout his career; in the 1960s, however, this was particularly true. One of the most important collaborators during this period was Gerard Malanga. Malanga assisted the artist with producing silkscreens, films, sculpture, and other works at "The Factory", Warhol's aluminum foil-and-silver-paint-lined studio on 47th Street (later moved to Broadway). Other members of Warhol's Factory crowd included Freddie Herko, Ondine, Ronald Tavel, Mary Woronov, Pietro Psaier, Billy Name, and Brigid Berlin (from whom he apparently got the idea to tape record his phone conversations). During this decade, Warhol also groomed a retinue of bohemian eccentrics upon whom he bestowed the designation "Superstars", including Edie Sedgwick, Viva, and Ultra Violet. These people all participated in the Factory films, and some, like Berlin, remained friends with Warhol until his death. Important figures in the New York underground art/cinema world (e.g. writer John Giorno, film-maker Jack Smith) also appear in Warhol films of the 1960s, revealing Warhol's connections to a diverse range of artistic scenes during this period. By the end of the decade, Andy Warhol was himself a celebrity, appearing frequently in newspapers and magazines alongside Factory cohorts like Sedgwick.
On June 3, 1968, Valerie Solanas shot Warhol and art critic and curator Mario Amaya at Warhol's studio.
Before the shooting, Solanas had been a marginal figure in the Factory scene. She founded a "group" called S.C.U.M. (Society for Cutting up Men) and authored the S.C.U.M. Manifesto, a separatist feminist attack on patriarchy. Solanas appears in the 1968 Warhol film, I, A Man. Earlier on the day of the attack, Solanas had been turned away from the Factory after asking for the return of a script she had given to Warhol. The script, apparently, had been misplaced.
Amaya received only minor injuries and was released from the hospital later the same day. Warhol however, was seriously wounded by the attack and barely survived (doctors opened his chest and massaged his heart to help stimulate its movement again). He suffered physical effects for the rest of his life. The shooting had a profound effect on Warhol's life and art.
Solanas was arrested the day after the assault. By way of explanation, she said that "He had too much control over my life." After the shooting, the Factory scene became much more tightly controlled, and for many this event brought the "Factory 60s" to an end.
Warhol used to socialize at Serendipity 3 and, later in the 70s, Studio 54, nightspots in New York City. He was generally regarded as quiet, shy, and as a meticulous observer. Art critic Robert Hughes called him "the white mole of Union Square".
Warhol had a re-emergence of critical and financial success in the 1980s, partially due to his affiliation and friendships with a number of prolific younger artists, who were dominating the "bull market" of '80s New York art: Jean-Michel Basquiat, Julian Schnabel, David Salle and the so-called Neo-Expressionists, as well as Francesco Clemente, Enzo Cucchi and members of the Transavantguardia movement, which had become influential.
Many people think of Warhol as "asexual" and merely a "voyeur", but these notions have been debunked by biographers (such as Victor Bockris), explored by other members of The Factory scene such as Bob Colacello (in his book Holy Terror: Andy Warhol Close Up), and by scholars like art historian Richard Meyer (in his book Outlaw Representation). The question of how his sexuality influenced Warhol's work and shaped his relationship to the art world is a major subject of scholarship on the artist, and is an issue that Warhol himself addressed in interviews, in conversation with his contemporaries, and in his publications (e.g. Popism: The Warhol Sixties).
Throughout his career, Warhol produced erotic photography and drawings of male nudes. Many of his most famous works (portraits of Liza Minnelli, Judy Garland, Elizabeth Taylor, and films like Blow Job, My Hustler, and Lonesome Cowboys) draw from gay underground culture and/or openly explore the complexity of sexuality and desire. Many of his films premiered in gay porn theaters. That said, some stories about Warhol's development as an artist revolved around the obstacle his sexuality initially presented as he tried to launch his career. The first works that he submitted to a gallery in the pursuit of a career as an artist were homoerotic drawings of male nudes. They were rejected for being too openly gay. In Popism, furthermore, the artist recalls a conversation with the film maker Emile de Antonio about the difficulty Warhol had being accepted socially by the then more famous (but closeted) gay artists Jasper Johns and Robert Rauschenberg. De Antonio explained that Warhol was "too swish and that upsets them." In response to this, Warhol writes, "There was nothing I could say to that. It was all too true. So I decided I just wasn't going to care, because those were all the things that I didn't want to change anyway, that I didn't think I 'should' want to change.. Other people could change their attitudes but not me". In exploring Warhol's biography, many turn to this period - the late 1950s and early 1960s - as a key moment in the development of his persona. Some have suggested that his frequent refusal to comment on his work, to speak about himself (confining himself in interviews to responses like "Uhm, No" and "Uhm, Yes", and often allowing others to speak for him), and even the evolution of his Pop style can be traced to the years when Warhol was first dismissed by the inner circles of the New York art world.
Warhol was a practicing Byzantine Rite Catholic. He regularly volunteered at homeless shelters in New York, particularly during the busier times of the year, and described himself as a religious person. Many of his later works contain almost-hidden religious themes or subjects, and a body of religious-themed works was found posthumously in his estate. Warhol also regularly attended Mass during his life, and the priest at Warhol's church, Saint Vincent's, said that the artist went there almost daily. His art is noticeably influenced by the eastern Christian iconographic tradition which was so evident in his places of worship.
Warhol died in New York City at 6:32 a.m. on February 22, 1987. According to news reports, he had been making good recovery from a routine gallbladder surgery at New York Hospital before dying in his sleep from a sudden heart attack. The hospital staff had failed to adequately monitor his condition and overloaded him with fluids after his operation, causing him to suffer from a fatal case of water intoxication, which prompted Warhol's lawyers to sue the hospital for negligence. Prior to his diagnosis and operation, Warhol delayed having his recurring gallbladder problems checked, as he was afraid to enter hospitals and see doctors.
Warhol's body was taken back to Pittsburgh by his brothers for burial. The wake was at Thomas P. Kunsak Funeral Home and was an open-coffin ceremony. The coffin was a solid bronze casket with gold plated rails and white upholstery. Warhol wore a black cashmere suit, a paisley tie, a platinum wig, and sunglasses. He was holding a small prayer book and a red rose.
The funeral liturgy was held at the Holy Ghost Byzantine Catholic Church on Pittsburgh's North Side. The eulogy was given by Monsignor Peter Tay. Fellow artist Yoko Ono also made an appearance. The coffin was covered with white roses and asparagus ferns.
After the liturgy, the coffin was driven to St. John the Baptist Byzantine Catholic Cemetery in Bethel Park, a south suburb of Pittsburgh. At the grave, the priest said a brief prayer and sprinkled holy water on the casket. Before the coffin was lowered, Paige Powell dropped a copy of Interview magazine, an Interview t-shirt, and a bottle of the Estee Lauder perfume "Beautiful" into the grave. Warhol was buried next to his mother and father.
Weeks later a memorial service was held in Manhattan for Warhol on April 1, 1987 at St. Patrick's Cathedral, New York.
Warhol had so many possessions that it took Sotheby's nine days to auction his estate after his death; the auction grossed more than US$20 million. His total estate was worth considerably more, in no small part due to shrewd investments over the years.
Two years after Warhol's death, Songs for Drella, a co-commissioned work by The Brooklyn Academy of Music and The Arts at St. Ann's in New York City, was staged as a concept album performed by Lou Reed and John Cale, alumni of The Velvet Underground. The performance was filmed and directed by Ed Lachman, on December 6, 1989, and released on VHS and laserdisc formats. It was released on CD in a black velveteen package in 1990 by Sire Records. Drella was a nickname coined by Warhol superstar Ondine for Warhol, a portmanteau of Dracula and Cinderella, used by Warhol's crowd.
Songs for Drella offers a kind of vie romancée of Warhol, focusing on his interpersonal relations. The songs fall roughly into three categories: Warhol's (semi-fictitious) first-person perspective, third-person narratives chronicling events and affairs, and first-person feelings towards and commentaries on Warhol by Reed and Cale themselves. On Drella, Reed apologizes to a departed Warhol and comes to terms with his part in their personal conflict.
Reed and Cale had been playing the songs live in 1989 as a song cycle before committing them to tape. By the end of recording Cale vowed never to work with Reed again due to personal differences; nevertheless, Songs for Drella would prove to be the overture to a full-blown Velvet Underground reunion.
Although the album was conceived as an indivisible whole, a single was released off it, "Nobody But You".
On the twentieth anniversary of his death The Gershwin Hotel in New York City held a week-long series of events commemorating Warhol's art and his superstars. There was an award ceremony, a fashion show, and Blondie performed at the closing party. At the same time, The Carrozzini von Buhler Gallery in New York City held an exhibit titled, Andy Warhol: In His Wake. The exhibit featured the art of Warhol's superstars Ultra Violet, Billy Name, Taylor Mead, and Ivy Nicholson as well as art by a younger generation of artists who have been inspired by Warhol. One interactive sculpture in the exhibit, The Great Warhola, by Cynthia von Buhler, depicted Warhol as an arcade fortune-telling machine. The gallery was transformed to look like Warhol's silver factory. Factory Girl, a film about the life of Edie Sedgwick, starring Sienna Miller and Hayden Christensen, was also released one week before the anniversary of Warhol's death.
By the beginning of the 1960s, Warhol was a very successful commercial illustrator. His detailed and elegant drawings for I. Miller shoes were particularly popular. These illustrations consisted mainly of "blotted ink" drawings (or monoprints), a technique which he applied in much of his early art. Although many artists of this period worked in commercial art, most did so discreetly. Warhol was so successful, however, that his profile as an illustrator seemed to undermine his efforts to be taken seriously as an artist.
In the early 1960s, Warhol tried to exhibit some of his drawings using these techniques in a gallery, only to be turned down. He began to rethink the relationship between his commercial work and the rest of his art. Instead of treating these things as opposites, he merged them, and began to take commercial and popular culture more explicitly as his topic.
Pop Art was an experimental form that several artists were independently adopting; some of these pioneers, such as Roy Lichtenstein, would later become synonymous with the movement. Warhol, who would become famous as the "Pope of Pop", turned to this new style, where popular subjects could be part of the artist's palette. His early paintings show images taken from cartoons and advertisements, hand-painted with paint drips. Those drips emulated the style of successful abstract expressionists (such as Robert Rauschenberg). Eventually, Warhol pared his image vocabulary down to the icon itself—to brand names, celebrities, dollar signs—and removed all traces of the artist's "hand" in the production of his paintings.
To him, part of defining a niche was defining his subject matter. Cartoons were already being used by Lichtenstein, typography by Jasper Johns, and so on; Warhol wanted a distinguishing subject. His friends suggested he should paint the things he loved the most. In his signature way of taking things literally, for his first major exhibition he painted his famous cans of Campbell's Soup, which he claimed to have had for lunch for most of his life.
He loved celebrities, so he painted them as well. From these beginnings he developed his later style and subjects. Instead of working on a signature subject matter, as he started out to do, he worked more and more on a signature style, slowly eliminating the hand-made from the artistic process. Warhol frequently used silk-screening; his later drawings were traced from slide projections. Warhol went from being a painter to being a designer of paintings. At the height of his fame as a painter, Warhol had several assistants who produced his silk-screen multiples, following his directions to make different versions and variations.
Warhol produced both comic and serious works; his subject could be a soup can or an electric chair. Warhol used the same techniques—silkscreens, reproduced serially, and often painted with bright colors—whether he painted celebrities, everyday objects, or images of suicide, car crashes, and disasters (as part of a 1962-1963 series called "Death and Disaster"). The "Death and Disaster" paintings (such as "Red Car Crash", "Purple Jumping Man", "Orange Disaster") transform personal tragedies into public spectacles, and signal the use of images of disaster in the then evolving media.
Warhol worked across a wide range of media — painting, photography, drawing, and sculpture. In addition, he was a highly prolific filmmaker. Between 1963 and 1968, he made more than sixty films. One of his most famous films, Sleep, monitors poet John Giorno sleeping for six hours. The 35-minute film Blow Job, is one continuous shot of the face of DeVeren Bookwalter supposedly receiving oral sex from filmmaker Willard Maas, although the camera never tilts down to see this. Another, 1964's Empire, consists of eight hours of footage of the Empire State Building in New York City at dusk. The 45-minute film 'Eat consists of a man eating a mushroom for 45 minutes.
Batman Dracula is a 1964 film that was produced and directed by Warhol, without the permission of DC Comics. It was screened only at his art exhibits. A fan of the Batman series, Warhol's movie was an "homage" to the series, and is considered the first appearance of a blatantly campy Batman. The film was until recently thought to have been lost, until scenes from the picture were shown at some length in the 2006 documentary Jack Smith and the Destruction of Atlantis.
Warhol's 1965 film 'Vinyl' is an adaptation of Anthony Burgess' popular dystopian novel A Clockwork Orange. Others record improvised encounters between Factory regulars such as Brigid Berlin, Viva, Edie Sedgwick, Candy Darling, Holly Woodlawn, Ondine, Nico, and Jackie Curtis. Legendary underground artist Jack Smith appears in the film Camp.
His most popular and critically successful film was 1966's Chelsea Girls. The film was highly innovative in that it consisted of two 16 mm films being projected simultaneously, with two different stories being shown in tandem. From the projection booth, the sound would be raised for one film to elucidate that "story" while it was lowered for the other. The multiplication of images evoked Warhol's seminal silk-screen works of the early 1960s. The influence of the film's split-screen, multi-narrative style could be felt in such modern work as Mike Figgis' Timecode and, however indirectly, the early seasons of 24.
Other important films include Bike Boy, My Hustler, and Lonesome Cowboys, a raunchy pseudo-western. These and other titles document gay underground and camp culture, and continue to feature prominently in scholarship about sexuality and art - see, for example, Mathew Tinkom's Working Like a Homosexual (Duke University Press, 2002) or Juan Suarez's Bike Boys, Drag Queens, and Superstars (Indiana University Press, 1996). Blue Movie, a film in which Warhol superstar Viva makes love and fools around in bed with a man for 33 minutes of the film's playing-time, was Warhol's last film as director. The film was at the time scandalous for its frank approach to a sexual encounter. For many years Viva refused to allow it to be screened. It was publicly screened in New York in 2005 for the first time in over thirty years.
After his June 3, 1968 shooting, a reclusive Warhol relinquished his personal involvement in filmmaking. His acolyte and assistant director, Paul Morrissey, took over the film-making chores for the Factory collective, steering Warhol-branded cinema towards more mainstream, narrative-based, B-movie exploitation fare with Flesh, Trash, and Heat. All of these films, including the later "Andy Warhol's Dracula and Andy Warhol's Frankenstein", were far more mainstream than anything Warhol as a director had attempted. These latter "Warhol" films starred Joe Dallesandro, who was more of a Morrissey star than a true Warhol superstar.
In order to facilitate the success of these Warhol-branded, Morrissey-directed movies in the marketplace, all of Warhol's earlier avant-garde films were removed from distribution and exhibition by 1972.
Another film, "Andy Warhol's Bad, made significant impact as a "Warhol" film yet was directed by Jed Johnson. Bad" starred the infamous Carroll Baker, Susan Blond and a young Perry King.
The first volume of a catalogue raisonne for the Factory film archive, edited by Callie Angell, was published in the spring of 2006.
In the mid 1960s, Warhol adopted the band The Velvet Underground, making them a crucial element of the Exploding Plastic Inevitable multimedia performance art show. Warhol, with Paul Morrissey, acted as the band's manager, introducing them to Nico (who would perform with the band at Warhol's request). In 1966 he "produced" their first album The Velvet Underground and Nico, as well as providing its album art. His actual participation in the album's production amounted to simply paying for the studio time. After the band's first album, Warhol and band leader Lou Reed started to disagree more about the direction the band should take, and the contact between them faded.
Warhol designed many album covers for various artists starting with the photographic cover of John Wallowitch's debut album, This Is John Wallowitch!! (1964). Warhol designed the cover art for The Rolling Stones albums Sticky Fingers (1971) and Love You Live (1977). In 1975, Warhol was commissioned to do several portraits of the band's frontman Mick Jagger.
Warhol was also friendly with many recording artists, including Deborah Harry, Grace Jones and John Lennon - he designed the cover to Lennon's 1986 posthumously released Menlove Ave. Warhol also appeared as a bartender in The Cars' music video for their single "Hello Again", and Curiosity Killed The Cat's video for their "Misfit" single (both videos, and others, were produced by Warhol's video production company).
Warhol strongly influenced the New Wave/punk rock band Devo, as well as David Bowie. Bowie recorded a song called "Andy Warhol" for his 1971 album Hunky Dory. Lou Reed wrote the song "Andy's Chest", about Valerie Solanas, the woman who shot Warhol, in 1969. He recorded it with the Velvet Underground, but this version wasn't officially released until the VU album appeared in 1985. He recorded a new version for his 1972 solo album Transformer, produced by Bowie and Mick Ronson.
Beginning in the early 1950s, Warhol produced several unbound portfolios of his work.
The first of several bound self-published books by Warhol was 25 Cats Name Sam and One Blue Pussy, printed in 1954 by Seymour Berlin on Arches brand watermarked paper using his blotted line technique for the lithographs. The original edition was limited to 190 numbered, hand colored copies, using Dr. Martin's ink washes. Most of these were given by Warhol as gifts to clients and friends. Copy #4, inscribed "Jerry" on the front cover, was given to Geraldine Stutz, who at the time was with I. Miller Shoes. Later the president of Henri Bendel and then while head of Panache Press an imprint of Random House she used this copy for a facsimile printing in 1987. Her estate consigned the original limited edition to Doyle New York where it sold in May 2006 for US $35,000.
Later Warhol "wrote" several books that were commercially printed.
Warhol created the fashion magazine Interview that is still published today. The loopy title script on the cover is thought to be either his own handwriting or that of his mother, Julia Warhola, who would often do text work for his early commercial pieces.
As stated, although Andy Warhol is most known for his paintings and films, he has authored works in many different media.
In many ways Warhol refined and expanded the idea of what it means to be an artist. Warhol frequently took on the position of a producer, rather than a creator - this is true not only of his work as a painter (he had assistants do much of the work of producing his paintings), it is true of his film-making and commercial enterprises as well. He liked to coin an idea and then oversee or delegate its execution. As he refined this element of his work The Factory evolved from an atelier into an office. He became (and still is) the public face of a company, and a brand.
He founded the gossip magazine Interview, a stage for celebrities he "endorsed" and a business staffed by his friends. He collaborated with others on all of his books (some of which were written with Pat Hackett.) He adopted the young painter Jean-Michel Basquiat, and the band The Velvet Underground, presenting them to the public as his latest interest, and collaborating with them. One might even say that he produced people (as in the Warholian "Superstar" and the Warholian portrait). He endorsed products, appeared in commercials, and made frequent celebrity guest appearances on television shows and in films (he appeared in everything from Love Boat to Saturday Night Live and the Richard Pryor movie, Dynamite Chicken).
In this respect Warhol was a fan of "Art Business" and "Business Art" - he, in fact, wrote about his interest in thinking about art as business in The Philosophy of Andy Warhol from A to B and Back Again. This was a radical new stance, as artists traditionally positioned themselves against commercialism. Warhol and other pop-artists helped redefine the artist's position as professional, commercial, and popular. He did this using methods, imagery and talents that were (or at least seemed to be) available to everyone. In this respect Pop Art has contributed to a philosophical and practical incorporation of art into popular culture and society, and art offered to us as a product of that society.
Two museums are dedicated to Andy Warhol. The Andy Warhol Museum, one of the Carnegie Museums of Pittsburgh, is located at 117 Sandusky Street in Pittsburgh, Pennsylvania. It is the largest American art museum dedicated to a single artist, holding more than 12,000 works by the artist himself.
The other museum is the Andy Warhol Museum of Modern Art, established in 1991 by Andy's brother John Warhola, the Slovak Ministry of Culture, and the Warhol Foundation in New York. It is located in the small town of Medzilaborce, Slovakia. Andy's parents were born 15 kilometers away in the village of Miková. The museum houses several originals donated mainly by the Andy Warhol Foundation in New York and also personal items donated by Warhol's relatives.
An exhibit dedicated to the works of Andy Warhol is on display at the World of Coke in Atlanta, Georgia.
Andy Warhol is portrayed by Crispin Glover in Oliver Stone's film The Doors (1991). He is also played by David Bowie in Basquiat, a film by Julian Schnabel. In the film I Shot Andy Warhol, directed by Mary Harron (1996), the actor Jared Harris portrayed Warhol. Actor Mark Bringleson makes a brief cameo as Warhol in Austin Powers: International Man of Mystery, painting a supine woman's outfit to match the pattern on the floor of the Electric Psychedelic Pussycat Swingers' Club while looking at a Campbell's Soup can. Also, many films by Jonas Mekas have the moments of Andy's life caught (for example "Super 8 films"; "Scenes From The Life Of Andy Warhol" and many more). Sean Gregory Sullivan depicted Warhol in the 1998 film 54. The latest film actor to portray the artist is Guy Pearce in the 2007 film, Factory Girl.
Andy Warhol: A Documentary Film is a reverential four-hour 2006 movie by Ric Burns.
The 2001 documentary, Absolut Warhola, was produced by German director Stanislaw Mucha, featuring Warhol's parents' family and hometown in Slovakia.
Gus Van Sant was planning a version of Warhol's life with River Phoenix in the lead role just before Phoenix's death in 1993 (as discussed in an interview with the two, included in the published My Own Private Idaho script book).
Asteroid 6701 Warhol is named for Andy Warhol.

""'AmeriKKKa's Most Wanted""' is rapper Ice Cube's influential debut solo album, released after his acrimonious split from his former group N.W.A. It was originally released on May 16, 1990. Primarily produced by The Bomb Squad (Public Enemy's production team), the album was an unexpectedly large critical and commercial success, and remains one of the defining hip hop albums of the 1990s era. Ice Cube's social, and political commentary, which was delivered in an incisive manner, has influenced numerous rappers since, particularly in the gangsta rap and political rap subgenres. The album cemented Cube's reputation as a gifted lyricist, and introduced him as a highly literate scribe on the hardships of life in South Central, Los Angeles, as well as an outspoken critic of the American Justice System, and race relations in the United States. The album was certified double platinum for sales of over 2 million units in the United States.
The title of the album is an allusion to a television show called "America's Most Wanted", wherein real-life crimes are reenacted and viewers are asked to call in with any information about the alleged perpetrators. The show has taken criticism for its reenactments. They are believed to perpetuate stereotypes regarding the criminality of African-American men and other minorities, such as Latinos. The intentional misspelling of "America" with three K's equates the show and status quo society with the Ku Klux Klan.
"AmeriKKKa's Most Wanted" is mostly a socio-political conscious and gangsta rap album. The songs delve into the issues of ghetto life, drug addiction, racism and poverty. Throughout the album, Ice Cube incessantly attacks racist institutions and social norms which directly or indirectly allow the oppression of those living in the ghettos of Los Angeles to continue.
Predating the Rodney King incident, "Endangered Species (Tales from the Darkside)" can be seen as prophetic in its assessment of police brutality and the inadequate justice handed to police officers who use excessive force against ethnics.
Throughout the album, Cube takes some controversial stands, referring to certain types of African-Americans as "oreo cookies"; an epithet implying that they appear to be black on the outside, but are white inside. Arsenio Hall is specifically mentioned as being a "sell-out," while the same accusation is implied to be leveled at Cube's former bandmate Eazy-E. Cube also heavily criticizes R&B and hip hop radio stations for watered-down broadcasting. The titular song on the album directly parodies the television show, "America's Most Wanted", exposing the bias and glee with which the program displays in arresting Afro-American men.
Nevertheless, the album received criticism for alleged sexism, particularly for "You Can't Fade Me," a track, in which Cube fantasizes about kicking a pregnant, former one-night stand in the stomach in order to cause a miscarriage, and avoid having to pay child support.
The release of "AmeriKKKa's Most Wanted", and its subsequent success were wholly unexpected, as Cube had only recently split from his former group, N.W.A. His former bandmates, in the meantime had resorted to taunting him in interviews. The album initially charted without the support of a lead single or video, although the title song would later receive a pressing, and a rare video for "Who's the Mack?" did eventually surface. Regardless of the drawbacks, the album shipped half a million copies in its first week out, and was certified Platinum two months later.
"AmeriKKKa's Most Wanted" received The Source's highly-coveted (at the time) 'five mics' award; a 'classic' rating. It was the second album to be awarded this, and up until Jay-Z's The Blueprint in 2001, one of only ten albums to be approved for five mics by The Source. In 1998, the album was selected as one of The Source Magazine's 100 Best Rap Albums. In 2005, comedian Chris Rock ranked it 17th on his list of the Top 25 Hip-Hop Albums ever.
Produced entirely by the Bomb Squad (during the height of Public Enemy's success) and Da Lench Mob, "AmeriKKKa's Most Wanted received accolades for innovation in production upon release. Since this time, West Coast rap has largely taken a separate direction from the sound present on AmeriKKKa's Most Wanted", and headed more towards the glossy beats, and smooth drawls popularised by Dr. Dre and Snoop Dogg.
Although Ice Cube's popularity among mainstream listeners has lessened since the 2000s, and his sound may be considered distinctively old school to modern ears, many rappers themselves have been influenced by his innovative lyrical techniques. His style of rap, drenched in real life sentiment, and socio-political awareness, influenced the music of West Coast rappers, including that of Tupac, Ras Kass, and Xzibit, as well as East Coast rappers Nas, The Notorious B.I.G. and more recently, Saigon. While Ice Cube's early albums often described true circumstances in outlandish fashion, for example using fairytale characters to tell a violent and tragic story in "A Gangsta's Fairytale", later rappers would take this to the extreme, often describing physically impossible acts of violence in an outrageously exaggerated manner.


Afrika Bambaataa is a DJ and community leader from the South Bronx, who was instrumental in the early development of hip hop throughout the 1970s. Like many of the early pioneers in Hip-Hop, he is of West Indian (Caribbean) descent. On September 27, 2007, he was nominated for induction into the Rock and Roll Hall of Fame.
Bambaataa was a founding member of the Bronx River Projects-area street gang, The Savage Seven. Due to the explosive growth of the gang, it later became known as the Black Spades, and he rose to the position of Division Leader. After a life-changing visit to Africa, he changed his name to Afrika Bambaataa Aasim. Bambaataa was influenced by the courage and strategic brilliance of Shaka Zulu seen in the movie and TV series "Shaka Zulu".
Bambaataa decided to use his leadership to turn those involved in the gang life into something more positive to the community. This began the development of which later became known as the Universal Zulu Nation, a group of socially & politically aware rappers, B-boys, graffiti artists and other people involved in hip hop culture. By 1977, inspired by DJ Kool Herc and after Disco King Mario loaned him his first equipment, Bambaataa began organizing block parties all around the South Bronx. He even faced his mentor, Disco King Mario in a DJ battle. He then began performing at Stevenson High School and formed the Bronx River organization, then later simply "The Organization". Bambaataa had deejayed with his own sound system at the Bronx River Community Center, with Mr. Biggs, Queen Kenya, and Cowboy, who accompanied him in performances in the community. Because of his prior status in the Black Spades, he already had an established party crowd drawn from former members of the gang. He became known as one of the best DJs in the Bronx.
About a year later he reformed the group, calling it the Zulu Nation (inspired by his wide studies on African history at the time). Five b-boys (break dancers) joined him who he called the Shaka ZULU Kings, a.k.a. ZULU Kings; there were also the Shaka Zulu Queens. As he continued deejaying, more DJs, rappers, break dancers, graffiti writers, and artists followed his parties, and he took them under his wing and made them members of his Zulu Nation. He was also the founder of the SoulSonic Force, which originally consisted of approximately twenty Zulu Nation members: Mr. Biggs, Queen Kenya, DJ Cowboy SoulSonic Force (#2), Mr. Biggs, Pow Wow, G.L.0.B.E. (creator of the "MC popping" rap style), DJ Jazzy Jay, Cosmic Force, Queen Lisa Lee, Prince Ikey C, Ice Ice (#1), Chubby Chub; Jazzy Five-DJ Jazzy Jay, Mr. Freeze, Master D.E.E. Kool DJ Red Alert, Sundance, Ice Ice (#2), CharlieChew, Master Bee, Busy Bee Starski, Akbar (Lil Starski), and Raheim. The personnel for the Soul Sonic Force were groups within groups with whom he would perform and make records.
In 1980, his groups made their first recording with Paul Winley Records titled, "Death Mix". Winley also recorded Soul Sonic Force's landmark single, "Zulu Nation Throwdown", produced by Disco King Mario. Disappointed with the results of the single, he left the company.
In 1982, hip-hop artist Fab 5 Freddy was putting together music packages in the largely white downtown Manhattan New-Wave clubs, and invited Bam to perform at one of them, called the Mudd Club. It was the first time Bam had performed before a predominantly white crowd, making it one of the first times that hip-hop had fused with White culture. Attendance for Bam's parties downtown became so large that he had to move to larger venues, first to the Ritz, with Malcolm McLaren's group Bow Wow Wow (and where the Rock Steady Crew b-boys became part of the Zulu Nation), then to the Peppermint Lounge, The Jefferson, Negril, Danceteria, and the Roxy. "Planet Rock", a popular single, came out that June under the name Afrika Bambaataa and the Soulsonic Force. The song melded the main melody from Kraftwerk's "Trans-Europe Express" with electronic beats based on their track "Numbers" as well as portions from records by Ennio Morricone and Captain Sky - thus creating a new style of music altogether, electro funk. It influenced many styles of electronic and dance music, e.g. freestyle music, house music and techno music.
Bambaataa organized the very first European hip hop tour. Along with himself were rapper and graffiti artist Rammellzee, Zulu Nation DJ Grand Mixer DXT (formerly Grand Mixer D.St), B-boy and B-girl crews the Rock Steady Crew, and the Double Dutch Girls, as well as legendary graffiti artists Fab 5 Freddy, Phase 2, Futura 2000, and Dondi.
Afrika Bambaataa is one of the three main originators of break-beat deejaying, and is respectfully known as the "Grandfather" and "Godfather" of Hip Hop Culture as well as The Father of The Electro Funk Sound.
Around October 1985, Bambaataa and other music stars worked on the anti-apartheid album Sun City with Little Steven Van Zandt, Run-D.M.C. Lou Reed, and numerous others. During 1988, he recorded another landmark piece as "Afrika Bambaataa and Family" on Capitol Records, titled The Light, featuring Nona Hendryx, UB40, Boy George, George Clinton, Bootsy Collins, and Yellowman. Bam had recorded a few other works with Family three years earlier, one titled "Funk you" in 85, and the other titled Beware (The Funk Is Everywhere) in 1986.
In 1990, Bam made Life magazine's "Most Important Americans of the 20th Century" issue. He was also involved in the anti-apartheid work "Hip Hop Artists Against Apartheid" for Warlock Records. He teamed with the Jungle Brothers to record the album Return to Planet Rock (The Second Coming).
Greenstreet Records, John Baker, and Bambaataa organized a concert at Wembley Stadium in London for the A.N.C. (African National Congress), in honor of Nelson Mandela's release from prison. The concert brought together performances by British and American rappers, and also introduced both Nelson and Winnie Mandela and the A.N.C. to hip-hop audiences. In relation to the event, the recording Ndodemnyama (Free South Africa) helped raise approximately $30,000 for the A.N.C. Bam also helped to raise funds for the organization in Italy.
From the mid-1990s, Bam returned to his electro roots, collaborating with WestBam (who was named after him) which culminated in the 2004 album Dark Matter Moving at the Speed of Light which featured Gary Numan and many others. In 2000, Rage Against the Machine covered Afrika's song "Renegades of Funk" for their album Renegades. In that same year, Afrika Bambaataa collaborated with Leftfield on the song "Afrika Shox", the first single from Leftfield's Rhythm and Stealth. "Afrika Shox" is also popularly known from the soundtrack to Vanilla Sky. In 2006, he was featured on the British singer Jamelia's album Walk With Me on a song called Do Me Right, and on Mekon‎'s album Some Thing Came Up, on the track D-Funktional. Bambaataa has also performed the lyrics on the track "Is There Anybody Out There" by The Bassheads. As an actor, he has played a variety of both hilarious and serious voice-over character roles in the international television series known around the world as Kung Faux from Dubtitled Entertainment and Tommy Boy Films.
On September 27, 2007, it was announced that Afrika Bambaataa was one of the nine nominees for the 2008 Rock and Roll Hall of Fame Inductions.
On December 22nd, 2007, he made a surprise appearance performing at the First Annual Tribute Fit For the King of King Records, Mr. Dynamite James Brown in Covington, KY.
Around the early 1990s, many violent films were produced that glorified California gang life, fueling hype about "Bloods" and "Crips". The Bloods and Crips, two major black street gangs that feud in West Coast ghettos, had now been adopted by New York and other East Coast youth who admired the image seen on screen. A rash of initiation assaults, raids, and gang violence ensued after being denounced in the early stages of hip hop. Suddenly a trend of Bloods and Crips association and attire was seen in rap music, and gangs began to target innocent people and fight with each other. Bambaataa, having seen it lead to increased negativity in the past, began holding peace conferences. He called on all gang leaders from the Latin Kings street gang, Crips, and Bloods and formed a peace treaty in the streets. Bambaataa is credited for preventing huge gang wars and an outbreak of crime while outsiders and politicians credited Rudy Giuliani, the Mayor of New York City at the time.

He succeeded his father Chagri Begh as governor of Khorasan in 1059. When his uncle Toğrül died he was succeeded by Suleiman, Alp Arslan's brother. Alp Arslan and his uncle Kutalmish both contested this succession. Alp Arslan defeated Kutalmish for the throne and succeeded on April 27, 1064 as sultan of Great Seljuk, and thus became sole monarch of Persia from the river Oxus to the Tigris.
In consolidating his empire and subduing contending factions he was ably assisted by Nizam ul-Mulk, his Persian vizier, and one of the most eminent statesmen in early Muslim history. With peace and security established in his dominions, he convoked an assembly of the states and declared his son Malik Shah I his heir and successor. With the hope of acquiring immense booty in the rich church of St. Basil in Caesarea Mazaca, the capital of Cappadocia, he placed himself at the head of the Turkish cavalry, crossed the Euphrates and entered and plundered that city. He then marched into Armenia and Georgia, which he conquered in 1064.
In 1068, en route to Syria, Alp Arslan invaded the Byzantine Empire. The emperor Romanus IV Diogenes, assuming the command in person, met the invaders in Cilicia. In three arduous campaigns, the first two of which were conducted by the emperor himself while the third was directed by Manuel Comnenus (great-uncle of Emperor Manuel Comnenus), the Turks were defeated in detail in 1070 driven across the Euphrates. In 1071 Romanus again took the field and advanced with 40,000 men, including a contingent of the Cuman Turks as well as contingents of Franks and Normans, under Ursel of Bahol, into Armenia.
At Manzikert, on the Murad Tchai, north of Lake Van, Diogenes was met by Alp Arslan. The sultan proposed terms of peace, which were rejected by the emperor, and the two forces met in the Battle of Manzikert. The Cuman mercenaries among the Byzantine forces immediately defected to the Turkish side; and, seeing this, "the Western mercenaries rode off and took no part in the battle." The Byzantines were totally routed.
As suggested by this conversation, what would seem to have been an act of mercy on Arslan's part indeed proved to be the crueler punishment: following his return, Romanus was deposed, blinded and exiled to the island of Proti and died as the result of an infection from an injury during his blinding.
Alp Arslan's victories changed the balance in near Asia completely in favour of the Seljuk Turks and Sunni Muslims. While the Byzantine Empire was to continue for nearly another four centuries, and the Crusades would contest the issue for some time, the victory at Manzikert signalled the beginning of Turkish ascendancy in Anatolia. Most historians, including Edward Gibbon, date the defeat at Manzikert as the beginning of the end of the Eastern Roman Empire. Certainly the entry of Turkic farmers following their horsemen ended the themes in Anatolia which had furnished the Empire with men and treasure.
Alp Arslan's strength lay in the military realm. Domestic affairs were handled by his able vizier, Nizam al-Mulk, the founder of the administrative organization which characterized and strengthened the sultanate during the reigns of Alp Arslan and his son, Malik Shah. Military fiefs, governed by Seljuk princes, were established to provide support for the soldiery and to accommodate the nomadic Turks to the established Persian agricultural scene. This type of military fiefdom enabled the nomadic Turks to draw on the resources of the sedentary Persians and other established cultures within the Seljuk realm, and allowed Alp Arslan to field a huge standing army, without depending on tribute from conquest to pay his soldiery. He not only had enough food from his subjects to maintain his military, but the taxes collected from traders and merchants added to his coffers sufficiently to fund his continuous wars.
Suleiman ibn Kutalmish was the son of the contender for Arslan's throne; he was appointed governor of the north-western provinces. An explanation for this choice can only be conjectured from Ibn al-Athir’s account of the battle between Alp-Arslan and Kutalmish, in which he writes that Alp-Arslan wept for the latter's death and greatly mourned the loss of his kinsman.
Since the 2002 Turkmen calendar reform, the month of August has been named after Arp Arslan.

The American Film Institute (AFI) is an independent non-profit organization created by the National Endowment for the Arts, which was established in 1967 when President Lyndon B. Johnson signed the National Foundation on the Arts and the Humanities Act.
George Stevens, Jr. was the first CEO and director. In 1980 Jean Picker Firstenberg became Director and CEO. Bob Gazzale, a fifteen-year veteran of the AFI, was named president and CEO November 2007.
In 1973, the AFI established a Life Achievement Award. Their own film festival, AFI Fest, was launched in 1987 and has been held every year. AFI Fest is the first film festival in the United States to carry FIAPF accreditation. Beginning in 2007, AFI opened up a satellite festival under the name AFI DALLAS.
In 1998, the 100th anniversary of American film, AFI began its 100 Years.. series, celebrating and promoting interest in film history; they also preserve old films, which are subject to degradation of film stock.
The AFI re-opened the AFI Silver theatre in Silver Spring, Maryland, near Washington, D.C. in April 2003. The AFI Conservatory focuses on training through hands-on experience with established figures. AFI also produces film education and appreciation materials for middle and high school students. In spite of its name, AFI does not focus exclusively on film, but also on television and video.


In film criticism, the 1950s-era auteur theory holds that a director's films reflect that director's personal creative vision, as if they were the primary "auteur" (the French word for "author"). In some cases, film producers are considered to have a similar "auteur" role for films that they have produced.
In law the auteur is the creator of a film as a work of art, and is the original copyright holder. Under European Union law the film director shall always be considered the author or one of the authors of a film.
Auteur theory has had a major impact on film criticism ever since it was advocated by film director and film critic François Truffaut in 1954. "Auteurism" is the method of analyzing films based on this theory or, alternately, the characteristics of a director's work that makes her or him an auteur. Both the auteur theory and the auteurism method of film analysis are frequently associated with the French New Wave and the film critics who wrote for the influential French film review periodical Cahiers du cinéma.
Auteur theory draws on the work of André Bazin, co-founder of the Cahiers du cinéma, who argued that films should reflect a director's personal vision. Bazin championed filmmakers such as Howard Hawks, Alfred Hitchcock and Jean Renoir. Although Bazin provided a forum for auteurism to flourish, he himself remained wary of its excesses. Another key element of auteur theory comes from Alexandre Astruc's notion of the caméra-stylo or "camera-pen" and the idea that directors should wield their cameras like writers use their pens and that they need not be hindered by traditional storytelling.
Truffaut and the members of the Cahiers recognized that moviemaking was an industrial process. However, they proposed an ideal to strive for: the director should use the commercial apparatus the way a writer uses a pen and, through the mise en scène, imprint their vision on the work (conversely, the role of the screenwriter was minimized in their eyes). While recognizing that not all directors reached this ideal, they valued the work of those who neared it.
Much of Truffaut's writing of this period, and of his colleagues at the film criticism magazine Cahiers du cinéma, was designed to lambaste post-war French cinema, and especially the big production films of the cinéma de qualité ("quality films"). Truffaut's circle referred to these films with disdain as sterile, old-fashioned cinéma de papa (or "Dad's cinema"). During the Nazi occupation, the Vichy government did not allow the exhibition of U.S. films such as The Maltese Falcon and Citizen Kane. When French film critics were finally able to see these 1940s U.S. movies in 1946, they were enamoured by these films.
Truffaut's theory maintains that all good directors (and many bad ones) have such a distinctive style or consistent theme that their influence is unmistakable in the body of their work. Truffaut himself was appreciative of both directors with a marked visual style (such as Alfred Hitchcock), and those whose visual style was less pronounced but who had nevertheless a consistent theme throughout their movies (such as Jean Renoir's humanism).
The auteur theory was used by the directors of the nouvelle vague (New Wave) movement of French cinema in the 1960s (many of whom were also critics at the Cahiers du cinéma) as justification for their intensely personal and idiosyncratic films. One of the ironies of the auteur theory is that, at the very moment Truffaut was writing, the break-up of the Hollywood studio system during the 1950s was ushering in a period of uncertainty and conservatism in American cinema, with the result that fewer of the sort of films Truffaut admired were actually being made.
The "auteur" approach was adopted in English-language film criticism in the 1960s. In the UK, Movie adopted auteurism, while in the U.S. Andrew Sarris introduced it in the essay, "Notes on the Auteur Theory in 1962". This essay is where the half-French, half-English term, "auteur theory", originated. To be classified as an "auteur", according to Sarris, a director must accomplish technical competence in their technique, personal style in terms of how the movie looks and feels, and interior meaning (although many of Sarris's auterist criteria were left vague). Later in the decade, Sarris published The American Cinema: Directors and Directions, 1929–1968, which quickly became the unofficial bible of auteurism.
The auteur theory was also challenged by the influence of New Criticism, a school of literary criticism. The New Critics argued that critics made an "intentional fallacy" when they tried to interpret works of art by speculating about what the author meant, based on the author's personality or life experiences. New Critics argued that that information or speculation about an author's intention was secondary to the words on the page as the basis of the experience of reading literature.


Akira Kurosawa was a prominent Japanese film director, film producer, and screenwriter. His first credited film (Sanshiro Sugata) was released in 1943; his last (Madadayo) in 1993. His many awards include the Légion d'Honneur and an Oscar for Lifetime Achievement.
Akira Kurosawa was born to Isamu and Shima Kurosawa on March 23, 1910. He was the youngest of eight children born to the Kurosawas in a suburb of Tokyo. Shima Kurosawa was forty years old at the time of Akira's birth and his father Isamu was forty-five. Akira Kurosawa grew up in a household with three older brothers and four older sisters. Of his three older brothers, one died before Akira was born and one was already grown and out of the household. One of his four older sisters had also left the home to begin her own family before Kurosawa was born. Kurosawa's next-oldest sibling, a sister he called "Little Big Sister," also died suddenly after a short illness when he was ten years old.
Kurosawa's father worked as the director of a junior high school operated by the Japanese military and the Kurosawas descended from a line of former samurai. Financially, the family was above average. Isamu Kurosawa embraced western culture both in the athletic programs that he directed and by taking the family to see films, which were then just beginning to appear in Japanese theaters. Later, when Japanese culture turned away from western films, Isamu Kurosawa continued to believe that films were a positive educational experience.
In primary school, Akira Kurosawa was encouraged to draw by a teacher who took an interest in mentoring his talents. His older brother, Heigo, had a profound impact on him. Heigo was very intelligent and won several academic competitions, but also had what was later called a cynical or dark side. In 1923, the Great Kantō earthquake destroyed Tokyo and left 100,000 people dead. In the wake of this event, Heigo, 17, and Akira, 13, made a walking tour of the devastation. Corpses of humans and animals were piled everywhere. When Akira would attempt to turn his head away, Heigo urged him not to. According to Akira, this experience would later instruct him that to look at a frightening thing head-on is to defeat its ability to cause fear.
Heigo eventually began a career as a benshi in Tokyo film theaters. Benshi narrated silent films for the audience and were a uniquely Japanese addition to the theater experience. However, with the impact of talking pictures on the rise, benshi were losing work all over Japan. Heigo organized a benshi strike that failed. Akira was likewise involved in labor-management struggles, writing several articles for a radical newspaper while improving and expanding his skills as a painter and reading literature. Akira never considered himself a Communist, despite his activities that he later would describe as reckless.
When Akira Kurosawa was in his early 20s, his older brother Heigo committed suicide. Four months later, the oldest of Kurosawa's brothers also died, leaving Akira as the only surviving son of an original four at age 23.
In 1936, Kurosawa learned of an apprenticeship program for directors through a major film studio, PCL (which later became Toho). He was hired and worked as an assistant director to Kajiro Yamamoto. After his directorial debut with Sanshiro Sugata, his next few films were made under the watchful eye of the wartime Japanese government and sometimes contained nationalistic themes. For instance, The Most Beautiful is a propaganda film about Japanese women working in a military optics factory. Judo Saga 2 portrays Japanese judo as superior to western (American) boxing.
His first post-war film No Regrets for Our Youth, by contrast, is critical of the old Japanese regime and is about the wife of a left-wing dissident who is arrested for his political leanings. Kurosawa made several more films dealing with contemporary Japan, most notably Drunken Angel and Stray Dog. However, it was his period film Rashomon that made him internationally famous and won the Golden Lion at the Venice Film Festival.
Kurosawa had a distinctive cinematic technique, which he had developed by the 1950s, and which gave his films a unique look. He liked using telephoto lenses for the way they flattened the frame and also because he believed that placing cameras farther away from his actors produced better performances. He also liked using multiple cameras, which allowed him to shoot an action scene from different angles. Another Kurosawa trademark was the use of weather elements to heighten mood: for example the heavy rain in the opening scene of Rashomon, and the final battle in Seven Samurai, the intense heat in Stray Dog, the cold wind in Yojimbo, the snow in Ikiru, and the fog in Throne of Blood. Kurosawa also liked using frame wipes, sometimes cleverly hidden by motion within the frame, as a transition device.
He was known as "Tenno", literally "Emperor", for his dictatorial directing style. He was a perfectionist who spent enormous amounts of time and effort to achieve the desired visual effects. In Rashomon, he dyed the rain water black with calligraphy ink in order to achieve the effect of heavy rain, and ended up using up the entire local water supply of the location area in creating the rainstorm. In the final scene of Throne of Blood, in which Mifune is shot by arrows, Kurosawa used real arrows shot by expert archers from a short range, landing within centimetres of Mifune's body. In Ran, an entire castle set was constructed on the slopes of Mt. Fuji only to be burned to the ground in a climactic scene.
Other stories include demanding a stream be made to run in the opposite direction in order to get a better visual effect, and having the roof of a house removed, later to be replaced, because he felt the roof's presence to be unattractive in a short sequence filmed from a train.
His perfectionism also showed in his approach to costumes: he felt that giving an actor a brand new costume made the character look less than authentic. To resolve this, he often gave his cast their costumes weeks before shooting was to begin and required them to wear them on a daily basis and "bond with them." In some cases, such as with Seven Samurai, where most of the cast portrayed poor farmers, the actors were told to make sure the costumes were worn down and tattered by the time shooting started.
Kurosawa did not believe that "finished" music went well with film. When choosing a musical piece to accompany his scenes, he usually had it stripped down to one element (e.g. trumpets only). Only towards the end of his films are more finished pieces heard.
A notable feature of Kurosawa's films is the breadth of his artistic influences. Some of his plots are based on William Shakespeare's works: "Ran" is loosely based on King Lear, Throne of Blood is based on Macbeth, while The Bad Sleep Well parallels Hamlet, but is not affirmed to be based on it. Kurosawa also directed film adaptations of Russian literary works, including The Idiot by Dostoevsky and The Lower Depths, a play by Maxim Gorky. Ikiru was inspired by Leo Tolstoy's The Death of Ivan Ilyich. Dersu Uzala was based on the 1923 memoir of the same title by Russian explorer Vladimir Arsenyev. Story lines in Red Beard can be found in The Insulted and Humiliated by Dostoevsky.
High and Low was based on "King's Ransom by American crime writer Ed McBain, Yojimbo" may have been based on Dashiell Hammett's Red Harvest and also borrows from American Westerns, and Stray Dog was inspired by the detective novels of Georges Simenon. The American film director John Ford also had a large influence on his work.
Despite criticism by some Japanese critics that Kurosawa was "too Western", he was deeply influenced by Japanese culture as well, including the Kabuki and Noh theaters and the Jidaigeki (period drama) genre of Japanese cinema.
Kurosawa's films have had a major influence on world cinema and continue to inspire filmmakers, and others, around the globe.
The story was also used as inspiration in numerous novels, among them Stephen King's 5th Dark Tower novel, Wolves of the Calla.
Rashomon not only helped open Japanese cinema to the world, but also entered the English language as a term for fractured, inconsistent narratives (see rashomon effect).
Yojimbo was the basis for the Sergio Leone western A Fistful of Dollars and two Bruce Willis films, prohibition-era Last Man Standing, and modern day Lucky Number Slevin.
The Hidden Fortress is an acknowledged influence on George Lucas's Star Wars films, in particular Episodes IV and VI and most notably in the characters of R2-D2 and C-3PO. Lucas also used a modified version of Kurosawa's wipe transition effect throughout the Star Wars saga.
During his most productive period, from the late 40s to the mid-60s, Kurosawa often worked with the same group of collaborators. Fumio Hayasaka composed music for seven of his films — notably Rashomon, Ikiru and Seven Samurai. Many of Kurosawa's scripts, including Throne of Blood, Seven Samurai and Ran were co-written with Hideo Oguni. Yoshiro Muraki was Kurosawa's production designer or art director for most of his films after Stray Dog in 1949, and Asakazu Nakai was his cinematographer on 11 films including Ikiru, Seven Samurai and Ran. Kurosawa also liked working with the same group of actors, especially Takashi Shimura, Tatsuya Nakadai, and Toshirō Mifune. His collaboration with the latter, which began with 1948's Drunken Angel and ended with 1965's Red Beard, is one of the most famous director-actor combinations in cinema history.
The film Red Beard marked a turning point in Kurosawa's career in more ways than one. In addition to being his last film with Mifune, it was his last in black-and-white. It was also his last as a major director within the Japanese studio system making roughly a film a year. Kurosawa was signed to direct a Hollywood project, Tora! Tora! Tora!; but 20th Century Fox replaced him with Toshio Masuda and Kinji Fukasaku before it was completed. His next few films were a lot harder to finance and were made at intervals of five years. The first, Dodesukaden, about a group of poor people living around a rubbish dump, was not a success.
After an attempted suicide, Kurosawa went on to make several more films, although he had great difficulty in obtaining domestic financing despite his international reputation. Dersu Uzala, made in the Soviet Union and set in Siberia in the early 20th century, was the only Kurosawa film made outside of Japan and not in the Japanese language. It is about the friendship of a Russian explorer and a nomadic hunter, and won the Oscar for Best Foreign Language Film. Kagemusha, financed with the help of the director's most famous admirers, George Lucas and Francis Ford Coppola, is the story of a man who is the body double of a medieval Japanese lord and takes over his identity after the lord's death. The film was awarded by the Palme d'Or (Golden Palm) at the 1980 Cannes Film Festival (which was shared this year with Bob Fosse's All That Jazz). Ran was the director's version of Shakespeare's King Lear, set in medieval Japan. It was by far the largest project of Kurosawa's late career, and he spent a decade planning it and trying to obtain funding, which he was finally able to do with the help of the French producer Serge Silberman. The film was an international success and is generally considered Kurosawa's last masterpiece. In an interview, Kurosawa said that he considered it to be the best film he ever made.
Kurosawa made three more films during the 1990s which were more personal than his earlier works. Dreams is a series of vignettes based on his own dreams. Rhapsody in August is about memories of the Nagasaki atomic bomb and his final film, Madadayo, is about a retired teacher and his former students. Kurosawa died of a stroke in Setagaya, Tokyo, at age 88.
After the Rain is a 1998 posthumous film directed by Kurosawa's closest collaborator, Takashi Koizumi, co-produced by Kurosawa Production (Hisao Kurosawa) and starring Tatsuda Nakadai and Shiro Mifune, son of Toshirō Mifune. Screenplay, script and dialogues were both written by Kurosawa himself. The story is based on a short novel by Shugoro Yamamoto, Ame Agaru.
Kurosawa's wife was Yoko Yaguchi. He had two children with her: a son named Hisao and a daughter named Kazuko.
Kurosawa was a notoriously lavish gourmet, and spent huge quantities of money on film sets providing an incredibly large quantity of fine delicacies, especially meat, for the cast and crew, although the meat was sometimes left over from recording sound effects of the sound of blades cutting flesh in the many swordfight scenes.

ancient Egypt entered a period of slow, steady decline, during which Egypt was conquered by a succession of foreign powers. The rule of the pharaohs officially ended in 31 BC when the early Roman Empire conquered Egypt and made it a province.
The civilization of ancient Egypt thrived from adaptation to the conditions of the Nile River Valley. Controlled irrigation of the fertile valley produced surplus crops which fueled social development and culture. With resource to spare, the administration sponsored mineral exploitation of the valley and surrounding desert regions, the early development of an independent writing system, the organization of collective construction and agricultural projects, trade with surrounding regions, and a military that defeated foreign enemies and asserted Egyptian dominance. Motivating and organizing these activities was a bureaucracy of elite scribes, religious leaders, and administrators under the control of the divine pharaoh who ensured the cooperation and unity of the Egyptian people by means of an elaborate system of religious beliefs.
the imaginations of tourists and writers for centuries. With the translation of hieroglyphs and a newfound respect for antiquities and excavations, the once-lost cultural heritage of the ancient Egyptians can once again be understood.
By the late Paleolithic period, the arid climate of northern Africa had become increasingly hot and dry, forcing the populations of the area to concentrate along the Nile valley, and since nomadic hunter-gatherers began living in the region during the Pleistocene some 1.8 million years ago, the Nile has been the lifeline of Egypt. The fertile floodplain of the Nile gave humans the opportunity to develop a settled agricultural economy and a more sophisticated, centralized society that became a cornerstone in the history of human civilization.
The Egyptian language belongs to the Afro-Asiatic language phylum and is related to the Semitic languages, such as Arabic and Hebrew, as well as the Afro-Asiatic languages of North Africa, such as Berber and Cushitic. Used continuously from before 3000 BC to the 11th century AD, ancient Egyptian was, at one point, the longest-surviving language in the world. The language underwent major changes in its pronunciation and usage over the course of history and was spoken in many dialects. The oldest stage of the language, Old Egyptian, was used until about 2100 BC, when it was gradually displaced by Middle Egyptian. By 1600 BC, Late Egyptian began to develop and was used until about 600 BC. Demotic developed from Late Egyptian and survived until the 5th century AD; it was at one time commonly used alongside Coptic, the final phase of the language that was used from the 1st to the 11th century AD. A dialect of Coptic remained in use for services of the Coptic church and is still in limited use today.
The ancient Egyptian writing system is known as "hieroglyphic" (incorrectly termed "hieroglyphics") and is composed of some 500 symbols called hieroglyphs. There is no explanation for exactly how the system was devised, but it was suddenly adopted and developed shortly before 3000 BC. Each hieroglyph is a picture of a real thing—a bird, tool, or body part— and most of the common hieroglyphs correspond to a letter or letter combination in the alphabet. Words in the language are spelled out by stringing together the hieroglyphs whose sounds make up the word. Like the semitic languages, ancient Egyptian does not indicate vowels.
Hieroglyphs were a formal script, used on stone monuments and in tombs, that could be as detailed as individual works of art. In day-to-day writing, scribes used a cursive form of writing, called hieratic, which was quicker and easier. While formal hieroglyphs may be read in rows or columns in either direction, hieratic was always written from right to left, usually in horizontal rows. After Demotic became the dominant spoken language, a new form of writing, of the same name, became the prevalent writing style, and it is this form of writing—along with formal hieroglyphs—that accompany the Greek text on the Rosetta Stone. In the 1st century AD, Coptic Christians living in Egypt discarded the native demotic script and instead wrote their language, using a modified Greek alphabet, in a script also known as Coptic. Although formal hieroglyphs were used in a ceremonial role until the 4th century AD, towards the end only a small handful of highly educated priests could still read them; as the traditional religious establishments were disbanded, the knowledge of their meaning was lost. Only in 1822, after the discovery of the Rosetta stone in 1799 and years of research by Thomas Young and Jean-François Champollion, were the hieroglyphs deciphered.
Writing first appeared in association with kingship on labels and tags for items found in royal tombs. By the Old Kingdom, this tradition of writing had evolved into the tomb autobiography, such as those of Harkhuf and Weni. The genre known as Sebayt (Instructions) was developed to communicate teachings and guidance from famous nobles; the Ipuwer papyrus, a poem of lamentations describing natural disasters and social upheaval, is an extreme example of such an instruction. During the First Intermediate Period and the Middle Kingdom, the prose style of literature matured, with The Story of Sinuhe perhaps being the classic of Egyptian literature. Also written at this time was the Westcar Papyrus, a set of stories told to Khufu by his sons relating the marvels performed by priests. Towards the end of the New Kingdom, the Story of Wenamun was written. It tells the story of a noble who is robbed on his way to buy cedar from Lebanon and of his struggle to return to Egypt; the text also shows the end of united Egypt and the start of the tumultuous Third Intermediate Period.
Most ancient Egyptians were farmers tied to the land. The dwelling was restricted to immediate family members, and were constructed of mud-brick designed to remain cool in the heat of the day. Each home had a kitchen with an open roof, which contained a grindstone for milling flour and a small oven for baking bread. Walls were painted white and could be covered with dyed linen wall hangings. Floors were covered with reed mats, and wooden stools, beds raised from the floor, and individual tables comprised the furniture.
The ancient Egyptians placed a great value on hygiene and appearance. Most bathed in the Nile and used a pasty soap made from animal fat and chalk. Men shaved their entire bodies for cleanliness, and aromatic perfumes and ointments covered bad odors and soothed skin. Clothing was made from simple linen sheets which were bleached white, and both men and women of the upper classes wore wigs, jewelery, and cosmetics. Children went without clothing until maturity, at about age twelve, and at this age males were circumcised and had their heads shaved. Mothers were responsible for taking care of the children, while the father provided the family's income.
The staple of the diet consisted of bread and beer, supplemented with vegetables such as onions and garlic, and fruit such as dates and figs. Wine and meat were enjoyed on feast days and for the upper classes. Fish, meat, and foul could be salted or dried, and could be cooked in stews or roasted on a grill. Music and dance were popular entertainments for those who could afford them. Early instruments included flutes and harps, while instruments similar to trumpets, oboes, and pipes developed later and became popular. In the New Kingdom, the Egyptians played on bells, cymbals, tambourines, and drums and imported lutes and lyres from Asia. The sistrum was a rattle-like musical instrument that was especially important in religious ceremonies.
The ancient Egyptians enjoyed a variety of leisure activities, including games and music. Senet, a board game where pieces moved according to random chance, was particularly popular from the earliest times; another similar game was mehen, which had a circular gaming board. Juggling and ball games were popular with children, and wrestling is also documented in a tomb at Beni Hasan. The wealthy members of ancient Egyptian society enjoyed hunting and boating as well.
The architecture of ancient Egypt includes some of the most famous structures in the world: the Great Pyramids of Giza, Abu Simbel, and the temples at Thebes. All major building projects were organized and funded by the state, and they not only fulfilled religious, military, and commemorative purposes, but also reinforced the power and reputation of the pharaoh to ensure his legacy for all time. The ancient Egyptians were skilled builders with expert knowledge of basic surveying and construction techniques. Using simple but effective measuring ropes, plum bobs, and sighting instruments, architects could build large stone structures with accuracy and precision.
Most buildings in ancient Egypt were constructed from perishable materials such as mud bricks and wood, and have not survived. Important structures such as temples and tombs were intended to last forever and were instead constructed of stone. The first large scale stone building in the world, the mortuary complex of Djoser, was built in the Third Dynasty as a stone imitation of the mud-brick and wooden structures used in daily life.
The architectural elements used in Djoser's mortuary complex, including post and lintel construction of huge stone roof blocks supported by external walls and closely spaced columns, would be copied many times in Egyptian history. Decorative styles introduced in the Old Kingdom, such as the lotus and papyrus motifs, are a recurring theme in ancient Egyptian architecture.
The earliest tomb architecture in ancient Egypt was the mastaba, a flat-roofed rectangular structure of mudbrick or stone built over an underground burial chamber. The mastaba was the most popular tomb among the nobility in the Old Kingdom, and the first pyramid, the step pyramid of Djoser, is actually a series of stone mastabas stacked on top of each other. The step pyramid was itself the inspiration for the first true pyramids. Pyramids were built by the pharaohs of the Old and Middle Kingdoms, but later rulers abandoned them in favor of less conspicuous rock-cut tombs. New Kingdom pharaohs built their rock-cut tombs in the Valley of the Kings, and by the Third Intermediate Period, the pharaohs had abandoned building grand tomb architecture altogether.
The earliest preserved ancient Egyptian temples, dating back to the Old Kingdom, consist of single, enclosed halls with roof slabs supported by columns. The mortuary temples connected to the pyramids at Giza are examples of this early temple. During the Fifth Dynasty, pharaohs developed the sun temple, the focus of which was a squat, pyramid-shaped obelisk known as a ben-ben stone. The ben-ben stone and other temple structures were surrounded by an outer wall and connected to the Nile via a causeway terminating in a valley temple. In the New Kingdom, architects added the pylon, the open courtyard, and the enclosed hypostyle hall to the front of the temple's sanctuary. Because the common people were not allowed past the entry pylon, the deity residing in the inner sanctuary was distanced from the outside world. This type of cult temple was standardly used until the Ptolemaic and Roman Periods.
The ancient Egyptians produced art to serve functional purposes rather than to express creative genius. For over 3500 years, artists adhered to artistic forms that were developed during the Old Kingdom, following a strict set of principles that resisted foreign influence and internal change. These artistic standards—simple lines, shapes, and flat areas of color combined with the characteristic flat projection of figures with no indication of spatial depth—created a sense of order and balance within a composition. The ancient Egyptians made little distinction between images and text, which were intimately interwoven on tomb and temple walls, coffins, stelae, and even statues. This mentality is evident even in the earliest examples of Egyptian art, such as the Narmer Palette, where the figures being depicted may also be read as hieroglyphs. Because of the rigid rules that governed its highly stylized and symbolic appearance, ancient Egyptian art served its political and religious purposes with precision and clarity.
Pharaohs used reliefs carved on stelae, temple walls, and obelisks to record victories in battle, royal decrees, and religious scenes. These art forms glorified the pharaoh, recorded that ruler's version of historical events, and established the relationship between the Egyptians and their deities. Common citizens had access to pieces of funerary art, such as shabti statues and books of the dead, which they believed would protect them in the afterlife. During the Middle Kingdom, wooden or clay models depicting scenes from everyday life became popular additions to the tomb. In an attempt to duplicate the activities of the living in the afterlife, these models show laborers, houses, boats, and even military formations that are scale representations of the ideal ancient Egyptian afterlife.
During the turbulent times of the Late Period, artists—or more likely their patrons—sought to reinforce continuity with their historical predecessors and enhance their political legitimacy by adopting an "archaising" style. Copying the unique style of the Old Kingdom, artists carved statues and reliefs that are sometimes indistinguishable from objects created some two thousand years earlier. In this Saite style, poses, hairstyles, musculature, and composition were heavily influenced from the past. Artists did have some room for innovation, however, as they adapted historic themes and patterns to Late Period uses.
Despite the homogeneity of ancient Egyptian art, the styles of particular times and places sometimes reflected changing cultural or political attitudes. After the invasion of the Hyksos in the Second Intermediate Period, Minoan style frescoes were found in Avaris, suggesting political and cultural connections with Crete. The most striking example, however, comes from the Amarna period, where the appearance of the royal figure and artistic subject matter were radically altered to conform to Akhenaten's revolutionary religious ideas. In Amarna art, The pharaoh was depicted with swelling thighs and an oblong head in shocking contrast to traditional motifs. There is no secure explanation why Akhenaten allowed himself to be portrayed in this fashion, but he may have been trying to show himself with both male and female characteristics. The standard religious scenes were replaced by those of the royal family worshipping the Aten, which, along with Akhenaten himself, had become the central focus of the new religion. After Akhenaten's death, the new art forms and religion were quickly and thoroughly erased, replaced by the traditional forms.
Beliefs in the divine and in the afterlife were ingrained in the ancient Egyptian civilization from its inception; pharaonic rule was based upon the doctrine of the divine right of kings. The Egyptian pantheon was populated by a diverse array of gods who had supernatural, though sometimes limited, powers and were called upon for help or protection. However, the gods were not always viewed as benevolent, and Egyptians believed they had to be appeased with offerings and prayers. The structure of this pantheon changed continually as new deities were promoted in the hierarchy, but priests made no effort to organize the diverse and sometimes conflicting creation myths and stories into a coherent system.
Officially, the gods were worshiped in cult temples by priests acting on the king's behalf. At the center of the temple, the cult statue of the god was placed in a shrine where the god could manifest himself. Temples were not places of public worship or congregation, and only on select feast days and celebrations would a shrine carrying the statue of the god be brought out for public worship. Normally, the god's domain was sealed off from the outside world and was only accessible to temple officials; common citizens seeking a more direct interaction with the gods could worship private statues and stelae in the home, and amulets offered continuous, personal protection against the forces of chaos.
After the New Kingdom, the pharaoh's connection to the divine, and thus his role as a spiritual intermediary, were de-emphasized as religious customs shifted to direct worship of the gods. As a result, priests developed a system of oracles to communicate the will of the gods directly to the people. An oracle could be a statue of the god which could be asked a yes or no question, to which it would "respond" by hidden manipulations of a priest; the priests could also pose questions to the oracle behind closed doors. Oracles became very popular for appealing legal verdicts or for justifying military actions and political decisions.
The Egyptians believed that every human being was composed of physical and spiritual parts, called aspects. In addition to the body, each person had a šwt (shadow), a ba (personality or soul), a ka (life-force), and a name. The heart, rather than the brain, was considered the seat of thoughts and emotions. After death, the spiritual aspects were released from the body and could move at will, but they required the physical remains (or a substitute, such as a statue) as a permanent home. The ultimate goal of the deceased was to rejoin his ka and ba and become one of the "blessed dead", living on as an akh, or "effective one". In order for this to happen, the deceased had to be judged worthy in a trial, in which the heart was weighed against a "feather of truth". If deemed worthy, the deceased could continue their existence on earth in spiritual form.
The ancient Egyptians maintained an elaborate set of burial customs that they believed were necessary to ensure immortality after death. These customs involved preserving the body by mummification, performing burial ceremonies, and interring, along with the body, goods to be used by the deceased in the afterlife.
Before the Old Kingdom, bodies buried in desert pits were naturally preserved by desiccation. The arid, desert conditions continued to be a boon throughout the history of ancient Egypt for the burials of the poor, who could not afford the elaborate burial preparations available to the elite. However, many wealthier Egyptians lost the advantage of natural mummification by the desert when they began to bury their dead in stone tombs. As a result, the wealthy elite of the Old and Middle Kingdoms began to make use of artificial mummification, which involved removing the internal organs, wrapping the body in linen, coating it with plaster or resin, and sometimes painting or sculpting facial details. The body was then buried in a rectangular stone sarcophagus or wooden coffin. Beginning in the Fourth Dynasty, the intestines, lungs, liver, and stomach were preserved separately in canopic jars and symbolically protected by likenesses of the Four sons of Horus.
By the New Kingdom, the ancient Egyptians had perfected the art of mummification; the best technique took 70 days and involved removing the internal organs, removing the brain through the nose, and desiccating the body in a mixture of salts called natron. The body was then wrapped in linen with protective amulets inserted between layers and placed in a decorated anthropoid coffin. Mummies of the Late Period were also placed in painted cartonnage mummy cases. Actual preservation practices declined during the Ptolemaic and Roman eras, while greater emphasis was placed on the outer appearance of the mummy, which was decorated with elaborate rhomboidal patterns formed by the wrapping bandages.
Wealthy members of society were buried with larger quantities of luxury items and furniture, but all burials, regardless of social status, included goods for the deceased, such as food and jewelry. Beginning in the New Kingdom, books of the dead were included in the grave and contained spells and instructions for protection in the afterlife. New Kingdom Egyptians were also buried with shabti statues, which they believed would perform manual labor for them in the afterlife.
All Egyptian burials was accompanied by rituals in which the deceased was magically re-animated. This procedure involved touching the mouth and eyes of the deceased with ceremonial instruments to restore the power of speech, movement, and sight. After burial, living relatives were expected to occasionally bring food to the tomb and recite prayers on behalf of the deceased.
The ancient Egyptians engaged in trade with their foreign neighbors to obtain rare, exotic goods not found in Egypt. In the Predynastic Period, they established trade with Nubia to obtain gold and incense. They also established trade with Palestine, as evidenced by Palestinian-style oil jugs found in the burials of the First Dynasty pharaohs. By the Second Dynasty, the ancient Egyptians had established trade with Byblos, a critical source of quality timber not found in Egypt. In the Fifth Dynasty, trade was established with the Land of Punt, which provided gold, aromatic resins, ebony, ivory, and wild animals such as monkeys and baboons.
Egypt relied on trade with Anatolia for essential quantities of tin as well as supplementary supplies of copper, both metals being necessary for the manufacture of bronze. The ancient Egyptians prized the blue stone lapis lazuli, which had to be imported from far-away Afghanistan. Egypt's Mediterranean trade partners also included Greece and Crete, which provided, among other goods, supplies of olive oil. In exchange for its luxury imports and raw materials, Egypt mainly exported grain, gold, linen, and papyrus, in addition to other finished goods including glass and stone objects.
The ancient Egyptian military was responsible for maintaining Egypt's domination in the ancient Near East. The military protected mining expeditions to the Sinai during the Old Kingdom and fought civil wars during the First and Second Intermediate Periods. The military was responsible for maintaining fortifications along important trade routes, such as those found at the city of Buhen on the way to Nubia. Forts also were constructed to serve as military bases, such as the fortress at Sile, which was a base of operations for expeditions to the Levant. In the New Kingdom, a series of pharaohs used the standing Egyptian army to attack and conquer Kush and parts of the Levant.
Typical military equipment included bows and arrows, spears, and round-topped shields made by stretching animal skin over a wooden frame. In the New Kingdom, the military began using chariots that were introduced by the Hyksos invaders of the Second Intermediate Period. Weapons and armor continued to improve after the adoption of bronze: shields were now made from solid wood with a bronze buckle, spears were tipped with a bronze point, and a type of scimitar made of bronze, the Khopesh, was adopted from Asian soldiers.
The Egyptian pharaoh was usually depicted in art and literature riding at the head of the army, and there is some evidence that at least a few pharaohs, such as Seqenenre Tao II and his sons, did in fact do so. Soldiers were recruited from the general population, but during, and especially after, the New Kingdom, mercenaries from Nubia, Kush, and Libya were hired to fight for Egypt while under the command of their own officers.
In technology, medicine and mathematics, ancient Egypt achieved a relatively high standard of productivity and sophistication. Traditional empiricism, as evidenced by the Edwin Smith and Ebers papyri (circa 1600 BC), is first credited to Egypt, and the roots of the scientific method can also be traced back to the ancient Egyptians. The Egyptians created their own alphabet and the decimal system, although it is unclear—due to the margin of error in carbon-dating tests—whether the Egyptians were the first to do so.
they melted and finished, however they did have technical expertise in making different kinds of objects as well as adding trace elements to control the color of the finished glass. A range of colors could be produced, including yellow, red, green, blue, purple, and white, and the glass could be made either transparent or opaque.
The medical problems of the ancient Egyptians stemmed directly from their environment. Living and working close to the Nile brought hazards from malaria and debilitating schistosomiasis parasites, which caused liver and intestinal damage. Dangerous wildlife such as crocodiles and hippos were also a common threat. The life-long labors of farming and building put stress on the spine and joints, and traumatic injuries from construction and warfare all took a significant toll on ancient Egyptians. The grit and sand from stone-ground flour abraded teeth, leaving them susceptible to abcesses (though caries were rare). The diets of the wealthy were rich in sugars, which promoted periodontal disease. Despite the flattering physiques portrayed on tomb walls, the overweight mummies of many of the upper class show the effects of a life of overindulgence. Life expectancy was about 35 for men and 30 for women, but reaching adulthood was difficult as about one-third of the population died in infancy.
Ancient Egyptian physicians were renowned in the ancient Near East for their healing skills. Medical papyri show that they performed thorough examinations and treated patients using a combination of prayers, protective amulets, and remedies derived from natural products. Wounds were treated by bandaging with raw meat, honey was used to prevent infection, and opium was used to relieve pain. Garlic and onions were used regularly to promote good health and were thought to relieve asthma symptoms. Ancient Egyptian surgeons stitched wounds, set broken bones, and amputated diseased limbs, but they recognized that some injuries were so serious that they could only make the patient comfortable until he died.
Texts such as the Rhind Mathematical Papyrus and the Berlin Papyrus show that the ancient Egyptians could perform the four basic mathematical operations—addition, subtraction, multiplication, and division—use fractions, compute the volumes of boxes and pyramids, and calculate the surface areas of rectangles, triangles, circles and even spheres. They understood basic concepts of algebra and geometry, and could solve simple sets of simultaneous equations. Mathematics were always used for practical purposes, such as calculating food rations, building supplies, or the labor force necessary for a project.
Mathematics notation was decimal, and based on hieroglyphic signs for each power of ten up to one million. The symbol was written as many times as necessary to add up to the desired number, so to write the number eighty, the symbol for ten was written eight times. Because ancient Egyptian methods of calculation could not handle fractions with a numerator greater than one, these types of fractions had to be written out as the sum of several fractions. For example, the fraction was always resolved into the sum of +. Such conversions were facilitated by standard tables of values.
The ancient Egyptians had no concept of pi and never made any efforts to calculate it, but they could approximate the area of a circle using a simple formula, which was to subtract of the diameter and square the result. In modern notation, this would be expressed as Area ≈ [()D]². Additionally, the golden ratio seems to be reflected in many Egyptian constructions, including the pyramids, but its use may have been an unintended consequence of the ancient Egyptian practice of combining the use of knotted ropes with an intuitive sense of proportion and harmony.
collectors destroyed a significant portion of the country's historical legacy, some foreigners had more noble motives. Napoleon, for example, arranged the first scientific studies in egyptology when he brought some 150 scientists and artists to study and document Egypt's natural history, which was published in the "Description de l'Ėgypte", a work of more than 7000 pages and 3000 drawings. The decipherment of hieroglyphs in 1822 allowed the history of ancient Egypt, written in their own words, to be rediscovered and understood.
Since the 19th century, the Egyptian Government and archaeologists alike have begun to recognize the importance of cultural respect and integrity in excavations. The Supreme Council of Antiquities now approves and oversees all excavations, which are aimed at finding information rather than treasure. The council also supervises museums and monument reconstruction programs, which are designed to preserve and share the historical legacy of ancient Egypt for all.


Analog Brothers is an experimental rap crew featuring Ice Oscillator also known as Ice T (keyboards, drums, vocals), Keith Korg also known as Kool Keith (bass, strings, vocals), Mark Moog also known as Marc Live (drums, violyns and vocals), Silver Synth also known as Black Silver (synthesizer, lazar bell and vocals), and Rex Roland also known as Pimp Rex (keyboards, vocals, production). Their CD Pimp To Eat featured guest appearances by various members of Rhyme Syndicate, Odd Oberheim, Jacky Jasper (who appears as Jacky Jasper on the song "We Sleep Days" and H-Bomb on "War"), D.J. Cisco from S.M. the Synth-a-Size Sisters and Teflon.
While they only did one album together as the Analog Brothers, a few bootlegs of their live concert performances, including freestyles with original lyrics, have occasionally surfaced online. After Pimp to Eat, the Analog Brothers continued performing together in various line ups. Kool Keith and Marc Live joined with Jacky Jasper to release two albums as KHM. Marc Live rapped with Ice T's group SMG. Marc also formed a group with Black Silver called Live Black, but while five of their tracks were released on a demo CD sold at concerts, Live Black's first album has yet to be released.
In addition to all this, the Analog Brothers continue to make frequent appearances on each other's solo albums.

The motor neurone diseases (or motor neuron diseases) (MND) are a group of progressive neurological disorders that destroy motor neurones, the cells that control voluntary muscle activity such as speaking, walking, breathing, and swallowing.
Spinal muscular atrophy (SMA) is sometimes (but not always) considered a form of MND.
In this article, MND refers to a group of diseases which affect the motor neurones. In the United States, the term ALS is more commonly used, where it is also known as Lou Gehrig's disease, after the baseball player. Although previously described by other neurologists of the 19th century, it was Jean-Martin Charcot, a French neurologist, who suggested grouping together a number of disparate conditions all affecting the lateral horn of the spinal cord in 1869. In France the disease is sometimes known as Maladie de Charcot (Charcot's disease), although it may also be referred to by the direct translation of ALS, Sclerose Laterale Amyotrophique (SLA). To help prevent confusion, the annual scientific research conference dedicated to the study of MND is called the International ALS/MND Symposium.
Neurological examination presents specific signs associated with upper and lower motor neurone degeneration. Signs of upper motor neurone damage include spasticity, brisk reflexes and the Babinski sign. Signs of lower motor neurone damage include weakness and muscle atrophy.
Note that every muscle group in the body requires both upper and lower motor neurones to function. It is a common misconception that "upper" motor neurones control the arms, whilst "lower" motor neurones control the legs. The signs described above can occur in any muscle group, including the arms, legs, torso, and bulbar region.
Symptoms usually present between the ages of 50-70, and include progressive weakness, muscle wasting, and muscle fasciculations; spasticity or stiffness in the arms and legs; and overactive tendon reflexes. Patients may present with symptoms as diverse as a dragging foot, unilateral muscle wasting in the hands, or slurred speech.
The symptoms described above may resemble a number of other rare diseases, known as "MND Mimic Disorders". These include, but are not limited to multifocal motor neuropathy, Kennedy's disease, hereditary spastic paraplegia, spinal muscular atrophy and monomelic amyotrophy. A small subset of familial MND cases occur in children, such as "juvenile ALS", Madras syndrome, and individuals who have inherited the ALS2 gene. However, these are not typically referred to as MND, but by their specific names.
The diagnosis of MND is a clinical one, established by a neurologist on the basis of history and neurological examination. There is no diagnostic test for MND. Investigations such as blood tests, electromyography (EMG), magnetic resonance imaging (MRI), and sometimes genetic testing are useful to rule out other disorders that may mimic MND. However, the diagnosis of MND remains a clinical one. Having excluded other diseases, a relatively rapid progression of symptoms is a strong diagnostic factor. Although an individual's progression may sometimes "plateau", it will not improve.
A set of diagnostic criteria called the El Escorial criteria have been defined by the World Federation of Neurologists for use in research, particularly as inclusion/exclusion criteria for clinical trials. Owing to a lack of clinical diagnostic criteria, some neurologists use the El Escorial criteria during the diagnostic process, although strictly speaking this is functionality creep, and some have questioned the appropriateness of the criteria in a clinical setting.
It it possible that Transcranial Magnetic Stimulation can be used to diagnose MND.
Most cases of MND progress quite quickly, with noticeable decline occurring over the course of months. Although symptoms may present in one region, they will typically spread. If restricted to one side of the body they are more likely to progress to the same region on the other side of the body before progressing to a new region. After several years, most patients require help to carry out activities of daily living such as self care, feeding, and transportation.
MND is typically fatal within 2-5 years. Around 50% die within 14 months of diagnosis. The remaining 50% will not necessarily die within the next 14 months as the distribution is significantly skewed. As a rough estimate, 1 in 5 patients survive for 5 years, and 1 in 10 patients survive 10 years. Professor Stephen Hawking is a well-known example of a person with MND, and has lived for more than 40 years with the disease.
Mortality normally results when control of the diaphragm is impaired and the ability to breathe is lost. One exception is PLS, which may last for upwards of 25 years. Given the typical age of onset, this effectively leaves most PLS patients with a normal life span. PLS can progress to ALS, decades later.
Approximately 10% of cases are "familial MND", defined either by a family history of MND or by testing positive for a known genetic mutation associated with the disease. The following genes are known to be linked to ALS: Cu/Zn superoxide dismutase, (a small number of cases), senataxin () and vesicle associated protein B ().
Of these, SOD1 mutations account for some 20% of familial MND cases. The SOD1 gene codes for the enzyme superoxide dismutase, a free radical scavenger that reduces the oxidative stress of cells throughout the body. So far over 100 different mutations in the SOD1 gene have been found, all of which cause some form of ALS(ALSOD database). In North America, the most commonly occurring mutation is known as A4V and occurs in up to 50% of SOD1 cases. In people of Scandinavian extraction there is a relatively benign mutation called D90A which is associated with a slow progression. Future research is concentrating on identifying new genetic mutations and the clinical syndrome associated with them. Familial MND may also confer a higher risk of developing cognitive changes such as frontotemporal dementia or executive dysfunction (see 'extra-motor change in MND' below).
It is thought that SOD1 mutations confer a toxic gain, rather than a loss, of function to the enzyme. SOD1 mutations may increase the propensity for the enzyme to form protein aggregates which are toxic to nerve cells.
Skeletal muscles are innervated by a group of neurones (lower motor neurones) located in the ventral horns of the spinal cord which project out the ventral roots to the muscle cells. These nerve cells are themselves innervated by the corticospinal tract or upper motor neurones that project from the motor cortex of the brain. On macroscopic pathology, there is a degeneration of the ventral horns of the spinal cord, as well as atrophy of the ventral roots. In the brain, atrophy may be present in the frontal and temporal lobes. On microscopic examination, neurones may show spongiosis, the presence of astrocytes, and a number of inclusions including characteristic "skein-like" inclusions, bunina bodies, and vacuolisation.
There is a role in excitotoxicity and oxidative stress, presumably secondary to mitochondrial dysfunction. In animal models, death by apoptosis has also been identified.
Around a third of all MND patients experience labile affect, also known as emotional lability, pseudobulbar affect, or pathological laughter and crying. Patients with pseudobulbar palsy are particularly likely to be affected, as are patients with PLS.
Cognitive change can and does occur in between 33–50% of patients. A small proportion exhibit a form of frontotemporal dementia characterised by behavioural abnormalities such as disinhibition, apathy, and personality changes. A small proportion of patients may also suffer from an aphasia, which causes difficulty in naming specific objects. A larger proportion (up to 50%) suffer from a milder version of cognitive change which primarily affects what is known as executive function. Briefly, this is the ability of an individual to initiate, inhibit, sustain, and switch attention and is involved in the organisation of complex tasks down to smaller components. Often patients with such changes find themselves unable to do the family finances or drive a car. Depression is surprisingly rare in MND (around 5–20%) relative to the frequency with which it is found in other, less severe, neurological disorders e.g. ~50% in multiple sclerosis and Parkinson's disease, ~20% in Epilepsy. Depression does not necessarily increase as the symptoms progress, and in fact many patients report being happy with their quality of life despite profound disability. This may reflect the use of coping strategies such as reevaluating what is important in life.
Although traditionally thought only to affect the motor system, sensory abnormalities are not necessarily absent, with some patients finding altered sensation to touch and heat, found in around 10% of patients. Patients with a predominantly upper motor neurone syndrome, and particularly PLS, often report an enhanced startle reflex to loud noises.
Neuroimaging and neuropathology has demonstrated extra-motor changes in the frontal lobes including the inferior frontal gyrus, superior frontal gyrus, anterior cingulate cortex, and superior temporal gyrus. The degree of pathology in these areas has been directly related to the degree of cognitive change experienced by the patient, if any. Patients with MND and dementia have been shown to exhibit marked frontotemporal lobe atrophy as revealed by MRI or SPECT neuroimaging.
The incidence of MND is approximately 1–5 out of 100,000 people. Men have a slightly higher incidence rate than women. Approximately 5,600 cases are diagnosed in the U.S. every year. By far the greatest risk factor is age, with symptoms typically presenting between the ages of 50-70. Cases under the age of 50 years are called "young onset MND", whilst incidence rates appear to tail off after the age of 85.
Tentative environmental risk factors identified so far include: exposure to severe electrical shock leading to coma, having served in the first Gulf War, and playing professional Association football. However, these findings have not been firmly identified and more research is needed.
There are three "hot spots" of MND in the world. One is in the Kii peninsula of Japan, one amongst a tribal population in Papua New Guinea. Chamorro inhabitants from the island of Guam in the Pacific Ocean have an increased risk of developing a form of MND known as Guamanian ALS-PD-dementia complex or "lytico bodig", although the incidence rate has declined over the last 50 years and the average age of onset has increased. Putative theories involve neurotoxins in the traditional diet including cycad nut flour and bats that have eaten cycad nuts.
Currently there is no cure for ALS. The only drug that affects the course of the disease is riluzole. The drug functions by blocking the effects of the neurotransmitter glutamate, and is thought to extend the lifespan of an ALS patient by only a few months.
The lack of effective medications to slow the progression of ALS does not mean that patients with ALS cannot be medically cared for. Instead, treatment of patients with ALS focuses on the relief of symptoms associated with the disease. This involves a variety of health professionals including neurologists, speech-language pathologists, physical therapists, occupational therapists, dieticians, respiratory therapists, social workers, palliative care specialists, specialist nurses and psychologists. A list of neurology clinics that specialize in the care of patients with ALS can be found on the World Federation of Neurology website (http://www.wfnals.org/clinics/).
The search for a drug that will slow MND progression is under way. For example, recent research using mouse models suggests that minocycline, a common antibiotic, may also be effective in extending the lifespan of MND sufferers. This drug must pass clinical trials with ALS patients before it may be used as a general treatment for MND.
Minocycline extends the lifespan of MND mice with SOD1 mutations, but it does not prevent their eventual death. Other agents that are currently in trials include ceftriaxone, arimoclomol, IGF-1 and coenzyme Q10 to name but a few.
Amyotrophic comes from the Greek language: A- means "no", myo refers to "muscle", and trophic means "nourishment"; amyotrophic therefore means "no muscle nourishment," which describes the characteristic atrophication of the sufferer's disused muscle tissue. Lateral identifies the areas in a person's spinal cord where portions of the nerve cells that are affected are located. As this area degenerates it leads to scarring or hardening ("sclerosis") in the region.


According to the formulations of Daniels, abjads differ from alphabets in that only consonants, not vowels, are represented among the basic graphemes. Abjads differ from another category invented by Daniels, abugidas, in that in abjads the vowel sound is implied by phonology, and where vowel marks exist for the system, such as nikkud for Hebrew and harakāt for Arabic, their use is optional and not the dominant (or literate) form. In an abugida, the vowels (other than the "inherent" vowel) are always marked, either with a diacritic, a minor attachment to the letter or a standalone glyph. Some abugidas use a special symbol to suppress" the inherent vowel so that the consonant alone can be properly represented. In a syllabary, a grapheme denotes a complete syllable, that is, either a lone vowel sound or a combination of a vowel sound with one or more consonant sounds.
The system takes its name from the Arabic word for alphabet, which is made up of the first four letters of the Arabic alphabet in the older abjadi order, just as the English word "alphabet" is made up of the names of the first two letters of the Greek alphabet (alpha and beta).
All known abjads belong to the Semitic family of scripts. These scripts are thought to derive from the Proto-Sinaitic alphabet (dated to about 1500 BC) which is thought to derive from Egyptian hieroglyphs. The abjad was significantly simpler than the earlier hieroglyphs. The number of distinct glyphs was reduced tremendously, at the cost of increased ambiguity.
The first abjad to gain widespread usage was the Phoenician abjad. Unlike other contemporary scripts, such as Cuneiform and Egyptian hieroglyphs, the Phoenician script consisted of only about two dozen symbols. This made the script easy to learn, and Phoenician seafaring merchants took the script wherever they went. Phoenician gave way to a number of new writing systems, including the Greek alphabet, the first "true" alphabet, and Aramaic, a widely used abjad. Greek evolved into the modern western alphabets, such as Latin and Cyrillic, while Aramaic became the ancestor of many modern abjads and abugidas of Asia.
Aramaic spread across Asia, reaching as far as India and becoming Brahmi, the ancestral abugida to most modern Indian and Southeast Asian scripts. In the Middle East, Aramaic gave rise to the Hebrew and Nabatean abjads, which retained many of the Aramaic letter forms. The Syriac script was a cursive variation of Aramaic. It is unclear whether the Arabic abjad was derived from Nabatean or Syriac.
Modern abjads have also been used for isopsephy, a system of assigning numeric values to individual letters. Before the development of the positional number system, this was one of the regular systems for writing numbers. In some languages, the relationship between words and numbers created by this system has led to poetic and mystical usages.
"Impure" abjads have characters for some vowels, optional vowel diacritics, or both. The term "pure" abjad refers to scripts entirely lacking in vowel indicators. However, most modern abjads, such as Arabic, Hebrew, Aramaic and Avestan, are "impure" abjads, that is, they also contain symbols for some of the vowel phonemes. An example of a pure abjad is ancient Phoenician.
In the 9th century BC, the Greeks adapted the Phoenician script for use in their own language. The phonetic structure of the Greek language created too many ambiguities when the vowels went unrepresented, so the script was modified. They did not need letters for the guttural sounds represented by aleph, he, heth or ayin, so these symbols were assigned vocalic values. The letters waw and yod were also used. The Greek alphabet became the world's first "true" alphabet.
Abugidas developed along a slightly different route. The basic consonantal symbol was considered to have an inherent "a" vowel sound. Hooks or short lines attached to various parts of the basic letter modify the vowel. In this way, the South Arabian alphabet evolved into the Ge'ez alphabet between the 5th century BC and the 5th century AD. Similarly, around the 3rd century BC, the Brāhmī script developed from the Aramaic abjad.
The abjad form of writing is well-adapted to the grammatical structure of the languages it is used to write. This is because words in such languages are formed from a root consisting of (usually) three consonants, the vowels being used to indicate inflectional or derived forms. For instance, from the Arabic root ذبح (to sacrifice) can be derived the forms ذَبَح (he sacrificed), ذَبَحْتَ (you (masculine singular) sacrificed), ذَبَّح (he slaughtered), يُذَبَّح (he will slaughter), and مَذْبَح (slaughterhouse).
Many non-Semitic languages such as English could, theoretically, be written without vowels, but it would be more difficult, though many words could be interpreted in context. Many European languages, however, would lose grammatical information such as gender, case, and/or number. This fact can be used to semi-bowdlerise offensive language, a practice known as disemvoweling.


An abugida (from Ge‘ez አቡጊዳ ’äbugida) is a segmental writing system in which each letter (basic character) represents a consonant accompanied by a specific vowel; other vowels are indicated by modification of the consonant sign, either by means of diacritics or through a change in the form of the consonant. In some abugidas, the absence of a vowel is indicated overtly. About half the writing systems in the world, including the extensive Brahmic system used for most Indo-Aryan languages, are abugidas.
The term abugida is taken from a Ge'ez name for its own fidel script, derived from its first four letters aləf, bet, gäməl, dənt, or A B G D (based on the ancestral West Semitic character order). This order also corresponds to the Greek alphabet order (Α, Β, Γ, Δ), much like the word alphabet is derived from the Greek names of their first two letters, alpha, beta.
The Ge'ez term "abugida" was adopted into English as a linguistic term by Peter T. Daniels. According to him, an abugida is to be contrasted with a syllabary, where symbols with consonants or vowels in common show no particular resemblance to each another, but also to be contrasted with an alphabet proper, where independent letters are used to denote consonants and vowels. Less formally, both abugidas and alphabets proper may be referred to as "alphabets".
Others, however, consider abugidas to be syllabaries, "semi-syllabaries", or "alpha-syllabaries".
There are three principal families of abugidas, which function somewhat differently. The best known is the Brahmic family of India and Southeast Asia, in which vowels are marked with diacritics and syllable-final consonants, when they occur, are indicated with ligatures, diacritics, or with a special vowel-canceling mark. In the Ethiopic family, vowels are marked my modifying the shapes of the consonants, and one of these pulls double duty for final consonants. In the Cree family, vowels are marked by rotating or flipping the consonants, and final consonants are indicated with either special diacritics or superscript forms of the main initial consonants.
In many of the Brahmic scripts, a syllable beginning with a cluster is treated as a single character for purposes of vowel marking, so a vowel marker like ि -i, falling before the character it modifies, may appear several positions before the place where it is pronounced. For example, the game cricket in Hindi is क्रिकेट krikeţ; the diacritic for /i/ appears before the consonant cluster /kr/, not before the /r/. A more unusual example is seen in the Batak alphabet: Here the syllable bim is written ba-ma-i-(virama). That is, the vowel diacritic and virama are both written after the consonants for the whole syllable.
In many abugidas, there is also a diacritic to suppress the inherent vowel, yielding the bare consonant. In Devanagari, क् is k, and ल् is l. This is called the virama in Sanskrit, or halant in Hindi. It may be used to form consonant clusters, or to indicate that a consonant occurs at the end of a word. For text information processing on computer, other means of expressing these functions include special conjunct forms in which two or more consonant characters are merged to express a cluster, such as Devanagari: क्ल kla. (Note that on some fonts display this as क् followed by ल, rather than forming a conjunct. This expedient is used by ISCII and South Asian scripts of Unicode.) Thus a closed syllable such as kal requires two akshara to write.
In Ethiopic, which gave us the word abugida, the diacritics have fused to the consonants to the point that they must be considered modifications of the form of the letters. Children learn each modification separately, as in a syllabary; nonetheless, the graphic similarities between syllables with the same consonant is readily apparent, unlike the case in a true syllabary.
In the family of abugidas known as Canadian Aboriginal Syllabics, vowels are indicated by changing the orientation of the akshara. For example, Inuktitut ᐱ pi, ᐳ pu, ᐸ pa; ᑎ ti, ᑐ tu, ᑕ ta. In Canadian syllabics it is not possible to distinguish a basic or default vowel, unlike Indic abugidas. Bare consonants are indicated either by separate raised letters, or by superscript versions of the aksharas; there is no vowel-killer mark.
The Róng script used for the Lepcha language goes further than other Indic abugidas, in that a single akshara can represent a closed syllable: Not only the vowel, but any final consonant is indicated by a diacritic. For example, the syllable [sok] would be written as something like s̥̽, here with an underring representing /o/ and an overcross representing the diacritic for final /k/. Most other Indic abugidas can only indicate a very limited set of final consonants with diacritics, such as /ŋ/ or /r/, if they can indicate any at all.
Examples of abugidas include the various scripts of the Brahmic family, Ethiopic Ge'ez, and Canadian Aboriginal Syllabics.
A typical abugida is Devanagari, in which Hindi is written. There is no basic sign representing the consonant k; rather the unmodified letter क represents the syllable ka; the a is not marked on the symbol, and thus is the so-called inherent vowel. The vowel may be changed by adding vowel marks (diacritics) to the basic character, producing other syllables beginning with k-, such as कि ki, कु ku, के ke, को ko. These diacritics are applied to other consonant characters for other syllables. For example, from ल la is formed लि li, लु lu, ले le, लो lo. Such a consonant with either an inherent or marked vowel is called an akshara.
Though now an abugida, the Ge'ez alphabet was actually an abjad until the 4th century AD. In the Ge'ez abugida, the form of the letter itself may be altered. For example, ሀ hä (basic form), ሁ hu (with a right-side diacritic that does not alter the letter), ሂ hi (with a subdiacritic that compresses the letter, so that the whole fidel occupies the same amount of space), ህ hə (where the letter is modified with a kink in the left arm).
The Pahawh Hmong script represents both consonants and vowels with full letters. However, the graphic order is vowel-consonant even though they are pronounced as consonant-vowel. This is rather like the /o/ vowel in the Indic abugidas. Pahawh Hmong is unusual in that, while the inherent vowel /au/ is unwritten, so is the inherent consonant /k/. For the syllable /kau/, which requires one or the other of the inherent sounds to be overt, it is /au/ that is written. That is, a Pahawh akshara appears to be a vowel with an inherent consonant rather than the other way around.
It is difficult to draw a dividing line between abugidas and other segmental scripts. For example, the Meroitic script of ancient Sudan did not indicate an inherent a (one symbol stood for both m and ma, for example), and is thus similar to Brahmic family abugidas. However, the other vowels were indicated with full letters, not diacritics or modification, so the system was essentially an alphabet that did not bother to write the most common vowel.
Thaana is also like an abugida in that vowels are marked with diacritics. However, all vowels are marked, as is the absence of a vowel; there is no inherent vowel. Normally no letter may occur without a diacritic. That is, it is equivalent to an abjad with obligatory vowel marking, like the Arabic alphabet as used for Kurdish in Iraq, as is thus essentially alphabetic. Note that it developed among a population that was already literate with an abugida for their language.
Several systems of shorthand use diacritics for vowels, but they do not have an inherent vowel, and are thus more similar to Thaana and Kurdish than to the Brahmic scripts. The Gabelsberger shorthand system and its derivatives modify the following consonant to represent vowels. The Pollard script, which was based on shorthand, also uses diacritics for vowels; the placements of the vowel relative to the consonant indicates tone.
As the term alphasyllabary suggests, abugidas have been considered an intermediate step between alphabets and syllabaries. Historically, abugidas appear to have evolved from abjads (vowelless alphabets). They contrast with syllabaries, where there is a distinct symbol for each syllable or consonant-vowel combination, and where these have no systematic similarity to each other, and typically develop directly from logographic scripts. Compare the Devanagari examples above to sets of syllables in the Japanese hiragana syllabary: か ka, き ki, く ku, け ke, こ ko have nothing in common to indicate k; while ら ra, り ri, る ru, れ re, ろ ro have neither anything in common for r, nor anything to indicate that they have the same vowels as the k set.
Most Indian and Indochinese abugidas appear to have first evolved from abjads with the Kharoṣṭhī and Brāhmī scripts; the abjad in question is usually considered to be the Aramaic one, but while the link between Aramaic and Kharosthi is more or less undisputed, this is not the case with Brahmi. The Kharosthi family does not survive today, but Brahmi's descendants include most of the modern scripts of South and Southeast Asia. Although Ge'ez derived from a different abjad, one theory is that its evolution into an abugida may have been influenced by Christian missionaries from India.


ABBA was a Swedish Edison award and Eurovision winning pop/dance group active between 1972 and 1982. The quartet was formed through the friendship of Benny Andersson and Björn Ulvaeus and also consists of Anni-Frid Lyngstad and Agnetha Fältskog. The band members were at one time married respectively, and together they have topped the charts worldwide from the mid-1970s to the early 1980s. The name "ABBA" is an acronym formed from the first letters of each of the group member's given name.
ABBA enjoyed immense international popularity employing catchy song hooks, simple lyrics, and a Wall of Sound achieved by overdubbing the female singers' voices in multiple harmonies. As their popularity grew, they were sought after to tour Europe, Australia, and North America, where they met criticism for their uneven live performances, although they continued to release studio albums to great commercial success. At the height of their popularity, however, both marriages of the band members failed, and the relationship changes were reflected in their music, as they produced more thoughtful lyrics with different compositions.
They remain a fixture of radio playlists and are one of the world's best selling bands, having sold more than 350 million records world wide. ABBA was also the first pop group from mainland Europe to enjoy consistent success in the charts of the English-speaking countries, mainly the United Kingdom, the United States, Canada, Ireland, South Africa, Australia, and New Zealand. Their enormous popularity subsequently opened the doors for other Continental European acts. The music of ABBA has been re-arranged into the successful musical Mamma Mia! that has toured worldwide and is in production for a movie version to be released in 2008.
Benny Andersson was a member of a popular Swedish pop-rock group that performed covers of international hits named The Hep Stars from the age of 18. He played keyboards and eventually started writing original compositions for his band, many of which became major hits including "No Response" that hit #3 in 1965, "Sunny Girl", "Wedding", "Consolation", all of which hit #1 in 1966. Andersson also had a fruitful songwriting collaboration with Lasse Berghagen, with whom he composed his first Svensktoppen entry "Sagan Om Lilla Sofi" in 1968.
Björn Ulvaeus also began his musical career at 18, when he fronted The Hootenanny Singers, a popular Swedish folk-skiffle group. Ulvaeus started writing English language songs for his group, and even had a brief solo career alongside.
The Hootenanny Singers and The Hep Stars sometimes crossed paths while touring, and on one occasion in June 1966 Ulvaeus and Andersson decided to write a song together. Their first attempt was "Isn't It Easy to Say", a song later recorded by The Hep Stars. Stig Anderson was the manager of The Hootenanny Singers and founder of the Polar Music label. He saw potential in the collaboration, and encouraged them to compose more. Both also began playing occasionally with the other's bands on stage and on record, although not until 1969 did the pair write and produce some of their first real hits together: "Ljuva Sextiotal" ('Merry Sixties'), recorded by Brita Borg and The Hep Stars' 1969 hit "Speleman".
Andersson wrote and submitted the song "Hej, Clown" for the 1969 Melodifestivalen, the Swedish Eurovision Song Contest finals. The song tied for first, but re-voting relegated Andersson's song to second place. On this occasion, Andersson briefly met his future spouse; singer Anni-Frid Lyngstad, who also participated in the contest. A month later, the two had become a couple. As the two bands began to break up, Andersson and Ulvaeus teamed up and eventually recorded their first album together in 1970, called Lycka ("Happiness" in Swedish), that included original compositions sung by both men. Ulvaeus still occasionally recorded and performed with The Hootenanny Singers until the summer of 1974, and Andersson took part in producing their records.
Agnetha Fältskog had a #1 record in Sweden when she was only 17, and was soon noted by the critics and songwriters as a talented singer/songwriter of schlager style songs. Fältskog's main inspiration in her early years were singers like Connie Francis. Along with her own compositions, she recorded covers of foreign hits and performed them on tours in Swedish folkparks. She submitted an original song for Melodifestivalen at 17 years old, titled "Försonade", but it was rejected. She briefly met Anni-Frid Lyngstad for the first time during a TV show in January 1968, and Björn Ulvaeus at a concert venue a few months later.
During filming of a Swedish TV special in May 1969, Fältskog met Ulvaeus again, and they eventually became romantically involved and they married in 1971. Fältskog and Ulvaeus eventually got involved in each others recording sessions. and soon even Andersson and Lyngstad added backing vocals to her 1970 album "Som Jag Är" (As I Am). In 1973, Fältskog starred as Mary Magdalene in the original Swedish production of Jesus Christ Superstar and attracted favourable reviews. Between 1967 and 1975, Fältskog released five studio albums.
Anni-Frid "Frida" Lyngstad sang from the age of thirteen with various dance bands and worked mainly in a jazz-oriented cabaret style. She also formed her own band named Anni-Frid Four. In the summer of 1967, she won a national talent competition with the song "En Ledig Dag", included in the EMI Compilation Frida 1967-1972. The first prize was to perform live on the most popular TV show in Sweden, and included was a recording contract with EMI. This first TV performance is included in "Frida the DVD. Lyngstad released several singles on EMI and had many hits in the Swedish charts. When Benny Andersson started to produce her recordings in 1971, she got her first #1 single, "Min Egen Stad" (My Own Town), when all four future ABBA members sang the backup vocals. Lyngstad toured and performed regularly in the folkpark circuit and made appearances on radio and TV. She met Björn Ulvaeus briefly in 1963 during a talent contest, and Agnetha Fältskog during a TV show in early 1968.
Lyngstad finally linked up with her future bandmates in 1969. On March 1, 1969, she participated in the Melodifestivalen, where she met Andersson for the first time. A few weeks later they met again during a concert tour in southern Sweden and they soon became a couple. Andersson produced her single "Peter Pan" in September 1969; the first collaboration between her and Benny & Björn -as they had written the song. Later Andersson produced Lyngstad's debut album, Frida, which was released in March 1971 and praised by critics. Lyngstad also played in several revues and cabaret shows in Stockholm between 1969 and 1973. After ABBA formed, she recorded another successful album in 1975, Frida Ensam, which included the original Swedish rendition of "Fernando", which became a huge hit in Scandinavia before the English version was recorded.
An attempt at combining their talents occurred in April 1970 when the two couples went on holiday together to the island of Cyprus. What started as singing for fun on the beach ended up as an improvised live performance in front of the United Nations soldiers stationed on the island. Andersson and Ulvaeus were at this time recording their first album together, "Lycka", which was to be released in September 1970. Fältskog and Lyngstad added backing vocals on several tracks during June, and the idea of them all working together saw them launch their own stage act, "Festfolk", which translated from Swedish to mean both "Party People" and "Engaged Couples", on November 1, 1970 in Gothenburg. The cabaret show attracted positive reviews. The foursome performed the Andersson and Ulvaeus hit "Hej, Gamle Man"; the first recording credited to all four- and solo numbers from respective albums, but the foursome did not feel like working together, and soon concentrated on individual projects again.
"Hej, Gamle Man" became the foursome's first hit, reaching no 5 on the sales charts, and no 1 on Svensktoppen, staying there for 15 weeks.
In the first half of 1971, the four artists worked more together, adding vocals to the others recordings. Fältskog, Andersson and Ulvaeus went on a tour together in May, while Lyngstad toured on her own. Frequent recording sessions brought the foursome tighter together during the summer.
After the 1970 release of Andersson and Ulvaeus' album "Lycka", two more singles were released in Sweden, "Det Kan Ingen Doktor Hjälpa" and "Tänk Om Jorden Vore Ung", with more prominent vocals by Fältskog and Lyngstad and moderate chart success. Fältskog released her fourth album in 1971 and married Ulvaeus on July 6. Andersson, Ulvaeus, and Fältskog started performing together on a regular basis during the summer of 1971.
Stig Anderson, founder and owner of Polar, was determined to break into the mainstream international market with music by Andersson and Ulvaeus. "One day the pair of you will write a song that becomes a worldwide hit", he predicted. Stig encouraged Ulvaeus and Andersson to write a song for Melodifestivalen, and after two rejected entries in 1971, Andersson and Ulvaeus submitted their new song "Säg Det Med En Sång" ("Say It With A Song") for the 1972 contest, and they chose newcomer Lena Anderson to perform. The song won third place, encouraging Stig and became a huge hit in Sweden. The first signs of foreign success came as a surprise, as the Andersson and Ulvaeus single "She's My Kind of Girl" was released by chance by Epic in Japan in March 1972, giving the duo a Top 10 hit. Two more singles were released in Japan, "Merry-Go-Round" and "Love Has Its Ways".
Ulvaeus and Andersson persevered with their songwriting and experimented with new sounds and vocal arrangements. "People Need Love" was released in June 1972, featuring guest vocals by the women, who were now given much greater prominence. Stig Anderson released it as a single, credited to Björn & Benny, Agnetha & Anni-Frid. The song reached #17 in the Swedish combined single and album charts, enough to convince them they were on to something. The single also became the first record to chart for the quartet in the United States, where it peaked at #114 on the Cashbox singles chart and #117 on Record World's singles chart. Billed as Björn & Benny (with Svenska Flicka), it was released there on Playboy Records. However, according to Stig Anderson, "People Need Love" could have been a much bigger American hit, but a small label like Playboy Records did not have the distribution resources to meet the demand for the single from retailers and radio programmers. The foursome decided to record their first album together and sessions began on September 26, 1972. The two women then shared lead vocal on "Nina, Pretty Ballerina", and their voices combined in harmonies for the first time gave them an idea of the qualities of their combined talents.
For 1973, the band and their manager Stig Anderson decided to have another try at the Melodifestivalen, this time with the song "Ring Ring." The studio sessions were handled by Michael B. Tretow, who experimented with a "wall of sound" production technique that became the wholly new ABBA sound. Anderson arranged an English translation of the lyrics by Neil Sedaka and Phil Cody and they thought this would be a surefire winner, but in the Melodifestivalen, on February 10, 1973, it placed third, and thus never reached the international contest. Nevertheless the proto-group put out their first album, called Ring Ring. The album did well and the "Ring Ring" single was a hit in many parts of Europe, but Stig Anderson felt the true breakthrough could only come with a UK or US hit.
In the spring of 1973, Stig Anderson, tired of unwieldy names, started to refer to the group privately and publicly as ABBA. At first this was as a pun, since Abba was also the name of a well-known fish-canning company in Sweden. However, since the fish canners were unknown outside Sweden, Anderson came to believe the name would work in international markets. A competition to find a suitable name for the group was held in a Gothenburg newspaper. The group were impressed with the names "Alibaba" and "Baba", but in the end all the entries were ignored and it was announced in the summer that the name "ABBA" was official. Later the group negotiated with the canners for the right to the name. "ABBA" is an acronym formed from the first letters of each group member's name: Agnetha, Björn, Benny and Anni-Frid (Frida). The first 'B' in the logo version of the name was reversed on the band's promotional material from 1976 onwards and became the group's registered trademark. The first time the name is found written on paper is on a recording session sheet from the Metronome Studio in Stockholm, dated October 16, 1973. It was first written as "Björn, Benny, Agnetha & Frida", but was subsequently crossed out with "ABBA" written in large letters on top.
Ulvaeus, Andersson, and manager Stig Anderson believed in the possibilities of using the Melodifestivalen and Eurovision TV contests as a way to make the music business aware of the band and Andersson, Ulvaeus and Stig as composers. In late 1973, they were invited by Swedish television to contribute a song for the 1974 contest, and from a number of newly written compositions, the foursome chose the upbeat "Waterloo"; the group was now inspired by the growing glam rock scene in England. "Waterloo" was an unashamedly glam-style pop track produced with Michael B. Tretow's wall-of-sound approach.
ABBA won their national heats on Swedish TV on February 9, 1974, and with this third attempt were far more experienced and better prepared for the international contest. With an album's worth of material released when the show was held at the Brighton Dome in England on April 6, 1974, the song won and catapulted them into British consciousness for the first time—and to the top of the charts all over Europe. Winning the Eurovision Song Contest gave ABBA the chance to tour Europe and perform on major TV shows; thus the band saw the "Waterloo" single climb the charts in many European countries. "Waterloo" was ABBA's first UK #1 single. In the US, it reached #6 on the Billboard Hot 100 chart, paving the way for their first album there that was their second album, Waterloo —although it only peaked at #145 on the Billboard 200 album chart.
ABBA's follow-up single, "Honey, Honey", reached #27 in the US, and was a Top 3 hit in Germany. However, in the UK, a cover version of the song by the act Sweet Dreams made #10 because ABBA's British record company, Epic, decided to re-release a remixed version of "Ring Ring" instead. It failed to reach the Top 30, increasing growing speculation that the group were simply Eurovision one-hit wonders.
In November 1974, ABBA embarked on their first European tour, playing dates in Denmark, West Germany, and Austria. It wasn't as successful as the band had hoped, since most of the venues didn't sell out, and due to a lack of demand, they were even forced to cancel a few shows, including a sole scheduled concert in Switzerland. The second leg of the tour which took them through Scandinavia in January 1975 was entirely different. They played to full houses and finally got the reception they hoped for. For three weeks in the summer of 1975, ABBA compensated for the planned 1974 Swedish tour they were forced to cancel after their Eurovision triumph. They played sixteen open-air dates in Sweden and Finland, attracting huge crowds. Their Stockholm show at the Gröna Lund amusement park was seen by an estimated audience of 19,200.
The release of their third album, ABBA, known to fans as "The Limo Album", and their single "SOS" brought back their presence in the UK, where the single hit #6 and the album reached #13. Huge success was further solidified with "Mamma Mia" reaching the #1 spot in the UK at the end of January 1976. In the US, "SOS" reached #10 on the Record World Top 100 singles chart and #15 on the Billboard Hot 100 chart, picking up the BMI Award along the way as one of the most played songs on American radio in 1975.
Yet the success of the group in the United States remained uneven. While they managed to break into the US singles market where, by early 1976, they already had four Top 30 singles, the album market proved to be tough to crack. The eponymous ABBA album generated no fewer than three real American hits, but it only peaked at #165 on the Cashbox album chart and #174 on the Billboard 200 chart. Opinions were voiced, by Creem in particular, that in the US ABBA had endured "a very sloppy promotional campaign".
In Australia, the airing of the videos for "I Do, I Do, I Do, I Do, I Do" and "Mamma Mia" on nationwide TV in August 1975 started an immense interest for ABBA, resulting in #1 positions on both the single and album charts for months. The 1976 compilation album 'The Best of ABBA' is still the biggest selling album ever in Australia, selling 1.1 million copies and spending 16 weeks at #1. On Saturday, March 20, 1976, at 6.30 pm, Australian TV's Channel 9 broadcast "The Best of ABBA", filmed during the group's visit the week before. The transmission had more than half of the population watching: 54 percent of viewers according to contemporary reports, a record previously held the moon landing in 1969. The record remains unbeaten as of 2007.
Ulvaeus and Andersson in Swedish for Lyngstad's 1975 solo album Frida ensam (Frida alone). After Lyngstad's major success with the song in Scandinavia, the group decided to record an English version. With "Fernando" hitting #1 in twelve countries worldwide, it occupied the top position in Australia for 15 weeks, equalling with The Beatles for longest number one for Hey Jude, making it one of the best-selling singles of all time in that country. That same year, the group received its first international prize, with "Fernando" being chosen as the "Best Studio Recording of 1975". In the US, "Fernando" reached the Top 10 of the Cashbox Top 100 singles chart and #13 on the Billboard Hot 100. It also topped the Billboard Adult Contemporary chart, ABBA's first American number one single of any kind.
The group's next album, Arrival, represented a new level of accomplishment in both songwriting and studio work, prompting rave reviews from more rock-orientated UK music weeklies such as Melody Maker and New Musical Express, and mostly appreciative notices from American critics. In fact, hit after hit flowed from Arrival: "Money, Money, Money", "Knowing Me, Knowing You", and "Dancing Queen". In 1977, Arrival was nominated for the inaugural BRIT Award in the category "Best International Album of the Year". By this time ABBA were very popular in the UK, most of Western Europe and Australia.
Their popularity in the US would remain on a comparatively smaller scale, and "Dancing Queen" became the only Billboard Hot 100 #1 single ABBA ever had there (they did, however, get three more singles to the #1 position on other Billboard charts, including Billboard Adult Contemporary and Hot Dance Club Play). Nevertheless, Arrival finally became a true breakthrough release for ABBA on the US album market where it peaked at #20 on the Billboard album chart, while reaching platinum sales there as well.
In January 1977, ABBA hit the road. The group's status had changed dramatically and they were clearly regarded as superstars. They opened their much anticipated tour in Oslo, Norway, on January 28, and mounted a lavishly produced spectacle that included a few scenes from their self-penned mini-operetta. The concert attracted immense media attention from across Europe and Australia. They continued the tour through Western Europe visiting Gothenburg, Copenhagen, Berlin, Cologne, Amsterdam, Antwerp, Essen, Hanover, Hamburg, and ended it with shows in the UK in Manchester, Birmingham, Glasgow and two sold-out concerts at London's Royal Albert Hall. Tickets for these two shows were available only by mail application and it was later revealed that the box-office received 3.5 million requests for tickets, enough to fill the venue 580 times. There were, however, complaints about the group's performance lacking the same intriguing qualities on stage as what was presented in the studio, as an article in The Times accused the show of being boring. One of the Royal Albert Hall concerts was filmed and recorded for the intention of a television special.
After the European leg of the tour, in March 1977, ABBA played eleven dates in Australia before a total of 145,000 people. The opening concert in Sydney at the Sydney Showground on March 3 before over 20,000 was marred by torrential rain and Fältskog slipped on the wet stage during the concert. However, all four members would later recall this concert to be the most memorable of their career. Upon their arrival in Melbourne, a civic reception was held at the Town Hall and ABBA appeared on the balcony to greet an enthusiastic crowd of 6,000 people. In Melbourne, ABBA played three concerts at the Sidney Myer Music Bowl with 14,500 at each including the Australian Prime Minister. At the first Melbourne concert, an additional 16,000 people gathered outside the fenced-off area to listen to the concert. In Adelaide, the group performed one concert at West Lakes Football Stadium before a record-breaking 21,000 people with another 10,000 listening outside. During the first of five concerts in Perth, there was a bomb scare with everyone having to evacuate the concert hall. The trip was accompanied by mass hysteria and unprecedented media attention, and is vividly captured on film in ABBA: The Movie, directed by Lasse Hallström.
In December 1977, ABBA followed up Arrival with the more musically and lyrically ambitious fifth album The Album, which was released to coincide with ABBA: The Movie. Although the album was less well-received by the critics in the UK, it did spawn more worldwide hits: "The Name of the Game" and "Take a Chance on Me", both of which topped the UK charts, and reached #12 and #3, respectively, on the Billboard Hot 100 chart in the US. Although "Take a Chance on Me" did not top the American charts, it has actually proved to be ABBA's biggest hit single in the United States, selling more copies than "Dancing Queen". The Album also included the ABBA signature tune, "Thank You for the Music", released as a single in the UK in 1983, and had been the B-side of "Eagle" in countries where the latter had been released.
By 1978, ABBA was a megagroup. They converted a vacant theatre into the Polar Music Studio, a state-of-the-art studio in Stockholm. The studio was used by several other bands; notably, Genesis' Duke and Led Zeppelin's In Through the Out Door were recorded there. During May, the group went to the US for a huge promotional campaign, and performed on Olivia Newton-John's TV show. However, a lot of effort was put into the new recording studio in Stockholm. The recording sessions for "Summer Night City" were an uphill struggle, but upon release the song became another significant hit for the group. The track would also set the stage for ABBA's foray into disco with their upcoming album.
On January 9, 1979, the group performed Chiquitita at the Music for UNICEF Concert held at the United Nations General Assembly to celebrate UNICEF's Year of the Child. ABBA donated the copyright of this worldwide hit to the UNICEF; see Music for UNICEF Concert. The single was released the following week, and reached #1 in ten countries.
In mid-January 1979, Ulvaeus and Fältskog announced they were getting divorced. The news caused a massive interest from the media, and led to speculation about the band's future. ABBA assured the press and their fanbase they were continuing their work as a group, and that the divorce would not affect them. Nonetheless, the media continued to confront them with this in interviews.
The group's sixth album, Voulez-Vous, was released in April 1979, with two background tracks recorded in the famous Criteria Studios in Miami, U.S. with the assistance, among others, of the recording engineer Tom Dowd. The album topped the charts across Europe and in Japan and Mexico, hit the Top 10 in Canada and Australia and the Top 20 in the US. None of the singles from the album reached #1 on the UK charts, but "Chiquitita", "Does Your Mother Know", "Angeleyes", the Double A-side in UK for the single "Voulez-Vous", and "I Have a Dream" all charted no lower than #4. In Canada, "I Have a Dream" became ABBA's second #1 on the RPM Adult Contemporary chart, after "Fernando" hit the top previously. Later that year, the group released their second compilation album, Greatest Hits Vol. 2, which featured a brand new track: "Gimme! Gimme! Gimme! (A Man After Midnight)". In Russia during the late 1970s, they were paid in oil commodities because of an embargo on the ruble.
On September 13, 1979, ABBA began their first (and only) North American Tour at the Northlands Coliseum, in Edmonton, Canada, with a full house of 14,000. During the next four weeks, they played a total of seventeen sold-out dates, thirteen in the U.S. and four in Canada. The last scheduled ABBA concert on U.S. soil, in Washington, DC, was canceled due to Agnetha Fältskog's emotional distress suffered during the flight from New York to Boston, when the private plane she was on was subjected to extreme weather conditions and was unable to land for an extended period. The tour ended with a show in Toronto, Canada at Maple Leaf Gardens before a capacity crowd of 18,000. The shows also generated the same type of complaints that were expressed during the group's 1977 tour: many fans regarded ABBA as more of a studio group than a live band. On October 19, 1979, the tour resumed in Western Europe where the band played 23 sold-out gigs, including an unprecedented six sold-out nights at London's Wembley Arena.
In March 1980, ABBA traveled to Japan where upon their arrival at Narita International Airport, they were besieged by thousands of fans. The group played eleven concerts to full houses, including six shows at Tokyo's Budokan. This tour was the last "on the road" adventure of their career. The same year saw the release of ABBA's seventh album Super Trouper, which reflected a certain change in ABBA's style with more prominent use of synthesisers and increasingly more personal lyrics. It set a record for the most pre-orders ever received for a UK album after one million copies were ordered before release. Anticipation for the album had been built up by "The Winner Takes It All", the group's eighth UK chart topper (and their first since 1978). In the US, the single reached #8 on the Billboard Hot 100 chart and became ABBA's second Billboard Adult Contemporary #1. The song was allegedly written about Ulvaeus and Fältskog's marital tribulations. The next single from the album, "Super Trouper", also hit #1 in the UK, the group's ninth and final UK chart-topper. Another track from Super Trouper, "Lay All Your Love on Me", released in 1981 as a 12-inch single only in selected territories, managed to top the Billboard Hot Dance Club Play chart and peaked at #7 on the UK singles chart becoming at the time the highest ever charting 12-inch release in UK chart history.
Also in 1980, ABBA recorded a compilation of Spanish-language versions of their hits called Gracias Por La Música. It was released in Spanish-speaking countries as well as Japan and Australia. The album became a major success, and along with the Spanish version of "Chiquitita", this signaled the group's breakthrough in Latin America.
In January 1981, Ulvaeus married Lena Källersjö, and manager Stig Anderson celebrated his 50th birthday with a huge party. For this occasion, ABBA recorded the track 'Hovas Vittne' as a tribute to him, and released it only on 200 red vinyl copies, to be distributed to the guests attending the party. This single has become a most sought-after collectible. In mid-February, Andersson and Lyngstad announced they were filing for divorce. Information surfaced that their marriage had been an uphill struggle for years, and Benny had already met another woman, Mona Nörklit, whom he married in November the same year.
Andersson and Ulvaeus had songwriting sessions during the first months of 1981, and recording sessions began in mid-March. At the end of April, the group recorded a TV special with the US talk show host Dick Cavett. The Visitors, ABBA's eighth and final studio album, showed a songwriting maturity and depth of feeling distinctly lacking from their earlier recordings but still placing the band squarely in the pop genre, with catchy tunes and harmonies. Although not revealed at the time of its release, the album's title track, according to Ulvaeus, refers to the secret meetings held against the approval of totalitarian governments in Soviet-dominated states, while other tracks address topics like failed relationships, the threat of war, aging, loss of innocence, and a parent watching a child grow up. This change of content was reflected in the relative commercial decline, mostly evident in the UK, after the release of the #3 single "One of Us" in December 1981.
Although it topped the charts across most of Europe, entered the Top 20 in France and Japan and the Top 30 in the US and Australia, The Visitors was not as commercially successful as its predecessors. A track from the The Visitors, "When All Is Said and Done", was released as a single in North America, Australia and New Zealand, and fittingly became ABBA's final Top 40 hit in the US, while reaching #4 on the RPM Adult Contemporary chart in Canada. The song's lyrics, as with "The Winner Takes It All" and "One of Us", dealt with the painful experience of splitting up from a long-term partner, though it looked at it more optimistically. With the now publicized story of Andersson and Lyngstad's divorce, speculation increased of tension within the band. Also released in the US was the title track of The Visitors, which hit the Top Ten on the Billboard Hot Dance Club Play chart.
In the spring of 1982, songwriting sessions had started and the group came together for more recordings. Plans were not completely clear, but a new album was discussed and the prospect of a small tour suggested. The recording sessions in May and June were a struggle, and only three songs were eventually recorded: "You Owe Me One", "I Am The City", and "Just Like That". Andersson and Ulvaeus were not satisfied with the outcome, so the tapes were shelved and the group took a break for the summer.
Back in the studio again in early August, the group had changed plans for the rest of the year: they settled for a Christmas release of a double album compilation of all their past single releases to be named The Singles: The First Ten Years.
New songwriting and recording sessions took place, and during October and November, they released the singles The Day Before You Came/Cassandra and Under Attack/You Owe Me One, the A-sides of which were included on the compilation album. There was little interest in the singles in the UK, though both singles became Top 5 hits in The Netherlands and Belgium. The album went to #1 in the UK and Belgium, Top 5 in the Netherlands and West Germany and Top 20 in many other countries.
"I Am the City" and "Just Like That", were left unreleased on The Singles: The First Ten Years for possible inclusion on the next projected studio album from ABBA, though this never came to fruition. "I Am the City" was eventually released as a bonus track on the compilation album More ABBA Gold in 1993, while "Just Like That" has been recycled in new songs with other artists produced by Andersson and Ulvaeus. A reworked version of the verses ended up in the musical Chess. The chorus section of "Just Like That" was eventually released on a retrospective boxset in 1994. Despite numerous requests from fans, Ulvaeus and Andersson are still refusing to release ABBA's version of "Just Like That" in its entirety, even though the complete version surfaced on bootlegs.
The group traveled to London to promote The Singles: The First Ten Years in the first week of November 1982, appearing on Saturday Superstore and The Late, Late Breakfast Show, and also to West Germany in the second week, to perform on Show Express. On November 19, 1982, ABBA appeared for the last time in Sweden on the TV programme Nöjesmaskinen, and on December 11, 1982, they made their last performance ever, transmitted to the UK on Noel Edmonds' The Late, Late Breakfast Show, via a live link from a TV studio in Stockholm.
In interviews, ABBA talked about a future Massive Tour, performing in front of famous sites like the pyramids, but behind the scenes a growing disagreement with manager Stig Anderson led to the four members selling their shares in the record company and leaving future plans for ABBA on hold. Although plans suggested future recording work as a foursome, they have not professionally reunited.
Andersson and Ulvaeus began collaborating with Tim Rice in early 1983 on writing songs for the musical project Chess, while Fältskog and Lyngstad both concentrated on international solo careers. While Andersson & Ulvaeus were working on the musical, a further cooperation between three of them came with the musical Abbacadabra that was produced in France for television. It was a children's musical utilising 14 ABBA songs. Alain and Daniel Boublil, who wrote Les Miserables, had been in touch with Stig Anderson about the project, and the TV musical was aired over Christmas 1983 on the British channel ITV.
Lyngstad, who had recently moved to Paris, participated in the French version, and recorded a single, "Belle", a duet with French singer Daniel Balavoine. The song was a cover of ABBA's instrumental 1976 track "Arrival". As the single "Belle" sold well in France, Cameron Mackintosh wanted to stage an English language version of the show in London, with the French lyrics translated by David Wood and Don Black; Andersson and Ulvaeus, got involved in the project, and contributed with one new song, "The Seeker". "Abbacadabra" premièred December 8, 1983 at The Lyric Hammersmith Theatre in London, to mixed reviews and full houses for eight weeks, closing on January 21, 1984. Lyngstad was involved in this production as well, recording 'Belle' in English as "Time"; a duet with actor and singer B. A. Robertson: the single sold well, this time produced and recorded by Andersson and Ulvaeus.
All four members made their last public appearance, as four friends more than as ABBA, in January 1986, when they recorded a video of themselves performing an acoustic version of "Tivedshambo", which was the first song written by their manager, Stig Anderson, for a Swedish TV show honouring Anderson on his 55th birthday. The four had not seen each other for more than two years. That same year they also performed privately at another friend's 40th birthday: their old tour manager, Claes af Geijerstam. They sang a self-composed song titled "Der Kleine Franz" that later was to surface in Chess. The same year ABBA Live was released, featuring selections of live performances from the group's 1977 and 1979 tours. Their last appearance as a group was filmed privately by Anders Glenmark. They were guests on the 50th birthday of Görel Hanser in 1999. Hanser was a long-time friend of all four, and also former secretary of Stig Anderson. Honouring Görel, ABBA performed a Swedish birthday song "Med En Enkel Tulipan" a cappella.
Benny Andersson has on several occasions performed old ABBA songs. In June 1992, he and Björn Ulvaeus appeared with U2 at a Stockholm concert, singing the chorus of "Dancing Queen", and a few years later during the final performance of the B & B in Concert in Stockholm, Andersson joined the cast for an encore at the piano. Andersson frequently adds an ABBA song to the playlist when he performs with his BAO! band. He also played the piano during new recordings of the ABBA songs "Like an Angel Passing Through My Room" with opera singer Anne Sofie von Otter, and "When All Is Said And Done" with Swede Victoria Tolstoy. Andersson and Ulvaeus both did an a capella rendition of the first verse of "Fernando" as they accepted their Ivor Novello award in London in 2002. Frida Lyngstad performed and recorded an a cappella version of "Dancing Queen" with the Swedish group The Real Group in 1993, and has also re-recorded "I Have a Dream" with Swiss singer Dan Daniell in 2003.
ABBA has never officially announced the end of the group, but as the years pass by the chances of ABBA working together again have become increasingly slim, and the group is now considered dissolved.
In October 1984, Ulvaeus and Andersson released the musical concept double album Chess, The singles "One Night in Bangkok" and "I Know Him So Well" (later also recorded by Whitney Houston) were both huge successes. In May 1986, the musical premièred in the West End of London, and ran for almost three years. On Broadway it opened in April 1988, but closed within two months due to very bad reviews. The musical has been staged regularly on small scale to great success, and even the concert version is popular. In Stockholm, the composers staged Chess På Svenska ('Chess in Swedish') in 2003, with new material.
What is considered to be Andersson and Ulvaeus' masterpiece, however, is Kristina från Duvemåla, a Swedish epic musical, which the composers premiered in Malmö in southern Sweden in October 1995, directed for the stage by Lars Rudolfsson and based on the The Emigrants tetralogy by Swedish novelist Vilhelm Moberg. The musical ran for five years in Stockholm, and an English version has been in the works for a long time, and it had been reported that the Broadway pre-production is in its earliest stage.
Andersson has recently released his 3rd album BAO 3 with new material with his band BAO! and vocalists Helen Sjöholm and Tommy Körberg -as well as having filled two of Sweden's largest concert venues in October and November 2007 with an audience of 14,000.
Björn Ulvaeus has not appeared on stage performing music since ABBA, but had a reunion with his co-members of The Hootenanny Singers on 16 July 2005 at a music festival in his hometown of Västervik, singing their 1966 hit "Marianne".
Andersson and Ulvaeus are highly involved in the world wide productions of the musical Mamma Mia! alongside Lyngstad attending premieres. They are also involved in the production of the film version of the musical, to open in June 2008; Benny Andersson produces the Soundtrack.
Both female members of ABBA pursued solo careers on the international scene following the break-up of the band. In 1982, Lyngstad chose Genesis drummer and singer Phil Collins to produce the album "Something's Going On" and unveiled the single and video "I Know There's Something Going On" in autumn of that year. The single became a #1 hit in France, where it spent five weeks at the top, Belgium, Switzerland and Costa Rica. The track reached #3 in Austria, the Netherlands, Norway, Sweden and Poland, and was also a Top 10 hit in Germany, Italy, South Africa and Finland. In the United States, the single reached #13. In all, "I Know There's Something Going On" sold 3.5 million copies worldwide and is the biggest selling single any of the four members have had outside ABBA. Lyngstad's album sold 1.5 million copies internationally. Frida's second solo album after ABBA was the experimental Shine (produced by Steve Lillywhite), released in 1984. The album proved a big success in Sweden, reaching #6 there. It was also Frida's final studio album release for twelve years.
Agnetha Fältskog followed in 1983 with the album Wrap Your Arms Around Me. This included the hit single "The Heat Is On", which was a hit in Europe and Scandinavia. In the US, Fältskog scored a Billboard Top 30 hit with "Can't Shake Loose". In Europe, the single "Wrap Your Arms Around Me" was another successful hit, topping the charts in Belgium and Denmark, reaching the Top 5 in Sweden and the Top 20 in Germany and France. Her album sold 1.2 million copies worldwide.
Fältskog's second post-ABBA solo album was Eyes of a Woman, released in March 1985, which reached #2 in Sweden and performed reasonably well in Europe. The first single from the album was "I Won't Let You Go". In November 1987, Fältskog released her third post-ABBA solo album, the Peter Cetera-produced I Stand Alone, (which also included the Billboard hit "I Wasn't The One"). The album sold very well in Sweden, where it spent eight weeks at #1. Later that year, however, Fältskog withdrew from public life and halted her music career for a while. In 1996, she released her autobiography, As I Am, and a compilation album featuring her solo hits alongside some ABBA classics. In 2004, she made a successful comeback, releasing the critically acclaimed album My Colouring Book, which debuted at #1 in Sweden (achieving triple-platinum status), #6 in Germany, and #12 in the UK, winning a silver award, and achieving gold status in Finland. The single "If I Thought You'd Ever Change Your Mind" became Fältskog's biggest solo hit in the UK, reaching the #11 position. The single saw the #2 spot in Sweden and was a hit throughout Scandinavia and Europe. In January 2007, she sang a live duet on stage with Swedish singer Tommy Körberg at the after party for the final showing of the musical, Mamma Mia! in Stockholm, at which Benny Andersson and Björn Ulvaeus were also present.
In 1992, Frida was asked and chosen to be the chairperson for the environmental organisation "Artister för miljön" (Artists for the Environment) in Sweden. Frida accepted and became chairwoman for this organisation from 1992 to 1995. To mark her interests for the environment, she recorded the Julian Lennon song Saltwater and performed it live in Stockholm. She arranged and financed summer camps for poor children in Sweden, focussing on environmental and ecological issues. Her environmental work for this organisation led up to the decision to record again. Djupa andetag (Deep Breaths) was released towards the end of 1996 and became a huge success in Sweden, where it reached #1 and Scandinavia. The lyrics for the single from this album, "Även en blomma" (Even a Flower), deal with environmental issues. In 2004, Lyngstad recorded a song called "The Sun Will Shine Again", written especially for her and released with former Deep Purple member Jon Lord. The couple made several TV performances with this song in Germany. The following year, she released a career retrospective DVD, "Frida the DVD and also a boxset, The "Frida Box Set". Lyngstad lives a low-profile life but occasionally appears at a party or charity function. On August 26, 1992, she married Prince Heinrch Ruzzo Reuss von Plauen, of the German Reuss family. Von Plauen died of lymphoma at the age of 49. In addition to losing her husband, Lyngstad had also lost her daughter in a car crash a year earlier.
The same year ABBA went separate ways, the French production of a 'tribute' show; a children's TV musical named Abbacadabra, using 14 of ABBA's songs, spawned new interest in the groups music. The London staging of the musical had stars like Elaine Paige, and Finola Hughes singing new lyrics to the old hits.
After receiving little attention during the late 1980s, ABBA experienced a major resurgence in the new decade: starting with UK synth-pop duo Erasure's release of an EP featuring cover versions of their songs, which topped the charts in the spring of 1992. As U2 arrived in Stockholm for a concert in June of that year, the band paid homage to ABBA by inviting Björn Ulvaeus and Benny Andersson to join them on stage for a rendition of "Dancing Queen", playing guitar and keyboards. The September 1992 release of ABBA Gold: Greatest Hits, a new compilation album, ended up selling massively worldwide and setting chart longevity records. In the U.S. the album became the most popular ABBA release ever there, selling more than six million copies to date.
The enormous interest in the Gold compilation saw the release of More ABBA Gold: More ABBA Hits in 1993. This collection also contained the bonus track "I Am the City", one of the unreleased songs from the 1982 recording sessions.
In 1994, two Australian movies caught the attention of the world's media, both focussing on admiration for ABBA: The Adventures of Priscilla, Queen of the Desert and "Muriel's Wedding. The same year, Thank You for the Music", a four-disc box set comprising all the group's hits and stand-out album tracks, was released with the involvement of all four members. For this release, several demo versions and odd tracks were discovered in the Polar vaults.
Sinéad O'Connor and Boyzone's Stephen Gately have recorded "Chiquitita", Tanita Tikaram, and Blancmange paid tribute to "The Day Before You Came", Cliff Richard covered "Lay All Your Love On Me", while Dionne Warwick and Peter Cetera recorded their versions of "SOS". U.S. alternative-rock musician Marshall Crenshaw has also been known to play a version of "Knowing Me, Knowing You" in concert appearances. Swedish metal guitarist Yngwie Malmsteen covered "Gimme! Gimme! Gimme! (A Man After Midnight)" with slightly altered lyrics.
Tribute albums were released both in Sweden and the UK, and tribute bands such as Bjorn Again and Arrival found a market; the former had to put together several incarnations of themselves to cover the huge demand.
In Sweden, the growing recognition of the legacy of Andersson and Ulvaeus resulted in the 1998 B & B Concerts: a tribute concert (with Swedish singers who had worked with the composers through the years) showcasing not only their ABBA years, but even hits from the 1960s and after ABBA. The concert was a huge success, released on CD, and later toured Scandinavia and even went to Beijing in the People's Republic of China for two concerts. In 1999, Sweden saw the birth of ABBA Teens, later re-named A*Teens, recording techno-pop versions of ABBA songs to huge success worldwide: not only the English original versions, but ABBA's Spanish versions also.
In April 1999, the Mamma Mia! musical opened in London, and soon premièred in cities worldwide to huge success.
In 2000 ABBA were reported to have turned down an offer of approximately US$1,000,000,000 (one billion US dollars) to do a reunion tour consisting of 100 concerts.
For the 2004 semi-final of the Eurovision Song Contest, staged in Istanbul thirty years after ABBA had won the contest in Brighton, all four members of ABBA appeared briefly in a special comedy video made for the interval act, entitled "Our Last Video Ever". Each of the four members of the group made a brief cameo role, as did others such as Cher and Rik Mayall. The video was not included in the official DVD release of the Eurovision Contest, but was issued as a separate DVD release, retitled "The Last Video" at the request of the former ABBA members. It was billed as the first time the four had worked together since the group spilt. In fact, they each filmed their appearances separately.
With Mamma Mia!'s huge success worldwide, and the forthcoming film starring Meryl Streep and Pierce Brosnan, there is a huge interest in ABBA's music. However, in a November 2004 interview with the German magazine Bunte, Ulvaeus said a reunion would not satisfy ABBA's many fans, even though there are legions of them around the world often clamouring for one.
ABBA were widely noted for the colourful and trend-setting costumes its members wore. The videos that accompanied some of their biggest hits are often cited as being among the earliest examples of the genre. Most of ABBA's videos (and ABBA: The Movie) were directed by Lasse Hallström who would later direct the films My Life as a Dog, The Cider House Rules and Chocolat.
ABBA made videos because their songs were hits in so many different countries and personal appearances weren't always possible. This was also in an effort to minimise travelling, particularly to countries that would have required extremely long flights. Fältskog and Ulvaeus had two young children, and Fältskog, who was also afraid of flying, was very reluctant to leave her children for such a long time. ABBA's manager, Stig Anderson, realised the potential of showing a simple video clip on television to publicise a single or album, thereby allowing easier and quicker exposure than a concert tour. Some of these videos became classics because of the 1970s era costumes and early video effects, such as the grouping of the band members in different combinations of pairs, overlapping one singer's profile with the other's full face, and the contrasting of one member against another.


An Allegiance is a duty of fidelity said to be owed by a subject or a citizen to his/her state or sovereign.
Mid. English ligeaunce; med. Latin ligeantia; the al- was probably added through confusion with another legal term, allegeance, an allegation; the French allegeance comes from the English; the word is formed from "liege," of which the derivation is given under that heading; the connection with Latin ligare, to bind, is erroneous.
The term allegiance is often used by English legal commentators in a larger sense, divided by them into natural and local, the latter applying to the deference which even a foreigner must pay to the institutions of the country in which he happens to live; but it is in its proper sense, in which it indicates national character and the subjection due to that character, that the word is important.
In that sense it represents the feudal liege homage, which could be due only to one lord, while simple homage might be due to every lord under whom the person in question held land.
The English doctrine, which was at one time adopted in the United States, asserted that allegiance was indelible: "Nemo potest exuere patriam". Accordingly, as the law stood before 1870, every person who by birth or naturalization satisfied the conditions set forth, though he should be removed in infancy to another country where his family resided, owed an allegiance to the British crown which he could never resign or lose, except by act of parliament or by the recognition of the independence or the cession of the portion of British territory in which he resided.
Allegiance is the tie which binds the subject to the Sovereign in return for that protection which the Sovereign affords the subject. It was the mutual bond and obligation between monarch and subjects, whereby subjects are called his liege subjects, because they are bound to obey and serve him; and he is called their liege lord, because he should maintain and defend them (Ex parte Anderson (1861) 3 El & El 487; 121 ER 525; China Navigation Co v Attorney-General (1932) 48 TLR 375; Attorney-General v Nissan [1969] 1 All ER 629; Oppenheimer v Cattermole [1972] 3 All ER 1106). The duty of the Crown towards its subjects is to govern and protect. The reciprocal duty of the subject towards the Crown is that of allegiance.
Natural allegiance and obedience is an incident inseparable to every subject, for as soon as the Sovereign is born, they owe allegiance and obedience (Ex parte Anderson" (1861) 3 El & El 487; 121 ER 525). Natural-born subjects owe allegiance wherever they may be. Where territory is occupied in the course of hostilities by an enemy's force, even if the annexation of the occupied country is proclaimed by the enemy, there can be no change of allegiance during the progress of hostilities on the part of a citizen of the occupied country (R v Vermaak (1900) 21 NLR 204 (South Africa)).
Allegiance is owed both to the Sovereign as a natural person and to the Sovereign in the political capacity (Re Stepney Election Petition, Isaacson v Durant (1886) 17 QBD 54 (per Lord Coleridge CJ)). Attachment to the person of the reigning Sovereign is not sufficient. Loyalty requires affection also to the office of the Sovereign, attachment to royalty, attachment to the law and to the constitution of the realm, and he who would, by force or by fraud, endeavour to prostrate that law and constitution, though he may retain his affection for its head, can boast but an imperfect and spurious species of loyalty ("R v O'Connell (1844) 7 ILR 261).
(d) A legal obedience, where a particular law requires the taking of an oath of allegiance by subject or alien alike.
Natural allegiance was acquired by birth within the Sovereign's dominions (except for the issue of diplomats or of invading forces or of an alien in enemy occupied territory). The natural allegiance and obedience is an incident inseparable to every subject, for as soon as they are born they owe by birthright allegiance and obedience to the Sovereign (Ex p. Anderson (1861) 3 E & E 487). A natural-born subject owes allegiance wherever they may be, so that where territory is occupied in the course of hostilities by an enemy's force, even if the annexation of the occupied country is proclaimed by the enemy, there can be no change of allegiance during the progress of hostilities on the part of a citizen of the occupied country (R v Vermaak (1900) 21 NLR 204 (South Africa)).
Local allegiance was due by an alien while in the protection of the Crown. All friendly resident aliens incurred all the obligations of subjects (The Angelique (1801) 3 Ch Rob App 7). An alien, coming into a colony also became, temporarily a subject of the Crown, and acquired rights both within and beyond the colony, and these latter rights could not be affected by the laws of that colony (Routledge v Low (1868) LR 3 HL 100; 37 LJ Ch 454; 18 LT 874; 16 WR 1081, HL; Reid v Maxwell (1886) 2 TLR 790; Falcon v Famous Players Film Co [1926] 2 KB 474).
A resident alien owed allegiance even when the protection of the Crown was withdrawn owing to the occupation of an enemy, because the absence of the Crown's protection was temporary and involuntary (de Jager v Attorney-Geneneral of Natal [1907] AC 326).
Legal allegiance was due when an alien took an oath of allegiance required for a particular office under the Crown.
By the Naturalization Act 1870, it was made possible for British subjects to renounce their nationality and allegiance, and the ways in which that nationality is lost are defined. So British subjects voluntarily naturalized in a foreign state are deemed aliens from the time of such naturalization, unless, in the case of persons naturalized before the passing of the act, they have declared their desire to remain British subjects within two years from the passing of the act. Persons who from having been born within British territory are British subjects, but who at birth became under the law of any foreign state subjects of such state, and also persons who though born abroad are British subjects by reason of parentage, may by declarations of alienage get rid of British nationality. Emigration to an uncivilized country leaves British nationality unaffected: indeed the right claimed by all states to follow with their authority their subjects so emigrating is one of the usual and recognized means of colonial expansion.
The doctrine that no man can cast off his native allegiance without the consent of his sovereign was early abandoned in the United States, and on July 27, 1868, the day before the Fourteenth Amendment was adopted, U.S. Congress declared in the preamble of the Expatriation Act that "the right of expatriation is a natural and inherent right of all people, indispensable to the enjoyment of the rights of life, liberty and the pursuit of happiness," and (Section I) one of "the fundamental principles of this government" (United States Revised Statutes, sec. 1999). Every citizen of a foreign state in America owes a double allegiance, one to it and one to the United States. He may be guilty of treason against one or both. If the demands of these two sovereigns upon his duty of allegiance come into conflict, those of the United States have the paramount authority in American law.

An absolute majority or majority of the entire membership (in American English, a supermajority voting requirement) is a voting basis which usually requires that more than half of all the members of a group (including those absent and those present but not voting) must vote in favour of a proposition in order for it to be passed. In practical terms, it may mean that abstention from voting could be equivalent to a no vote.
Absolute majority can be contrasted with simple majority which only requires a majority of those actually voting to approve a proposition for it to be enacted.
Absolute majority voting is most often used to pass significant changes to constitutions or to by-laws in order to ensure that there is substantial support for a proposal.
In parliamentary procedure, the vote of a majority of the entire membership is frequently an alternative to a requirement of previous notice. A motion to rescind and expunge from the minutes can only be passed by a majority of the entire membership. If the deliberative assembly is a board of a larger organization, a majority of the entire membership means a majority of board members.

Afrika Islam, born Charles Glenn, and known also as the Son of Bambaataa, is a hip-hop producer. He left New York for Los Angeles and went on to co-produce most of Ice T's early albums, namely Rhyme Pays and Power (Ice T album); the latter is deemed to be Ice's finest effort by some aficionados. In the late 1990s, Afrika Islam joined German techno icon Westbam to form Mr. X and Mr. Y, a techno duo that made commercial techno with Electro influences. "Back to Berlin" quotes from the Old School rap classic "New York New York" by Grandmaster Flash.


Adventure International was a video game publishing company that existed from 1978 until 1985, started by Scott and Alexis Adams. Their games were notable for being the first implementation of the adventure genre to run on a microcomputer system. The adventure game concept originally came from Colossal Cave Adventure which ran strictly on large mainframe systems at the time.
After the success of their first game Adventureland, games followed rapidly, with Adventure International (or "AI") releasing about two games a year. Initially the games were drawn from the founders imagination, with themes ranging from fantasy to horror and sometimes science fiction. Some of the later games were written by Scott Adams and other collaborators. Adventure Internationals' games became known for quality, with a reputation only exceeded in the field at the time by Infocom.
Fourteen games later, Adventure International began to release games drawn from film and fiction. The extremely rare Buckaroo Banzai game, developed with Phillip Case, was based on the film The Adventures of Buckaroo Banzai Across the Eighth Dimension (1984). Other games came from a more well known source: Marvel Comics. Adventure International released three Questprobe games based on the Marvel characters: "The Incredible Hulk", "Spider-Man" and "Torch and the Thing".
By the end of 1982, game tastes were changing. The traditional text-based adventure game market had moved to graphical based adventures. Games like The Hobbit had increased expectations of such games, and although Adventure International games included graphics of a sort, they were significantly inferior to contemporary offerings at the time and the company was rapidly losing market share. At its peak in late 1983 to early 1984 Adventure International employed approximately 50 individuals, and published titles from over 300 independent programmer/authors.
Adventure International went bankrupt in 1985. The copyrights for its games reverted to the bank and eventually back to Scott Adams who released them as shareware.
In Europe the "Adventure International" name was a trading name of Adventure Soft and other games were released under the name that were not from Adventure International in the USA.
The games were written using an in-house adventure creator with text compression and a sophisticated command interpreter running on a BBC Micro and a graphics tool running on an Apricot F1. The two parts were then merged, using a cross-compiler when necessary.
A later Adventure International title, Saigon: The Final Days, had as its very dark scenario the escape of a soldier from Vietnam at the end of the war.
A quirk in this game's input parser provided an unintentional surprise bit of morbid gameplay. At one point in the game, the player must figure out how to cross a predator-infested river. Entering the command "confess to war crimes" here would not be rejected as gibberish as one might expect, but would actually kill the player. This turned out to not be a planned feature; the parser was finding the command "swim" embedded in the phrase ("confess to war crimes"), and swimming across the river was invariably a fatal move.
The actual solution to the game was no less macabre, involving zipping oneself into a body bag to be carried out of the country by an evacuation helicopter.



Sir Arthur Charles Clarke, CBE (born 16 December 1917) is a British science fiction author, inventor, and futurist, most famous for his novel 2001: A Space Odyssey, and for collaborating with director Stanley Kubrick on the film of the same name. Clarke is the last surviving member of what was sometimes known as the "Big Three" of science fiction, which included Robert A. Heinlein and Isaac Asimov.
Clarke was born in Minehead, Somerset, United Kingdom. As a boy, he enjoyed stargazing and reading old American science fiction pulp magazines (many of which made their way to the UK in ships with sailors who read them to pass the time). After secondary school and studying at Huish's Grammar School, Taunton, he was unable to afford a university education and got a job as an auditor in the pensions section of the Board of Education.
During the Second World War, he served in the Royal Air Force as a radar specialist and was involved in the early warning radar defence system which contributed to the RAF's success during the Battle of Britain. Clarke actually spent most of his service time working on Ground Controlled Approach (GCA) radar, as documented in his semi-autobiographical novel Glide Path. Although GCA did not see much practical use in the war, after several more years of development it was vital to the Berlin Airlift of 1948-1949. He was demobilised with the rank of Flight Lieutenant. After the war, he earned a first-class degree in mathematics and physics at King's College London.
In the postwar years, Clarke became involved with the British Interplanetary Society and served for a time as its chairman. His most important contribution may have been the idea that geostationary satellites would be ideal telecommunications relays. He was the first in the world to propose this concept, doing so in a paper privately circulated among the core technical members of the BIS in 1945. The concept later was published in Wireless World in October of that year. Clarke also has written a number of non-fiction books describing the technical details and societal implications of rocketry and space flight. The most notable of these may be The Exploration of Space (1951) and The Promise of Space (1968). In recognition of these contributions, a geostationary orbit sometimes is referred to as a "Clarke orbit".
While Clarke had a few stories published in fanzines between 1937 and 1945, his first professional sales appeared in Astounding Science Fiction in 1946: "Loophole" was published in April, while "Rescue Party", his first sale, was published in May. Along with his writing, Clarke briefly worked as Assistant Editor of Science Abstracts (1949) before devoting himself to writing full-time from 1951 onward. Clarke also contributed to the Dan Dare series published in Eagle, and his first three published novels were written for children.
Clarke corresponded with C. S. Lewis in the 1940s and 1950s, and once met in an Oxford pub, the Eastgate, to discuss science fiction and space travel. Clarke, after Lewis's death, voiced great praise for him, saying the Ransom Trilogy was one of the few works of science fiction that could be considered literature.
In 1948, he wrote "The Sentinel" for a BBC competition. Though the story was rejected, it changed the course of Clarke's career. Not only was it the basis for A Space Odyssey, but "The Sentinel" also introduced a more mystical and cosmic element to Clarke's work. Many of Clarke's later works feature a technologically advanced but prejudiced mankind being confronted by a superior alien intelligence. In the cases of The City and the Stars, "Childhood's End, and the 2001 series, this encounter produces a conceptual breakthrough that accelerates humanity into the next stage of its evolution.
In 1953, Clarke met and quickly married Marilyn Mayfield, a 22-year-old American divorcee with a young son. They separated permanently after six months, although the divorce was not finalised until 1964.
Clarke has lived in Sri Lanka since 1956, immigrating there when it was still called Ceylon, first in Unawatuna on the south coast, and then in Colombo. Clarke holds citizenship of both the UK and Sri Lanka. He long has been an avid scuba diver and a member of the Underwater Explorers Club; living in Sri Lanka has afforded him the opportunity to visit the ocean year-round. It also inspired the locale for his novel The Fountains of Paradise, in which he first described a space elevator. This, he believes, ultimately will be his legacy, more so than geostationary satellites, once space elevators make space shuttles obsolete.
His many predictions culminated in 1958 when he began a series of essays in various magazines that eventually became Profiles of the Future, published in book form in 1962. A timetable up to the year 2100 describes inventions and ideas including such things as a "global library" for 2005.
Early in his career, Clarke had a fascination with the paranormal, and has stated that it was part of the inspiration for his novel Childhood's End. He also has said that he was one of several who were fooled by a Uri Geller demonstration at Birkbeck College. Although he long has since dismissed and distanced himself from nearly all pseudoscience, he still advocates research into purported instances of psychokinesis and other similar phenomena.
In the early 1970s, Clarke signed a three-book publishing deal, a record for a science-fiction writer at the time. The first of the three was Rendezvous with Rama in 1973, which won him all the main genre awards and has spawned sequels, which, along with the 2001" series, formed the backbone of his later career.
In 1975, Clarke's short story "The Star" was not included in a new high school English textbook in Sri Lanka because of concerns that it might offend Roman Catholics even though it already had been selected. The same textbook also caused controversy because it replaced Shakespeare's work with that of Bob Dylan, John Lennon, and Isaac Asimov.
In the 1980s, Clarke became well known to many for his television programmes "Arthur C. Clarke's Mysterious World and Arthur C. Clarke's World of Strange Powers".
In 1988, he was diagnosed with post-polio syndrome and has needed to use a wheelchair most of the time since then. On 10 September, 2007, while commenting on the Cassini probe's flyby of Iapetus (which plays an important role in 2001: A Space Odyssey), Clarke mentioned that he now is completely wheelchair-bound by polio, and does not plan to leave Sri Lanka again.
Clarke was the first Chancellor of the International Space University, serving from 1989 to 2004, and also served as Chancellor of Moratuwa University in Sri Lanka from 1979 to 2002.
In December 2007, the occasion of his 90th birthday, Clarke recorded a video message to his friends and fans, bidding them "good-bye".
In early 1998, Clarke was to be made a knight, with Prince Charles visiting Sri Lanka in order to make the investiture. Just before the ceremony, a British tabloid, The Sunday Mirror, claimed in a sensationalist story that Clarke was an avowed paedophile, giving supposed quotations from Clarke about the harmlessness of his predilection for boys. Clarke released a statement saying that "the accusations are such nonsense that I have found it difficult to treat them with the contempt that they deserve." He also said, "I categorically state that The Sunday Mirror's article is grossly defamatory and contains statements which in themselves and by innuendo are quite false, grossly inaccurate and extremely harmful." He later asked that the investiture of his knighthood be delayed "in order to avoid embarrassment to His Royal Highness the Prince of Wales during his visit to Sri Lanka." In answer to the newspaper's allegations, Clarke was investigated by Sri Lankan authorities, who eventually dismissed the accusations. The Sunday Mirror later printed a retraction and Clarke was made a Knight Bachelor on May 26, 2000, in a ceremony in Colombo. A formal investigation undertaken by Sri Lankan police cleared Clarke in April 1998.
Clarke's work is marked by an optimistic view of science empowering mankind's exploration of the solar system. His early published stories would usually feature the extrapolation of a technological innovation or scientific breakthrough into the underlying decadence of his own society.
The Sentinel (1948) introduced a religious theme to Clarke's work, a theme that he later explored more deeply in The City and the Stars. His interest in the paranormal was influenced by Charles Fort and embraced the belief that humanity may be the property of an ancient alien civilisation. Surprisingly for a writer who is often held up as an example of hard science fiction's obsession with technology, three of Clarke's novels have this as a theme. Another theme of The Sentinel was the notion that the evolution of an intelligent species would eventually make them something close to gods, which was also explored in his 1953 novel "Childhood's End. He also briefly touched upon this idea in his novel Imperial Earth". This idea of transcendence through evolution seems to have been influenced by Olaf Stapledon, who wrote a number of books dealing with this theme. Clarke has said of Stapledon's 1930 book Last and First Men that "No other book had a greater influence on my life.. [It] and its successor Star Maker (1937) are the twin summits of [Stapledon's] literary career".
Clarke's first venture into film was the Stanley Kubrick-directed 2001: A Space Odyssey. Kubrick and Clarke had met in 1964 to discuss the possibility of a collaborative film project. As the idea developed, it was decided that the story for the film was to be loosely based on Clarke's short story The Sentinel, written in 1948 as an entry in a BBC short story competition. Originally, Clarke was going to write the screenplay for the film, but this proved to be more tedious than he had estimated. Instead, Kubrick and Clarke decided it would be best to write a novel first and then adapt it for the film upon its completion. However, as Clarke was finishing the book, the screenplay was also being written simultaneously.
Clarke's influence on the directing of 2001: A Space Odyssey is also felt in one of the most memorable scenes in the movie when astronaut Bowman shuts down HAL by removing modules from service one by one. As this happens, we witness HAL's consciousness degrading. By the time HAL's logic is completely gone, he begins singing the song Daisy Bell. This song was chosen due to a coincidence when in 1962 Clarke visited his friend and colleague John Pierce at the Bell Labs Murray Hill facility. A remarkable speech synthesis demonstration by physicist John Larry Kelly, Jr was taking place at the time. Kelly was using an IBM 704 computer to synthesise speech. His voice recorder synthesiser vocoder reproduced the vocal for Daisy Bell, with musical accompaniment from Max Mathews, creating one of the most famous moments in the history of Bell Labs. Arthur C. Clarke was so impressed that he later told Kubrick to use it in this climactic scene.
Due to the hectic schedule of the film's production, Kubrick and Clarke had difficulty collaborating on the book. Clarke completed a draft of the novel at the end of 1964 with the plan to publish in 1965 in advance of the film's release in 1966. After many delays the film was released in the spring of 1968, before the book was completed. The book was credited to Clarke alone. Clarke later complained that this had the effect of making the book into a novelisation, that Kubrick had manipulated circumstances to downplay his authorship. For these and other reasons, the details of the story differ slightly from the book to the movie. The film is a bold artistic piece with little explanation for the events taking place. Clarke, on the other hand, wrote thorough explanations of "cause and effect" for the events in the novel. Despite their differences, both film and novel were well received.
In 1972, Clarke published The Lost Worlds of 2001, which included his account of the production and alternate versions of key scenes. The "special edition" of the novel A Space Odyssey (released in 1999) contains an introduction by Clarke, documenting his account of the events leading to the release of the novel and film.
In 1982 Clarke continued the 2001 epic with a sequel, 2010: Odyssey Two. This novel was also made into a film, 2010, directed by Peter Hyams for release in 1984. Due to the political environment in America in the 1980s, the novel and film present a Cold War theme, with the looming tensions of nuclear war. The film was not considered to be as revolutionary or artistic as 2001, but the reviews were still positive and it has earned over 40 million dollars since its release in North America.
Clarke's email correspondence with Hyams was published in 1984. Titled The Odyssey File: The Making of 2010, and co-authored with Hyams, it illustrates his fascination with the then-pioneering medium and its use for them to communicate on an almost daily basis at the time of planning and production of the film while living on different continents. The book also includes Clarke's list of the best science-fiction films ever made.
A movie interpretation of Clarkes award-winning 1972 novel Rendezvous with Rama is currently in pre-production, awaiting a adaptation of the novel for the movie screen. Acclaimed director David Fincher is assigned to the project together with actor Morgan Freeman. According to IMDB the movie is expected to be released sometime in 2009.
Clarke's most important contribution may be the idea that geostationary satellites would be ideal telecommunications relays. He proposed this concept in a paper titled "Extra-Terrestrial Relays — Can Rocket Stations Give Worldwide Radio Coverage?", published in Wireless World in October 1945. The geostationary orbit is now sometimes known as the Clarke Orbit or the Clarke Belt in his honour.
However, it is not clear that this article was actually the inspiration for the modern telecommunications satellite. John R. Pierce, of Bell Labs, arrived at the idea independently in 1954, and he was actually involved in the Echo satellite and Telstar projects. Moreover, Pierce stated that the idea was "in the air" at the time and certain to be developed regardless of Clarke's publication. Nevertheless, Clarke described the idea so thoroughly that his article has been cited as prior art in judgements denying patents on the concept.
The geostationary orbit itself had been described earlier, for example in Hermann Oberth's 1923 book Die Rakete zu den Planetenräumen(The Rocket into Interplanetary Space) and in Herman Potočnik's (written by pseudonym Hermann Noordung) 1928 book Das Problem der Befahrung des Weltraums — der Raketen-Motor (The Problem of Space Travel — The Rocket Motor) published in Berlin.

The Apple Newton, or simply Newton, is an early line of personal digital assistants developed and marketed by Apple Computer (now Apple Inc.) from 1993 to 1998. Some electronic engineering and the manufacture of the Newton was done in Japan by Sharp. The original Newtons were based on the ARM 610 RISC processor and featured handwriting recognition software. Apple's official name for the device was "MessagePad"; the term "Newton" was Apple's name for the operating system it used (Newton OS), but popular usage of the word Newton has grown to include the device and its software together. The name is an allusion to Isaac Newton's apple.
The Newton project was not originally intended to produce a PDA. The PDA category did not exist for most of Newton's genesis, and the "personal digital assistant" term itself was coined relatively late in the development cycle by Apple's then-CEO John Sculley, the driving force behind the project. Newton was intended to be a complete reinvention of personal computing, similar to the modern tablet PC. For most of its design lifecycle Newton had a large-format screen, more internal memory, and a object-oriented graphics kernel. One of the original motivating use cases for the design was known as the "Architect Scenario," in which Newton's designers imagined a residential architect working quickly with a client to sketch, clean up, and interactively modify a simple two-dimensional home plan.
For a portion of the Newton's development cycle (roughly the middle third), the project's intended programming language was Dylan though in fact the language and environment never matured enough for any applications to be successfully written. Dylan was a small, efficient object-oriented Lisp variant that still retains some interest. Although it was efficient (for its day, and considering its substantial run-time dynamism), Dylan never lived up to its developers' performance expectations and was a tough sell for a development team unaccustomed to Lisp programming. When the move was made to a smaller form factor (designed by Jonathan Ive), Dylan was relegated to experimental status in the "Bauhaus Project" and eventually canceled outright. Its replacement, NewtonScript which had garbage collection, tight integration with the "soup" storage and user-interface toolkit, and was specifically designed to run in small RAM/large ROM environments.
The project missed its original goals to reinvent personal computing, and then to rewrite contemporary application programming. The Newton projectfell victim to project slippage, scope creep, and a growing fear that it would interfere with Macintosh sales. It was reinvented as a PDA which would be a complementary Macintosh peripheral instead of a stand-alone computer which might compete with the Macintosh.
The Newton was pre-loaded with a variety of software to aid in personal data organization and management. This included such applications as Notes, Names, and Dates, as well as a variety of productivity tools such as a calculator, conversion calculators (metric conversions, currency conversions, etc), time-zone maps, etc. In later versions of the Newton OS these applications were refined, and new ones were added, such as the Works word processor and the Newton Internet Enabler, as well as the inclusion of bundled 3rd party applications, such as the QuickFigure Works spreadsheet (a "lite" version of Pelicanware's QuickFigure Pro), Pocket Quicken, the NetHopper web browser, and the EnRoute email client. Various Newton applications had full import/export capabilities with popular desktop office suite and PIM (Personal Information Manager) application file formats, primarily by making use of Apple's bundled Newton Connection Utilities.
The Notes application allowed users to create small documents that could contain text that had been typed, or that had been recognized from handwriting, as well as free-hand sketches, "Shapes", and "ink text".
In version 2 of the Newton OS, the Notes application (as well as Names) could accept what Apple termed "stationery", 3rd-party created plug-in modules that could extend the functionality of the basic applications.
One of the new types of Notes stationery added to Newton OS 2.0 was a hierarchical, bullet-ed, collapsible, multi-line "Checklist", an implementation of outliner software. This could be used for organizing thoughts, priorities, "to do" lists, planning steps and sub-tasks, etc. Each bullet point could contain as many lines of text as desired. A bullet point could be dragged and placed underneath another bullet point, thus forming a hierarchical outline/tree. When a bullet point was dragged, the entire sub-tree of child bullet points underneath it (if any) would be dragged along as well. If a bullet point had child bullet points, tapping the hollow parent bullet point once would "roll up" or collapse all the children ("windowshade" effect). The parent bullet point would become a solid black circle and all the children would disappear. Tapping the parent bullet point again would make the children re-appear.
The Names application was used for storing contacts. Contacts created either on the Newton or on a Windows or Macintosh desktop PIM could be synchronized to each other. Entering a date in Names for fields such as birthday or anniversary automatically created corresponding repeating events in the Dates application. Each contact had an attached free-form notes field available to it, that could contain any mix of interleaved text, ink text, Shapes, or Sketches. Like Notes, Names could be extended by developers, to create special new categories of contacts with specialized pre-defined fields. Names shipped with 3 types of contacts, "people", "companies", and "groups", but a developer could define new types, for instance "client", "patient", etc.
Dates supplied calendar, events, meeting, and alarms functions, including an integrated "to do" list manager. It offered many different display and navigation styles, including a list view, graphical day "time blocking" view, or a week, month, or year grid. As with Names, Dates items created either on the Newton or on a Windows or Macintosh desktop PIM could be synchronized to each other.
With the 1xx series, an optional keyboard became available, which can also be used via the dongle on a 2x00.
The MessagePad can be used with the screen turned horizontally ("landscape") as well as vertically ("portrait"). A change of a setting instantly rotates the contents of the display by 90, 180 or 270 degrees. Handwriting recognition still works properly with the display rotated.
In initial versions (Newton OS 1.x) the Newton's handwriting recognition gave extremely mixed results for users and was often inaccurate. The original handwriting recognition engine was called Calligrapher, and was licensed from a Russian company called Paragraph International. Calligrapher's design was quite sophisticated; it attempted to learn the user's natural handwriting, using a database of known words to make guesses as to what the user was writing, and could interpret writing anywhere on the screen, whether hand-printed, in cursive, or a mix of the two. Palm Pilot's Graffiti had a less sophisticated design than Calligrapher, but was more accurate in practise due to its reliance on a simplified alphabet which clearly differentiated similar characters.
For editing text, Newton had an intuitive system for handwritten editing, such as scratching out words to be deleted, circling text to be selected, or using written carets to mark inserts.
Later releases of the Newton operating system retained the original recognizer for compatibility, but added a hand-printed-text-only (not cursive) recognizer, code-named "Rosetta," which was developed by Apple, included in version 2.0 of the Newton operating system, and refined in Newton 2.1. Rosetta is generally considered a significant improvement and many reviewers, testers, and users consider the Newton 2.1 handwriting recognition software better than any of the alternatives even 10 years after it was introduced. Recognition and computation of handwritten horizontal and vertical formulas such as "1 + 2 =" was also under development but never released.
A critical feature of the Newton handwriting recognition system is the modeless error correction. That is, correction done in situ without using a separate window or widget, using a minimum of gestures. If a word is recognized improperly, the user could double-tap the word and a list of alternatives would pop up in a menu under the stylus. Most of the time, the correct word will be in the list. If not, a button at the bottom of the list allows the user to edit individual characters in that word. Other pen gestures could do such things as transpose letters (also in situ). Error correction in many current handwriting systems provides such functionality but adds more steps to the process, greatly increasing the interruption to a user's workflow that a given correction requires.
Text could also be entered by tapping with the stylus on a small on-screen pop-up QWERTY virtual keyboard. Newton could also accept free-hand "Sketches", "Shapes", and "ink text", much like a desktop computer graphics tablet. With "Shapes", Newton could recognize that the user was attempting to draw a circle, a line, a polygon, etc, and it would clean them up into "perfect" vector representations (with modifiable control points and defined vertices) of what the user was attempting to draw. "Shapes" and "Sketches" could be scaled or deformed once drawn. "Ink text" captured the user's free-hand writing but allowed it to be treated somewhat like recognized text when manipulating for later editing purposes ("ink text" supported word wrap, could be formatted to be bold, italic, etc). At any time a user could also direct the Newton to recognize selected "ink text" and turn it into recognized text (deferred recognition). A Newton Note document (or the notes attached to each contact in Names and each calendar event) could contain any mix of interleaved text, ink text, Shapes, and Sketches.
The Newton OS consists of three layers. At the lowest level, a microkernel handles resources like tasks and memory. On top of the microkernel, the bulk of the operating system is implemented in C++, including the communications layer, handwriting recognition, and the NewtonScript environment. The top layer consists of built-in and user installed applications written in NewtonScript.
NewtonScript is an advanced object-oriented programming language, developed by Apple employee Walter Smith. Some programmers complained at the $1000 cost of the Toolbox programming environment (later in the life of the Newton, the programming environment was made available free of charge). Additionally, it required learning a new way of programming. Despite this, many third party and shareware applications are available for Newton.
Data in Newton is stored in object-oriented databases known as soups. One of the innovative aspects of Newton is that soups are available to all programs; and programs can operate cross-soup; meaning that the calendar can refer to names in the address book; a note in the notepad can be converted to an appointment, and so forth; and the soups can be programmer-extended — a new address book enhancement can be built on the data from the existing address book.
While the soup concept works well within the Newton system itself, it causes several issues. First, it makes it difficult to synchronize data with other systems, like a desktop Macintosh or PC since the data stored in soups does not correspond well with such file based systems. Apple's utility to perform this task, the Newton Connection Utility, was complex and was never completed to perform to the satisfaction of most users. The realization that a hand held computer needs to work within the existing data environment of its users was key to the success of the later Palm Pilot platform. Difficulty in working and sharing data with other systems was a key contributor to Newton's demise.
The second consequence of the data-object soup is that objects can extend built-in applications such as the address book so seamlessly that Newton users can not distinguish which program or add-on object is responsible for the various features on their own system. A user rebuilding their system after extended usage might find themselves unable to manually restore their system to the same functionality because some long-forgotten downloaded extension was missing. Data owned and used by applications and extensions themselves is tossed in the "Storage" area of the "Extras" drawer. There is no built-in distinction between types of data in that area. For example, an installed application's icon could be sitting right next to a database of addresses used by another installed extension further down the list.
Finally, the data soup concept works well for data like addresses, which benefit from being shared cross-functionally, but it works poorly for discrete data sets like files and documents. Later, the 2.0 release of the Newton OS introduced Virtual Binary Objects to alleviate the problem of handling large data objects.
See Apple Newton Software --> Backup for further details.
Earlier MessagePads use Macintosh-standard serial ports — round Mini-DIN 8 connectors instead of the more common trapezoidal DE-9, commonly called DB-9. The 2000/2100 models have a proprietary small flat connector, called an InterConnect port, used with an adapter. In addition, all models have infrared connectivity, initially only the Sharp ASK protocol, later IrDA. Unlike the Palm, all MessagePad models are equipped with a standard PC Card expansion slot (two on the 2000/2100). This allows native modem and even Ethernet connectivity; Newton users have also written drivers for 802.11b wireless networking cards and ATA-type flash memory cards (including the popular CompactFlash format), as well as for Bluetooth cards. Newton can also dial a phone number through the MessagePad speaker by, simply holding a telephone handset up to the speaker, and fax support is built in at the operating system level, although it requires external cards or a small serial Apple modem powered by AA batteries.
As with the contemporary early-model PI-series Sharp Zaurus PDAs in Japan, the MessagePad and MessagePad 100 used AAA batteries. The early Zaurus used 2x AAA batteries, whereas the MessagePad and MessagePad 100 used 4x AAA batteries. However, even with twice as many batteries, AAA batteries proved to be an inadequate power source for the consumption needs of the Newton.
The use of 4x AA NiCd (MessagePad 110, 120 and 130) and 4x AA NiMH cells (2x00 series, eMate 300) give a runtime of up to 30 hours (MP 2100 w/ 2x 20 MB linear Flash memory PC Cards, no backlight usage) and up to 24 hours with backlight on. While adding more weight to the Newtons than AAA batteries or custom battery packs, the choice of an easily replaceable/rechargeable cell format gives the user a still unsurpassed runtime and flexibility of power supply. This, together with the Flash memory used as internal storage (if all cells lost their power, no data was lost due to the static character of this storage), gave birth to the slogan "Newton never dies, it only gets new batteries".
The MessagePad 2000 and 2100, with a vastly improved handwriting recognition system, 162 MHz StrongARM SA-110 RISC processor, Newton 2.1 OS, and a better, clearer, backlit screen, attracted critical plaudits. Although their size and expense were factors which kept them from being as popular as later Palm OS devices, the Newton still has a small but passionate user base.
The eMate 300, which used a laptop form factor, was derived from the Apple Newton, and was offered to schools in 1997 as an inexpensive ($799 US, originally sold to education markets only) and durable computer for classroom use. However, in order to achieve its low price, the eMate 300 did not have all the features of the contemporary Newton equivalent, the MessagePad 2000, and was cancelled along with the rest of the Newton line.
Many prototypes of additional Newton models were spotted. Most notable was a Newton tablet or "slate," a large, flat screen that could be written on. Others included a "Kids Newton" with side handgrips and buttons, "VideoPads" which would have incorporated a video camera and screen on their flip-top covers for two-way communications, the "Mini 2000" which would have been very similar to Palm Pilot, and the "NewtonPhone" (developed by Siemens AG) which incorporated a handset and a keyboard.
Apple and third parties marketed several "wallets" (cases) for the MessagePads, which would hold them securely along with the owner's credit cards, driver's license, business cards, and cash. These wallets were even larger than the MessagePads and even less able to fit in a pocket, so they were most often used as a protective case for the unit to shield it from bumps and scratches. Some cases included a metal or plastic shield inside the fabric to protect the glass LCD screen. The MessagePad has a receiver in the middle back to accept a pin that was mounted on the case. This allowed the Newton to be held by the case without the use of adhesives or straps.
Although the Apple Newton was produced for six years, it was never as successful in the marketplace as Apple had hoped. This has been attributed to two primary reasons: the Newton's high price (which went up to $1000 when models 2000 and 2100 were introduced), and its large size (it failed the "pocket test" by not fitting in an average coat, shirt, or trouser pocket).
The MessagePad and MessagePad 100 were also limited by the very short lifetime of their inadequate AAA batteries.
Critics also panned the handwriting recognition, trumpeted in the Newton's marketing campaign, available in the debut models, and it was this problem that was famously skewered in the Doonesbury comic strips and the animated television series The Simpsons. Although the handwriting recognition was greatly improved in later models, these initial problems marred Newton's reputation in the eyes of the public, and PDAs would remain a niche product until Palm, Inc.'s Palm Pilot, which emerged shortly before the Newton was discontinued. The Palm Pilot, with its smaller, thinner shape, lower cost, excellent PC synchronization, and more robust Graffiti handwriting recognition system — which had been available first as a software package for the Newton — managed to restore the viability of the PDA market after Newton's commercial failure. Palm Computing was co-founded by ex-Apple employee Donna Dubinsky.
Another factor which limited the Newton's appeal was that desktop connectivity was not included in the basic retail package. Desktop computer synchronization hardware and software had to be purchased separately adding to the expense of the basic package.
Before the Newton project was cancelled, it was "spun off" into an Apple wholly owned subsidiary company, Newton Inc. but was reabsorbed several months later when Steve Jobs ousted Apple CEO Gil Amelio and resumed control of Apple. Two ex-Apple Newton developers founded Pixo, the company that created the iPod's OS.
Speculation continued for several years that Apple might release a new PDA with some Newton technology or collaborate with Palm. Feeding a bit of speculation, Apple put the "Print Recognizer" part of the Newton 2.1 handwriting recognition system into Mac OS X version 10.2 (known as "Jaguar"). It can be used with graphics tablets to seamlessly input handwritten printed text anywhere there was an insertion point on the screen. This technology, known as "Inkwell", appears in the System Preferences whenever a tablet input device is plugged in. Whether Apple will ever utilize such technology again in a handheld device remains to be seen. An Easter egg in Print Recognizer on the Newton (write "ROSETTA! ROSETTA! ROSETTA!", and the Newton will insert "ROSETTA! ROSETTA! Hey, that's me!" instead) was present in Inkwell in Mac OS 10.2 and 10.3, but seems to have been removed in 10.4. This led to speculation that Inkwell was a direct port of Print Recognizer, but may have just been a programmer being nostalgic. The Rosetta name was later used for Apple's PowerPC emulation layer for Intel-based Macs.
At an All Things Digital conference in 2004, Steve Jobs made reference to a new "Apple PDA" (likely a successor to the Newton) which the company had developed but had decided not to bring to market.
The Apple iPhone, announced by Steve Jobs at Macworld on 9 January 2007, was described by one blogger as "surprisingly close to what a current-generation Newton might look like if Jobs hadn't killed the line in 1997". Many of the iPhone's icons are reminiscent of the Newton 2x00 soft icons at the bottom of the screen.
Since 2004, the Einstein Project has been working on emulating the Newton for use as an alternate OS on other platforms. It is currently available for the Sharp Zaurus, Apple's Mac OS X, Nokia N770 and N800, and the PepperPad 3. The emulator is an open source project, but requires an original Newton ROM to be installed in order to function.
So if you remove ALL patches to the eMate 300 NOS you will end up with an NOS of 2.2.00-0 which is documented in photo located here.
The Newton OS was also licensed to a number of third party developers including Sharp and Motorola who developed additional PDA devices that used the operating system. Motorola added wireless connectivity to the unit, and renamed it the Marco.
A possible Newton revival has been a common source of speculation among the Macintosh user base; when patents for a tablet based Macintosh were applied for, rumor sites jumped at the possibility of a new Tablet PC style Macintosh. Also, the Apple iPhone has PDA functions, and could be considered a successor to the Newton.
There were a number of projects that used the Newton as a portable information device in cultural settings such as museums. For example, Visible Interactive created a walking tour in San Francisco's Chinatown but the most significant effort took place in Malaysia at the Petronas Discovery Center, known as Petrosains.
In 1995, an exhibit design firm, DMCD Inc. was awarded the contract to design a new 100,000 square foot (9300 m²) science museum in the Petronas Towers in Kuala Lumpur. A major factor in the award was the concept that visitors would use a Newton to access additional information, find out where they were in the museum, listen to audio, see animations, control robots and other media, and to bookmark information for printout at the end of the exhibit.
The device became known as the ARIF, a Malay word for "wise man" or "seer" and it was also an acronym for A Resourceful Informative Friend. Some 400 ARIFS were installed and over 300 are still in use today. The development of the ARIF system was extremely complex and required a team of hardware and software engineers, designers, and writers. ARIF is an ancestor of the PDA systems used in museums today and it boasted features that have not been attempted since.


Alfred Elton van Vogt (April 26, 1912 – January 26, 2000) was a Canadian-born science fiction author who was one of the most prolific, yet complex, writers of the mid-twentieth century "Golden Age" of the genre.
Born on a farm in Edenburg, a Russian Mennonite community east of Gretna, Manitoba, Canada, van Vogt is one of the most popular and highly esteemed writers of the Golden Age of Science Fiction. After starting his writing career by writing for 'true confession' style pulp magazines like True Story, van Vogt decided to switch to writing something he enjoyed, science fiction.
Van Vogt's first published SF story, "Black Destroyer" (Astounding Science Fiction, July 1939), was inspired by On the Origin of Species by Charles Darwin. The story depicted a fierce, carnivorous alien stalking the crew of an exploration spaceship. It was the cover story of this issue of Astounding, the issue often described as having ushered in the Golden Age of science fiction. The story became an instant classic and eventually served as the inspiration for a number of science fiction movies. In 1950 it was combined with "War of Nerves" (1950), "Discord in Scarlet" (1939) and "M33 in Andromeda" (1943) to form the novel The Voyage of the Space Beagle (1950).
In 1941 van Vogt decided to become a full time writer, quitting his job at the Canadian Department of National Defence. Extremely prolific for a few years, van Vogt wrote a large number of short stories. In the 1950s, many of them were retrospectively patched together into novels, or "fixups" as he called them, a term which entered the vocabulary of science fiction criticism. Sometimes this was successful (The War against the Rull) while other times the disparate stories thrown together made for a less coherent plot (Quest for the Future).
One of van Vogt's best-known novels of this period is Slan, which was originally serialised in Astounding Science Fiction (September - December 1940). Using what became one of van Vogt's recurring themes, it told the story of a 9-year-old superman living in a world in which his kind are slain by Homo sapiens.
A sequel, Slan Hunter, was prepared by his widow, Lydia van Vogt, and Kevin J. Anderson, starting from an incomplete draft and outline left by the late van Vogt. It was released July 10, 2007 (ISBN 978-0765316752). Lydia van Vogt had already given permission to publish her introduction online.
In 1944, van Vogt moved to Hollywood, California, where his writing took on new dimensions after World War II. Van Vogt was always interested in the idea of all-encompassing systems of knowledge (akin to modern meta-systems), the characters in his very first story used a system called 'Nexialism' to analyze the alien's behaviour, and he became interested in the General Semantics of Alfred Korzybski. He was also profoundly affected by revelations of totalitarian police states that emerged after World War II. He wrote a mainstream novel that was set in Communist China, The Violent Man (1962); he said that to research this book he had read 100 books about China.
He subsequently wrote three novels merging these overarching themes, The World of Null-A and The Pawns of Null-A in the late 1940s, and Null-A Three in the early 1980s. Null-A, or non-Aristotelian logic, refers to the capacity for, and practice of, using intuitive, inductive reasoning (compare fuzzy logic), rather than reflexive, or conditioned, deductive logic.
Van Vogt systematized his writing method, using scenes of 800 words or so where a new complication was added or something resolved. Several of his stories hinge upon temporal conundra, a favorite theme. He stated that he acquired many of his writing techniques from three books, "Narrative Technique" by Thomas Uzzell, and "The Only Two Ways to Write a Story" plus "Twenty Problems of the Short-Story Writer", both by John Gallishaw.
He said many of his ideas came from dreams, and indeed his stories at times had the incoherence of dreams, but at their best, as in the science fantasy novel The Book of Ptath, his works had all the vision and power a dream can impart. Throughout his writing life he arranged to be awakened every 90 minutes during his sleep period so he could write down his dreams.
In the 1950s, van Vogt briefly became involved in L. Ron Hubbard's projects. Van Vogt operated a storefront for Dianetics, the secular precursor to Hubbard's Church of Scientology, in the Los Angeles area for a time, before winding up at odds with Hubbard and his methods. His writing more or less stopped for some years, a period in which he bitterly claimed to have been harassed and intimidated by Hubbard's followers. In this period he was limited to collecting old short stories to form notable fixups like: The Mixed Men (1952), The War Against the Rull (1959), The Beast (1963) and the two novels of the "Linn" cyle, which were inspired (like Asimov's Foundation series) by the fall of the Roman Empire. He resumed writing again in the 1960s, mainly at Frederik Pohl's invitation, while remaining in Hollywood with his second wife, Lydia Bereginsky, who cared for him through his declining years. In this later period, his novels were conceived and written as unitary works.
On January 26, 2000, van Vogt died in Los Angeles, USA from Alzheimer's disease.
In 1946, van Vogt and his first wife, Edna Mayne Hull, were co-Guests of Honor at the fourth World Science Fiction Convention.
In 1980, van Vogt received a "Casper Award" (precursor to the Canadian Aurora Awards) for Lifetime Achievement. In 1995 he was awarded the Damon Knight Memorial Grand Master Award. In 1996, van Vogt was recognized on two occasions: the World Science Fiction Convention presented him with a Special Award for six decades of golden age science fiction, and the Science Fiction and Fantasy Hall of Fame included him among its initial four inductees.
Fellow science fiction author Philip K. Dick has said that van Vogt's stories spurred his interest in science fiction with their strange sense of the unexplained, that something more was going on than the protagonists realized.
Writer and critic Damon Knight wrote in 1945 that "van Vogt is not a giant as often maintained. He's only a pygmy using a giant typewriter".

Almost every April Fools' Day (1 April) since 1989, the Internet Engineering Task Force has published one or more humorous RFC documents, following in the path blazed by the June 1973 RFC 527 entitled ARPAWOCKY. The following list also includes humorous RFCs published on other dates.
The IETF accepts submission of properly formatted April Fools' Day RFCs from the general public, and considers them for publication in the same year if received at least two weeks prior to April, 1st.

Anna Sergeyevna Kournikova (Russian: Анна Сергеевна Ку́рникова (listen), Anna Sergeevna Kurnikova; born June 7, 1981) is a retired Russian professional tennis player and model. Although she never won a singles tournament, her celebrity made her one of the best known tennis players worldwide. At the peak of her fame, fans looking for images of Kournikova made her name (or misspellings of it) one of the most common search strings on Google.
She was born in Moscow in the former Soviet Union to Alla and Sergei Kournikov; she and her mother later emigrated to the United States. Currently, she resides in Miami Beach, Florida.
Kournikova's major-league tennis career has been curtailed for the past several years, and possibly ended, by serious back and spinal problems. She has had some success at the singles game, but her specialty has been doubles, where she has at times been the world's No.1 doubles player. With Martina Hingis as her partner, she won Grand Slam titles in Australia in 1999 and 2002.
Kournikova's playing style fits the profile for a doubles player, and is complemented by her height. She has been compared to such players as Pam Shriver and Peter Fleming.
At ages 13 and 14, Kournikova made headlines in international junior tennis, winning several tournaments including the 1995 Italian Open. She was 14 years old when she ended 1995 as Junior European Champion Under 18 and ITF Junior World Champion Under 18.
Kournikova debuted in professional tennis at age 14 in the Fed Cup for Russia, the youngest player ever to participate and win. At age 15, she reached the fourth round of the 1996 U.S. Open, only to be stopped by then-top ranked player, Steffi Graf.
Kournikova was a member of the Russian delegation to the 1996 Olympic Games in Atlanta, Georgia. In 1997, as a 16-year-old, she reached the semi-finals of Wimbledon, where she lost to the eventual champion, Martina Hingis by a score of 6-3, 6-2. 1998 was her breakthrough year, when she broke into the WTA's top 20 rankings for the first time and scored impressive victories over Martina Hingis, Lindsay Davenport, and Steffi Graf. Kournikova's two Grand Slam doubles titles came in 1999 and 2002, both at the Australian Open in the Women's Doubles event with partner Martina Hingis, with whom she played frequently starting in 1999.
Kournikova proved a successful doubles player on the professional circuit, winning 16 tournament doubles titles, including two Australian Opens and being a finalist in mixed doubles at the U.S. Open and at Wimbledon, and reaching the No.1 ranking in doubles in the Women's Tennis Association tour rankings. Her pro career doubles record was 200-71. However, her singles career plateaued after 1999. For the most part, she managed to retain her ranking between 10 and 15 (her career high singles ranking was No.8), but her expected finals breakthrough failed to occur; she only reached four finals out of 130 singles tournaments, never in a Grand Slam event, and never won one. As a player, Kournikova was noted for her footspeed and aggressive baseline play and excellent angles and dropshots; however, her flat, high-risk groundstrokes tended to produce high numbers of errors and her serve was sometimes unreliable in singles. Her singles record is 209-129.
Her final playing years were marred by a string of injuries, especially back injuries, which caused her ranking to erode gradually. Kournikova has not played on the WTA tour since 2003, but still plays exhibition matches for charitable causes.
In late 2004, she participated in three events organized by Elton John and by fellow tennis players Serena Williams and Andy Roddick. In January 2005, she played in a doubles charity event for the Indian Ocean tsunami with John McEnroe, Roddick, and Chris Evert.
In November 2005, she teamed up with Martina Hingis, playing against Lisa Raymond and Samantha Stosur in the WTT finals for charity. Kournikova is also a member of the Sacramento Capitals in the World Team Tennis (WTT), playing doubles only.
In a feature for ELLE magazine's July 2005 issue, Kournikova stated that if she were 100% fit, she would like to come back and compete again.
Most of Kournikova's fame has come from the publicity surrounding her personal life as well as numerous modeling shoots. During her debut at the 1996 U.S. Open at the age of 15, Kournikova's beauty was noticed by the world and soon pictures of her appeared in numerous magazines worldwide.
Kournikova's marital status has been an issue on several occasions. There were conflicting rumors about whether or not she was engaged to hockey player Pavel Bure. There were reports that she married NHL hockey star Sergei Fedorov in 2001. Kournikova's representatives have denied this, but Fedorov stated in 2003 that the couple had married and since divorced. Kournikova currently has a relationship with pop star Enrique Iglesias (in whose video, "Escape", she appeared), and rumors that the couple had secretly married appeared in 2003 and again in 2005. Kournikova herself has consistently refused to directly confirm or deny rumors about the status of her personal relationships. But, in May 2007, Enrique Iglesias was (mistakenly, as he would clarify later) quoted in the NY Sun that he had no intention to marry Anna and settle down because they had split up. The singer would later deny these rumors of 'divorce' or simply separation.
In 2000, Kournikova became the new face for Berlei's shock absorber sports bras range, and appeared in the highly successful "only the ball should bounce" bill board campaign. Photographs of her scantily-clad form have appeared in various men's magazines, including more than one much-publicized Sports Illustrated Swimsuit Issue (2004 - 2005), where she posed in bikinis and swimsuits, and in other popular men's publications such as FHM and Maxim.
Kournikova was named one of "People's 50 Most Beautiful People in 1998, 2000, 2002, and 2003 and was voted "hottest female athlete" and "hottest couple" (with Iglesias) on ESPN.com. In 2002 she also placed first in FHM's 100 Sexiest Women in the World" in U.S. and UK editions.
By contrast, ESPN — citing the degree of hype as compared to actual accomplishments as a singles player — ranked Kournikova 18th in its "25 Biggest Sports Flops of the Past 25 Years". Kournikova was also ranked #1 in the ESPN Classic series "Who's number 1?" when the series featured sports most overrated athletes.

Alfons Maria Jakob (born July 2, 1884, Aschaffenburg/Bavaria; died October 17, 1931, Hamburg) was a German neurologist with important contributions on neuropathology.
Alfons Maria Jakob was the son of a shopkeeper. He studied medicine in Munich, Berlin, and Strasbourg, where obtained his doctorate in 1908. In 1909 he commenced clinical work under the psychiatrist Emil Kraepelin and did laboratory work with Franz Nissl and Alois Alzheimer in Munich.
In 1911 he went to Hamburg to work with Theodor Kaes and became head of the laboratory of anatomical pathology at the psychiatric State Hospital Hamburg-Friedrichsberg. Following the death of Kaes in 1913, Jakob succeeded him as prosector. After serving in the German army in World War I, he returned to Hamburg and climbed the academic ladder. He was habilitated in neurology in 1919 and in 1924 became professor of neurology. Under Jakob's guidance the department grew rapidly. He made notable contributions to knowledge on concussion and secondary nerve degeneration and became a doyen of neuropathology.
Jakob published five monographs and more than 75 papers. His neuropathological studies contributed greatly to the delineation of several diseases, including multiple sclerosis and Friedreich's ataxia. He first recognised and described Alper's disease and Creutzfeldt-Jakob disease (the latter with Hans Gerhard Creutzfeldt). He accumulated immense experience in neurosyphilis, having a 200-bedded ward devoted exclusively to that disorder. Jakob made a lecture tour of the U.S.A. and South-America where he wrote a paper on the neuropathology of yellow fever.
He suffered from chronic osteomyelitis for the last 7 years of his life. This eventually caused a retroperitoneal abscess and paralytic ileus from which he died following operation.

Agnosticism (from the Greek α-γνωστικισμός, a, meaning "without", and gnosticism or gnosis, meaning "knowledge") is the philosophical view that the truth value of certain claims — particularly metaphysical claims regarding theology, afterlife or the existence of God, gods, deities, or even ultimate reality — is unknown or, depending on the form of agnosticism, inherently unknowable due to the nature of subjective experience perceived by that individual.
Agnostics claim either that it is not possible to have absolute or certain knowledge of the existence or non-existence of God or gods; or, alternatively, that while individual certainty may be possible, they personally have no knowledge. Agnosticism in both cases involves some form of skepticism. Some agnostics are termed agnostic theists since, while they do not claim to know any deity exists, they do believe (with varying degrees of skepticism) in at least one.
Demographic research services normally list agnostics in the same category as atheists and non-religious people, although this can be misleading depending on the number of agnostic theists who identify themselves first as agnostics and second as followers of a particular religion.
"Agnostic" was introduced by Thomas Henry Huxley in 1869 to describe his philosophy which rejects Gnosticism, by which he meant not simply the early 1st millennium religious group, but all claims to spiritual or mystical knowledge. This is not the same as the trivial interpretation of the word, and carries a more negative implication for religion than that trivial interpretation.
Early Christian church leaders used the Greek word gnosis (knowledge) to describe "spiritual knowledge." Agnosticism is not to be confused with religious views opposing the doctrine of gnosis and Gnosticism — these are religious concepts that are not generally related to agnosticism. Huxley used the term in a broad sense.
In recent years, use of the word to mean "not knowable" is apparent in scientific literature in psychology and neuroscience, and with a meaning close to "independent", in technical and marketing literature, e.g. "platform agnostic" or "hardware agnostic". This is a less than accurate use of the term "agnostic" and should be replaced with "technology indifferent" (having no bias, prejudice, or preference).
Agnosticism maintains that the nature and attributes of God are beyond the grasp of man's finite and limited mind; those divine attributes transcend human comprehension. The concept of God is just too big a subject for a person to wrap his or her mind around. Humans might apply terms such as those found in the Catholic Encyclopedia that attempt to characterize god, terms such as "infinitely perfect spiritual substance," "omnipotent," "eternal," "incomprehensible," "infinite in intellect and will and in every perfection" but, the agnostic would assert, these terms only underscore the inadequacy of our mental equipment to understand so vast, ephemeral and elusive a concept.
1. You believe the philosophical view that the truth value of certain claims —particularly metaphysical claims regarding theology, afterlife or the existence of god, gods, deities, or even ultimate reality— can be known.
2. You don't believe the philosophical view that the truth value of certain claims —particularly metaphysical claims regarding theology, afterlife or the existence of god, gods, deities, or even ultimate reality— can be known.
3. You have doubts about the philosophical view that the truth value of certain claims —particularly metaphysical claims regarding theology, afterlife or the existence of god, gods, deities, or even ultimate reality— can be known, though that doesn't necessarily make one officially Agnostic, but rather simply exhibiting agnostic doubt, which does not have to disqualify a belief that one can actually know truth.
As an example a person can be a Presbyterian, and not be absolutely certain that there is a God. This person simply has faith that there is without reason.
Among the most famous agnostics (in the original sense) have been Thomas Henry Huxley, Robert G. Ingersoll and Bertrand Russell.
Huxley's agnosticism is believed to be a natural consequence of the intellectual and philosophical conditions of the 1860s, when clerical intolerance was trying to suppress scientific discoveries which appeared to clash with a literal reading of the Book of Genesis and other established Jewish and Christian doctrines. Agnosticism should not, however, be confused with natural theology, deism, pantheism, or other science positive forms of theism.
By way of clarification, Huxley states, "In matters of the intellect, follow your reason as far as it will take you, without regard to any other consideration. And negatively: In matters of the intellect, do not pretend that conclusions are certain which are not demonstrated or demonstrable" (Huxley, Agnosticism, 1889). While A. W. Momerie has noted that this is nothing but a definition of honesty, Huxley's usual definition goes beyond mere honesty to insist that these metaphysical issues are fundamentally unknowable.
Note that he didn't say "supreme" or "supernatural" intelligence, as these terms are metaphysically loaded.


Argon () is a chemical element designated by the symbol Ar. Argon has atomic number 18 and is the third element in group 18 of the periodic table (noble gases). Argon is present in the Earth's atmosphere at 0.93%, making it the most abundant noble gas on Earth. Its full outer shell makes argon stable and resistant to bonding with other elements. Its triple point temperature of 83.8058 K is a defining fixed point in the International Temperature Scale of 1990.
Argon has approximately the same solubility in water as oxygen gas and is 2.5 times more soluble in water than nitrogen gas. Argon is colorless, odorless, tasteless and nontoxic in both its liquid and gaseous forms. Argon is inert under most conditions and forms no confirmed stable compounds at room temperature.
Although argon is a noble gas, it has been found to have the capability of forming some compounds. For example, the creation of argon hydrofluoride (HArF), a metastable compound of argon with fluorine and hydrogen, was reported by researchers at the University of Helsinki in 2000. Although the neutral ground-state chemical compounds of argon are presently limited to HArF, argon can form clathrates with water when atoms of it are trapped in a lattice of the water molecules. Also argon-containing ions and excited state complexes, such as ArH+ and ArF, respectively, are known to exist. Theoretical calculations have shown several argon compounds that should be stable but for which no synthesis routes are currently known.
Argon (Greek meaning "lazy one," in reference to its chemical inactivity) was suspected to be present in air by Henry Cavendish in 1785 but was not discovered until 1894 by Lord Rayleigh and Sir William Ramsay in Scotland in an experiment in which they removed all of the oxygen and nitrogen from a sample of air. Argon was also encountered in 1882 through independent research of H.F. Newall and W.N. Hartley. Each observed new lines in the color spectrum of air but were unable to identify the element responsible for the lines. Argon became the first member of the noble gases to be discovered. The symbol for argon is now Ar, but up until 1957 it was A.
Argon constitutes 0.934% by volume and 1.29% by mass of the Earth's atmosphere, and air is the primary raw material used by industry to produce purified argon products. Argon is isolated from air by fractionation, most commonly by cryogenic fractional distillation, a process that also produces purified nitrogen, oxygen, neon, krypton and xenon.
The Martian atmosphere in contrast contains 1.6% of argon-40 and 5 ppm of argon-36. The Mariner spaceprobe fly-by of the planet Mercury in 1973 found that Mercury has a very thin atmosphere with 70% argon, believed to result from releases of the gas as a decay product from radioactive materials on the planet. In 2005, the Huygens probe also discovered the presence of argon-40 on Titan, the largest moon of Saturn.
The main isotopes of argon found on Earth are 40Ar (99.6%), 36Ar (0.34%), and 38Ar (0.06%). Naturally occurring 40K with a half-life of 1.25 years, decays to stable 40Ar (11.2%) by electron capture and positron emission, and also to stable 40Ca (88.8%) via beta decay. These properties and ratios are used to determine the age of rocks.
In the Earth's atmosphere, 39Ar is made by cosmic ray activity, primarily with 40Ar. In the subsurface environment, it is also produced through neutron capture by 39K or alpha emission by calcium. 37Ar is created from the decay of 40Ca as a result of subsurface nuclear explosions. It has a half-life of 35 days.
Argon’s complete octet of electrons indicates full s and p subshells. This full outer energy level makes argon very stable and extremely resistant to bonding with other elements. Before 1962, argon and the other noble gases were considered to be chemically inert and unable to form compounds; however, compounds of the heavier noble gases have since been synthesized. In August 2000, the first argon compounds were formed by researchers at the University of Helsinki. By shining ultraviolet light onto frozen argon containing a small amount of hydrogen fluoride, argon hydrofluoride (HArF) was formed. It is stable up to 40 kelvins (−233 °C).
The discovery of argon difluoride (ArF2) was announced in 2003. But this is unconfirmed and most probably incorrect.
Argon-40, the most abundant isotope of argon, is produced by the decay of potassium-40 with a half-life of 1.26e+9 years by electron capture or positron emission.
Other noble gases would probably work as well in most of these applications, but argon is by far the cheapest. Argon is inexpensive since it is a byproduct of the production of liquid oxygen and liquid nitrogen, both of which are used on a large industrial scale. The other noble gases (except helium) are produced this way as well, but argon is the most plentiful since it has the highest concentration in the atmosphere.
The next most common reason for using argon is its low thermal conductivity.
It is used for thermal insulation in energy efficient windows. Argon is also used in technical scuba diving to inflate a dry suit, because it is inert and has low thermal conductivity.
Argon is also used for the specific way it ionizes and emits light. It is used in plasma globes and calorimetry in experimental particle physics. Blue argon lasers are used in surgery to weld arteries, destroy tumors, and to correct eye defects. In microelectronics, argon ions are used for sputtering.
Finally, there are a number of miscellaneous uses. Argon-39, with a half life of 269 years, has been used for a number of applications, primarily ice core and ground water dating. The argon-40/potassium-40 ratio is used in dating igneous rocks.
Cryosurgery procedures such as cryoablation use liquified argon to destroy cancer cells. In surgery it is used in a procedure called "argon enhanced coagulation" which is a form of argon plasma beam electrosurgery. The procedure carries a risk of producing gas embolism in the patient and has resulted in the death of one person via this type of accident.
Although argon is non-toxic, it does not satisfy the body's need for oxygen and is a simple asphyxiant. People have suffocated by breathing argon by mistake.

Arsenic () is a chemical element that has the symbol As and atomic number 33. Arsenic was first written about by Albertus Magnus (Germany) in 1250. Its Atomic Mass is 74.92. Its Ionic Charge is (3-) Its position in the periodic table is shown at right. This is a notoriously poisonous metalloid that has many allotropic forms: yellow (molecular non-metallic) and several black and gray forms (metalloids) are a few that are seen. Three metalloidal forms of arsenic with different crystal structures are found free in nature (the minerals arsenic sensu stricto and the much rarer arsenolamprite and pararsenolamprite), but it is more commonly found as arsenide and arsenate compounds. Several hundred such mineral species are known. Arsenic and its compounds are used as pesticides, herbicides, insecticides and various alloys.
The most common oxidation states for arsenic are -3 (arsenides: usually alloy-like intermetallic compounds), +3 (arsenates(III) or arsenites, and most organoarsenic compounds), and +5 (arsenates(V): the most stable inorganic arsenic oxycompounds). Arsenic also bonds readily to itself, forming, for instance, As-As pairs in the red sulfide realgar and square As43- ions in the arsenide skutterudite. In the +3 oxidation state, the stereochemistry of arsenic is affected by possession of a lone pair of electrons.
Arsenic is very similar chemically to its predecessor, phosphorus. Like phosphorus, it forms colourless, odourless, crystalline oxides As2O3 and As2O5 which are hygroscopic and readily soluble in water to form acidic solutions. Arsenic (V) acid, like phosphoric acid, is a weak acid. Like phosphorus, arsenic forms an unstable, gaseous hydride: arsine (AsH3). The similarity is so great that arsenic will partly substitute for phosphorus in biochemical reactions and is thus poisonous. However, in subtoxic doses, soluble arsenic compounds act as stimulants, and were once popular in small doses as medicinals by people in the mid 18th century.
When heated in air it oxidizes to arsenic trioxide; the fumes from this reaction have an odor resembling garlic. This odor can be detected on striking arsenide minerals such as arsenopyrite with a hammer. Arsenic (and some arsenic compounds) sublimes upon heating at atmospheric pressure, converting directly to a gaseous form without an intervening liquid state. The liquid state appears at 20 atmospheres and above, which explains why the melting point is higher than the boiling point. Elemental arsenic is found in many solid forms: the yellow form is soft, waxy and unstable, and is made of tetrahedral As4 molecules similar to the molecules of white phosphorus. The gray, black or 'metallic' forms have somewhat layered crystal structures with bonds extending throughout the crystal. They are brittle semiconductors with a metallic luster. The density of the yellow form is 1.97 g/cm³; rhombohedral 'gray arsenic' is much denser with a density of 5.73 g/cm³; the other metalloidal forms are similarly dense.
Lead hydrogen arsenate has been used, well into the 20th century, as an insecticide on fruit trees (sometimes resulting in brain damage to those working the sprayers), and Scheele's Green (a copper arsenate) has even been recorded in the 19th century as a coloring agent in sweets. In the last half century, monosodium methyl arsenate (MSMA), a less toxic organic form of arsenic, has replaced lead arsenate's role in agriculture.
The application of most concern to the general public is probably that of wood which has been treated with chromated copper arsenate ("CCA", or "Tanalith", and the vast majority of older "pressure treated" wood). CCA timber is still in widespread use in many countries, and was heavily used during the latter half of the 20th century as a structural, and outdoor building material, where there was a risk of rot, or insect infestation in untreated timber. Although widespread bans followed the publication of studies which showed low-level leaching from in-situ timbers (such as children's playground equipment) into surrounding soil, the most serious risk is presented by the burning of CCA timber. Recent years have seen fatal animal poisonings, and serious human poisonings resulting from the ingestion - directly or indirectly - of wood ash from CCA timber (the lethal human dose is approximately 20 grams of ash). Scrap CCA construction timber continues to be widely burnt through ignorance, in both commercial and domestic fires. Protocols for safe disposal of CCA timber are still in place only patchily; there is concern in some quarters about the widespread landfill disposal of such timber.
During the 18th, 19th, and 20th centuries, a number of arsenic compounds have been used as medicines, including arsphenamine (by Paul Ehrlich) and arsenic trioxide (by Thomas Fowler).
Arsphenamine as well as Neosalvarsan was indicated for syphilis and trypanosomiasis, but has been superseded by modern antibiotics.
Arsenic trioxide has been used in a variety of ways over the past 200 years, but most commonly in the treatment of cancer. The US Food and Drug Administration in 2000 approved this compound for the treatment of patients with acute promyelocytic leukemia that is resistant to ATRA. It was also used as Fowler's solution in psoriasis.
Copper acetoarsenite was used as a green pigment known under many different names, including 'Paris Green' and 'Emerald Green'. It caused numerous arsenic poisonings.
Exposure to higher-than-average levels of arsenic can occur in some occupations placing workers at risk. Industries that use inorganic arsenic and its compounds include wood preservation, glass production, nonferrous metal alloys, and electronic semiconductor manufacturing. Inorganic arsenic is also found in coke oven emissions associated with the smelter industry.
The word arsenic is borrowed from the Persian word زرنيخ Zarnikh meaning "yellow orpiment". Zarnikh was borrowed by Greek as arsenikon, which means masculine or potent. Arsenic has been known and used in Persia and elsewhere since ancient times. As the symptoms of arsenic poisoning were somewhat ill-defined, it was frequently used for murder until the advent of the Marsh test, a sensitive chemical test for its presence. (Another less sensitive but more general test is the Reinsch test.) Due to its use by the ruling class to murder one another and its potency and discreetness, arsenic has been called the Poison of Kings and the King of Poisons.
During the Bronze Age, arsenic was often included in bronze, which made the alloy harder (so-called "arsenical bronze").
element in 1250. In 1649 Johann Schröder published two ways of preparing arsenic.
In the Victorian era, 'arsenic' (colourless, crystalline, soluble 'white arsenic') was mixed with vinegar and chalk and eaten by women to improve the complexion of their faces, making their skin paler to show they did not work in the fields. Arsenic was also rubbed into the faces and arms of women to 'improve their complexion'. The accidental use of arsenic in the adulteration of foodstuffs led to the Bradford sweet poisoning in 1858, which resulted in approximately 20 deaths and 200 people taken ill with arsenic poisoning.
In 2005, China was the top producer of white arsenic with almost 50% world share followed by Chile and Peru, reports the British Geological Survey.
Arsenopyrite also unofficially called mispickel (FeAsS) is the most common arsenic-bearing mineral. On roasting in air, the arsenic sublimes as arsenic (III) oxide leaving iron oxides.
The most important compounds of arsenic are arsenic (III) oxide, As2O3, ('white arsenic'), the yellow sulfide orpiment (As2S3) and red realgar (As4S4), Paris Green, calcium arsenate, and lead hydrogen arsenate. The latter three have been used as agricultural insecticides and poisons. Orpiment and realgar were formerly used as painting pigments, though they have fallen out of use due to their toxicity and reactivity. Although arsenic is sometimes found native in nature, its main economic source is the mineral arsenopyrite mentioned above; it is also found in arsenides of metals such as silver, cobalt (cobaltite: CoAsS and skutterudite: CoAs3) and nickel, as sulfides, and when oxidised as arsenate minerals such as mimetite, Pb5(AsO4)3Cl and erythrite, Co3(AsO4)2. 8H2O, and more rarely arsenites ('arsenite' = arsenate(III), AsO33- as opposed to arsenate (V), AsO43-).
In addition to the inorganic forms mentioned above, arsenic also occurs in various organic forms in the environment. Inorganic arsenic and its compounds, upon entering the food chain, are progressively metabolised to a less toxic form of arsenic through a process of methylation. For example certain molds produce significant amounts of trimethylarsine if inorganic arsenic is present.
Nickernuts are said to contain arsenic.
See also Arsenide minerals, Arsenate minerals.
Arsenic and many of its compounds are especially potent poisons. Arsenic disrupts ATP production through several mechanisms. At the level of the citric acid cycle, arsenic inhibits pyruvate dehydrogenase and by competing with phosphate it uncouples oxidative phosphorylation, thus inhibiting energy-linked reduction of NAD+, mitochondrial respiration, and ATP synthesis. Hydrogen peroxide production is also increased, which might form reactive oxygen species and oxidative stress. These metabolic interferences lead to death from multi-system organ failure (see arsenic poisoning) probably from necrotic cell death, not apoptosis. A post mortem reveals brick red colored mucosa, due to severe hemorrhage. Although arsenic causes toxicity, it can also play a protective role.
Elemental arsenic and arsenic compounds are classified as "toxic" and "dangerous for the environment" in the European Union under directive 67/548/EEC.
The IARC recognizes arsenic and arsenic compounds as group 1 carcinogens, and the EU lists arsenic trioxide, arsenic pentoxide and arsenate salts as category 1 carcinogens.
Arsenic is known to cause arsenicosis due to its manifestation in drinking water, "the most common species being arsenate [HAsO42- ; As(V)] and arsenite [H3AsO3 ; As(III)]". The ability of arsenic to undergo redox conversion between As(III) and As(V) makes its availability in the environment possible. According to Croal, Gralnick, Malasarn, and Newman, "[the] understanding [of] what stimulates As(III) oxidation and/or limits As(V) reduction is relevant for bioremediation of contaminated sites (Croal). The study of chemolithoautotrophic As(III) oxidizers and the heterotrophic As(V) reducers can help the understanding of the oxidation and/or reduction of arsenic.
Arsenic contamination of groundwater has led to a massive epidemic of arsenic poisoning in Bangladesh and neighbouring countries. It is estimated that approximately 57 million people are drinking groundwater with arsenic concentrations elevated above the World Health Organization's standard of 10 parts per billion. The arsenic in the groundwater is of natural origin, and is released from the sediment into the groundwater due to the anoxic conditions of the subsurface. This groundwater began to be used after western NGOs instigated a massive tube well drinking-water program in the late twentieth century. This program was designed to prevent drinking of bacterially contaminated surface waters, but failed to test for arsenic in the groundwater.(2) Many other countries and districts in South East Asia, such as Vietnam, Cambodia, and Tibet, China, are thought to have geological environments similarly conducive to generation of high-arsenic groundwaters. Arsenicosis was reported in Nakhon Si Thammarat, Thailand in 1987, and the dissolved arsenic in the Chao Phraya River is suspected of containing high levels of naturally occurring arsenic, but has not been a public health problem due to the use of bottled water.
The northern United States, including parts of Michigan, Wisconsin, Minnesota and the Dakotas are known to have significant concentrations of arsenic in ground water. Increased levels of skin cancer has been associated with arsenic exposure in Wisconsin, even at levels below the 10 part per billion drinking water standard.
Epidemiological evidence from Chile shows a dose dependent connection between chronic arsenic exposure and various forms of cancer, particularly when other risk factors, such as cigarette smoking, are present. These effects have been demonstrated to persist below 50 parts per billion.
A study of cancer rates in Taiwan suggested that significant increases in cancer mortality appear only at levels above 150 parts per billion.
Analyzing multiple epidemiological studies on inorganic arsenic exposure suggests a small but measurable risk increase for bladder cancer at 10 parts per billion. According to Peter Ravenscroft, of the Department of Geography at the University of Cambridge roughly 80 million people worldwide consume between 10 and 50 parts per billion arsenic in their drinking water. If they all consumed exactly 10 parts per billion arsenic in their drinking water, the previously cited multiple epidemiological study analysis would predict an additional 2,000 cases of bladder cancer alone. This represents a clear underestimate of the overall impact, since it does not include lung or skin cancer, and explicitly underestimates the exposure. Those exposed to levels of arsenic above the current WHO standard should weigh the costs and benefits of arsenic remmediation.
Arsenic can be removed from drinking water through coprecipitation of iron minerals by oxidation and filtering. When this treatment fails to produce acceptable results, adsorptive arsenic removal media may be utilized. Several adsorptive media systems have been approved for point of service use in a study funded by the United States Environmental Protection Agency (U.S.EPA) and the National Science Foundation (NSF).
Magnetic separations of arsenic at very low magnetic field gradients have been demonstrated in point-of-use water purification with high–surface area and monodisperse magnetite (Fe3O4) nanocrystals. Using the high specific surface area of Fe3O4 nanocrystals the mass of waste associated with arsenic removal from water has been dramatically reduced.
Arsenic also occurs in the II oxidation state, but only in the As24+ cation, As(II) is never found otherwise.
See also Arsenic compounds.
Arsenic has been proposed as a "salting" material for nuclear weapons (cobalt is another, better-known salting material). A jacket of 75As, irradiated by the intense high-energy neutron flux from an exploding thermonuclear weapon, would transmute into the radioactive isotope 76As with a half-life of 1.0778 days and produce approximately 1.13 MeV of gamma radiation, significantly increasing the radioactivity of the weapon's fallout for several hours. Such a weapon is not known to have ever been built, tested, or used.

Antimony ( (US), /ˈæntɪməni/ (UK)) is a chemical element with the symbol Sb (, meaning "mark") and atomic number 51. A metalloid, antimony has four allotropic forms. The stable form of antimony is a blue-white metalloid. Yellow and black antimony are unstable non-metals. Antimony is used in flame-proofing, paints, ceramics, enamels, a wide variety of alloys, electronics, and rubber.
Antimony in its elemental form is a silvery white, brittle, fusible, crystalline solid that exhibits poor electrical and heat conductivity properties and vaporizes at low temperatures. A metalloid, antimony resembles a metal in its appearance and in many of its physical properties, but does not chemically react as a metal. It is also attacked by oxidizing acids and halogens. Antimony and some of its alloys are unusual in that they expand on cooling. Antimony is geochemically categorized as a chalcophile, occurring with sulfur and the heavy metals lead, copper, and silver.
Estimates of the abundance of antimony in the Earth's crust range from 0.2 to 0.5 ppm.
Antimony compounds in the form of oxides, sulfides, sodium antimonate, and antimony trichloride are used in the making of flame-proofing compounds, ceramic enamels, glass, paints, and pottery. Antimony trioxide is the most important of the antimony compounds and is primarily used in flame-retardant formulations. These flame-retardant applications include such markets as children's clothing, toys, aircraft and automobile seat covers. It is also used in the fiberglass composites industry as an additive to polyester resins for such items as light aircraft engine covers. The resin will burn while a flame is held to it but will extinguish itself as soon as the flame is removed. Antimony sulfide is also one of the ingredients of safety matches.
In the 1950s, tiny beads of a lead-antimony alloy were used for the emitters and collectors of NPN alloy junction transistors.
The natural sulfide of antimony, stibnite, was known and used in Biblical times as medicine and as a cosmetic. Stibnite is still used in some developing countries as medicine. Antimony has been used for the treatment of schistosomiasis. Antimony attaches itself to sulfur atoms in certain enzymes which are used by both the parasite and human host. Small doses can kill the parasite without causing damage to the patient. Antimony and its compounds are used in several veterinary preparations like Anthiomaline or Lithium antimony thiomalate, which is used as a skin conditioner in ruminants. Antimony has a nourishing or conditioning effect on keratinized tissues, at least in animals. Tartar emetic is another antimony preparation which is used as an anti-schistosomal drug. Treatments chiefly involving antimony have been called antimonials.
Antimony-based drugs such as Allopurinol, and Meglumine, are also considered the drugs of choice for the treatment of Leishmaniasis in domestic animals. Unfortunately, as well as having low therapeutic indices, the drugs are poor at penetrating the bone marrow, where some of the Leishmania amastigotes reside, and so cure of the disease - especially the visceral form - is very difficult.
A coin made of antimony was issued in the Keichow Province of China in 1931. The coins were not popular, being too soft and they wore quickly when in circulation. After the first issue no others were produced.
The ancient words for antimony mostly have, as their chief meaning, kohl, the sulfide of antimony. Pliny the Elder, however, distinguishes between male and female forms of antimony; his male form is probably the sulfide, the female form, which is superior, heavier, and less friable, is probably native metallic antimony.
The Egyptians called antimony mśdmt; in hieroglyphics, the vowels are uncertain, but there is an Arabic tradition that the word is mesdemet. The Greek word, stimmi, is probably a loan word from Arabic or Egyptian, and is used by the Attic tragic poets of the 5th century BC; later Greeks also used stibi, as did Celsus and Pliny, writing in Latin, in the first century AD. Pliny also gives the names stimi [sic], larbaris, alabaster, and the "very common" platyophthalmos, "wide-eye" (from the effect of the cosmetic). Later Latin authors adapted the word to Latin as stibium. The Arabic word for the substance, as opposed to the cosmetic, can appear as ithmid, athmoud, othmod, or uthmod. Littré suggests the first form, which is the earliest, derives from stimmida, (one) accusative for stimmi.
The use of Sb as the standard chemical symbol for antimony is due to the 18th century chemical pioneer, Jöns Jakob Berzelius, who used this abbreviation of the name stibium.
The medieval Latin form, from which the modern languages, and late Byzantine Greek, take their names, is antimonium. The origin of this is uncertain; all suggestions have some difficulty either of form or interpretation. The popular etymology, from anti-monachos or French antimoine, still has adherents; this would mean "monk-killer", and is explained by many early alchemists being monks, and antimony being poisonous. So does the hypothetical Greek word antimonos, "against one", explained as "not found as metal", or "not found unalloyed".
Lippmann conjectured a Greek word, anthemonion, which would mean "floret", and he cites several examples of related Greek words (but not that one) which describe chemical or biological efflorescence.
The early uses of antimonium include the translations, in 1050-1100, by Constantine the African of Arabic medical treatises. Several authorities believe that antimonium is a scribal corruption of some Arabic form; Meyerhof derives it from ithmid; other possibilities include Athimar, the Arabic name of the metal, and a hypothetical *as-stimmi, derived from or parallel to, the Greek.
Antimony's sulfide compound, antimony (III) trisulfide, Sb2S3 was recognized in antiquity, at least as early as 3000 BC. Pastes of Sb2S3 powder in fat or in other materials have been used since that date as eye cosmetics in the Middle East and farther afield; in this use, Sb2S3 is called kohl. It was used to darken the brows and lashes, or to draw a line around the perimeter of the eye.
An artifact made of antimony dating to about 3000 BC was found at Tello, Chaldea (part of present day Iraq), and a copper object plated with antimony dating between 2500 BC and 2200 BC has been found in Egypt. There is some uncertainty as to the description of the artifact from Tello. Although it is sometimes reported to be a vase, a recent detailed discussion of it reports it to be rather a fragment of indeterminate purpose.
According to the history of metallurgy, the first description of a procedure for isolating antimony is in the book De la pirotechnia of 1540 by Vannoccio Biringuccio, written in Italian. This book precedes the more famous 1556 book in Latin by Agricola, De re metallica, even though Agricola has been often incorrectly credited with the discovery of metallic antimony.
According to the traditional history of western alchemy, metallic antimony was described (previous to Biringuccio) by the putative Prior Basilius Valentinus in a Latin manuscript, Currus Triumphalis Antimonii, supposedly circa 1450. This manuscript was published in 1604 in English translation as The Triumphal Chariot of Antimony, by Johann Thölde (1565–1614). The marvelous discovery of a complete set of Valentinus' manuscripts, including the alchemical tales, is fully described by Jean-Jacques Manget in his Bibliotheca chemica curiosa (1702): the manuscripts had been enclosed for more than a century in a pillar of St. Peter's Abbey, at Erfurt, until the pillar was shattered by a thunderbolt. Many scholars have considered Basilius Valentinus a mythological personage. Gottfried Wilhelm Leibniz (1646–1716) declared, after careful enquiry, that no Prior Valentinus ever existed in the Abbey of Erfurt, rather that the name was only a pseudonym – probably of Thölde himself – used to merge poorly translated materials of various origins.
According to the traditional history of Middle Eastern alchemy, pure antimony was well known to Geber, sometimes called "the Father of Chemistry", in the 8th century. Here there is still an open controversy: Marcellin Berthelot, who translated a number of Geber's books, stated that antimony is never mentioned in them, but other authors claim that Berthelot translated only some of the less important books, while the more interesting ones (some of which might describe antimony) are not yet translated, and their content is completely unknown.
Even though this element is not abundant, it is found in over 100 mineral species. Antimony is sometimes found native, but more frequently it is found in the sulfide stibnite (Sb2S3) which is the predominant ore mineral. Commercial forms of antimony are generally ingots, broken pieces, granules, and cast cake. Other forms are powder, shot, and single crystals.
In 2005, China was the top producer of antimony with about 84% world share followed at a distance by South Africa, Bolivia and Tajikistan, reports the British Geological Survey.
The largest mine in China is Xikuangshan mine in Hunan Province.
See also Antimonide minerals, Antimonate minerals.
Antimony and many of its compounds are toxic. Clinically, antimony poisoning is very similar to arsenic poisoning. In small doses, antimony causes headache, dizziness, and depression. Larger doses cause violent and frequent vomiting, and will lead to death in a few days.
See also arsenic poisoning.
The acidic nature of the drink is sufficient to dissolve small amounts of antimony oxide contained in the packaging of the drink; modern manufacturing methods prevent this occurrence. However, researchers are concerned that antimony levels correspond to duration the bottle is left to stand - the longer the beverage has been bottled, the higher the antimony leached.
See also Antimony compounds.


Actinium () is a chemical element with the symbol Ac and atomic number 89.
Actinium is a silvery, radioactive, metallic element. Due to its intense radioactivity, actinium glows in the dark with a pale blue light.
Actinium is found only in traces in uranium ores as 227Ac, an α and β emitter with a half-life of 21.773 years. One ton of uranium ore contains about a tenth of a gram of actinium. 235U (or 239Pu) is the parent isotope of the actinium series decay chain which ends with the stable isotope 207Pb.
It is about 150 times as radioactive as radium, making it valuable as a neutron source. Otherwise it has no significant industrial applications.
225Ac is used in medicine to produce 213 in a reusable generator or can be used alone as an agent for radio-immunotherapy for Targeted Alpha Therapy (TAT). 225Ac was first produced artificially by the ITU in Germany using a cyclotron and by Dr Graeme Melville at St George Hospital in Sydney using a linac in 2000.
Actinium was discovered in 1899 by André-Louis Debierne, a French chemist, who separated it from pitchblende. Friedrich Oskar Giesel independently discovered actinium in 1902 and called it "emanium" in 1904. Debierne's name was retained because it had seniority. The chemical behavior of actinium is similar to that of the rare earth lanthanum.
The word actinium comes from the Greek aktis, aktinos, meaning beam or ray.
Actinium is found in trace amounts in uranium ore, but more commonly is made in milligram amounts by the neutron irradiation of 226 in a nuclear reactor. Actinium metal has been prepared by the reduction of actinium fluoride with lithium vapor at about 1100 to 1300ºC.
Naturally occurring actinium is composed of 1 radioactive isotope; 227Ac. 36 radioisotopes have been characterized with the most stable being 227Ac with a half-life of 21.772 y, 225Ac with a half-life of 10.0 days, and 226Ac with a half-life of 29.37 h. All of the remaining radioactive isotopes have half-lifes that are less than 10 hours and the majority of these have half lifes that are less than 1 minute. The shortest-lived isotope of actinium is 217Ac which decays through alpha decay and electron capture. It has a half-life of 69 ns. Actinium also has 2 meta states.
Purified 227Ac comes into equilibrium with its decay products at the end of 185 days, and then decays according to its 21.773-year half-life.
The isotopes of actinium range in atomic weight from 206 u (206Ac) to 236 u (236Ac).
227Ac is extremely radioactive, and in terms of its potential for radiation induced health effects, 227Ac is even more dangerous than plutonium. Ingesting even small amounts of 227Ac would be fatal.


Americium () is a synthetic element that has the symbol Am and atomic number 95. A radioactive metallic element, americium is an actinide that was obtained in 1944 by bombarding plutonium with neutrons and was the fourth transuranic element to be discovered. It was named for the Americas, by analogy with europium.
Pure americium has a silvery and white lustre. At room temperatures it slowly tarnishes in dry air. It is more silvery than plutonium or neptunium and apparently more malleable than neptunium or uranium. Alpha emission from 241Am is approximately three times that of radium. Gram quantities of 241Am emit intense gamma rays which creates a serious exposure problem for anyone handling the element.
Americium is also fissile; the critical mass for an unreflected sphere of 241Am is approximately 60 kilograms. It is unlikely that Americium would be used as a weapons material, as its minimum critical mass is considerably larger than more readily obtained plutonium or uranium isotopes.
This element can be produced in kilogram amounts and has some uses (mostly 241Am since it is easier to produce relatively pure samples of this isotope). Americium is the only synthetic element to have found its way into the household, where one type of smoke detector contains a tiny amount (about 0.2 microgram) of 241Am as a source of ionizing radiation. 241Am has been used as a portable gamma ray source for use in radiography. The element has also been employed to gauge glass thickness to help create flat glass. 242Am is a neutron emitter and has found uses in neutron radiography as well as a neutron emitting radioactive source used in well logging applications (Am241Be). It has also been cited for use as an advanced nuclear rocket propulsion fuel. This isotope is, however, extremely expensive to produce in usable quantities.
Americium was first isolated by Glenn T. Seaborg, Leon O. Morgan, Ralph A. James, and Albert Ghiorso in late 1944 at the wartime Metallurgical Laboratory at the University of Chicago (now known as Argonne National Laboratory). The team created the isotope 241Am by subjecting 239Pu to successive neutron capture reactions in a nuclear reactor. This created 240Pu and then 241Pu which in turn decayed into 241Am via beta decay. Seaborg was granted a patent for "Element 95 and Method of Producing Said Element," whose unusually terse claim number 1 reads simply, "Element 95." The discovery of americium and curium was first announced informally on a children's quiz show in 1945.
18 radioisotopes of americium have been characterized, with the most stable being 243Am with a half-life of 7370 years, and 241Am with a half-life of 432.2 years. All of the remaining radioactive isotopes have half-lives that are less than 51 hours, and the majority of these have half-lives that are less than 100 minutes. This element also has 8 meta states, with the most stable being 242mAm (t½ 141 years). The isotopes of americium range in atomic weight from 231.046 u (231Am) to 249.078 u (249Am).
In aqueous systems the most common oxidation state is +3. It is very much harder to oxidize Am(III) to Am(IV) than it is to oxidise Pu(III) to Pu(IV).
Currently the solvent extraction chemistry of americium is important as in several areas of the world scientists are working on reducing the medium term radiotoxicity of the waste from the reprocessing of used nuclear fuel.
See liquid-liquid extraction for some examples of the solvent extraction of americium.
Americium dioxide is used in smoke detectors.
Americium, unlike uranium, does not readily form a dioxide americyl core (AmO2). This is because americium is very hard to oxidise above the +3 oxidation state when it is in an aqueous solution. In the environment, this americyl core could complex with carbonate as well as other oxygen moieties (OH-, NO2-, NO3-, and SO4-2) to form charged complexes which tend to be readily mobile with low affinities to soil.
A large amount of work has been done on the solvent extraction of americium, as it is the case that americium and the other transplutonium elements are responsible for the majority of the long lived radiotoxicity of spent nuclear fuel. It is thought that by removal of the americium and curium that the used fuel will only need to be isolated from man and his environment for a shorter time than that required for the isolation of untreated used fuel. One recent EU funded project on this topic was known by the codename "EUROPART". Within this project triazines and other compounds were studied as potential extraction agents.


Astatine () is a radioactive chemical element with the symbol At and atomic number 85. It is the heaviest of the halogens.
This highly radioactive element has been confirmed by mass spectrometers to behave chemically much like other halogens, especially iodine (it would probably accumulate in the thyroid gland like iodine), though astatine is thought to be more metallic than iodine. Researchers at the Brookhaven National Laboratory have performed experiments that have identified and measured elementary reactions that involve astatine; however, chemical research into astatine is limited by its extreme rarity, which is a consequence of its extremely short half-life. Its most stable isotope has a half-life of around 8.3 hours. The final product of the decay of astatine is an isotope of lead. Following the color trends of the halogens, you will notice that the elements get darker in color. Following the trends, astatine is expected to be a nearly black solid, which, when heated, sublimes into a dark, purplish vapor (darker than iodine). Astatine is expected to form ionic bonds with metals such as sodium, like the other halogens, but it can be displaced from the salts by lighter, more reactive halogens. Astatine can also react with hydrogen to form hydrogen astatide, which when dissolved in water, forms hydroastatic acid. Astatine is the least reactive of the halogens, being less reactive than iodine.
The existence of "eka-iodine" had been predicted by Mendeleev. Astatine (after Greek αστατος astatos, meaning "unstable") was first synthesized in 1940 by Dale R. Corson, K. R. MacKenzie, and Emilio Segrè at the University of California, Berkeley by barraging bismuth with alpha particles. An earlier name for the element was alabamine (Ab).
The name Dakin was proposed for this element in 1937 by chemist Rajendralal De working in Dhaka.
Astatine occurs naturally from uranium-235 and uranium-238 decay, but because of its short half-life is only found in minute amounts.
Astatine is the rarest naturally-occurring element, with the total amount in Earth's crust estimated to be less than 1 oz (28 g) at any given time. This amounts to less than one teaspoon of the element. Guinness World Records has dubbed the element the rarest on Earth, stating: "Only around 0.9 oz (25 g) of the element astatine (At) occurring naturally". Isaac Asimov, in a 1957 essay on large numbers, scientific notation, and the size of the atom, wrote that in "all of North and South America to a depth of ten miles", the number of astatine atoms at any time is "only a trillion".
Astatine is produced by bombarding bismuth with energetic alpha particles to obtain relatively long-lived 209At - 211At, which can then be distilled from the target by heating in the presence of air.
Multiple compounds of astatine have been synthesized in microscopic amounts and studied as intensively as possible before their inevitable radioactive disintegration. While these compounds are primarily of theoretical interest, they are being studied for potential use in nuclear medicine.
Astatine has 33 known isotopes, all of which are radioactive; the range of their mass numbers is from 191 to 223. There exist also 23 metastable excited states. The longest-lived isotope is 210At, which has a half-life of 8.1 hours; the shortest-lived known isotope is 213At, which has a half-life of 125 nanoseconds.
Because of the extremely short life span of astatine no practical applications exist other than scientific study.
The istope 211 of astatine is used for treating different type of tumours. Astatine 211 is an alpha emitter with a physical halflife of 7.2 h. This features have been used in nuclude radiotherapy.
Since Astatine is radioactive, it should be handled with care. Because of its extreme rarity, it is not likely that the general public will be exposed.
Astatine is a halogen, and standard precautions apply. It is less reactive than iodine, but they share similar characteristics.


An atom is the smallest particle that comprises a chemical element. An atom consists of an electron cloud that surrounds a dense nucleus. This nucleus contains positively charged protons and electrically neutral neutrons, whereas the surrounding cloud is made up of negatively charged electrons. When the number of protons in the nucleus equals the number of electrons, the atom is electrically neutral; otherwise it is an ion and has a net positive or negative charge. An atom is classified according to its number of protons and neutrons: the number of protons determines the chemical element and the number of neutrons determines the isotope of that element.
The concept of the atom as an indivisible component of matter was first proposed by early Indian and Greek philosophers. In the 17th and 18th centuries, chemists provided a physical basis for this idea by showing that certain substances could not be further broken down by chemical methods. During the late 19th and the early 20th centuries, physicists discovered subatomic components and structure inside the atom, thereby demonstrating that the 'atom' was not indivisible. The principles of quantum mechanics, including the wave–particle duality of matter, were used to successfully model the atom.
Relative to everyday experience, atoms are minuscule objects with proportionately tiny masses that can only be observed individually using special instruments such as the scanning tunneling microscope. More than 99.9% of an atom's mass is concentrated in the nucleus, with protons and neutrons having about equal mass. In atoms with too many or too few neutrons relative to the number of protons, the nucleus is unstable and subject to radioactive decay. The electrons surrounding the nucleus occupy a set of stable energy levels, or orbitals, and they can transition between these states by the absorption or emission of photons that match the energy differences between the levels. The electrons determine the chemical properties of an element, and strongly influence an atom's magnetic properties.
The concept that matter is composed of discrete units and cannot be divided into arbitrarily tiny quantities has been around for millennia, but these ideas were founded in abstract, philosophical reasoning rather than experimentation and empirical observation. The nature of atoms in philosophy varied considerably over time and between cultures and schools, and often had spiritual elements. Nevertheless, the basic idea of the atom was adopted by scientists thousands of years later because it elegantly explained new discoveries in the field of chemistry.
The earliest references to the concept of atoms date back to ancient India in the 6th century BCE. The Nyaya and Vaisheshika schools developed elaborate theories of how atoms combined into more complex objects (first in pairs, then trios of pairs). The references to atoms in the West emerged a century later from Leucippus whose student, Democritus, systemized his views. In approximately 450 BCE, Democritus coined the term átomos (Greek ἄτομος), which meant "uncuttable" or "the smallest indivisible particle of matter", i.e. something that cannot be divided. Although the Indian and Greek concepts of the atom were based purely on philosophy, modern science has retained the name coined by Democritus.
Further progress in the understanding of atoms did not occur until the science of chemistry began to develop. In 1661, the natural philosopher Robert Boyle published The Sceptical Chymist in which he argued that matter was composed of various combinations of different "corpuscules" or atoms, rather than the classical elements of air, earth, fire and water. In 1789 the term element was defined by the French nobleman and scientific researcher Antoine Lavoisier to mean basic substances that could not be further broken down by the methods of chemistry.
law of multiple proportions—and why certain gases dissolved better in water than others. He proposed that each element consists of atoms of a single, unique type, and that these atoms could join to each other, to form chemical compounds.
Additional validation of particle theory (and by extension atomic theory) occurred in 1827 when botanist Robert Brown used a microscope to look at dust grains floating in water and discovered that they moved about erratically—a phenomenon that became known as "Brownian motion". J. Desaulx suggested in 1877 that the phenomenon was caused by the thermal motion of water molecules, and in 1905 Albert Einstein produced the first mathematical analysis of the motion, thus confirming the hypothesis.
However, in 1909, researchers under the direction of physicist Ernest Rutherford bombarded a sheet of gold foil with helium ions and discovered that a small percentage were deflected through much larger angles than was predicted using Thomson's proposal. Rutherford interpreted the gold foil experiment as suggesting that the positive charge of an atom and most of its mass was concentrated in a nucleus at the center of the atom (the Rutherford model), with the electrons orbiting it like planets around a sun. Positively charged helium ions passing close to this dense nucleus would then be deflected away at much sharper angles.
While experimenting with the products of radioactive decay, in 1913 radiochemist Frederick Soddy discovered that there appeared to be more than one type of atom at each position on the periodic table. The term isotope was coined by Margaret Todd as a suitable name for different atoms that belong to the same element. J.J. Thomson created a technique for separating atom types through his work on ionized gases, which subsequently led to the discovery of stable isotopes.
Meanwhile, in 1913, physicist Niels Bohr revised Rutherford's model by suggesting that the electrons were confined into clearly defined orbits, and could jump between these, but could not freely spiral inward or outward in intermediate states. An electron must absorb or emit specific amounts of energy to transition between these fixed orbits. When the light from a heated material is passed through a prism, it produced a multi-colored spectrum. The appearance of fixed lines in this spectrum was successfully explained by the orbital transitions.
In 1926, Erwin Schrödinger, using Louis de Broglie's 1924 proposal that particles behave to an extent like waves, developed a mathematical model of the atom that described the electrons as three-dimensional waveforms, rather than point particles. A consequence of using waveforms to describe electrons is that it is mathematically impossible to obtain precise values for both the position and momentum of a particle at the same time; this became known as the uncertainty principle. In this concept, for each measurement of a position one could only obtain a range of probable values for momentum, and vice versa. Although this model was difficult to visually conceptualize, it was able to explain observations of atomic behavior that previous models could not, such as certain structural and spectral patterns of atoms larger than hydrogen. Thus, the planetary model of the atom was discarded in favor of one that described orbital zones around the nucleus where a given electron is most likely to exist.
The development of the mass spectrometer allowed the exact mass of atoms to be measured. The device uses a magnet to bend the trajectory of a beam of ions, and the amount of deflection is determined by the ratio of an atom's mass to its charge. The chemist Francis William Aston used this instrument to demonstrate that isotopes had different masses. The mass of these isotopes varied by integer amounts, called the whole number rule. The explanation for these different atomic isotopes awaited the discovery of the neutron, a neutral-charged particle with a mass similar to the proton, by the physicist James Chadwick in 1932. Isotopes were then explained as elements with the same number of protons, but different numbers of neutrons within the nucleus.
In the 1950s, the development of improved particle accelerator and particle detectors allowed scientists to study the impacts of atoms moving at high energies. Neutrons and protons were found to be hadrons, or composites of smaller particles called quarks. Standard models of nuclear physics were developed that successfully explained the properties of the nucleus in terms of these sub-atomic particles and the forces that govern their interactions.
Around 1985, Steven Chu and co-workers at Bell Labs developed a technique for lowering the temperatures of atoms using lasers. In the same year, a team led by William D. Phillips managed to contain atoms of sodium in a magnetic trap. The combination of these two techniques and a method based on the Doppler effect, developed by Claude Cohen-Tannoudji and his group, allows small numbers of atoms to be cooled to several microkelvin. This allows the atoms to be studied with great precision, and later led to the discovery of Bose-Einstein condensation.
Historically, single atoms have been prohibitively small for scientific applications. Recently, devices have been constructed that use a single metal atom connected through organic ligands to construct a single electron transistor. Experiments have been carried out by trapping and slowing single atoms using laser cooling in a cavity to gain a better physical understanding of matter.
Though the word atom originally denoted a particle that cannot be cut into smaller particles, in modern scientific usage the atom is composed of various subatomic particles. The constituent particles of an atom consist of the electron, the proton and, for atoms other than hydrogen-1, the neutron.
or 1.6929 g.
Neutrons and protons have comparable dimensions—on the order of 2.5 m—although the 'surface' of these particles is not sharply defined.
In the Standard Model of physics, both protons and neutrons are composed of elementary particles called quarks. The quark is a type of fermion, one of the two basic constituents of matter—the other being the lepton, of which the electron is an example. There are six types of quarks, and each has a fractional electric charge of either +2/3 or &minus;1/3. Protons are composed of two up quarks and one down quark, while a neutron consists of one up quark and two down quarks. This distinction accounts for the difference in mass and charge between the two particles. The quarks are held together by the strong nuclear force, which is mediated by gluons. The gluon is a member of the family of bosons, which are elementary particles that mediate physical forces.
where A is the total number of nucleons. This is much smaller than the radius of the atom, which is on the order of 105 fm. The nucleons are bound together by a short-ranged attractive potential called the residual strong force. At distances smaller than 2.5 fm, this force is much more powerful than the electrostatic force that causes positively charged protons to repel each other.
Atoms of the same element have the same number of protons, called the atomic number. Within a single element, the number of neutrons may vary, determining the isotope of that element. The number of neutrons relative to the protons determines the stability of the nucleus, with certain isotopes undergoing radioactive decay.
A nucleus that has a different number of protons than neutrons can potentially drop to a lower energy state through a radioactive decay that causes the number of protons and neutrons to more closely match. As a result, atoms with matching numbers of protons and neutrons are more stable against decay. However, with increasing atomic number, the mutual repulsion of the protons requires an increasing proportion of neutrons to maintain the stability of the nucleus, which slightly modifies this trend of equal numbers of protons to neutrons.
fuse together into a single nucleus. Nuclear fission is the opposite process, causing a nucleus to split into two smaller nuclei—usually through radioactive decay. The nucleus can also be modified through bombardment by high energy subatomic particles or photons. In such processes that change the number of protons in a nucleus, the atom becomes an atom of a different chemical element.
The mass of the nucleus following a fusion reaction is less than the sum of the masses of the separate particles. The difference between these two values is emitted as energy, as described by Albert Einstein's mass–energy equivalence formula, E = mc², where m is the mass loss and c is the speed of light. This deficit is the binding energy of the nucleus.
The fusion of two nuclei that have lower atomic numbers than iron and nickel is an exothermic process that releases more energy than is required to bring them together. It is this energy-releasing process that makes nuclear fusion in stars a self-sustaining reaction. For heavier nuclei, the total binding energy begins to decrease. That means fusion processes with nuclei that have higher atomic numbers is an endothermic process. These more massive nuclei can not undergo an energy-producing fusion reaction that can sustain the hydrostatic equilibrium of a star.
The electrons in an atom are attracted to the protons in the nucleus by the electromagnetic force. This force binds the electrons inside an electrostatic potential well surrounding the smaller nucleus, which means that an external source of energy is needed in order for the electron to escape. The closer an electron is to the nucleus, the greater the attractive force. Hence electrons bound near the center of the potential well require more energy to escape than those at the exterior.
Electrons, like other particles, have properties of both a particle and a wave. The electron cloud is a region inside the potential well where each electron forms a type of three-dimensional standing wave—a wave form that does not move relative to the nucleus. This behavior is defined by an atomic orbital, a mathematical function that characterises the probability that an electron will appear to be at a particular location when its position is measured. Only a discrete (or quantized) set of these orbitals exist around the nucleus, as other possible wave patterns will rapidly decay into a more stable form. Orbitals can have one or more ring or node structures, and they differ from each other in size, shape and orientation.
Each atomic orbital corresponds to a particular energy level of the electron. The electron can change its state to a higher energy level by absorbing a photon with sufficient energy to boost it into the new quantum state. Likewise, through spontaneous emission, an electron in a higher energy state can drop to a lower energy state while radiating the excess energy as a photon. These characteristic energy values, defined by the differences in the energies of the quantum states, are responsible for atomic spectral lines.
The amount of energy needed to remove or add an electron (the electron binding energy) is far less than the binding energy of nucleons. For example, it requires only 13.6 eV to strip a ground-state electron from a Hydrogen atom. Atoms are electrically neutral if they have an equal number of protons and electrons. Atoms that have either a deficit or a surplus of electrons are called ions. Electrons that are farthest from the nucleus may be transferred to other nearby atoms or shared between atoms. By this mechanism, atoms are able to bond into molecules and other types of chemical compounds like ionic and covalent network crystals.
By definition, any two atoms with an identical number of protons in their nuclei belong to the same chemical element. Atoms with the same number of protons but a different number of neutrons are different isotopes of the same element. Hydrogen atoms, for example, always have only a single proton, but isotopes exist with no neutrons (hydrogen-1, sometimes called protium, by far the most common form), one neutron (deuterium) and two neutrons (tritium). The known elements form a continuous range of atomic numbers from hydrogen with a single proton up to the 118-proton element ununoctium. All known isotopes of elements with atomic numbers greater than 82 are radioactive.
Because the large majority of an atom's mass comes from the protons and neutrons, the total number of these particles in an atom is called the mass number. The mass of an atom at rest is often expressed using the unified atomic mass unit (u), which is also called a Dalton (Da). This unit is defined as a twelfth of the mass of a free neutral atom of carbon-12, which is approximately 1.66&times;10−24 g. hydrogen-1, the lightest isotope of hydrogen and the atom with the lowest mass, has an atomic weight of 1.007825 u. An atom has a mass approximately equal to the mass number times the atomic mass unit. The heaviest stable atom is lead-208, with a mass of 207.9766521 u.
As even the most massive atoms are far too light to work with directly, chemists instead use the unit of moles. The mole is defined such that one mole of any element will always have the same number of atoms (about 6.022&times;1023). This number was chosen so that if an element has an atomic mass of 1 u, a mole of atoms of that element will have a mass of 1 g. Carbon, for example, has an atomic mass of 12 u, so a mole of carbon atoms weighs 12 g.
Atoms lack a well-defined outer boundary, so the dimensions are usually described in terms of the distances between two nuclei when the two atoms are joined in a chemical bond. The radius varies with the location of an atom on the atomic chart, the type of chemical bond, the number of neighboring atoms (coordination number) and a quantum mechanical property known as spin. On the periodic table of the elements, atom size tends to increase when moving down columns, but decrease when moving across rows (left to right). Consequently, the smallest atom is helium with a radius of 32 pm, while one of the largest is caesium at 225 pm. These dimensions are thousands of times smaller than the wavelengths of light (400–700 nm) so they can not be viewed using an optical microscope. However, individual atoms can be observed using a scanning tunneling microscope.
Some examples will demonstrate the minuteness of the atom. A typical human hair is about 1 million carbon atoms in width. A single drop of water contains about 2 sextillion (2) atoms of oxygen, and twice the number of hydrogen atoms. A single carat diamond with a mass of 0.2 g contains about 10 sextillion atoms of carbon. If an apple was magnified to the size of the Earth, then the atoms in the apple would be approximately the size of the original apple.
Every element has one or more isotopes that have unstable nuclei that are subject to radioactive decay, causing the nucleus to emit particles or electromagnetic radiation. Radioactivity can occur when the radius of a nucleus is large compared with the radius of the strong force, which only acts over distances on the order of 1 fm.
Each radioactive isotope has a characteristic decay time period—the half-life—that is determined by the amount of time needed for half of a sample to decay. This is an exponential decay process that steadily decreases the proportion of the remaining isotope by 50% every half life. Hence after two half-lives have passed only 25% of the isotope will be present, and so forth.
Elementary particles possess an intrinsic quantum mechanical property known as spin. This is analogous to the angular momentum of an object that is spinning around its center of mass, although strictly speaking these particles are believed to be point-like and cannot be said to be rotating. Spin is measured in units of the reduced Planck constant (), with electrons, protons and neutrons all having spin ½, or "spin-½". In an atom, electrons in motion around the nucleus possess orbital angular momentum in addition to their spin, while the nucleus itself possesses angular momentum due to its nuclear spin.
The magnetic field produced by an atom—its magnetic moment—is determined by these various forms of angular momentum, just as a rotating charged object classically produces a magnetic field. However, the most dominant contribution comes from spin. Due to the nature of electrons to obey the Pauli exclusion principle, in which no two electrons may be found in the same quantum state, bound electrons pair up with each other, with one member of each pair in a spin up state and the other in the opposite, spin down state. Thus these spins cancel each other out, reducing the total magnetic dipole moment to zero in some atoms with even number of electrons.
In ferromagnetic elements such as iron, an odd number of electrons leads to an unpaired electron and a net overall magnetic moment. The orbitals of neighboring atoms overlap and a lower energy state is achieved when the spins of unpaired electrons are aligned with each other, a process is known as an exchange interaction. When the magnetic moments of ferromagnetic atoms are lined up, the material can produce a measurable macroscopic field. Paramagnetic materials have atoms with magnetic moments that line up in random directions when no magnetic field is present, but the magnetic moments of the individual atoms line up in the presence of a field.
The nucleus of an atom can also have a net spin. Normally these nuclei are aligned in random directions because of thermal equilibrium. However, for certain elements (such as xenon-129) it is possible to polarize a significant proportion of the nuclear spin states so that they are aligned in the same direction—a condition called hyperpolarization. This has important applications in magnetic resonance imaging.
When an electron is bound to an atom, it has a potential energy that is inversely proportional to its distance from the nucleus. This is measured by the amount of energy needed to unbind the electron from the atom, and is usually given in units of electronvolts (eV). In the quantum mechanical model, a bound electron can only occupy a set of states centered on the nucleus, and each state corresponds to a specific energy level. The lowest energy state of a bound electron is called the ground state, while an electron at a higher energy level is in an excited state.
In order for an electron to transition between two different states, it must absorb or emit a photon at an energy matching the difference in the potential energy of those levels. The energy of an emitted photon is proportional to its frequency, so these specific energy levels appear as distinct bands in the electromagnetic spectrum. Each element has a characteristic spectrum that can depend on the nuclear charge, subshells filled by electrons, the electromagnetic interactions between the electrons and other factors.
When a continuous spectrum of energy is passed through a gas or plasma, some of the photons are absorbed by atoms, causing electrons to change their energy level. Those excited electrons that remain bound to their atom will spontaneously emit this energy as a photon, traveling in a random direction, and so drop back to lower energy levels. Thus the atoms behave like a filter that forms a series of dark absorption bands in the energy output. (An observer viewing the atoms from a different direction, which does not include the continuous spectrum in the background, will instead see a series of emission lines from the photons emitted by the atoms.) Spectroscopic measurements of the strength and width of spectral lines allow the composition and physical properties of a substance to be determined.
spin and motion of the outermost electron. When an atom is in an external magnetic field, spectral lines become split into three or more components; a phenomenon called the Zeeman effect. This is caused by the interaction of the magnetic field with the magnetic moment of the atom and its electrons. Some atoms can have multiple electron configurations with the same energy level, which thus appear as a single spectral line. The interaction of the magnetic field with the atom shifts these electron configurations to slightly different energy levels, resulting in multiple spectral lines. The presence of an external electric field can cause a comparable splitting and shifting of spectral lines by modifying the electron energy levels, a phenomenon called the Stark effect.
If a bound electron is in an excited state, an interacting photon with the proper energy can cause stimulated emission of a photon with a matching energy level. For this to occur, the electron must drop to a lower energy state that has an energy difference matching the energy of the interacting photon. The emitted photon and the interacting photon will then move off in parallel and with matching phases. That is, the wave patterns of the two photons will be synchronized. This physical property is used to make lasers, which can emit a coherent beam of light energy in a narrow frequency band.
behavior with other atoms. Atoms tend to chemically react with each other in a manner that will fill (or empty) their outer valence shells.
The chemical elements are often displayed in a periodic table that is laid out to display recurring chemical properties, and elements with the same number of valence electrons form a group that is aligned in the same column of the table. (The horizontal rows correspond to the filling of a quantum shell of electrons.) The elements at the far right of the table have their outer shell completely filled with electrons, which results in chemically inert elements known as the noble gases.
Quantities of atoms are found in different states of matter that depend on the physical conditions, such as temperature and pressure. By varying the conditions, materials can transition between solids, liquids, gases and plasmas. Within a state, a material can also exist in different phases. An example of this is solid carbon, which can exist as graphite or diamond.
then behaves as a single Super Atom, which may allow fundamental checks of quantum mechanical behavior.
The scanning tunneling microscope is a device for viewing surfaces at the atomic level. It uses the quantum tunneling phenomenon, which allows particles to pass through a barrier that would normally be insurmountable. Electrons tunnel through the vacuum between two planar metal electrodes, on each of which is an adsorbed atom, providing a tunneling-current density that can be measured. Scanning one atom (taken as the tip) as it moves past the other (the sample) permits plotting of tip displacement versus lateral separation for a constant current. The calculation shows the extent to which scanning-tunneling-microscope images of an individual atom are visible. It confirms that for low bias, the microscope images the space-averaged dimensions of the electron orbitals across closely packed energy levels—the Fermi level local density of states.
An atom can be ionized by removing one of its electrons. The electric charge causes the trajectory of an atom to bend when it passes through a magnetic field. The radius by which the trajectory of a moving ion is turned by the magnetic field is determined by the mass of the atom. The mass spectrometer uses this principle to measure the mass-to-charge ratio of ions. If a sample contains multiple isotopes, the mass spectrometer can determine the proportion of each isotope in the sample by measuring the intensity of the different beams of ions. Techniques to vaporize atoms include inductively coupled plasma atomic emission spectroscopy and inductively coupled plasma mass spectrometry, both of which use a plasma to vaporize samples for analysis.
A more area-selective method is electron energy loss spectroscopy, which measures the energy loss of an electron beam within a transmission electron microscope when it interacts with a portion of a sample. The atom-probe tomograph has sub-nanometer resolution in 3-D and can chemically identify individual atoms using time-of-flight mass spectrometry.
Spectra of excited states can be used to analyze the atomic composition of distant stars. Specific light wavelengths contained in the observed light from stars can be separated out and related to the quantized transitions in free gas atoms. These colors can be replicated using a gas-discharge lamp containing the same element. Helium was discovered in this way in the spectrum of the Sun 23 years before it was found on Earth.
Stable protons and electrons appeared one second after the Big Bang. During the following three minutes, Big Bang nucleosynthesis produced most of the helium, lithium, and deuterium atoms in the universe, and perhaps some of the beryllium and boron. The first atoms (complete with bound electrons) were theoretically created 380,000 years after the Big Bang—an epoch called recombination, when the expanding universe cooled enough to allow electrons to become attached to nuclei. Since then, atomic nuclei have been combined in stars through the process of nuclear fusion to produce elements up to iron.
Isotopes such as lithium-6 are generated in space through cosmic ray spallation. This occurs when a high-energy proton strikes an atomic nucleus, causing large numbers of nucleons to be ejected. Elements heavier than iron were produced in supernovae through the r-process and in AGB stars through the s-process, both of which involve the capture of neutrons by atomic nuclei. Elements such as lead formed largely through the radioactive decay of heavier elements.
Most of the atoms that make up the Earth and its inhabitants were present in their current form in the nebula that collapsed out of a molecular cloud to form the solar system. The rest are the result of radioactive decay, and their relative proportion can be used to determine the age of the Earth through radiometric dating. Most of the helium in the crust of the Earth (about 99% of the helium from gas wells, as shown by its lower abundance of helium-3) is a product of alpha decay.
There are a few trace atoms on Earth that were not present at the beginning (i.e. not "primordial"), nor are results of radioactive decay. Carbon-14 is continuously generated by cosmic rays in the atmosphere. Some atoms on Earth have been artificially generated either deliberately or as by-products of nuclear reactors or explosions. Of the transuranic elements—those with atomic numbers greater than 92—only plutonium and neptunium occur naturally on Earth. Transuranic elements have radioactive lifetimes shorter than the current age of the Earth and thus identifiable quantities of these elements have long since decayed, with the exception of traces of plutonium-244 possibly deposited by cosmic dust. Natural deposits of plutonium and neptunium are produced by neutron capture in uranium ore.
The Earth contains approximately 1.33 atoms. In the planet's atmosphere, small numbers of independent atoms exist for the noble gases, such as argon and neon. The remaining 99% of the atmosphere is bound in the form of molecules, including carbon dioxide and diatomic oxygen and nitrogen. At the surface of the Earth, atoms combine to form various compounds, including water, salt, silicates and oxides. Atoms can also combine to create materials that do not consist of discrete molecules, including crystals and liquid or solid metals. This atomic matter forms networked arrangements that lack the particular type of small-scale interrupted order associated with molecular matter.
While isotopes with atomic numbers higher than lead (82) are known to be radioactive, an "island of stability" has been proposed for some elements with atomic numbers above 103. These superheavy elements may have a nucleus that is relatively stable against radioactive decay. The most likely candidate for a stable superheavy atom, unbihexium, has 126 protons and 184 neutrons.
Each particle of matter has a corresponding antimatter particle with the opposite electrical charge. Thus, the positron is a positively charged antielectron and the antiproton is a negatively charged equivalent of a proton. For unknown reasons, antimatter particles are rare in the universe, hence, no antimatter atoms have been discovered. Antihydrogen, the antimatter counterpart of hydrogen, was first produced at the CERN laboratory in Geneva in 1996.
Other exotic atoms have been created by replacing one of the protons, neutrons or electrons with other particles that have the same charge. For example, an electron can be replaced by a more massive muon, forming a muonic atom. These types of atoms can be used to test the fundamental predictions of physics.


In geography, arable land (from Latin arare, to plough) is an agricultural term, meaning land that can be used for growing crops.
Of the earth's 148,000,000 km² (57 million square miles) of land, approximately 31,000,000 km² (12 million square miles) are arable; however, arable land is currently being lost at the rate of over 100,000 km² (38,610 square miles) per year. A major element of arable land loss comes from deforestation (starting in the Middle Ages in Europe as well as Asia). Such deforestation continues to the present day primarily in tropical countries by commercial over-exploitation of tropical forest. At times, deforestation can be so extreme that it leads to desertification, or the total loss of arable land, as has occurred in portions of the central highland plateau of Madagascar following extensive slash-and-burn activity.
A smaller, but important loss of arable land arises from the lack of renewal of rich flooding sediment due to flood control works. A large part of the arable land on earth is around the largest rivers on earth; for example, the Nile River, the Mississippi River, the Tigris and Euphrates Rivers, the Yellow River, the Amazon River, the Ganges and the Rhine River.
The most productive portion of arable land is that from sediments left by those rivers and the sea in geological times. In modern times, the rivers do not generally flood as much agricultural land, due to the demands of flood control to support intensive agriculture required of a heavily-populated Earth.
The Nile continues to flood regularly, overspilling its banks. When the flood is over, the waters recede, leaving behind rich silt. This silt provides excellent fertilizer for crops. Even if the land is over-farmed and all the nutrients are depleted from the soil, the land renews its fertility when new deposits of silt arrive following the next flood. Flood-control projects in the region, such as levees, may increase human comfort but cause substantial adverse impact to the quantity and quality of arable land.
Land which is unsuitable for arable farming usually has at least one of the following deficiencies: no source of fresh water; too hot (desert); too cold (Arctic); too rocky; too mountainous; too salty; too rainy; too snowy; too polluted; or too nutrient poor. Clouds may block the sunlight plants need for photosynthesis (making sunlight into food), reducing productivity. Plants can starve without light. Starvation and nomadism often exists on marginally arable land. Non-arable land is sometimes called wasteland, badlands, worthless or "no man's land".
However, non-arable land can be converted into arable land. New arable land makes more food, and can reduce starvation. This outcome also makes a country more self-sufficient and politically independent, because food importation is reduced. Making non-arable land arable often involves digging new irrigation canals and new wells, aqueducts, desalination plants, planting trees for shade in the desert, hydroponics, fertilizer, nitrogen fertilizer, pesticides, reverse osmosis water processors, PET film insulation or other insulation against heat and cold, digging ditches and hills for protection against the wind, and greenhouses with internal light and heat for protection against the cold outside and to provide light in cloudy areas. This process is often extremely expensive.


Aluminium (, /ˌæljəˈmɪniəm/) or aluminum (/əˈluːmɪnəm/, see spelling below) is a silvery white and ductile member of the boron group of chemical elements. It has the symbol Al; its atomic number is 13. It is not soluble in water under normal circumstances.
Aluminium is the most abundant metal in the Earth's crust, and the third most abundant element overall, after oxygen and silicon. It makes up about 8% by weight of the Earth’s solid surface. Aluminium is too reactive chemically to occur in nature as the free metal. Instead, it is found combined in over 270 different minerals. The chief source of aluminium is bauxite ore.
Aluminium is remarkable for its ability to resist corrosion (due to the phenomenon of passivation) and its light weight. Structural components made from aluminium and its alloys are vital to the aerospace industry and very important in other areas of transportation and building. Its reactive nature makes it useful as a catalyst or additive in chemical mixtures, including being used in ammonium nitrate explosives to enhance blast power.
Aluminium is a soft, lightweight, malleable metal with appearance ranging from silvery to dull gray, depending on the surface roughness. Aluminium is nontoxic, nonmagnetic, and nonsparking. It is also insoluble in alcohol, though it can be soluble in water only in certain forms. The yield strength of pure aluminium is 7–11 MPa, while aluminium alloys have yield strengths ranging from 200 MPa to 600 MPa. Aluminium has about one-third the density and stiffness of steel. It is ductile, and easily machined, cast, and extruded.
Corrosion resistance is excellent due to a thin surface layer of aluminium oxide that forms when the metal is exposed to air, effectively preventing further oxidation. The strongest aluminium alloys are less corrosion resistant due to galvanic reactions with alloyed copper.
Aluminium atoms are arranged in an face-centered cubic (FCC) structure. Aluminium has a high stacking-fault energy of approximately 200 mJ/m².
Aluminium is one of the few metals that retain full silvery reflectance in finely powdered form, making it an important component of silver paints. Aluminium mirror finish has the highest reflectance of any metal in the 200–400 nm (UV) and the 3000–10000 nm (far IR) regions, while in the 400–700 nm visible range it is slightly outdone by tin and silver and in the 700–3000 (near IR) by silver, gold, and copper.
Aluminium is a good thermal and electrical conductor, by weight better than copper. Aluminium is capable of being a superconductor, with a superconducting critical temperature of 1.2 kelvins.
Aluminium has nine isotopes, whose mass numbers range from 23 to 30. Only 27Al (stable isotope) and 26Al (radioactive isotope, t1/2 = 7.2 × 105 y) occur naturally, however 27Al has a natural abundance of 99.9+ %. 26Al is produced from argon in the atmosphere by spallation caused by cosmic-ray protons. Aluminium isotopes have found practical application in dating marine sediments, manganese nodules, glacial ice, quartz in rock exposures, and meteorites. The ratio of 26Al to 10Be has been used to study the role of transport, deposition, sediment storage, burial times, and erosion on 105 to 106 year time scales. Cosmogenic 26Al was first applied in studies of the Moon and meteorites. Meteorite fragments, after departure from their parent bodies, are exposed to intense cosmic-ray bombardment during their travel through space, causing substantial 26Al production. After falling to Earth, atmospheric shielding protects the meteorite fragments from further 26Al production, and its decay can then be used to determine the meteorite's terrestrial age. Meteorite research has also shown that 26Al was relatively abundant at the time of formation of our planetary system. Most meteoriticists believe that the energy released by the decay of 26Al was responsible for the melting and differentiation of some asteroids after their formation 4.55 billion years ago.
In the Earth's crust, Aluminium is the most abundant (8.13%) metallic element, and the third most abundant of all elements (after oxygen and silicon). However, because of its strong affinity to oxygen, it is not found in the elemental state but only in combined forms such as oxides or silicates. Aluminium is found in the Lithosphere. The most common form it is found in is that of Bauxite.
Although aluminium is the most abundant metallic element in the Earth's crust (believed to be 7.5 to 8.1 percent), it is rare in its free form, occurring in oxygen-deficient environments such as volcanic mud, and it was once considered a precious metal more valuable than gold. Napoleon III, emperor of the French, is reputed to have given a banquet where the most honoured guests were given aluminium utensils, while the other guests had to make do with gold ones. Aluminium has been produced in commercial quantities for just over 100 years.
Here the aluminium ion is being reduced (electrons are added). The aluminium metal then sinks to the bottom and is tapped off.
Unlike the anodes, the cathodes are not oxidized because there is no oxygen present at the cathode. The carbon cathode is protected by the liquid aluminium inside the cells. Nevertheless, cathodes do erode, mainly due to electrochemical processes. After five to ten years, depending on the current used in the electrolysis, a cell has to be rebuilt because of cathode wear.
Aluminium electrolysis with the Hall-Héroult process consumes a lot of energy, but alternative processes were always found to be less viable economically and/or ecologically. The world-wide average specific energy consumption is approximately 15±0.5 kilowatt-hours per kilogram of aluminium produced from alumina. (52 to 56 MJ/kg). The most modern smelters reach approximately 12.8 kW·h/kg (46.1 MJ/kg). (Compare this to the heat of reaction, 31 MJ/kg, and the Gibbs free energy of reaction, 29 MJ/kg.) Reduction line current for older technologies are typically 100 to 200 kA. State-of-the-art smelters operate with about 350 kA. Trials have been reported with 500 kA cells.
Recovery of the metal via recycling has become an important facet of the aluminium industry. Recycling involves melting the scrap, a process that uses only five percent of the energy needed to produce aluminium from ore. However, a significant part (up to 15% of input material) is lost as dross (ash-like oxide). Recycling was a low-profile activity until the late 1960s, when the growing use of aluminium beverage cans brought it to the public consciousness.
Electric power represents about 20% to 40% of the cost of producing aluminium, depending on the location of the smelter. Smelters tend to be situated where electric power is both plentiful and inexpensive, such as South Africa, the South Island of New Zealand, Australia, the People's Republic of China, the Middle East, Russia, Quebec and British Columbia in Canada, and Iceland.
In 2005, the People's Republic of China was the top producer of aluminium with almost one-fifth world share followed by Russia, Canada and USA reports the British Geological Survey.
Over the last 50 years, Australia has become a major producer of bauxite ore and a major producer and exporter of alumina. Australia produced 62 million tonnes of bauxite in 2005. The Australian deposits have some refining problems, some being high in silica but have the advantage of being shallow and relatively easy to mine.
Aluminium halides usually exist in the form AlX3.
e.g. AlF3, AlCl3, AlBr3, AlI3 etc.
In the journal Science of 14 January 2005 it was reported that clusters of 13 aluminium atoms (Al13) had been made to behave like an iodine atom; and, 14 aluminium atoms (Al14) behaved like an alkaline earth atom. The researchers also bound 12 iodine atoms to an Al13 cluster to form a new class of polyiodide. This discovery is reported to give rise to the possibility of a new characterisation of the periodic table: superatoms. The research teams were led by Shiv N. Khanna (Virginia Commonwealth University) and A. Welford Castleman Jr (Penn State University).
Aluminium is the most widely used non-ferrous metal. Global production of aluminium in 2005 was 31.9 million tonnes. It exceeded that of any other metal except iron (837.5 million tonnes).
Relatively pure aluminium is encountered only when corrosion resistance and/or workability is more important than strength or hardness. A thin layer of aluminium can be deposited onto a flat surface by physical vapor deposition or (very infrequently) chemical vapor deposition or other chemical means to form optical coatings and mirrors. When so deposited, a fresh, pure aluminium film serves as a good reflector (approximately 92%) of visible light and an excellent reflector (as much as 98%) of medium and far infrared.
Pure aluminium has a low tensile strength, but when combined with thermo-mechanical processing, aluminium alloys display a marked improvement in mechanical properties, especially when tempered. Aluminium alloys form vital components of aircraft and rockets as a result of their high strength-to-weight ratio. Aluminium readily forms alloys with many elements such as copper, zinc, magnesium, manganese and silicon (e.g. duralumin). Today, almost all bulk metal materials that are referred to loosely as "aluminium," are actually alloys. For example, the common aluminium foils are alloys of 92% to 99% aluminium.
Aluminium alloys with a wide range of properties are used in engineering structures. Alloy systems are classified by a number system (ANSI) or by names indicating their main alloying constituents (DIN and ISO).
One important structural limitation of aluminium alloys is their fatigue strength. Unlike steels, aluminium alloys have no well-defined fatigue limit, meaning that fatigue failure will eventually occur under even very small cyclic loadings. This implies that engineers must assess these loads and design for a fixed life rather than an infinite life.
Another important property of aluminium alloys is their sensitivity to heat.
Workshop procedures involving heating are complicated by the fact that aluminium, unlike steel, will melt without first glowing red. Forming operations where a blow torch is used therefore requires some expertise, since no visual signs reveal how close the material is to melting. Aluminium alloys, like all structural alloys, also are subject to internal stresses following heating operations such as welding and casting. The problem with aluminium alloys in this regard is their low melting point, which make them more susceptible to distortions from thermally induced stress relief. Controlled stress relief can be done during manufacturing by heat-treating the parts in an oven, followed by gradual cooling -- in effect annealing the stresses.
The low melting point of aluminium alloys has not precluded their use in rocketry; even for use in constructing combustion chambers where gases can reach 3500 K. The Agena upper stage engine used a regeneratively cooled aluminium design for some parts of the nozzle, including the thermally critical throat region.
Aluminium has about 65% of the conductivity of copper, the traditional household wiring material. In the 1960s aluminium was considerably cheaper than copper, and so was introduced for household electrical wiring in the United States, even though many fixtures had not been designed to accept aluminium wire. However, in some cases the greater coefficient of thermal expansion of aluminium causes the wire to expand and contract relative to the dissimilar metal screw connection, eventually loosening the connection. Also, pure aluminium has a tendency to creep under steady sustained pressure (to a greater degree as the temperature rises), again loosening the connection. Finally, Galvanic corrosion from the dissimilar metals increased the electrical resistance of the connection.
All of this resulted in overheated and loose connections, and this in turn resulted in fires. Builders then became wary of using the wire, and many jurisdictions outlawed its use in very small sizes in new construction. Eventually, newer fixtures were introduced with connections designed to avoid loosening and overheating. At first they were marked "Al/Cu", but they now bear a "CO/ALR" coding. In older assemblies, workers forestall the heating problem using a properly-done crimp of the aluminium wire to a short "pigtail" of copper wire. Today, new alloys, designs, and methods are used for aluminium wiring in combination with aluminium terminations.
Ancient Greeks and Romans used aluminium salts as dyeing mordants and as astringents for dressing wounds; alum is still used as a styptic. In 1761 Guyton de Morveau suggested calling the base alum alumine. In 1808, Humphry Davy identified the existence of a metal base of alum, which he at first termed alumium and later aluminum (see Etymology section, below).
Friedrich Wöhler is generally credited with isolating aluminium (Latin alumen, alum) in 1827 by mixing anhydrous aluminium chloride with potassium. As the metal had first been produced two years earlier (in an impure form) by Danish physicist and chemist Hans Christian Ørsted, Ørsted can also be listed as its discoverer. Further, Pierre Berthier discovered aluminium in bauxite ore and successfully extracted it. Frenchman Henri Etienne Sainte-Claire Deville improved Wöhler's method in 1846, and described his improvements in a book in 1859, chief among these being the substitution of sodium for the considerably more expensive potassium.
Before the Hall-Héroult process was developed, aluminium was exceedingly difficult to extract from its various ores. This made pure aluminium more valuable than gold. Bars of aluminium were exhibited alongside the French crown jewels at the Exposition Universelle of 1855, and Napoleon III was said to have reserved a set of aluminium dinner plates for his most honored guests.
Aluminium was selected as the material to be used for the apex of the Washington Monument in 1884, a time when one ounce (30 grams) cost the daily wage of a common worker on the project; aluminium was about the same value as silver.
The Cowles companies supplied aluminium alloy in quantity in the United States and England using smelters like the furnace of Carl Wilhelm Siemens by 1886. Charles Martin Hall of Ohio in the U.S. and Paul Héroult of France independently developed the Hall-Héroult electrolytic process that made extracting aluminium from minerals cheaper and is now the principal method used worldwide. The Hall-Heroult process cannot produce Super Purity Aluminium directly. Hall's process, in 1888 with the financial backing of Alfred E. Hunt, started the Pittsburgh Reduction Company today known as Alcoa. Héroult's process was in production by 1889 in Switzerland at Aluminium Industrie, now Alcan, and at British Aluminium, now Luxfer Group and Alcoa, by 1896 in Scotland.
By 1895 the metal was being used as a building material as far away as Sydney, Australia in the dome of the Chief Secretary's Building.
In November 2007 the price of aluminium on NYMEX was around $1.10 or $1.20 a pound.
The -ium suffix had the advantage of conforming to the precedent set in other newly discovered elements of the time: potassium, sodium, magnesium, calcium, and strontium (all of which Davy had isolated himself). Nevertheless, -um spellings for elements were not unknown at the time, as for example platinum, known to Europeans since the sixteenth century, molybdenum, discovered in 1778, and tantalum, discovered in 1802.
Americans adopted -ium to fit the standard form of the periodic table of elements, for most of the nineteenth century, with aluminium appearing in Webster's Dictionary of 1828. In 1892, however, Charles Martin Hall used the -um spelling in an advertising handbill for his new electrolytic method of producing the metal, despite his constant use of the -ium spelling in all the patents he filed between 1886 and 1903. It has consequently been suggested that the spelling reflects an easier to pronounce word with one fewer syllable, or that the spelling on the flier was a mistake. Hall's domination of production of the metal ensured that the spelling aluminum became the standard in North America; the Webster Unabridged Dictionary of 1913, though, continued to use the -ium version.
In 1926, the American Chemical Society officially decided to use aluminum in its publications; American dictionaries typically label the spelling aluminium as a British variant.
In the UK and other countries using British spelling, only aluminium is used. In the United States, the spelling aluminium is largely unknown, and the spelling aluminum predominates. The Canadian Oxford Dictionary prefers aluminum, whereas the Australian Macquarie Dictionary prefers aluminium. The spelling in virtually all other languages is analogous to the -ium ending.
The International Union of Pure and Applied Chemistry (IUPAC) adopted Aluminium as the standard international name for the element in 1990, but three years later recognized aluminum as an acceptable variant. Hence their periodic table includes both, but places aluminium first. IUPAC officially prefers the use of Aluminium in its internal publications, although several IUPAC publications use the spelling aluminum.
The toxicity of aluminium can be traced to increased deposition in bone and the central nervous system, particularly in the presence of reduced renal function. Because aluminium competes with calcium for absorption, increased amounts of dietary aluminium may contribute to the reduced skeletal mineralization (osteopenia) observed in preterm infants and infants with growth retardation. Full-term infants with normal renal function do not seem to be at substantial risk from aluminium toxicity from soy protein-based formulas.
Aluminium can cause neurotoxicity in very high doses which can alter the function of the blood-brain barrier. It is one of the few abundant elements that have no known function in living cells. A small percentage of people are allergic to it — they experience contact dermatitis: an itchy rash from using styptic or antiperspirant products, digestive disorders and inability to absorb nutrients from eating food cooked in aluminium pans, and vomiting and other symptoms of poisoning from ingesting such products as Amphojel, and Maalox (antacids). Such allergies are extremely rare though, in other people aluminium is not considered as toxic as heavy metals, but there is evidence of some toxicity if it is consumed in excessive amounts. The use of aluminium cookware, popular because of its corrosion resistance and good heat conduction, has not been shown to lead to aluminium toxicity in general. Excessive consumption of antacids containing aluminium compounds and excessive use of aluminium-containing antiperspirants are more likely causes of toxicity. Aluminium increases estrogen-related gene expression in human breast cancer cells grown in the laboratory. These salts' estrogen-like effects have led to their classification as a metalloestrogen.
It has been suggested that aluminium is a cause of Alzheimer's disease, as some brain plaques have been found to contain the metal. Research in this area has been inconclusive; aluminium accumulation may be a consequence of the Alzheimer's damage, not the cause. In any event, if there is any toxicity of aluminium it must be via a very specific mechanism, since total human exposure to the element in the form of naturally occurring clay in soil and dust is enormously large over a lifetime.
Mercury applied to the surface of an aluminium alloy can damage the protective oxide surface film by forming amalgam. This may cause further corrosion and weakening of the structure. For this reason, mercury thermometers are not allowed on many airliners, as aluminium is used in many aircraft structures.
Powdered aluminium can react with Fe2O3 to form Fe and Al2O3. This mixture is known as thermite, which burns with a high energy output. Thermite can be produced inadvertently during grinding operations, but the high ignition temperature makes incidents unlikely in most workshop environments.
Aluminium is primary among the factors that contribute to the loss of plant production on acid soils. Although it is generally harmless to plant growth in pH-neutral soils, the concentration in acid soils of toxic Al3+ cations increases and disturbs root growth and function.
Wheat's adaptation to allow aluminium tolerance is such that the aluminium induces a release of organic compounds that bind to the harmful aluminium cations. Sorghum is believed to have the same tolerance mechanism. The first gene for aluminium tolerance has been identified in wheat. A group in the U.S. Department of Agriculture showed that sorghum's aluminium tolerance is controlled by a single gene, as for wheat. This is not the case in all plants.


Advanced Chemistry is a German hip hop group from Heidelberg, a scenic city in Baden-Württemberg, South Germany. Advanced Chemistry was founded in 1987 by Toni L, Linguist, Gee-One, DJ Mike MD (Mike Dippon) and MC Torch. Nowadays, it is said that the original members of the Advanced Chemistry are the pioneers of German HipHop, although another hip hop band called "Die Fantastischen Vier" has dropped two singles and one album on a major label in 1991.
Influenced by North American conscious rap and the Native tongues movement, the central subjects of Advanced Chemistry's lyrics were politically and intellectually motivated and focused mainly on their identity as Germans of foreign descent and the status of hip hop around the world.
Several years after the founding, Gee One and DJ Mike MD left the group for realizing new dreams. Members include Toni L, Linguist, Torch; affiliated: Boulevard Bou.


Abdication (from the Latin abdicatio, disowning, renouncing, from ab, away from, and dicare, to declare, to proclaim as not belonging to one) is the act of renouncing and resigning from a formal office, especially from the supreme office of state. In Roman law the term was also applied to the disowning of a family member, as the disinheriting of a son. The term commonly applies to monarchs, or those who have been formally crowned. A similar term for an elected or appointed official is resignation.
Among the most memorable abdications of antiquity were those of Lucius Cornelius Sulla the Dictator in 79 BC, Emperor Diocletian in AD 305, and Emperor Romulus Augustulus in AD 476.
Probably the most famous abdication in recent memory is that of King Edward VIII of the United Kingdom in 1936. Edward abdicated the British throne in order to marry American divorcée Wallis Simpson, over the objections of the British establishment, the governments of the Commonwealth, the royal family and the Church of England. (See Abdication Crisis of Edward VIII.) This was also the first time in history that the British crown was surrendered entirely voluntarily. Richard II of England, for example, was forced to abdicate after the throne was seized by his cousin, Henry Bolingbroke, while Richard was out of the country.
When James II of England, after throwing the Great Seal of the Realm into the Thames, fled to France in 1688, he did not formally resign the crown, and the question was discussed in Parliament whether he had forfeited the throne or had abdicated. The latter designation was agreed upon, for, in a full assembly of the Lords and Commons, it was resolved in spite of James's protest "that King James II having endeavoured to subvert the constitution of the kingdom, by breaking the original contract between king and people, and, by the advice of Jesuits and other wicked persons, having violated the fundamental laws, and having withdrawn himself out of this kingdom, has abdicated the government, and that the throne is thereby vacant." The Scottish parliament pronounced a decree of forfeiture and deposition.
Because the title to the Crown depends upon statute, particularly the Act of Settlement 1701, a Royal Abdication can only be effected by an Act of Parliament; under the terms of the Statute of Westminster 1931, such an act must be passed by the parliament of all sixteen Commonwealth realms. To give legal effect to the abdication of King Edward VIII of the United Kingdom, His Majesty's Declaration of Abdication Act 1936 was passed.
Historically, if a monarch abdicated it was seen as a profound and shocking abandonment of royal duty. As a result, abdications usually only occurred in the most extreme circumstances of political turmoil or violence. This has changed in a small number of countries: the monarchs of the Netherlands, Luxembourg and Cambodia have abdicated as a result of old age. Prince Hans-Adam II of Liechtenstein recently made his son regent, an act which amounted to an abdication in fact if not in law.
1Charles abdicated as lord of the Netherlands (October 25, 1555) and king of Spain (January 16, 1556), in favor of his son Philip II of Spain. Also in 1556 he separately voluntarily abdicated his German possessions and the title of Holy Roman Emperor.
²Pedro IV of Portugal and Pedro I of Brazil were the same person. He was already Emperor of Brazil when he succeeded to the throne of Portugal in 1826, but abdicated it at once in favour of his daughter Maria II of Portugal. Later he abdicated the throne of Brazil in favor of his son Pedro II.
³Hans-Adam II made his son Alois regent, effectively abdicating; however, he still remains the formal Head of State.


The Anglican Communion is a world-wide affiliation of Anglican Churches. There is no single "Anglican Church" with universal juridical authority, since each national or regional church has full autonomy. As the name suggests, the Anglican Communion is an association of these churches in full communion with the Church of England (which may be regarded as the "mother church" of the worldwide communion), and specifically with its primate, the Archbishop of Canterbury. With over seventy-seven million members, the Anglican Communion is the third largest communion in the world, after the Roman Catholic Church and the Eastern Orthodox Churches.
The status of full communion means that all rites conducted in one church are recognised by the other. Some of these churches are known as Anglican, explicitly recognising the link to England (Ecclesia Anglicana means "Church of England"); others, such as the American and Scottish Episcopal churches, or the Church of Ireland, prefer a separate name. Each church has its own doctrine and liturgy, based in most cases on that of the Church of England; and each church has its own legislative process and overall episcopal polity, under the leadership of a local primate.
The Archbishop of Canterbury, religious head of the Church of England, has no formal authority outside that jurisdiction, but is recognised as symbolic head of the worldwide communion. Among the other primates, he is primus inter pares, or "first among equals".
The Anglican Communion considers itself to be part of the One, Holy, Catholic, and Apostolic Church and as being both Catholic and Reformed. For some adherents it represents a non-papal Catholicism, for others a form of Protestantism though without a dominant guiding figure such as Luther, Knox, Calvin, Zwingli or Wesley. For others, their self-identity represents some combination of the two. The communion encompasses a wide spectrum of belief and practice including evangelical, liberal, and catholic.
The Anglican Communion is one of the largest Christian denominations in the world with approximately 77 million members.
The Anglican Communion has no official legal existence nor any governing structure which might exercise authority over the member churches. There is an Anglican Communion Office in London, under the aegis of the Archbishop of Canterbury; but it serves merely a supporting and organisational role. Instead, the communion is held together by a shared history, expressed in its ecclesiology, polity, and ethos; and by participation in international consultative bodies.
Three elements have been important in holding the Communion together: First, the shared ecclesial structure of the churches, manifested in an episcopal polity maintained through the apostolic succession of bishops and synodical government; second, the principle of belief expressed in worship, investing importance in approved prayer books and their rubrics; and third, the historical documents and standard divines that have influenced the ethos of the Communion.
Originally, the Church of England was self-contained, and relied for its unity and identity on its own history, its traditional legal and episcopal structure, and its status as an established church of the state. As such, Anglicanism was from the outset a movement with an explicitly episcopal polity, a characteristic which has been vital in maintaining the unity of the Communion by conveying the episcopate's role in manifesting visible catholicity and ecumenism.
Early in its development, the Church developed a vernacular prayer book, called the Book of Common Prayer. Unlike other traditions, Anglicanism has never been governed by a magisterium nor by appeal to a founding theologian, nor by an extra-credal summary of doctrine (such as the Westminster Confession of the Presbyterian Church). Instead, Anglicans have typically appealed to the Book of Common Prayer and its offshoots as a guide to Anglican theology and practice. This had the effect of inculcating the principle of lex orandi, lex credendi ("the law of prayer is the law of belief") as the foundation of Anglican identity and confession.
Protracted conflict through the seventeenth century with more radical Protestants on the one hand and Roman Catholics who still recognised the primacy of the Pope on the other, resulted in a Church that was both deliberately vague about doctrinal principles, yet bold in developing parameters of acceptable deviation. These parameters were most clearly articulated in the various rubrics of the successive prayer books, as well as the Thirty-Nine Articles of Religion. These Articles, while never binding, have had an influence on the ethos of the Communion, an ethos reinforced by their interpretation and expansion by such influential early theologians as Richard Hooker, Lancelot Andrewes, John Cosin, and others.
Since there is no binding authority in the Communion, these international bodies are a vehicle for consultation and persuasion. In recent years, persuasion has tipped over into debates over conformity in certain areas of doctrine, discipline, worship, and ethics. The most notable example has been the objection of many provinces of the Communion (particularly in Africa; Asia; and Sydney, Australia) to the changing role of homosexuals in the North American churches (e.g. by blessing same-sex unions and ordaining and consecrating gays and lesbians in same-sex relationships), and to the process by which changes were undertaken. Those who objected condemned these actions as unscriptural, unilateral, and without the agreement of the Communion prior to these steps being taken. In response, the American Episcopal Church and the Anglican Church of Canada answered that the actions had been undertaken after lengthy scriptural and theological reflection, legally in accordance with their own canons and constitutions and after extensive consultation with the provinces of the Communion.
The Primates' Meeting voted to request the two churches to withdraw their delegates from the 2005 meeting of the Anglican Consultative Council, and Canada and the United States decided to attend the meeting but without exercising their right to vote. They have not been expelled or suspended, since there is no mechanism in this voluntary association to suspend or expel an independent province of the Communion. Since membership is based on a province's communion with Canterbury, expulsion would require the Archbishop of Canterbury's refusal to be in communion with the affected jurisdiction(s). In line with the suggestion of the Windsor Report, Dr Williams has recently established a working group to examine the feasibility of an Anglican covenant which would articulate the conditions for communion in some fashion.
In addition, there are six extra-provincial churches, five of which are under the metropolitical authority of the Archbishop of Canterbury.
The Anglican Communion is a relatively recent concept. The Church of England (which until the 20th century included the Church in Wales) initially split with the Roman Churches in 1538, rejoined in 1555 and split again during the reign of Elizabeth I (the Roman Catholic Church excommunicated Elizabeth I in response to the 1558 Act of Settlement). The Church of England has always thought of itself not as a new foundation but rather as a reformed continuation of the ancient "English church" and a reassertion of that church's rights. As such it was a distinctly local phenomenon.
Thus the only members of the present Anglican Communion existing by the mid-18th century were the Church of England, its closely-linked sister church, the Church of Ireland (which was also established under Henry VIII), and the Scottish Episcopal Church, which for parts of the 17th and 18th centuries was partially underground (it was suspected of Jacobite sympathies).
However, the enormous expansion in the 18th and 19th centuries of the British Empire brought the church along with it. At first all these colonial churches were under the jurisdiction of the Bishop of London. After the American Revolution, the parishes in the newly independent country found it necessary to break formally from a church whose Supreme Governor was (and remains) the British monarch. Thus they formed their own dioceses and national church, the Episcopal Church in the United States of America, in a mostly amicable separation.
At about the same time, in the colonies which remained linked to the crown, the Church of England began to appoint colonial bishops. In 1787 a bishop of Nova Scotia was appointed with a jurisdiction over all of British North America; in time several more colleagues were appointed to other cities in present-day Canada. In 1814 a bishop of Calcutta was made; in 1824 the first bishop was sent to the West Indies and in 1836 to Australia. By 1840 there were still only ten colonial bishops for the Church of England; but even this small beginning greatly facilitated the growth of Anglicanism around the world. In 1841 a "Colonial Bishoprics Council" was set up and soon many more dioceses were created.
In time, it became natural to group these into provinces, and a metropolitan appointed for each province. Although it had at first been somewhat established in many colonies, in 1861 it was ruled that, except where specifically established, the Church of England had just the same legal position as any other church. Thus a colonial bishop and colonial diocese was by nature quite a different thing from their counterparts back home. In time bishops came to be appointed locally rather than from England, and eventually national synods began to pass ecclesiastical legislation independent of England.
A crucial step in the development of the modern communion was the idea of the Lambeth Conferences, as discussed above. These conferences demonstrated that the bishops of disparate churches could manifest the unity of the church in their episcopal collegiality, despite the absence of universal legal ties. Some bishops were initially reluctant to attend, fearing that the meeting would declare itself a council with power to legislate for the church; but it agreed to pass only advisory resolutions. These Lambeth Conferences have been held roughly decennially since 1878 (the second such conference), and remain the most visible coming-together of the whole Communion.
The Anglican Communion hold that Apostolic Succession is a core element of the validity of clerical ordinations. The Roman Catholic Church does not recognize Anglican orders (see Apostolicae Curae). The Eastern Orthodox Churches and Oriental Orthodox churches have traditionally accepted the validity of Anglican orders.
One effect of the Communion's dispersed authority has been that conflict and controversy regularly arise over the effect divergent practices and doctrines in one part of the Communion have on others. Disputes that had been confined to the Church of England could be dealt with legislatively in that realm, but as the Communion spread out into new nations and disparate cultures, such controversies multiplied and intensified. These controversies have generally been of two types: liturgical and social.
The first such controversy of note concerned that of the growing influence of the Catholic Revival manifested in the so-called ritualism controversies of the late nineteenth and early twentieth centuries. Later, rapid social change and the dissipation of British cultural hegemony over its former colonies contributed to disputes over the role of women, the parameters of marriage and divorce, and the practice of contraception and abortion. More recently, disagreements over homosexuality have strained the unity of the Communion as well as its relationships with other Christian denominations (see Anglican views of homosexuality and Anglican realignment). Simultaneous with debates about social theology and ethics, the Communion has debated prayer book revision and the acceptable grounds for achieving full communion with non-Anglican churches.

Arne Kaijser (born 1950) is a professor of History of Technology at the Royal Institute of Technology in Stockholm, and the head of the university's department of History of science and technology.
Kaijser has published two books in Swedish: Stadens ljus. Etableringen av de första svenska gasverken and I fädrens spår. Den svenska infrastrukturens historiska utveckling och framtida utmaningar, and has co-edited several anthologies. Kaijser is also a member of the editorial board of two scientific journals: Journal of Urban Technology and Centaurus. Lately, he has been occupied with the history of Large Technical Systems.

An archipelago is a chain or cluster of islands. The word archipelago literally means "chief sea", from Greek arkhon (arkhi-) ("leader") and pelagos" ("sea"). In antiquity, the Archipelago (Greek: Αρхιπέλαγος) was the proper name for the Aegean Sea and, later, usage shifted to refer to the Aegean Islands (since the sea is remarkable for its large number of islands). It is now used to generally refer to any island group or, sometimes, to a sea containing a large number of scattered islands like the Aegea.
Archipelagoes are usually found in the open sea; less commonly, a large land mass may neighbor them, an example being Scotland which has more than 700 islands surrounding the mainland. Archipelagoes are often volcanic, forming along mid-ocean ridges or hotspots, but there are many other processes involved in their construction, including erosion, deposition, and land elevation.
The four largest modern states that are mainly archipelagos are Japan, the Philippines, New Zealand and Indonesia (the world's largest archipelagic state according to the CIA World Factbook).
The largest archipelago in the world by size is in Northern Canada, situated in the Arctic Ocean.


Sir Arthur Ignatius Conan Doyle, DL (22 May 1859 – 7 July 1930) was a British author most noted for his stories about the detective Sherlock Holmes, which are generally considered a major innovation in the field of crime fiction, and for the adventures of Professor Challenger. He was a prolific writer whose other works include science fiction stories, historical novels, plays and romances, poetry, and non-fiction.
Arthur Conan Doyle was born on 22 May 1859, in Edinburgh, Scotland, to an English father, Charles Altamont Doyle, and an Irish mother, Mary Foley, who had married in 1855. Although he is now referred to as "Conan Doyle", the origin of this compound surname is uncertain. Conan Doyle's father was an artist, as were his paternal uncles (one of whom was Richard Doyle), and his paternal grandfather John Doyle.
Conan Doyle was sent to the Roman Catholic Jesuit preparatory school Hodder Place, Stonyhurst, at the age of eight. He then went on to Stonyhurst College, but by the time he left the school in 1875, he had rejected Christianity to become an agnostic.
From 1876 to 1881 he studied medicine at the University of Edinburgh, including a period working in the town of Aston (now a district of Birmingham). While studying, he also began writing short stories; his first published story appeared in "Chambers's Edinburgh Journal" before he was 20. Following his term at university, he served as a ship's doctor on a voyage to the West African coast. He completed his doctorate on the subject of tabes dorsalis in 1885.
In 1882, he joined former classmate George Budd as his partner at a medical practice in Plymouth, but their relationship proved difficult, and Conan Doyle soon left to set up an independent practice. Arriving in Portsmouth in June of that year with less than £10 to his name, he set up a medical practice at 1 Bush Villas in Elm Grove, Southsea. The practice was initially not very successful; while waiting for patients, he again began writing stories. His first significant work was A Study in Scarlet, which appeared in "Beeton's Christmas Annual for 1887 and featured the first appearance of Sherlock Holmes, who was partially modelled after his former university professor, Joseph Bell. Future short stories featuring Sherlock Holmes were published in the English Strand Magazine. Interestingly, Rudyard Kipling congratulated Conan Doyle on his success, asking "Could this be my old friend, Dr. Joe?" Sherlock Holmes, however, was even more closely modelled after the famous Edgar Allan Poe character, C. Auguste Dupin.
While living in Southsea he played football for an amateur side (that disbanded in 1894), Portsmouth Association Football Club, as a goal keeper. (This club had no connection with the Portsmouth F.C. of today.) Conan Doyle was also a keen cricketer, and between 1900 and 1907 he played 10 first-class matches for the MCC. His highest score was 43 against London County in 1902. He was an occasional bowler who took just one first-class wicket.
In 1885, he married Louisa (or Louise) Hawkins, known as "Touie", who suffered from tuberculosis and died on 4 July 1906. He married Jean Leckie in 1907, whom he had first met and fallen in love with in 1897 but had maintained a platonic relationship with her out of loyalty to his first wife. Conan Doyle had five children, two with his first wife (Mary Louise (born 1889) and Alleyne Kingsley (1892 – 1918)) and three with his second wife (Jean Lena Annette, Denis Percy Stewart (17 March 1909 – 9 March 1955), second husband in 1936 of Georgian Princess Nina Mdivani (circa 1910 – 19 February 1987) (former sister-in-law of Barbara Hutton), and Adrian Malcolm).
In 1890, Conan Doyle studied the eye in Vienna; he moved to London in 1891 to set up a practice as an ophthalmologist. He wrote in his autobiography that not a single patient crossed his door. This gave him more time for writing, and in November 1891 he wrote to his mother: "I think of slaying Holmes.. and winding him up for good and all. He takes my mind from better things." His mother responded, saying, "You may do what you deem fit, but the crowds will not take this lightheartedly." In December 1893, he did so in order to dedicate more of his time to more "important" works (his historical novels).
Holmes and Moriarty apparently plunged to their deaths together down a waterfall in the story, "The Final Problem". Public outcry led him to bring the character back; Conan Doyle returned to the story in "The Adventure of the Empty House", with the explanation that only Moriarty had fallen but, since Holmes had other dangerous enemies, he had arranged to be temporarily "dead" also. Holmes ultimately appears in a total of 56 short stories and four Conan Doyle novels (he has since appeared in many novels and stories by other authors).
Following the Boer War in South Africa at the turn of the 20th century and the condemnation from around the world over the United Kingdom's conduct, Conan Doyle wrote a short pamphlet titled, The War in South Africa: Its Cause and Conduct, which justified the UK's role in the Boer war, and was widely translated.
Conan Doyle believed that it was this pamphlet that resulted in 1902 in his being knighted and appointed Deputy-Lieutenant of Surrey. He also in 1900 wrote the longer book, The Great Boer War. During the early years of the 20th century, Sir Arthur twice ran for Parliament as a Liberal Unionist, once in Edinburgh and once in the Hawick Burghs, but although he received a respectable vote he was not elected.
Conan Doyle was involved in the campaign for the reform of the Congo Free State, led by the journalist E. D. Morel and the diplomat Roger Casement. He wrote The Crime of the Congo in 1909, a long pamphlet in which he denounced the horrors in that country. He became acquainted with Morel and Casement, taking inspiration from them for two of the main characters in the novel, The Lost World (1912).
He broke with both when Morel became one of the leaders of the pacifist movement during the First World War, and when Casement committed treason against the UK during the Easter Rising out of conviction for his Irish nationalist views. Conan Doyle tried, unsuccessfully, to save Casement from the death penalty, arguing that he had been driven mad and was not responsible for his actions.
Conan Doyle was also a fervent advocate of justice, and personally investigated two closed cases, which led to two imprisoned men being released. The first case, in 1906, involved a shy half-British, half-Indian lawyer named George Edalji, who had allegedly penned threatening letters and mutilated animals. Police were set on Edalji's conviction, even though the mutilations continued after their suspect was jailed.
It was partially as a result of this case that the Court of Criminal Appeal was established in 1907, so not only did Conan Doyle help George Edalji, his work helped establish a way to correct other miscarriages of justice. The story of Conan Doyle and Edalji is told in fictional form in Julian Barnes' 2005 novel, Arthur & George.
The second case, that of Oscar Slater, a German Jew and gambling-den operator convicted of bludgeoning an 82-year-old woman in Glasgow in 1908, excited Conan Doyle's curiosity because of inconsistencies in the prosecution case and a general sense that Slater was framed.
After the death of his wife Louisa in 1906, and the deaths of his son Kingsley, his brother Innes, his two brothers-in-law, and his two nephews shortly after World War I, Conan Doyle sank into depression. He found solace supporting Spiritualism and its alleged scientific proof of existence beyond the grave.
According to the History Channel program Houdini: Unlocking the Mystery (which briefly explored the friendship between the two), Conan Doyle became involved with Spiritualism after the deaths of his son and his brother. Kingsley Doyle died from pneumonia on 28 October 1918, which he contracted during his convalescence after being seriously wounded during the 1916 Battle of the Somme. Brigadier-General Innes Doyle died in February 1919, also from pneumonia. Sir Arthur became involved with Spiritualism to the extent that he wrote a Professor Challenger novel on the subject, The Land of Mist.
His book, The Coming of the Fairies (1921) shows he was apparently convinced of the veracity of the Cottingley Fairies photographs, which he reproduced in the book, together with theories about the nature and existence of fairies and spirits.
In his The History of Spiritualism (1926) Conan Doyle praised the psychic phenomena and spirit materialisations produced by Eusapia Palladino and Mina "Margery" Crandon.
His work on this topic was one of the reasons that one of his short story collections, The Adventures of Sherlock Holmes, was banned in the Soviet Union in 1929 for supposed occultism. This ban was later lifted. Russian actor Vasily Livanov later received an Order of the British Empire for his portrayal of Sherlock Holmes.
Conan Doyle was friends for a time with the American magician Harry Houdini, who himself became a prominent opponent" of the Spiritualist movement in the 1920s following the death of his beloved mother. Although Houdini insisted that Spiritualist mediums employed trickery (and consistently attempted to expose them as frauds), Conan Doyle became convinced that Houdini himself possessed supernatural powers, a view expressed in Conan Doyle's The Edge of the Unknown. Houdini was apparently unable to convince Conan Doyle that his feats were simply magic tricks, leading to a bitter public falling out between the two.
Richard Milner, an American historian of science, has presented a case that Conan Doyle may have been the perpetrator of the Piltdown Man hoax of 1912, creating the counterfeit hominid fossil that fooled the scientific world for over 40 years. Milner says that Conan Doyle had a motive, namely revenge on the scientific establishment for debunking one of his favourite psychics, and that The Lost World contains several encrypted clues regarding his involvement in the hoax.
Samuel Rosenberg's 1974 book Naked is the Best Disguise purports to explain how Conan Doyle left, throughout his writings, open clues that related to hidden and suppressed aspects of his mentality.
Undershaw, the home Conan Doyle had built near Hindhead, south of London, and lived in for at least a decade, was a hotel and restaurant from 1924 until 2004. It was then bought by a developer, and has been empty since then while conservationists and Conan Doyle fans fight to preserve it.
A statue honours Conan Doyle at Crowborough Cross in Crowborough, East Sussex, England, where Sir Arthur lived for 23 years. There is also a statue of Sherlock Holmes in Picardy Place, Edinburgh, Scotland, close to the house where Conan Doyle was born.


An author is defined both as "the person who originates or gives existence to anything" and as "one who sets forth written statements" in the Oxford English Dictionary (1). The first entry suggests that authorship determines responsibility for what is created. The second entry goes on to clarify that, when using the term author, the "anything" which is created is most usually associated with written work.
In copyright law, there is necessarily little flexibility as to what constitutes authorship. The United States Copyright Office defines copyright as "a form of protection provided by the laws of the United States (title 17, U.S. Code) to authors of "original works of authorship" (2). Holding the title of "author" over any "literary, dramatic, musical, artistic, [or] certain other intellectual works" gives this person, the owner of the copyright, exclusive right to do or authorize any production or distribution of their work.
In literary theory, critics find complications in the term "author" beyond what constitutes authorship in a legal setting. In the wake of postmodern literature, critics such as Roland Barthes and Michel Foucault have examined the role and relevance of authorship to the meaning or interpretation of a text.
Barthes challenges the idea that a text can be attributed to any single author. He attests, in his essay "Death of the Author" (1968), that "it is language which speaks, not the author" (3). The words and language of a text itself determine and expose meaning for Barthes, and not someone possessing legal responsibility for the process of its production. Every line of written text is a mere reflection of references from any of a multitude of traditions, or, as Barthes puts it, "the text is a tissue of quotations drawn from the innumerable centres of culture"; it is never original (3). With this, the perspective of the author is removed from the text, and the limits formerly imposed by the idea of one authorial voice, one ultimate and universal meaning, are destroyed. The explanation and meaning of a work does not have to be sought in the one who produced it, "as if it were always in the end, through the more or less transparent allegory of the fiction, the voice of a single person, the author 'confiding' in us" (3). The psyche, culture, fanaticism of an author can be disregarded when interpreting a text, because the words are rich enough themselves with all of the traditions of language. To expose meanings in a written work without appealing to the celebrity of an author, their tastes, passions, vices, is, to Barthes, to allow language to speak, rather than author.
Michel Foucault argues in his famous essay "What is an author?" (1969), that all authors are writers, but not all writers are authors. He states that "a private letter may have a signer--it does not have an author" (4). For a reader to assign the title of author upon any written work is to attribute certain standards upon the text which, for Foucault, are working in conjunction with the idea of "the author function" (4). Foucault's author function is the idea that an author exists only as a function of a written work, a part of its structure, but not necessarily part of the interpretive process. The author's name "indicates the status of the discourse within a society and culture", and at one time was used as an anchor for interpreting a text, a practice which Barthes would argue is not a particularly relevant or valid endeavor (4).
Expanding upon Foucault's position, Alexander Nahamas writes that Foucault suggests "an author [..] is whoever can be understood to have produced a particular text as we interpret it", not necessarily who penned the text (5). It is this distinction between producing a written work and producing the interpretation or meaning in a written work that both Barthes and Foucault are interested in. Foucault warns of the risks of keeping the author's name in mind during interpretation, because it could affect the value and meaning with which one handles an interpretation.
A percentage calculated on a wholesale or a specific price and or a fixed amount on each book that is sold. Publishers, at times, reduced the risk of this type of arrangement, by agreeing only to pay this after a certain amount of copies had sold. In Canada this practice occurred during the 1890s, but was not commonplace until the 1920s.
(1) "Author." The Oxford English Dictionary. 2nd ed. 1989.
(2) "Copyright Office Basics." U.S. Copyright Office. July 2006. http://www.copyright.gov/circs/circ1.html.
(5) Hix, H. L. "Morte d'Author: An Autopsy". Philadelphia: Temple University Press, 1990.

Andrey (Andrei) Andreyevich Markov () (June 14, 1856 N.S. – July 20, 1922) was a Russian mathematician. He is best known for his work on theory of stochastic processes. His research later became known as Markov chains.
He and his younger brother Vladimir Andreevich Markov (1871-1897) proved Markov brothers' inequality.
His son, another Andrey Andreevich Markov (1903-1979), was also a notable mathematician, making contributions on constructive mathematics and recursive function theory.
Andrey Andreevich Markov was born in Ryazan as the son of the secretary of the public forest management of Ryazan, Andrey Grigorevich Markov, and his first wife, Nadezhda Petrovna Markova.
In the beginning of the 1860s Andrey Grigorevich moved to St Petersburg to become an asset manager of the princess Ekaterina Aleksandrovna Valvatyeva.
In 1866 Andrey Andreevich’s school life began with his entrance into Saint Petersburg’s fifth grammar school. Already during his school time Andrey was intensely engaged in higher mathematics. As a 17 year-old grammar school student he informed Bunyakovsky, Korkin and Yegor Zolotarev about an apparently new method to solve linear ordinary differential equations and was invited to the so-called Korkin Saturdays, where Korkin's students regularly met. In 1874 he finished the school and began his studies at the physico-mathematical faculty of St Petersburg University.
Among his teachers were Yulian Sokhotski (differential calculus, higher algebra), Konstantin Posse (analytic geometry), Yegor Zolotarev (integral calculus), Pafnuty Chebyshev (number theory, probability theory), Aleksandr Korkin (ordinary and partial differential equations), Okatov (mechanism theory), Somov (mechanics) and Budaev (descriptive and higher geometry).
In 1877 he was awarded the gold medal for his outstanding solution of the problem "About Integration of Differential Equations by Continuous Fractions with an Application to the Equation ". In the following year he passed the candidate examinations and remained at the university to prepare for the lecturer’s position.
Five years later, in January 1885, there followed his doctoral thesis "About Some Applications of Algebraic Continuous Fractions".
His pedagogical work began after the defense of his master thesis in autumn 1880. As a privatdozent he lectured on differential and integral calculus. Later he lectured alternately on "introduction to analysis", probability theory (succeeding Chebyshev who had left the university in 1882) and calculus of differences. From 1895/96 until 1905 he additionally lectured on differential calculus.
One year after the defense of the doctoral thesis, he was appointed extraordinary professor (1886) and in the same year he was elected adjunct to the Academy of Sciences. In 1890, after the death of Viktor Bunyakovsky, Markov became extraordinary member of the academy. His promotion to an ordinary professor of St Petersburg University followed in autumn 1894.
In 1896, he was elected ordinary member of the academy as the successor of Chebyshev. In 1905 he was appointed merited professor and got the right to retire which he immediately used. Till 1910, however, he continued to lecture calculus of differences.
In connection with student riots in 1908, professors and lecturers of Saint Petersburg University were ordered to observe their students. Markov initially refused to accept this decree and wrote an explanation in which he declined to be an "agent of the governance". Markov was rejected from a further teaching activity at the Saint Petersburg University, and he eventually decided to retire from the university.
In 1913 the council of Saint Petersburg elected nine scientists honorary members of the university.
Markov was among them, but his election was not affirmed by the minister of education. The affirmation was done only four years later, after the February revolution in 1917. Markov then resumed his teaching activities and lectured probability theory and calculus of differences until his death in 1922.


The English word "alumnus" comes from the Latin noun "alumnus" meaning "nursling" or "ward" and has come to mean, within common English usage, a graduate (or nursling) of a seat of learning. "Alumna" is a feminised form of "alumnus" that has entered common English usage.
The plural alumni is often erroneously used as a singular form for both genders; for example, "I am an alumni of the university," as opposed to "I am an alumnus/alumna of the university." This is likely due to a lack of understanding of Latin grammar and the fact that printed documents and university merchandise almost always use the plural form of the word.
Alumni reunions are popular events at many institutions. They are usually organized by alumni associations and are often social occasions for fundraising.
At most public schools, New Zealand schools, and a few universities in the UK, and to a lesser extent in Australia (who use the term "former student") and Canada, the phrases old boy and old girl are traditionally used for former school pupils, and old member (or "alumni" in New Zealand) for former university students. At the Royal Military College of Canada, the phrases former cadet and member of the old brigade are traditionally used as are college numbers. Another example is the term old corps, in reference to alumni from the Virginia Military Institute.
Some will use a specific term clearly linked to the school name, such as Old Etonian or Old Silcoatian (alumni of Eton College and Silcoates School), or a more obscure one, such as Old Citizen and Old Gregorian for those of the City of London School and Downside School.
In Scotland, the term former pupil (FP) is also used, especially when referring to sports teams of a school. Some U.S. schools, most notably Texas A&M University, also prefer former student.


Angst or anguish is a Germanic word for fear or anxiety. It is used in English to describe an intense feeling of emotional strife. In German, it is the fear of possible suffering and a behavior resulting from uncertainty and strain which is caused by pain, loss, and death. The term Angst distinguishes itself from the word Furcht (German for "fear") in that Furcht usually refers to a material threat (arranged fear), while Angst is usually a nondirectional emotion. However, today Furcht is rarely, if ever, used, and fear of [..] is expressed as Angst vor [..].
In other languages having the meaning of the Latin word anxietas and pavor, the derived words differ in meaning, e.g as in the French anxieté and peur.
The word Angst has existed since the 8th century, coming from the base-Indoeuropean *anghu-, "restraint" from which Old High German angust develops. It is pre-cognate with the Latin angustia, "tensity, tightness" and angor, "choking, clogging"; compare to the Greek "άγχος" (ankhos): stress.
A different but related meaning is used by existentialists, first attributed to Danish philosopher Søren Kierkegaard (1813–1855). In The Concept of Anxiety, Kierkegaard used the word Angest (Danish, meaning "dread") to describe a profound and deep-seated spiritual condition of insecurity and despair in the free human being. Where the animal is a slave to its instincts but always confident in its own actions, Kierkegaard believed that the freedom given to mankind leaves the human in a constant fear of failing its responsibilities to God. Kierkegaard's concept of angst is considered to be an important stepping stone for 20th-century existentialism. While Kierkegaard's feeling of angst is fear of actual responsibility to God, in modern use, angst was broadened by the later existentialists to include general frustration associated with the conflict between actual responsibilities to self, one's principles, and others (possibly including God). Martin Heidegger used the term in a slightly different way.
Angst, in contemporary connotative use, most often describes the intense frustration and other related emotions of teenagers and the mood of the music and art with which they identify. Punk rock, grunge, nu metal, emo, and virtually any alternative rock dramatically combining elements of discord, melancholy and excitement may be said to express angst.
Angst was probably first discussed in relation to contemporary music in the mid to late 1950s in relation to music favoured by people influenced by the campaign for nuclear disarmament, especially jazz and folk. Songs like Bob Dylan's 1963 Masters of War and "A Hard Rain's a-Gonna Fall" articulated the dread caused by the threat of nuclear extinction. A key text is Jeff Nuttall's book Bomb Culture (1968) which traced this pervasive theme in popular culture back to Hiroshima.
The term "angst" is now widely used as a theme by many great modern writers. Often, the expression is used as a common adolescent experience of malaise, as in J.D. Salinger's novel The Catcher in the Rye; in this sense it has become one of the central themes in modern fiction.


certain danger. Somatically the body prepares the organism to deal with threat (known as an emergency reaction): blood pressure and heart rate are increased, sweating is increased, bloodflow to the major muscle groups is increased, and immune and digestive system functions are inhibited. Externally, somatic signs of anxiety may include pale skin, sweating, trembling, and pupillary dilation. Emotionally, anxiety causes a sense of dread or panic and physically causes nausea, diarrhea, and chills. Behaviorally, both voluntary and involuntary behaviors may arise directed at escaping or avoiding the source of anxiety and often maladaptive, being most extreme in anxiety disorders. However, anxiety is not always pathological or maladaptive: it is a common emotion along with fear, anger, sadness, and happiness, and it has a very important function in relation to survival.
Neural circuitry involving the amygdala and hippocampus is thought to underlie anxiety (Rosen & Schulkin, 1998). When confronted with unpleasant and potentially harmful stimuli such as foul odors or tastes, PET-scans show increased bloodflow in the amygdala. In these studies, the participants also reported moderate anxiety. This might indicate that anxiety is a protective mechanism designed to prevent the organism from engaging in potentially harmful behaviors.
Sigmund Freud recognized anxiety as a "signal of danger" and a cause of "defensive behavior". He believed we acquire anxious feelings through classical conditioning and traumatic experiences.
We maintain anxiety through operant conditioning; when we see or encounter something associated with a previous traumatic experience, anxious feelings resurface. We feel temporarily relieved when we avoid/remove ourselves from situations which make us anxious/fearful, known as 'negative-reinforcement', but this only increases anxious feelings the next time we are in the same position, and we will want to escape the situation again and therefore will not make any progress against the anxiety, only intensifying the emotions or 'fear.' Phobias can be developed this way, as well as cured using the opposite 'positive-reinforcement' whereby instead of removal from the anxiety causing situation (which acts as a 'reward' [negative-reinforcement]) something positive can be added to the situation instead to act as a reward, like actually facing your fear and coming away from it safely. This is known as positive reinforcement of a negative situation.
Theologians like Paul Tillich and psychologists like Sigmund Freud have characterized anxiety as the reaction to what Tillich called, "The trauma of nonbeing." That is, the human comes to realize that there is a point at which he or she might cease to be (die), and their encounter with reality becomes characterized by anxiety.
Religion, according to both Tillich and Freud, then becomes a carefully crafted coping mechanism in response to this anxiety since they redefine death as the end of only the corporal part of human personal existence, assuming an immortal soul.
What then becomes of this soul and through what criteria is the cardinal difference of various religious faiths.
Philosophical ruminations are a part of this condition, and this is part of obsessive-compulsive disorder. They are typically about sex and religion or death. However, truly rational philosophical thinking is usually driven by a desire for a rational understanding of Ultimate Reality, rather than a desire to avoid death.
According to Viktor Frankl, author of "Man's Search for Meaning, when faced with extreme mortal dangers the very basic of all human wishes is to find a meaning of life to combat this "trauma of nonbeing" as death is near and to succumb to it (even by suicide) seems like a way out.
The "father" of existentialism, Soren Kierkegaard, regarded all humans to be born into despair by default (in The Sickness Unto Death). Such despair was created by having a false conception of the self. He regarded the mortal self which can exist relatively, and therefore be born or die, as the false self. The true self was the relationship of self to God (the Absolute, or Ultimate Reality), rather than to any relative object.
Test anxiety is the uneasiness, apprehension, or nervousness felt by students who have a fear of failing an exam. Students suffering from test anxiety may experience any of the following: the association of grades with personal worth, embarrassment by a teacher, taking a class that is beyond their ability, fear of alienation from parents or friends, time pressures, or feeling a loss of control. Emotional, cognitive, behavioral, and physical components can all be present in test anxiety. Sweating, dizziness, headaches, racing heartbeats, nausea, fidgeting, and drumming on a desk are all common. An optimal level of arousal is necessary to best complete a task such as an exam; however, when the anxiety or level of arousal exceeds that optimum, it results in a decline in performance. Because test anxiety hinges on fear of negative evaluation, debate exists as to whether test anxiety is itself a unique anxiety disorder or whether it is a specific type of social phobia. In 2006, approximately 49% of high school students were reportedly experiencing this condition.
While the term test anxiety refers specifically to students, many adults share the same experience with regard to their career or profession. The fear of failing a task and being negatively evaluated for it can have a similarly negative effect on the adult.
Anxiety when meeting or interacting with unknown people is a common stage of development in young people.
So-called "stranger anxiety" in younger people is not a phobia in the classic sense; rather it is a developmentally appropriate fear by young children of those who do not" share a 'loved-one', caretaker or parenting role. In adults, an excessive fear of other people is not a developmentally common stage.
Some research has strongly suggested that treating anxiety in cancer patients improves their quality of life. The treatment generally consists of counseling, relaxation techniques or pharmacologically with benzodiazepines.
Kava root is an effective natural treatment for short-term relief of mild anxiety.
Due to recent findings regarding side effects of prolonged used of Kava-Kava, some individuals have turned to other natural herbs such as valerian (herb) root, Chamomile, orange peel and peppermint, for example.


Alan Alexander Milne () (January 18, 1882 – January 31, 1956), also known as A. A. Milne, was an English author, best known for his books about the teddy bear Winnie-the-Pooh and for various children's poems. Milne was a noted writer, primarily as a playwright, before the huge success of Pooh overshadowed all his previous work.
Milne was born in Hampstead, London, England and grew up at Henley House School, 6/7 Mortimer Road, Kilburn, London, a small independent school run by his father, John V. Milne. One of his teachers was H. G. Wells. He attended Westminster School and Trinity College, Cambridge where he studied on a mathematics scholarship. While there, he edited and wrote for Granta, a student magazine. He collaborated with his brother Kenneth and their articles appeared over the initials AKM. Milne's work came to the attention of the leading British humour magazine Punch, where Milne was to become a contributor and later an assistant editor.
During World War II, he was Captain of the Home Guard in Hartfield & Forest Row, insisting on being plain 'Mr. Milne' to the members of his platoon.
Milne married Dorothy "Daphne" de Sélincourt in 1913, and their only son, Christopher Robin Milne, was born in 1920. In 1925, A. A. Milne bought a country home, Cotchford Farm, in Hartfield, East Sussex. He retired to the farm after a stroke and brain surgery in 1952 left him an invalid. Cotchford Farm was where the Rolling Stones' lead guitarist Brian Jones would later live and be found drowned in 1969. Cotchford Farm has since been demolished, due to the excessive maintenance and repair costs, and a new house built on the site.
Milne is most famous for his Pooh books about a boy named Christopher Robin, after his son, and various characters inspired by his son's stuffed animals, most notably the bear named Winnie-the-Pooh. The source of the name is reputedly a Canadian black bear named Winnie (after Winnipeg), that was used as a military mascot in World War I, and left to London Zoo after the war. E. H. Shepard illustrated the original Pooh books, using his own son's teddy, Growler ("a magnificent bear"), as the model. Christopher Robin Milne's own toys are now under glass in New York.
Milne also wrote a number of poems, including Vespers, "They're Changing Guard at Buckingham Palace, and King John's Christmas, which were published in the books When We Were Very Young and Now We Are Six". Several of Milne's children's poems were set to music by the composer Harold Fraser-Simson. His poems have been parodied many times, including with the books When We Were Rather Older and Now We Are Sixty.
The overwhelming success of his children's books was to become a source of considerable annoyance to Milne, whose self-avowed aim was to write whatever he pleased, and who had, until then, found a ready audience for each change of direction: he had freed pre-war Punch from its ponderous facetiousness; he had made a considerable reputation as a playwright (like his idol J. M. Barrie) on both sides of the Atlantic; he had produced a witty piece of detective writing in The Red House Mystery (although this was severely criticised by Raymond Chandler for the implausibility of its plot). Indeed, Milne's publisher was displeased when he announced his intention to write poems for children, and he had never lacked an audience.
But once Milne had, in his own words, "said Goodbye to all that in 70,000 words" (the approximate length of the four children's books), he had no intention of producing a copy of a copy, given that one of the sources of inspiration, his son, was growing older.
Even his old literary home, Punch, where the When We Were Very Young verses had first appeared, was ultimately to reject him, as Christopher Milne details in his autobiography The Enchanted Places, although Methuen continued to publish whatever Milne wrote, including the long poem 'The Norman Church' and an assembly of articles entitled Year In, Year Out (which Milne likened to a benefit night for the author).
He also adapted Kenneth Grahame's novel The Wind in the Willows for the stage as Toad of Toad Hall. The title was an implicit admission that such chapters as Chapter 7, The Piper at the Gates of Dawn, could not survive translation to the theatre. A special introduction written by Milne is included in some editions of Grahame's novel.
After Milne's death, his widow sold the rights to the Pooh characters to the Walt Disney Company, which has made a number of Pooh cartoon movies, as well as a large amount of Pooh-related merchandise. She also destroyed his papers.
Royalties from the Pooh characters paid by Disney to the Royal Literary Fund, part-owner of the Pooh copyright, provide the income used to run the Fund's Fellowship Scheme, placing professional writers in UK universities.

Alumni Athletic Club, usually just Alumni, is a rugby union and former Association football sports club from the Belgrano district of Buenos Aires in Argentina. The club was founded in 1891, with the name Buenos Aires English High School.
The club were the most successful teams in the amateur era of Argentine football, winning 10 of the 14 league championships they contested.
Alumni participated in the inaugural Association Football League (AAFL) league in 1893, and played again in 1895 and 1900, under the name English High School. In 1901 they changed their name to Alumni, they continued to play in the league until the club were disbanded in 1911.
The club were disbanded for two main reasons, the first was the shortage of players caused by the fact that they rarely allowed players from outside the institution of the English High School. The second main reason was that the club was losing a lot of money and it seemed unlikely that they could fulfil their fixtures for 1912.
Kept as a social club for several years, Alumni started a youth rugby team in 1951, which achieved good results. In 1960 the club presented a team that won the third division of the Buenos Aires league, reaching second division. The club would later climb up to first division and win 5 titles; 4 consecutive between 1989 and 1992, and in 2001.
Even though they only played 14 championships, they are still the 6th most successful team in Argentine football history, if counting amateur championships.


Addiction was a term used to describe a devotion, attachment, dedication, inclination, etc. Nowadays, however, the term addiction is used to describe a recurring compulsion by an individual to engage in some specific activity, despite harmful consequences to the individual's health, mental state or social life. The term is often reserved for drug addictions but it is sometimes applied to other compulsions, such as problem gambling, and compulsive overeating. Factors that have been suggested as causes of addiction include genetic, biological/pharmacological and social factors. Addiction can be caused by various factors such as depression or indigestion.
Decades ago addiction was a pharmacological term that clearly referred to the use of a tolerance-inducing drug in sufficient quantity as to cause tolerance (the requirement that greater dosages of a given drug be used to produce an identical effect as time passes). With that definition, humans (and indeed all mammals) can become addicted to various drugs quickly. Almost at the same time, a lay definition of addiction developed. This definition referred to individuals who continued to use a given drug despite their own best interest. This latter definition is now thought of as a disease state by the medical community.
Physical dependence, abuse of, and withdrawal from drugs and other miscellaneous substances is outlined in the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV TR). Terminology has become quite complicated in the field. To wit, pharmacologists continue to speak of addiction from a physiologic standpoint (some call this a physical dependence); psychiatrists refer to the disease state as dependence; most other physicians refer to the disease as addiction. The field of psychiatry is now considering, as they move from DSM-IV to DSM-V, transitioning from "dependence" to "addiction" as terminology for the disease state.
The medical community now makes a careful theoretical distinction between physical dependence (characterized by symptoms of withdrawal) and psychological dependence (or simply addiction). Addiction is now narrowly defined as "uncontrolled, compulsive use"; if there is no harm being suffered by, or damage done to, the patient or another party, then clinically it may be considered compulsive, but to the definition of some it is not categorized as "addiction". In practice, the two kinds of addiction are not always easy to distinguish. Addictions often have both physical and psychological components.
There is also a lesser known situation called pseudo-addiction. (Weissman and Gallagher, 1989) A patient will exhibit drug-seeking behavior reminiscent of psychological addiction, but they tend to have genuine pain or other symptoms that have been undertreated. Unlike true psychological addiction, these behaviors tend to stop when the pain is adequately treated.
The obsolete term physical addiction is deprecated, because of its connotations. In modern pain management with opioids physical dependence is nearly universal. While opiates are essential in the treatment of acute pain, the benefit of this class of medication in chronic pain is not well proven. Clearly, there are those who would not function well without opiate treatment; on the other hand, many states are noting significant increases in non-intentional deaths related to opiate use. High-quality, long-term studies are needed to better delineate the risks and benefits of chronic opiate use.
Not all doctors agree on what addiction or dependency is. Traditionally, addiction has been defined as being possible only to a psychoactive substance (for example alcohol, tobacco and other drugs) which ingested cross the blood-brain barrier, altering the natural chemical behavior of the brain temporarily. However, "Studies on phenomenology, family history, and response to treatment suggest that intermittent explosive disorder, kleptomania, pathological gambling, pyromania, and trichotillomania may be related to mood disorders, alcohol and psychoactive substance abuse, and anxiety disorders (especially obsessive-compulsive disorder).
It is generally accepted that addiction is a disease, a state of physiological or psychological dependence or devotion to something manifesting as a condition in which medically significant symptoms liable to have a damaging effect are present.
Many people, both psychology professionals and laypersons, now feel that there should be accommodation made to include psychological dependency on such things as gambling, food, sex, pornography, computers, work, exercise, cutting, shopping, and religion so these behaviours count as diseases as well and don't cause guilt, shame, fear, hopelessness, failure, rejection,anxiety, or humiliation symptoms associated with, among other medical conditions, depression,epilepsy, and hyperreligiosity In depression related to religious addiction "The religious addict seeks to avoid pain and overcome shame by becoming involved in a belief system which offers security through its rigidity and its absolute values." While religion and spirituality may play a key role in psychotherapeutic support and recovery, it can also be a source of pain, guilt and exclusion, and religious themes may also play a negative role in psychopathology. Although, the above mentioned are things or tasks which, when used or performed, do not fit into the traditional view of addiction and may be better defined as an obsessive-compulsive disorder,withdrawal symptoms may occur with abatement of such behaviors. It is said by those who adhere to a traditionalist view that these withdrawal-like symptoms are not strictly reflective of an addiction, but rather of a behavioral disorder. However, understanding of neural science, the brain, the nervous system, human behavior, and affective disorders has revealed "the impact of molecular biology in the mechanisms underlying developmental processes and in the pathogenesis of disease". The use of thyroid hormones as an effective adjunct treatment for affective disorders has been studied over the past three decades and has been confirmed repeatedly. In spite of traditionalist protests and warnings that overextension of definitions may cause the wrong treatment to be used (thus failing the person with the behavioral problem), popular media, and some members of the field, do represent the aforementioned behavioral examples as addictions.
Recently, some have modeled addiction using the tools of Economics, for instance, by calculating the elasticity of addictive goods and determining to what extent present income and consumption has on future consumption.
Physical dependence on a substance is defined by the appearance of characteristic withdrawal symptoms when the substance is suddenly discontinued. Opiates, benzodiazepines, barbiturates, alcohol and nicotine induce physical dependence. On the other hand, some categories of substances share this property and are still not considered addictive: cortisone, beta-blockers and most antidepressants are examples. So, while physical dependency can be a major factor in the psychology of addiction and most often becomes a primary motivator in the continuation of an addiction, the initial primary attribution of an addictive substance is usually its ability to induce pleasure, although with continued use the goal is not so much to induce pleasure as it is to relieve the anxiety caused by the absence of a given addictive substance, causing it to become used compulsively. An example of this is nicotine; A cigarette can be described as pleasurable, but is in fact fulfilling the physical addiction of the user, and therefore, is achieving pleasurable feelings relative to his/her previous state of physical withdrawal. Further, the physical dependency of the nicotine addict on the substance itself becomes an overwhelming factor in the continuation of use.
Some substances induce physical dependence or physiological tolerance - but not addiction - for example many laxatives, which are not psychoactive; nasal decongestants, which can cause rebound congestion if used for more than a few days in a row; and some antidepressants, most notably venlafaxine, paroxetine and sertraline, as they have quite short half-lives, so stopping them abruptly causes a more rapid change in the neurotransmitter balance in the brain than many other antidepressants. Many non-addictive prescription drugs should not be suddenly stopped, so a doctor should be consulted before abruptly discontinuing them.
The speed with which a given individual becomes addicted to various substances varies with the substance, the frequency of use, the means of ingestion, the intensity of pleasure or euphoria, and the individual's genetic and psychological susceptibility. Some people may exhibit alcoholic tendencies from the moment of first intoxication, while most people can drink socially without ever becoming addicted. Opioid dependent individuals have different responses to even low doses of opioids than the majority of people, although this may be due to a variety of other factors, as opioid use heavily stimulates pleasure-inducing neurotransmitters in the brain. Nonetheless, because of these variations, in addition to the adoption and twin studies that have been well replicated, much of the medical community is satisfied that addiction is in part genetically moderated. That is, one's genetic makeup may regulate how susceptible one is to a substance and how easily one may become psychologically attached to a pleasurable routine.
Eating disorders are complicated pathological mental illnesses and thus are not the same as addictions described in this article. Eating disorders, which some argue are not addictions at all, are driven by a multitude of factors, most of which are highly different than the factors behind addictions described in this article.
Psychological dependency is a dependency of the mind, and leads to psychological withdrawal symptoms (such as cravings, irritability, insomnia, depression, anorexia etc). Addiction can in theory be derived from any rewarding behaviour, and is believed to be strongly associated with the dopaminergic system of the brain's reward system (as in the case of cocaine and amphetamines). Some claim that it is a habitual means to avoid undesired activity, but typically it is only so to a clinical level in individuals who have emotional, social, or psychological dysfunctions (psychological addiction is defined as such), replacing normal positive stimuli not otherwise attained (see Rat Park).
It is considered possible to be both psychologically and physically dependent at the same time. Some doctors make little distinction between the two types of addiction, since the result, substance abuse, is the same. However, the cause and characteristics of each of the two types of addiction is quite different, as is the type of treatment preferred.
Psychological dependence does not have to be limited only to substances; even activities and behavioural patterns can be considered addictions, if they become uncontrollable, e.g. gambling, Internet addiction, computer addiction, sexual addiction / pornography addiction, reading, eating, self-harm, vandalism or work addiction.
Most countries have legislation which brings various drugs and drug-like substances under the control of licensing systems. Typically this legislation covers any or all of the opiates, amphetamines, cannabinoids, cocaine, barbiturates, hallucinogens (tryptamines, LSD, phencyclidine(PCP), psilocybin) and a variety of more modern synthetic drugs, and unlicensed production, supply or possession may be a criminal offense.
Usually, however, drug classification under such legislation is not related simply to addictiveness. The substances covered often have very different addictive properties. Some are highly prone to cause physical dependency, whilst others rarely cause any form of compulsive need whatsoever. Typically nicotine (in the form of tobacco) is regulated extremely loosely, if at all, although it is well-known as one of the most addictive substances ever discovered.
Also, although the legislation may be justifiable on moral grounds to some, it can make addiction or dependency a much more serious issue for the individual. Reliable supplies of a drug become difficult to secure as illegally produced substances may have contaminants. Withdrawal from the substances or associated contaminants can cause additional health issues and the individual becomes vulnerable to both criminal abuse and legal punishment. Criminal elements that can be involved in the profitable trade of such substances can also cause physical harm to users.
Some medical systems, including those of at least 15 states of the United States, refer to an Addiction Severity Index to assess the severity of problems related to substance use. The index assesses problems in six areas: medical, employment/support, alcohol and other drug use, legal, family/social, and psychiatric.
While addiction or dependency is related to seemingly uncontrollable urges, and arguably could have roots in genetic predispositions, treatment of dependency is conducted by a wide range of medical and allied professionals, including Addiction Medicine specialists, psychiatrists, and appropriately trained nurses, social workers, and counselors. Early treatment of acute withdrawal often includes medical detoxification, which can include doses of anxiolytics or narcotics to reduce symptoms of withdrawal. An experimental drug, ibogaine, is also proposed to treat withdrawal and craving. Alternatives to medical detoxification include acupuncture detoxification. In chronic opiate addiction, a surrogate drug such as methadone is sometimes offered as a form of opiate replacement therapy. But treatment approaches universal focus on the individual's ultimate choice to pursue an alternate course of action.
Chambless, D. L. et al. (1996). An update on empirically validated therapies. Clinical Psychology, 49, 5-14 ). In addition, the same author suggest that Social skills training adjunctive to inpatient treatment of alcohol dependence is probably efficacious.
The development of addiction is thought to involve a simultaneous process of 1) increased focus on and engagement in a particular behavior and 2) the attenuation or "shutting down" of other behaviors. For example, under certain experimental circumstances such as social deprivation and boredom, animals allowed the unlimited ability to self-administer certain psychoactive drugs will show such a strong preference that they will forgo food, sleep, and sex for continued access. The neuro-anatomical correlate of this is that the brain regions involved in driving goal-directed behavior grow increasingly selective for particular motivating stimuli and rewards, to the point that the brain regions involved in the inhibition of behavior can no longer effectively send "stop" signals. A good analogy is to imagine flooring the gas pedal in a car with very bad brakes. In this case, the limbic system is thought to be the major "driving force" and the orbitofrontal cortex is the substrate of the top-down inhibition.
A specific portion of the limbic circuit known as the mesolimbic dopaminergic system is hypothesized to play an important role in translation of motivation to motor behavior- and reward-related learning in particular. It is typically defined as the ventral tegmental area (VTA), the nucleus accumbens, and the bundle of dopamine-containing fibers that are connecting them. This system is commonly implicated in the seeking out and consumption of rewarding stimuli or events, such as sweet-tasting foods or sexual interaction. However, its importance to addiction research goes beyond its role in "natural" motivation: while the specific site or mechanism of action may differ, all known drugs of abuse have the common effect in that they elevate the level of dopamine in the nucleus accumbens. This may happen directly, such as through blockade of the dopamine re-uptake mechanism (see cocaine). It may also happen indirectly, such as through stimulation of the dopamine-containing neurons of the VTA that synapse onto neurons in the accumbens (see opiates). The euphoric effects of drugs of abuse are thought to be a direct result of the acute increase in accumbal dopamine.
The human body has a natural tendency to maintain homeostasis, and the central nervous system is no exception. Chronic elevation of dopamine will result in a decrease in the number of dopamine receptors available in a process known as downregulation. The decreased number of receptors changes the permeability of the cell membrane located post-synaptically, such that the post-synaptic neuron is less excitable- i.e.: less able to respond to chemical signaling with an electrical impulse, or action potential. It is hypothesized that this dulling of the responsiveness of the brain's reward pathways contributes to the inability to feel pleasure, known as anhedonia, often observed in addicts. The increased requirement for dopamine to maintain the same electrical activity is the basis of both physiological tolerance and withdrawal associated with addiction.
Downregulation can be classically conditioned. If a behavior consistently occurs in the same environment or contingently with a particular cue, the brain will adjust to the presence of the conditioned cues by decreasing the number of available receptors in the absence of the behavior. It is thought that many drug overdoses are not the result of a user taking a higher dose than is typical, but rather that the user is administering the same dose in a new environment.
In cases of physical dependency on depressants of the central nervous system such as opioids, barbiturates, or alcohol, the absence of the substance can lead to symptoms of severe physical discomfort. Withdrawal from alcohol or sedatives such as barbiturates or benzodiazepines (valium-family) can result in seizures and even death. By contrast, withdrawal from opioids, which can be extremely uncomfortable, is rarely if ever life-threatening. In cases of dependence and withdrawal, the body has become so dependent on high concentrations of the particular chemical that it has stopped producing its own natural versions (endogenous ligands) and instead produces opposing chemicals. When the addictive substance is withdrawn, the effects of the opposing chemicals can become overwhelming. For example, chronic use of sedatives (alcohol, barbiturates, or benzodiazepines) results in higher chronic levels of stimulating neurotransmitters such as glutamate. Very high levels of glutamate kill nerve cells, a phenomenon called excitatory neurotoxicity.
A stronger form of criticism comes from Thomas Szasz, who denies that addiction is a psychiatric problem. In many of his works, he argues that addiction is a choice, and that a drug addict is one who simply prefers a socially taboo substance rather than, say, a low risk lifestyle. In Our Right to Drugs, Szasz cites the biography of Malcolm X to corroborate his economic views towards addiction: Malcolm claimed that quitting cigarettes was harder than shaking his heroin addiction. Szasz postulates that humans always have a choice, and it is foolish to call someone an 'addict' just because they prefer a drug induced euphoria to a more popular and socially welcome lifestyle. Therefore, being 'addicted' to a substance is no different from being 'addicted' to a job at which you work everyday.
Szasz and Bryant are not alone in questioning the standard view of addiction. Professor John Booth Davies at the University of Strathclyde has argued in his book The Myth of Addiction that 'people take drugs because they want to and because it makes sense for them to do so given the choices available' as opposed to the view that 'they are compelled to by the pharmacology of the drugs they take'. He uses an adaptation of attribution theory (what he calls the theory of functional attributions) to argue that the statement 'I am addicted to drugs' is functional, rather than veridical. Stanton Peele has put forward similar views.
Experimentally, Bruce K. Alexander used the classic experiment of Rat Park to show that 'addicted' behaviour in rats only occurred when the rats had no other options. When other options and behavioural opportunities were put in place, the rats soon showed far more complex behaviours.
The word addiction is also sometimes used colloquially to refer to something for which a person has a passion, such as books, chocolate, work, the web, running, or eating.


In traditional logic, an axiom or postulate is a proposition that is not proved or demonstrated but considered to be self-evident. Therefore, its truth is taken for granted, and serves as a starting point for deducing and inferring other (theory dependent) truths.
In mathematics, the term axiom is used in two related but distinguishable senses: "logical axioms" and "non-logical axioms". In both senses, an axiom is any mathematical statement that serves as a starting point from which other statements are logically derived. Unlike theorems, axioms (unless redundant) cannot be derived by principles of deduction, nor are they demonstrable by mathematical proofs, simply because they are starting points; there is nothing else they logically follow from (otherwise they would be classified as theorems).
Logical axioms are usually statements that are taken to be universally true (e.g. ), while non-logical axioms (e.g, ) are actually defining properties for the domain of a specific mathematical theory (such as arithmetic). When used in that sense, "axiom," "postulate", and "assumption" may be used interchangeably. In general, a non-logical axiom is not a self-evident truth, but rather a formal logical expression used in deduction to build a mathematical theory. To axiomatize a system of knowledge is to show that its claims can be derived from a small, well-understood set of sentences (the axioms). There are typically multiple ways to axiomatize a given mathematical domain.
Outside logic and mathematics, the term "axiom" is used loosely for any established principle of some field.
The word "axiom" comes from the Greek word (axioma), a verbal noun from the verb (axioein), meaning "to deem worthy", but also "to require", which in turn comes from (axios), meaning "being in balance", and hence "having (the same) value (as)", "worthy", "proper". Among the ancient Greek philosophers an axiom was a claim which could be seen to be true without any need for proof.
The logico-deductive method whereby conclusions (new knowledge) follow from premises (old knowledge) through the application of sound arguments (syllogisms, rules of inference), was developed by the ancient Greeks, and has become the core principle of modern mathematics. Tautologies excluded, nothing can be deduced if nothing is assumed. Axioms and postulates are the basic assumptions underlying a given body of deductive knowledge. They are accepted without demonstration. All other assertions (theorems, if we are talking about mathematics) must be proven with the aid of these basic assumptions. However, the interpretation of mathematical knowledge has changed from ancient times to the modern, and consequently the terms axiom and postulate hold a slightly different meaning for the present day mathematician, than they did for Aristotle and Euclid.
The ancient Greeks considered geometry as just one of several sciences, and held the theorems of geometry on par with scientific facts. As such, they developed and used the logico-deductive method as a means of avoiding error, and for structuring and communicating knowledge. Aristotle's posterior analytics is a definitive exposition of the classical view.
An "axiom", in classical terminology, referred to a self-evident assumption common to many branches of science. A good example would be the assertion that When an equal amount is taken from equals, an equal amount results.
At the foundation of the various sciences lay certain additional hypotheses which were accepted without proof. Such a hypothesis was termed a postulate. While the axioms were common to many sciences, the postulates of each particular science were different. Their validity had to be established by means of real-world experience. Indeed, Aristotle warns that the content of a science cannot be successfully communicated, if the learner is in doubt about the truth of the postulates.
The classical approach is well illustrated by Euclid's elements, where a list of postulates is given (common-sensical geometric facts drawn from our experience), followed by a list of "common notions" (very basic, self-evident assertions).
A lesson learned by mathematics in the last 150 years is that it is useful to strip the meaning away from the mathematical assertions (axioms, postulates, propositions, theorems) and definitions. This abstraction, one might even say formalization, makes mathematical knowledge more general, capable of multiple different meanings, and therefore useful in multiple contexts.
Structuralist mathematics goes farther, and develops theories and axioms (e.g. field theory, group theory, topology, vector spaces) without any particular application in mind. The distinction between an "axiom" and a "postulate" disappears. The postulates of Euclid are profitably motivated by saying that they lead to a great wealth of geometric facts. The truth of these complicated facts rests on the acceptance of the basic hypotheses. However, by throwing out Euclid's fifth postulate we get theories that have meaning in wider contexts, hyperbolic geometry for example. We must simply be prepared to use labels like "line" and "parallel" with greater flexibility. The development of hyperbolic geometry taught mathematicians that postulates should be regarded as purely formal statements, and not as facts based on experience.
When mathematicians employ the axioms of a field, the intentions are even more abstract. The propositions of field theory do not concern any one particular application; the mathematician now works in complete abstraction. There are many examples of fields; field theory gives correct knowledge about them all.
It is not correct to say that the axioms of field theory are "propositions that are regarded as true without proof." Rather, the field axioms are a set of constraints. If any given system of addition and multiplication satisfies these constraints, then one is in a position to instantly know a great deal of extra information about this system.
Modern mathematics formalizes its foundations to such an extent that mathematical theories can be regarded as mathematical objects, and logic itself can be regarded as a branch of mathematics. Frege, Russell, Poincaré, Hilbert, and Gödel are some of the key figures in this development.
In the modern understanding, a set of axioms is any collection of formally stated assertions from which other formally stated assertions follow by the application of certain well-defined rules. In this view, logic becomes just another formal system. A set of axioms should be consistent; it should be impossible to derive a contradiction from the axiom. A set of axioms should also be non-redundant; an assertion that can be deduced from other axioms need not be regarded as an axiom.
It was the early hope of modern logicians that various branches of mathematics, perhaps all of mathematics, could be derived from a consistent collection of basic axioms. An early success of the formalist program was Hilbert's formalization of Euclidean geometry, and the related demonstration of the consistency of those axioms.
In a wider context, there was an attempt to base all of mathematics on Cantor's set theory. Here the emergence of Russell's paradox, and similar antinomies of naive set theory raised the possibility that any such system could turn out to be inconsistent.
The formalist project suffered a decisive setback, when in 1931 Gödel showed that it is possible, for any sufficiently large set of axioms (Peano's axioms, for example) to construct a statement whose truth is independent of that set of axioms. As a corollary, Gödel proved that the consistency of a theory like Peano arithmetic is an unprovable assertion within the scope of that theory.
It is reasonable to believe in the consistency of Peano arithmetic because it is satisfied by the system of natural numbers, an infinite but intuitively accessible formal system. However, at present, there is no known way of demonstrating the consistency of the modern Zermelo-Frankel axioms for set theory. The axiom of choice, a key hypothesis of this theory, remains a very controversial assumption. Furthermore, using techniques of forcing (Cohen) one can show that the continuum hypothesis (Cantor) is independent of the Zermelo-Frankel axioms. Thus, even this very general set of axioms cannot be regarded as the definitive foundation for mathematics.
These are certain formulas in a language that are universally valid, that is, formulas that are satisfied by every structure under every variable assignment function. In colloquial terms, these are statements that are true in any possible universe, under any possible interpretation and with any assignment of values. Usually one takes as logical axioms at least some minimal set of tautologies that is sufficient for proving all tautologies in the language; in the case of predicate logic more logical axioms than that are required, in order to prove logical truths that are not tautologies in the strict sense.
Each of these patterns is an axiom schema, a rule for generating an infinite number of axioms. For example, if, and are propositional variables, then and are both instances of axiom schema 1, and hence are axioms. It can be shown that with only these three axiom schemata and modus ponens, one can prove all tautologies of the propositional calculus. It can also be shown that no pair of these schemata is sufficient for proving all tautologies with modus ponens.
Other axiom schemas involving the same or different sets of primitive connectives can be alternatively constructed.
These axiom schemata are also used in the predicate calculus, but additional logical axioms are needed to include a quantifier in the calculus.
This means that, for any variable symbol, the formula can be regarded as an axiom. Also, in this example, for this not to fall into vagueness and a never-ending series of "primitive notions", either a precise notion of what we mean by (or, for that matter, "to be equal") has to be well established first, or a purely formal and syntactical usage of the symbol has to be enforced, only regarding it as a string and only a string of symbols, and mathematical logic does indeed do that.
Non-logical axioms are formulas that play the role of theory-specific assumptions. Reasoning about two different structures, for example the natural numbers and the integers, may involve the same logical axioms; the non-logical axioms aim to capture what is special about a particular structure (or set of structures, such as groups). Thus non-logical axioms, unlike logical axioms, are not tautologies. Another name for a non-logical axiom is postulate.
Almost every modern mathematical theory starts from a given set of non-logical axioms, and it was thought that in principle every theory could be axiomatized in this way and formalized down to the bare language of logical formulas. This turned out to be impossible and proved to be quite a story (see below); however recently this approach has been resurrected in the form of neo-logicism.
Non-logical axioms are often simply referred to as axioms in mathematical discourse. This does not mean that it is claimed that they are true in some absolute sense. For example, in some groups, the group operation is commutative, and this can be asserted with the introduction of an additional axiom, but without this axiom we can do quite well developing (the more general) group theory, and we can even take its negation as an axiom for the study of non-commutative groups.
Thus, an axiom is an elementary basis for a formal logic system that together with the rules of inference define a deductive system.
This section gives examples of mathematical theories that are developed entirely from a set of non-logical axioms (axioms, henceforth). A rigorous treatment of any of these topics begins with a specification of these axioms.
Basic theories, such as arithmetic, real analysis and complex analysis are often introduced non-axiomatically, but implicitly or explicitly there is generally an assumption that the axioms being used are the axioms of Zermelo–Fraenkel set theory with choice, abbreviated ZFC, or some very similar system of axiomatic set theory, most often Von Neumann–Bernays–Gödel set theory, abbreviated NBG. This is a conservative extension of ZFC, with identical theorems about sets, and hence very closely related. Sometimes slightly stronger theories such as Morse-Kelley set theory or set theory with a strongly inaccessible cardinal allowing the use of a Grothendieck universe are used, but in fact most mathematicians can actually prove all they need in systems weaker than ZFC, such as second-order arithmetic.
The study of topology in mathematics extends all over through point set topology, algebraic topology, differential topology, and all the related paraphernalia, such as homology theory, homotopy theory.
The development of abstract algebra brought with itself group theory, rings and fields, Galois theory.
This list could be expanded to include most fields of mathematics, including axiomatic set theory, measure theory, ergodic theory, probability, representation theory, and differential geometry.
The Peano axioms are the most widely used axiomatization of first-order arithmetic. They are a set of axioms strong enough to prove many important facts about number theory and they allowed Gödel to establish his famous second incompleteness theorem.
The standard structure is where is the set of natural numbers, is the successor function and is naturally interpreted as the number 0.
Probably the oldest, and most famous, list of axioms are the 4 + 1 Euclid's postulates of plane geometry. The axioms are referred to as "4 + 1" because for nearly two millennia the fifth (parallel) postulate ("through a point outside a line there is exactly one parallel") was suspected of being derivable from the first four. Ultimately, the fifth postulate was found to be independent of the first four. Indeed, one can assume that no parallels through a point outside a line exist, that exactly one exists, or that infinitely many exist. These choices give us alternative forms of geometry in which the interior angles of a triangle add up to less than, exactly, or more than a straight line respectively and are known as elliptic, Euclidean, and hyperbolic geometries.
The object of study is the real numbers. The real numbers are uniquely picked out (up to isomorphism) by the properties of a Dedekind complete ordered field, meaning that any nonempty set of real numbers with an upper bound has a least upper bound. However, expressing these properties as axioms requires use of second-order logic. The Löwenheim-Skolem theorems tell us that if we restrict ourselves to first-order logic, any axiom system for the reals admits other models, including both models that are smaller than the reals and models that are larger. Some of the latter are studied in non-standard analysis.
that is, for any statement that is a logical consequence of there actually exists a deduction of the statement from. This is sometimes expressed as "everything that is true is provable", but it must be understood that "true" here means "made true by the set of axioms", and not, for example, "true in the intended interpretation". Gödel's completeness theorem establishes the completeness of a certain commonly-used type of deductive system.
Note that "completeness" has a different meaning here than it does in the context of Gödel's first incompleteness theorem, which states that no recursive, consistent set of non-logical axioms of the Theory of Arithmetic is complete, in the sense that there will always exist an arithmetic statement such that neither nor can be proved from the given set of axioms.
There is thus, on the one hand, the notion of completeness of a deductive system and on the other hand that of completeness of a set of non-logical axioms. The completeness theorem and the incompleteness theorem, despite their names, do not contradict one another.
Early mathematicians regarded axiomatic geometry as a model of physical space, and obviously there could only be one such model. The idea that alternative mathematical systems might exist was very troubling to mathematicians of the 19th century and the developers of systems such as Boolean algebra made elaborate efforts to derive them from traditional arithmetic. Galois showed just before his untimely death that these efforts were largely wasted. Ultimately, the abstract parallels between algebraic systems were seen to be more important than the details and modern algebra was born. In the modern view we may take as axioms any set of formulas we like, as long as they are not known to be inconsistent.


Alpha (uppercase Α, lowercase α; ) is the first letter of the Greek alphabet. In the system of Greek numerals it has a value of 1. It was derived from the Phoenician letter Aleph. Letters that arose from Alpha include the Latin A and the Cyrillic letter А.
In both Classical Greek and Modern Greek, alpha represents the Open front unrounded vowel, /a/.
Plutarch in Moralia, presents a discussion on why the letter alpha stands first in the alphabet. Ammonius asks Plutarch what he, being a Boeotian, thinks of Cadmus, the Phoenician who reputedly settled in Thebes and introduced the alphabet to Greece, placing alpha first because it is the Phoenician name for ox -- which, unlike Hesiod, the Phoenicians considered not the second or third, but the first of all necessities.
"Nothing at all" Plutarch replied. He then added that he would rather be assisted by Lamprias, his own grandfather, than by Dionysus' grandfather, i.e. Cadmus. For Lamprias had said that the first articulate sound made is "alpha", because it is very plain and simple — the air coming off the mouth does not require any motion of the tongue — and therefore this is the first sound that children make.
The Homeric word "alphesiboios" (") is associated with both the root "alph-" and "ox". It is derived from "alphanō" () meaning to yield, earn and "bous" () meaning ox, hence alphesiboios means bringing in or acquiring oxen".
According to Plutarch's natural order of attribution of the vowels to the planets, alpha was connected with the Moon. Oxen were also associated with the Moon in both early Sumerian and Egyptian religious symbolism, possibly due to the crescent shape of their horns.
Alpha, both as a symbol and term, is used to refer to or describe a variety of things, including the first or most significant occurrence of something. The New Testament has God declaring himself to be the "Alpha and Omega, the beginning and the end, the first and the last." (Revelation 22:13, KJV, and see also 1:8).
The uppercase letter alpha is not generally used as a symbol because it tends to be rendered identically to the uppercase latin A.
Alpha is used extensively in physics and chemistry to represent many things, such as alpha radiation, alpha particles and alpha carbon. It is also commonly used in mathematics in algebraic solutions representing things like angle.
In the Runic alphabet of the Elder Futhark in received shamanic oral lore traditions from Scandinavia, the alphabet is a cycle rather than a linear progression and Ur commences the cycle that Fe closes, both are cattle, which is a correlate to the Christian Alpha and Omega.


Alvin Toffler (born October 3, 1928) is an American writer and futurist, known for his works discussing the digital revolution, communications revolution, corporate revolution and technological singularity. A former associate editor of Fortune magazine, his early work focused on technology and its impact (through effects like information overload). Then he moved to examining the reaction of and changes in society. His later focus has been on the increasing power of 21st century military hardware, weapons and technology proliferation, and capitalism. He is married to Heidi Toffler, also a writer and futurist. They live in Los Angeles. They wrote the books credited to "Alvin Toffler" together.
Accenture, the management consultancy, has dubbed him the third most influential voice among business leaders, after Bill Gates and Peter Drucker. He has also been described in the Financial Times as the "world's most famous futurologist".
People's Daily classes him among the 50 foreigners that shaped modern China.
In his book The Third Wave Toffler describes three types of societies, based on the concept of 'waves' - each wave pushes the older societies and cultures aside.
In this post-industrial society, there is a lot of diversity in lifestyles ("subcults").
Adhocracies (fluid organizations) adapt quickly to changes.
Information can substitute most of the material resources (see ersatz) and becomes the main material for workers (cognitarians instead of proletarians), who are loosely affiliated.
Mass customization offers the possibility of cheap, personalized, production catering to small niches (see Just In Time production).
The gap between producer and consumer is bridged by technology using a so called configuration system.
"Prosumers" can fill their own needs (see open source, assembly kit, freelance work). This was the notion that new technologies are enabling the radical fusion of the producer and consumer into the prosumer. In some cases prosuming entails a "third job" where the corporation "outsources" its labor not to other countries, but to the unpaid consumer, such as when we do our own banking through an ATM instead of a teller that the bank must employ, or trace our own postal packages on the internet instead of relying on a paid clerk.
Aging societies will be using new (medical) technologies from self-diagnosis to instant toilet urinalysis to self-administered therapies delivered by nanotechnology to do for themselves what doctors used to do. This will change the way the whole health industry works.
Since the 1960s, people have been trying to make sense out of the impact of new technologies and social change. Toffler's writings have been influential beyond the confines of scientific, economic and public policy discussions. Techno music pioneer Juan Atkins cites Toffler's phrase "techno rebels" in Future Shock as inspiring him to use the word "techno" to describe the musical style he helped to create.
Toffler's works and ideas have been subject to various criticisms, usually with the same argumentation used against futurology: that foreseeing the future is nigh impossible. In the 1990s, his ideas were publicly lauded by Newt Gingrich.
In 1996 Alvin and Heidi Toffler founded Toffler Associates, an executive advisory firm committed to helping commercial firms and government agencies adjust to the changes described in the Tofflers' works.
The development Toffler believes may go down as this era's greatest turning point is the creation of wealth in outer space. Wealth today, he argues, is created everywhere (globalisation), nowhere (cyberspace), and out there (outer space). Global positioning satellites are key to synchronising precision time and data streams for everything from cellphone calls to ATM withdrawals. They allow Just In Time productivity because of precise tracking. GPS is also becoming central to air-traffic control. And satellites increase agricultural productivity through tracking weather, enabling more accurate forecasts.
Two major predictions of Toffler's - the paperless office and human cloning - have yet to be realized, not due to technological barriers but to sociological and politico-religious conditions.


The Amazing Spider-Man is an American comic book series published by Marvel Comics, and additionally a spin-off television program and a daily newspaper comic strip, all featuring the adventures of the superhero Spider-Man.
Spider-Man first appeared in the comic book Amazing Fantasy #15 (Aug. 1962). The series was cancelled with that issue, but response to the character was so positive that a solo title, The Amazing Spider-Man, was launched with a March 1963 cover-date.
The character was created by writer-editor Stan Lee and artist and co-plotter Steve Ditko, and the pair produced 38 issues from 1963 to 1966. Since then, many writers and artists have taken over the monthly comic through the years, chronicling the adventures of Marvel's most identifiable hero.
The initial years of the book, under Lee and Ditko, chronicled Spider-Man's nascent career with his civilian life as hard-luck yet perpetually good-humored teenager Peter Parker. Parker balanced his career as Spider-Man with his job as a freelance photographer for The Daily Bugle (under the bombastic editor-publisher J. Jonah Jameson) to help support himself and his frail Aunt May. At the same time, Parker dealt with public hostility towards Spider-Man and the antagonism of his classmates Flash Thompson and Liz Allan at Midtown High School, while also embarking on a tentative, ill-fated romance with Jameson's secretary, Betty Brant.
By focusing on Parker's everyday problems, Lee and Ditko created a groundbreakingly flawed, self-doubting superhero, and the first major teenaged superhero to be a protagonist and not a sidekick. Ditko's quirky art provided a stark contrast to the more cleanly dynamic stylings of Marvel's most prominent artist, Jack Kirby, and Ditko's Spider-Man, slightly sinister yet affectionately cartoony, combined with the humor and pathos of Lee's writing to lay the foundation for what became an enduring mythos.
Parker began attending Empire State University in #31 (Dec. 1965), the issue which also featured the first appearances of friends and classmates Gwen Stacy and Harry Osborn. Harry's father, Norman Osborn first appeared in #23 (April 1965) as a member of Jameson's country club but is not named nor revealed as Harry's father until #37 (June 1966). Probably the most celebrated issue of the Lee-Ditko run is #33 (Feb. 1966), the third part of the story arc "If This Be My Destiny", and featuring the dramatic scene of Spider-Man, through force of will and thoughts of family, escaping from being pinned by heavy machinery.
Although credited only as artist for most of his run, Ditko would eventually plot the stories as well as draw them, leaving Lee to script the dialogue. However, a rift between Ditko and Lee developed, and the two men were not on speaking terms long before Ditko completed his last issue, The Amazing Spider-Man #38 (July 1966). The exact reasons for the Ditko-Lee split have been a source of controversy ever since.
In successor penciler John Romita Sr.'s first issue, #39 (Aug. 1966), archnemesis the Green Goblin discovers Spider-Man's secret identity and reveals his own to the captive hero. Romita's Spider-Man – more muscular and heroic-looking than Ditko's – became the model for two decades. The Lee-Romita era saw the introduction of such characters as Daily Bugle managing editor Joseph "Robbie" Robertson in #52 (Sept. 1967) and NYPD Captain George Stacy, father of Parker's girlfriend Gwen Stacy, in #56 (Jan. 1968). The most important supporting character to be introduced during the Romita era was Mary Jane Watson, who made her first full appearance in #42, (Nov. 1966), although she first appeared in #25 (June 1965) with her face obscured and had been mentioned since #15 (Aug. 1964).
Lee and Romita toned down the prevalent sense of antagonism in Parker's world by improving Parker's relationship with the supporting characters and having stories focused as much on the social and college lives of the characters as they did on Spider-Man's adventures. The stories also became more topical, addressing issues such as civil rights, racism, prisoners' rights, the Vietnam War, and political elections.
Issue #50 (June 1967) introduced the highly enduring criminal mastermind the Kingpin, who would become a major force as well in the superhero series Daredevil. Other notable first appearances in the Lee-Romita era include the Rhino in #41 (Oct. 1966), the The Shocker in #46 (March 1967), the Prowler in #78 (Nov. 1969), and the Kingpin's son, Richard Fisk, in #83 (April 1970).
Two spin-off series debuted in the 1970s: Marvel Team-Up in 1972, and The Spectacular Spider-Man in 1976. The flagship title's second decade took a grim turn with a story in #89-90 (Oct.-Nov. 1970) featuring the death of Captain George Stacy. This was also the first Spider-Man story to be penciled by Gil Kane, who would alternate drawing duties with Romita for the next year-and-a-half and would draw several landmark issues.
One such story took place in the controversial issues #96-98 (May-July 1971). Writer-editor Lee defied the Comics Code Authority with this story, in which Parker's friend Harry Osborn, was hospitalized after tripping on LSD. Lee wrote this story upon a request from the US Department of Health, Education and Welfare for a story about the dangers of drugs. Citing its dictum against depicting drug use, even in an anti-drug context, the CCA refused to put its seal on these issues. With the approval of Marvel publisher Martin Goodman, Lee had the comics published without the seal. The comics sold well and Marvel won praise for its socially conscious efforts. The CCA subsequently loosened the Code to permit negative depictions of drugs, among other new freedoms.
The "Six-Arm Saga" of #100-102 (Sept.-Nov. 1971) introduced Morbius, the Living Vampire. The second installment was the first Amazing Spider-Man story not written by co-creator Lee, with Roy Thomas taking over writing the book for several months before Stan Lee returned to write #105-110 (Feb.-July 1972). Lee, who was going on to become Marvel Comics' publisher, with Thomas becoming editor-in-chief, then turned writing duties over to 19-year-old wunderkind Gerry Conway, who scripted the series through 1975. Romita penciled Conway's first half-dozen issues, which introduced the gangster Hammerhead in #113 (Oct. 1972). Kane then succeeded Romita as penciler, although Romita would continue inking Kane for a time.
The most memorable work of the Conway/Kane/Romita team was #121-122 (June-July 1973), which featured the death of Gwen Stacy at the hands of The Green Goblin in the story which shocked readers, "The Night Gwen Stacy Died" (#121). Her demise and the Goblin's apparent death one issue later formed a story arc widely considered as the most defining in the history of Spider-Man. The aftermath of the story also deepened both the characterization of Mary Jane Watson and her relationship with Parker.
By late 1973, Gil Kane was succeeded by Ross Andru, whose run lasted nearly 60 issues, from 1973 to 1978. Issue #129 (Feb. 1974) introduced the Punisher, who would become one of Marvel Comics' principal and most widely recognized characters. The Conway-Andru era also featured the first appearances of the Man-Wolf in #124-125 (Sept.-Oct 1973); the near-marriage of Doctor Octopus and Aunt May in #134 (July 1974); Harry Osborn stepping into his father's role as the Green Goblin in #135-37 (Aug.-Oct. 1974); and the original "Clone Saga", containing the introduction of Spider-Man's clone, in #147-149 (Aug.-Oct. 1975).
Archie Goodwin and Gil Kane produced the title's 150th issue (Nov. 1975) before Len Wein became writer for two-and-a-half years.During Wein's tenure, Harry Osborn and Liz Allen dated and became engaged, J. Jonah Jameson was introduced to his eventual second wife, Marla Madison, and Aunt May suffered a heart attack. Wein's last story on Amazing was a five-issue arc in #176-180 (Jan.-May 1978) featuring a third Green Goblin (Harry Osborn’s psychiatrist, Bart Hamilton). Marv Wolfman, Marvel's editor-in-chief from 1975 to 1976, succeeded Wein as writer, and in his first issue, #182 (July 1978), had Parker propose marriage to Watson (who refused, in the following issue). Keith Pollard succeeded Ross Andru as artist shortly afterward, and with Wolfman introduced the likable rogue the Black Cat (Felicia Hardy) in #194 (July 1979). As a love interest for Spider-Man, the Black Cat would go on to be an important supporting character for the better part of the next decade.
The Amazing Spider-Man #200 (Jan. 1980) featured the return and death of the burglar who killed Spider-Man's Uncle Ben. Writer Marv Wolfman and penciler Keith Pollard both left the title by mid-year, succeeded by Dennis O'Neil, a writer known for groundbreaking 1970s work at rival DC Comics, and penciler John Romita, Jr. Roger Stern, who had written nearly 20 issues of sister title The Spectacular Spider-Man, took over Amazing in late 1981. During his two years on the title, Stern augmented the backgrounds of long-established Spider-Man villains, and with Romita Jr. created the mysterious supervillain the Hobgoblin in #238-239 (March-April 1983). Fans engaged with the mystery of the Hobgoblin's secret identity, which continued throughout #244-245 and 249-251 (Sept.-Oct. 1983 & Feb.-April 1984). One lasting changes was the reintroduction of Mary Jane Watson as a much more serious, mature woman who becomes Peter's confidant after she reveals that she knows his secret identity.
By mid-1984, Tom DeFalco and Ron Frenz took over scripting and penciling. DeFalco helped establish the maturation in Parker and Watson's relationship, laying the foundation for the character's eventual wedding. Notably, in #257 (Oct. 1984), Watson tells Parker that she knows he is Spider-Man, and in #259 (Dec. 1984), she reveals to Parker the extent of her troubled childhood. Other notable issues of the DeFalco-Frenz era include #252 (May 1984), with the first appearance of Spider-Man's black costume, which the hero would wear almost exclusively for the next four years' worth of comics; the debut of criminal mastermind the Rose, in #253 (June 1984); the revelation in258 (Nov. 1984) that the black costume is a living being, a symbiote; and the introduction of the female mercenary Silver Sable in #265 (June 1985).
Tom DeFalco and Ron Frenz were both removed from Amazing Spider-Man in 1986 by editor Owsley under acrimonious circumstances. A succession of artists including Alan Kupperberg, John Romita, Jr. and Alex Saviuk) penciled the book from 1987 to 1988; Owsley wrote the book for the first half of 1987, scripting the five-part "Gang War" story (#284-288) that DeFalco plotted. Former Spectacular Spider-Man writer Peter David scripted #289 (June 1987), which revealed the late Ned Leeds as being the Hobgoblin (although this was retconned in 1996 by Roger Stern into Leeds not being the original Hobgoblin after all).
David Michelinie took over as writer in the next issue, for a story arc in #290-292 (July-Sept. 1987) that led to the marriage of Peter Parker and Mary Jane Watson in Amazing Spider-Man Annual #21. Issue #298 (March 1988) was the first Spider-Man comic to be drawn by future industry star Todd McFarlane, the first regular artist on Amazing Spider-Man since the Frenz's departure. McFarlane revolutionized Spider-Man's look. His depiction – large-eyed, with wiry, contorted limbs, and messy, knotted, convoluted webbing – influenced the way virtually all subsequent artists would draw the character. McFarlane's other significant contribution to the Spider-Man canon was the design for what would become one of Spider-Man's most wildly popular antagonists, the supervillain Venom. Issue #299 (April 1988) featured Venom's first appearance (a last-page cameo) before his first full appearance in #300 (May 1988). The latter issue also featured Spider-Man reverting to his original red-and-blue costume.
Other notable issues of the Michelinie-McFarlane era include #312 (Feb. 1989), featuring the Green Goblin vs. the Hobgoblin; and #315-317 (May-July 1989), with the return of Venom. After the editorial and creative turmoil that beset Amazing Spider-Man in 1987, the Michelinie/McFarlane team at the tail-end of the 1980s restored a sense of creative consistency and quality to the book, and set the tone for Spider-Man for the next decade.
With a civilian life as a married man, the Spider-Man of the 1990s was different from the superhero of the previous three decades. Following his 1988-1989 run on Amazing Spider-Man, Todd McFarlane left the title in 1990 to write and draw a new series titled simply Spider-Man. McFarlane's successor, Erik Larsen, penciled the book from early 1990 to mid-1991. After issue #350, Larsen was succeeded by Mark Bagley, who had won the 1986 Marvel Tryout Contest and was assigned a number of low-profile penciling jobs followed by a run on New Warriors in 1990. Bagley penciled the flagship Spider-Man title from 1991 to 1996, with his art forming the basis for most Spider-Man licensed merchandise of decade and onward.
Issues #361-363 (April-June 1992) introduced Carnage, a second symbiote nemesis for Spider-Man. The series' 30th-anniversary issue, #365 (Aug. 1992), was a double-sized, hologram-cover issue with the cliffhanger ending of Peter Parker's parents, long thought dead, reappear alive. It would be close to two years before they were revealed to be impostors, who are killed in #388 (April 1994), scripter Michelinie's last issue. His 1987-1994 stint gave him the second-longest run as writer on the title, behind Stan Lee.
With #389, writer J.M. DeMatteis, whose Spider-Man credits included the 1987 "Kraven's Last Hunt" story arc and a 1991-1993 run on The Spectacular Spider-Man, took over the title. From October 1994 to June 1996, Amazing stopped running stories exclusive to it, and ran installments of multi-part stories that crossed over into all the Spider-Man books. One of the few self-contained stories during this period was in #400 (April 1995), which featured the death of Aunt May — later revealed to have been faked. The "Clone Saga" culminated with the revelation that the Spider-Man who had appeared in the previous 20 years of comics was a clone of the real Spider-Man. This plot twist was massively unpopular with many readers, and was later reversed in the "Revelations" story arc that crossed over the Spider-Man books in late 1996.
The Clone Saga tied into a publishing gap after #406 (Oct. 1995), when the title was temporarily replaced by The Amazing Scarlet Spider #1-2 (Nov.-Dec. 1995), featuring Ben Reilly. The series picked up again with #407 (Jan. 1996), with Tom DeFalco returning as writer. Bagley completed his 5½-year run by September 1996. A succession of artists. including Ron Garney, Steve Skroce, Joe Bennett, and Rafael Kayanan, penciled the book until the final issue, #441 (Nov. 1998), after which Marvel rebooted the title with vol. 2, #1 (Jan. 1999).
Marvel began The Amazing Spider-Man anew with vol. 2, #1 (Jan. 1999. Howard Mackie wrote the first 29 issues. With #30 (June 2001), J. Michael Straczynski took over as writer.
Issue #30 began a dual numbering system, with the original series numbering (#471) returned and placed alongside the volume-two number on the cover. Other longtime, rebooted Marvel Comics titles, including Fantastic Four, were given the dual numbering around this time. In October 2000, John Romita, Jr. succeeded John Byrne as artist. After vol. 2, #58 (Nov. 2003), the title reverted to its original numbering for #500 (Dec. 2003), with vol. 2, #1-58 considered #442-499 of the original run. Mike Deodato, Jr. penciled the book from mid-2004 until 2006.
Amazing Spider-Man vol. 2 #36 (#477) explores how Spider-Man and other heroes react to the September 11, 2001 attacks. The issue was written by J. Michael Straczynski and penciled by John Romita, Jr. It starts with a double page spread of the devastation and of Spidey holding his head in pain/anguish/disbelief, his only word "..God.." as well as a few brief thoughts of the act. The issue continues as Spider-Man swings down to help in the aftermath. Joining with other heroes in the rescue efforts, Spider-Man explores the wreckage and the broken hearts and his thoughts drive on, thinking through it all. At some point his thoughts become Straczynski's reflections and response. The script journeys from horror, pain and loss to end on strength. The story was notable for spotlighting the firefighters sifting through the wreckage, keeping the heroes assisting them few. The emphasis on "real life" heroes is most apparent on the last page, in a full-page splash wherein the super heroes seen in that issue stood in the background, and New York City firefighters and other city workers involved in helping during the events of 9/11 stood in the foreground.
The 2006 Civil War crossover includes The Amazing Spider-Man. Spider-Man originally fights alongside Iron Man and the government to fulfill the Superhuman Registration Act, capturing superheroes and jailing them until they register and reveal their identities. Spider-Man reveals his secret identity as Peter Parker to the world, but eventually realizes he is on the wrong side and, along with Captain America, becomes an opponent of the registration.
As of issue #539, almost immediately following the Civil War, Aunt May is shot by an unnamed assassin hired by the Kingpin to kill Peter. Peter dodged and knocked Mary Jane down but was unable to save Aunt May, who is badly injured. Peter takes Aunt May to the hospital, leaving instructions with Mary Jane on what to do. He then retrieves the long forgotten black costume to send a new message: when he finds who shot his aunt, he is going to kill them. He then discovers the name of the man who shot her, Jake Martino. As they were fighting, Peter demanded he tell him who hired him. Before he could get the name out, he was shot by an unknown assailant. Peter tracks down the shooter of Jake and discovers he works with the Kingpin. Spider-Man then proceeds to hunt down Fisk and promises to kill him. Utterly defeating Fisk in combat, Peter stops short of killing him, revealing that due to the fact their fight was witnessed by an entire prison's worth of witnesses, word will soon spread about Spider-Man's total defeat of Kingpin, and for a man who wants people to believe he's unbeatable, his reputation is everything. Peter promises to kill Fisk immediately after May dies, since it was Kingpin's order to shoot. Peter then tells the inmates to spread the word around the underworld that if anyone targets his family, he will kill them.
While Back in Black promotions from Marvel stated that this was his first time back in the black costume in twenty years, he made two brief returns to the costume in 1991's Spider-Man volume 1, #13, to battle Morbius the Living Vampire and in The Amazing Spider-Man vol. 2, #19 battling Venom which was the issue Brock's wife committed suicide.
One More Day is a four-part, crossover story arc, written partially by J. Michael Straczynski and illustrated by Joe Quesada, running through The Amazing Spider-Man #544-545 (Nov.-Dec. 2007), and Friendly Neighborhood Spider-Man #24 (Nov. 2007) and Sensational Spider-Man #41 (Dec. 2007), the final issues of those two titles. The demon Mephisto makes a Faustian bargain with Peter Parker and Mary Jane Watson-Parker, offering to save Parker's dying Aunt May if the couple will allow their marriage to have never existed, rewriting that portion of their pasts.
Following this, Marvel made The Amazing Spider-Man the company's sole Spider-Man title, upped its frequency of publication to three issues monthly, and inaugurated the series with the "back to basics" story arc "Brand New Day", in which Parker now found himself in a reality where he and Watson had never married — neither having any memory of being married together — and with domino-effect differences in their immediate world. The four initial writer-penciler teams were Dan Slott and Steve McNiven; Bob Gale and Phil Jiminez; Marc Guggenheim and Salvador Larroca; and Zeb Wells and Chris Bachalo.
Spidey got his shot at live-action TV stardom in April 1977, when he debuted in the Amazing Spider-Man TV series. Nicholas Hammond portrayed Peter Parker/Spider-Man in the short-lived series, which had started out as a series of TV-movies, obviously made to capitalize on the The Incredible Hulk television series. The show was canceled a year after its debut.
In 1995, BBC Radio commissioned a Spider-Man 'audio book' which aired on BBC Radio 1 over 50 episodes on week days between January 15, 1996 and March 24, 1996. The performance was co-produced by Brian May who also contributed to the musical arrangement and wrote and performed the theme tune.
The scope of the story included a number of familiar characters from the Spider-Man comic books as well as key figures from the Marvel "Heroes" universe such as Fantastic Four, Namor the Submariner, and Doctor Doom.
The role of Spider-Man was performed by William Dufries. Also included in the cast list was EastEnders star Anita Dobson.
The daily newspaper comic strip began on January 3, 1977. It was first written by Spider-Man co-creator Stan Lee and illustrated by John Romita. The strip was surprisingly successful in an era with few serialized adventure strips. The strip slowly grew in circulation and as of 2007 is still being published. Lee's brother Larry Lieber illustrated and later wrote the strip for much of its run. In 1992, Paul Ryan took over the penciling (with Joe Sinnott inking) on the Sunday version of the strip, and drew that feature for just over three years. While the strip and the comic book feature the same characters, they do not share the same continuity, and the strip has had a decreased emphasis on supervillain enemies. A rare exception was the 1987 wedding of Peter Parker and Mary Jane Watson which occurred in both the comic book and the comic strip. Guest stars in the newspaper strip include Wolverine, Daredevil and Dr. Strange. Villains include Dr. Doom, Kraven the Hunter, and The Rhino. Stories from the strip have been reprinted in paperback and in Comics Revue magazine.
Numerous video and computer games have been released whereby the player controlled Spider-Man and had to do battle with various enemies.

Archie is a given name of English origin. It is a popular diminutive of Archibald, meaning true, bold, and valuable.




Automated Alice is a fantastical book by British author Jeff Noon, first published in 1996. The book follows Alice's travels to a future Manchester city populated by Newmonians, Civil Serpents and a vanishing cat.
The book was written as both the third book in the Vurt series and the "trequel" to the famous Lewis Carroll books, Alice's Adventures in Wonderland and Through the Looking-Glass.
The story of Automated Alice tells of the character of Alice from Lewis Carrolls books in a future version of Manchester, England. After following a white termite through a grandfather clock, Alice, her parrot Whippoorwill and Alice's doll Celia, they get lost in a world inhabited by Newmonians, entities made from two objects combined, for example a zebra and a human.


Antigua and Barbuda is an island nation located in the eastern Caribbean Sea, on the sea's boundary with the Atlantic Ocean. There are two major islands - Antigua () and Barbuda (/bɑrˈbjuːdə/), which are close neighbors within the middle of the Leeward Islands, roughly 17 degrees north of the equator.
The islands of Antigua and Barbuda are part of the Lesser Antilles archipelago. To the south of Antigua and Barbuda lie the islands of Guadeloupe, Dominica, Martinique, Saint Lucia, Saint Vincent and the Grenadines, Barbados, Grenada and Trinidad and Tobago. Montserrat lies to the southwest; Saint Kitts and Nevis and Saint Eustatius are to the west, and Saint Barthélemy, Saint Martin and Anguilla are to the northwest.
Pre-ceramic Amerindians were the first to inhabit the islands of Antigua and Barbuda in 2400 BC. Later Arawak and Carib Amerindian tribes populated the islands. The island of Antigua was named Wadadli by these natives and is today called Wadadli by locals. Christopher Columbus landed on his second trip in 1493 and named the island Santa Maria de la Antigua after a church in Seville, Spain. Early settlement by the Spanish was replaced by English rule from 1632 (British rule from 1707 Acts of Union), with a French interlude in 1666. Slavery, established to run the sugar plantations on Antigua, was abolished in 1834.
The islands became an independent state within the Commonwealth of Nations on 1 November 1981, with Elizabeth II as the first Queen of Antigua and Barbuda and the Right Honourable Vere Cornwall Bird became the first prime minister.
The politics of Antigua and Barbuda takes place in a framework of a federal parliamentary representative democratic monarchy, whereby the Head of State is the monarch, who appoints the Governor-General as vice-regal representative. In 2007 Louise Lake-Tack became the first female to hold the position of Governor-General in the history of Antigua and Barbuda. A Council of Ministers is appointed by the Governor-General on the advice of the Prime Minister, currently Baldwin Spencer. The Prime Minister is the head of the government. Vere Cornwall Bird, Antigua and Barbuda's first Prime Minister, is credited with having brought Antigua and Barbuda and the Caribbean into a new era of independence.
Executive power is exercised by the government. Legislative power is vested in both the government and the two chambers of the Parliament. The bicameral Parliament consists of the Senate (seventeen-member body appointed by the governor general) and the House of Representatives (seventeen seats; members are elected by first past the post to serve five-year terms). The last elections held were on 23 March 2004, while the next are due in 2009. At the last elections, the Antigua Labour Party won four seats, while the United Progressive Party won thirteen.
Since 1949, the party system had been dominated by the personalist Antigua Labour Party. However, the Antigua and Barbuda legislative election, 2004, saw the defeat of the longest-serving elected government in the Caribbean. The Prime Minister, Lester Bryant Bird and deputy Robin Yearwood had been in office since 1994, when he succeeded his father, Vere Bird. The elder Bird had been Prime Minister from independence in 1981 and, before independence, had been Chief Minister of Antigua from 1960, except for the period 1971-76 when the Progressive Labour Movement (PLM) defeated them in those elections.
The Judicial Branch is the Eastern Caribbean Supreme Court (based in Saint Lucia; one judge of the Supreme Court is a resident of the islands and presides over the Court of Summary Jurisdiction). Antigua is also a member of the Caribbean Court of Justice. The Supreme Court of Appeal was the British Judicial Committee of the Privy Council up until 2001, when the nations of the Caribbean Community voted to abolish the right of appeal to the Privy Council in favour of a Caribbean Court of Justice. Some debate between member countries had repeatedly delayed the court's date of inauguration. As of March, 2005, only Barbados was set to replace appeals to the Privy Council with appeals the Caribbean Court of Justice, which then had come into operation.
The Royal Antigua and Barbuda Defence Force is the country's military. It has 185 members.
The island of Barbuda (1,241) and the uninhabited island of Redonda each enjoy dependency status.
The capital is the city of St. John's (population 21,514).
The country consists of a number of islands, of which Antigua is the largest and most populous. Barbuda, just north of Antigua, is the other main island. The islands have a warm, tropical climate, with nearly constant temperatures throughout the year. Redonda, another nearby island, which was annexed in the 1860s when its phosphate resources were discovered, is also the territory of Antigua and Barbuda although it has been unoccupied since 1930.
The islands are mostly low-lying with the highest point being Boggy Peak, at 402 metres (1,319 ft). The small country's main town is the capital, Saint John's, on Antigua; Barbuda's largest town is Codrington. Antigua & Barbuda combined have 365 beaches.
The Antiguan Racer is the rarest snake in the world with approximately only two hundred remaining in the wild. It is found on Bird Island, an island off the coast of Antigua.
Tourism dominates the economy, accounting for more than half of the GDP. Weak tourist arrival numbers since early 2000 have slowed the economy, however, and pressed the government into a tight fiscal corner. The dual-island nation's agricultural production is focused on the domestic market and constrained by a limited water supply and a labour shortage stemming from the lure of higher wages in tourism and construction work.
Manufacturing comprises enclave-type assembly for export with major products being bedding, handicrafts, and electronic components. Prospects for economic growth in the medium term will continue to depend on income growth in the industrialised world, especially in the United States, which accounts for about one-third of all tourist arrivals.
The majority of the population are of people of African, mixed African-European and European (predominately British) descent. There is a minority of people of Portuguese and mixed Portuguese-African ancestry, due to Portuguese indentured servants brought to the West Indies after the abolition of slavery. The majority of the white population is ethnically Irish and British, while there are also a few Christian Levantine Arabs (primarily of Syrian, Lebanese and Palestinian descent). There is a small population of Sephardic Jews.
An increasingly large percent of the population live abroad, most notably in the United States, Canada and the United Kingdom. A minority of the Antiguan residents are immigrants from other countries, particularly Dominica, Guyana and Jamaica with an increasing number of immigrants from the Dominican Republic, St. Vincent and the Grenadines and Nigeria. There is also a significant population of American citizens estimated at 4500 people which would make it one of the largest American citizen populations in the English speaking Eastern Caribbean.
Almost all Antiguans are Christians (74%), with the Anglican Church (about 44%) being the largest denomination. Catholicism is the other significant denomination, with the remainder being other Protestants: including Methodists, Moravians, Pentecostals and Seventh-Day Adventists. There are also Jehovah's Witnesses. Non-Christian religions practiced on the islands include Rastafari, Islam, Judaism, and Baha'i.
The official language of Antigua and Barbuda is English, but many of the locals speak Antiguan Creole. The Barbudan accent is slightly different from the Antiguan one. Spanish is also widely spoken in certain communities in Antigua where immigrants from the Dominican Republic make up large numbers.
Many of the words used in the Antiguan dialect are derived from British and also African origins. The dialect was formed when enslaved Africans owned by British planters imitated the 18th century English spoken by their masters; utilizing traditional African language structures they created an African-English hybrid or pidgin. This can be easily seen in some phrases like: "Me nah go" meaning "I am not going". Another example is: "Ent it?" meaning "Ain't it?" which is in itself dialect and means "Isn't it?". Common island proverbs often can be traced to Africa.
An independent scientific study ranked Antiugua and Barbuda as the 16th happiest country in the world. The culture is predominantly British which is evident throughout many aspects of the society. American popular culture also has a heavy influence. Family and religion play an important role in the lives of Antiguans. There is a national Carnival celebration held during August each year. Historically, Carnival commemorates the abolition of slavery in the British West Indies. The annual Carnival includes pageants, shows, contests and festive activities and is a notable tourist attraction.
Calypso and soca music are important in Antigua and Barbuda and Burning Flames is a popular band.
There are two daily newspapers: Daily Observer, and Antigua Sun which also publishes newspapers on other Caribbean islands. Most American television networks are available in addition to the local television stations. There are several local and regional radio stations.
Like in many commonwealth countries, cricket is a very popular sport. The 2007 Cricket World Cup was hosted in the West Indies from 11 March to 28 April 2007. Antigua hosted eight matches at the Sir Vivian Richards Stadium, which was completed on 11 February 2007 and can hold up to 20 000 people at full capacity.
Antigua is also a Host of twenty20 Cricket, a game created by Allen Stanford in 2006 as a regional cricket game with almost all Caribbean islands taking part.
Association football is also a very popular sport. Antigua has a national football team albeit inexperienced.
Athletics is also popular. Talented athletes are trained from a young age and Antigua and Barbuda have produced a few fairly adept athletes. Janill Williams, a young athlete with much promise comes from Gray's Farm, Antigua. Also, Sonia Williams and Heather Samuel have represented Antigua and Barbuda at the Olympic Games. Others prominent rising stars include Brendan Christian (100 m, 200 m), Daniel Bailey (100 m, 200 m) and James Grayman (High Jump).
The people of Antigua & Barbuda have a high level of literacy at well over 90%. In 1998, Antigua and Barbuda adopted a national mandate to become the preeminent provider of medical services in the Caribbean. As part of this mission, Antigua and Barbuda is building the most technologically advanced hospital in the Caribbean, the Mt. St. John Medical Centre. The island of Antigua currently has two medical schools, the American University of Antigua (AUA), founded in 2004 and The University of Health Sciences Antigua (UHSA), founded in 1982.
There is also a government owned state college in Antigua as well as the Antigua and Barbuda Institute of Information Technology (ABIIT). The University of the West Indies has a branch in Antigua for locals to continue University studies.
With the onset of the Internet more Antiguans are completing online degrees.
Antigua and Barbuda is a member of the United Nations, the Commonwealth of Nations, Caribbean Community, Organisation of Eastern Caribbean States, Organization of American States, World Trade Organization and the Eastern Caribbean's Regional Security System.
Antigua and Barbuda is also a member of the International Criminal Court (with a Bilateral Immunity Agreement of protection for the US-military as covered under Article 98).


A Man for All Seasons is a play by Robert Bolt. An early form of the play had been written for BBC Radio in 1954, but after Bolt's success with The Flowering Cherry, he reworked it for the stage.
It was first performed in London opening at the Globe Theatre (now called the Gielgud Theatre) on July 1 1960. It later found its way to Broadway, enjoying a critically and commercially successful run of over a year. It has had several revivals, and was subsequently made into a feature film and a television movie.
The plot is based on the true story of Sir Thomas More, the 16th-century Chancellor of England, who refuses to endorse or denounce King Henry VIII's wish to divorce his aging wife Catherine of Aragon, who could not bear him a son, so that he could marry Anne Boleyn, the sister of his former mistress.
The play portrays More as a man of principle, envied by rivals such as Thomas Cromwell and loved by the common people and by his family.
Bolt himself was an agnostic and a socialist, and thus he presumably admired More not because he identified with More's religious beliefs, but rather with his refusal to bend to the will of the king.
A Man for All Seasons struggles with ideas of identity and conscience. More argues repeatedly that a person is defined by his conscience. His own position is depicted as almost indefensible; the Pope is described as a "bad" and corrupt individual, forced by the Emperor to act according to his will. But as More says to Norfolk, "What matters is not that it's true, but that I believe it; or no, not that I believe it, but that I believe it." More fears that if he breaks with his conscience, he will be damned to hell, while his associates and friends are more concerned with holding onto their own temporal power.
More's persecution is made to seem even more unjust by the inclusion of Eustace Chapuys, the long-time Spanish ambassador to England, into the story. Chapuys recognizes More as a stout man of the church, and in Act II, after More's resignation from the Chancellorship, he informs More of a planned rebellion along the Scottish border, expecting More to be sympathetic. Instead, More informs Norfolk of the plot, showing him to be patriotic and loyal to the King. This, along with More's refusal to actually speak out against the King, shows him to be a loyal subject, and thus Cromwell appears to prosecute him out of personal spite and because he disagrees with the King's divorce.
Bolt also establishes an anti-authoritarian theme which recurs throughout his works. All people in positions of power — King Henry, Cromwell, Wolsey, Cranmer, Chapuys, even Norfolk — are depicted as being either corrupt, evil, or at best expedient and power-hungry. Bolt's later plays and film screenplays also delve into this theme. The theme of corruption is also illustrated, in Rich's rise to power, the Common Man being drawn into the events of the storyline, and in the (deliberately) anachronistic portrayal of Henry as a younger, athletic man (in 1530 he would have been in his forties and already putting on weight).
Some historians and critics have criticized the play's portrayal of More as a saintly character, noting that Bolt excises mentions of More's more negative activities, such as his campaign against William Tyndale and his persecution of Lutherans while serving as Chancellor. The depictions of Thomas Cromwell, the Duke of Norfolk, and Richard Rich are also historically suspect. (Also, in real life More had three paternal daughters, a son, and an adoptive daughter, but only his eldest, Margaret, appears in the play.) Bolt's decision to portray More through his relations with family and friends, and not the broader political context of the time period, has also been criticized.
The character of the Common Man serves as a narrator and framing device. A Brechtian character, he plays various small parts — More's servant, a publican, a boatman, More's jailer, jury foreman and executioner — who appear throughout the play, both taking part in and commenting on the action. Several sequences involving this character break the fourth wall — most notably, a sequence where the Common Man attempts to exit the stage and is addressed by Cromwell, who identifies him as a jury foreman. (Indeed, the "jury" consists of sticks or poles with the hats of the Common Man's various characters put on top.) Bolt created the Common Man for two main reasons: to illustrate the place and influence of the average person in history, even though they are usually overlooked, and to try and prevent the audience from sympathizing with the more titled characters such as More, realizing that the audience is more closely related to him – a classic case of Brechtian alienation, designed to prevent the audience from being too engrossed in More's plight. The character's role in the story has been interpreted in many different ways by different critics, from being a positive to a negative character. Many of Bolt's subsequent works featured similar characters.
Paul Scofield, who played the leading role in the West End premiere, reprised it on Broadway in 1962, winning a Tony Award.
Leo McKern played the Common Man in the West End version of the show, but was shifted to the role of Cromwell for the Broadway production - a role he later reprised in the film. While playing Cromwell, he appeared with one brown and one blue eye (McKern of course had lost an eye in accident and wore a glass one) to accentuate his character's evil nature.
Charlton Heston played More in several versions of the play off-Broadway in the '70s and '80s, eventually playing it on the West End. Heston considered it among his favourite roles. He also produced, directed, and starred in a film version of it (see below).
Another famous graduate of the play is Ian McKellen, whose first theatrical role was as Will Roper in a revival production in the late '60s. He would go on to play More in a later run of the show.
An acclaimed Canadian production starring William Hutt and directed by Walter Learning was presented at the Vancouver Playhouse and the Stratford Festival in 1986.
More recently, the play has been staged in London's West End at the Theatre Royal, Haymarket starring Martin Shaw and produced by Bill Kenwright. It closed on 1 April 2006.
Paul Scofield, who played the leading role in the West End stage premiere, played More again in the first of two film versions (1966), winning an Oscar in the process. The film also stars Robert Shaw as Henry VIII, Orson Welles as Wolsey, a young John Hurt as Richard Rich, and an older Wendy Hiller as More's second wife. It was directed by Fred Zinnemann. In addition to the Best Actor Oscar won by Scofield, the film won Academy Awards for screenplay, cinematography, costume design, Best Director, and Best Picture.
The 1988 version stars Charlton Heston (who also directed it) as More, Vanessa Redgrave (who appeared briefly and mutely in the 1966 version as Anne Boleyn) as More's wife, and Sir John Gielgud as Cardinal Wolsey.

Azincourt (historically, Agincourt in English) is a village commune of France, situated in the Pas-de-Calais département and in the Nord-Pas-de-Calais region of France.
Situated 20 km north-west of Saint-Pol-sur-Ternoise, Azincourt is famous as the site of the battle fought on 25 October 1415 in which the army led by King Henry V of England defeated the forces led by Charles d'Albret on behalf of Charles VI of France, and recorded in English history as the Battle of Agincourt.
The original battlefield museum in the village featured model knights made out of Action Man figures. However, this has now been replaced by a more professional exhibition space incorporating laser, video, slide shows, audio commentaries, and some interactive elements. The museum building is shaped like one of the many longbows famously deployed at the battle by King Henry's archers.
The village holds a festival in every other year, commemorating the battle and featuring various stalls and displays. The latest was held on July 21 through July 22 2007.
Azincourt is twinned with the English village of Middleham in North Yorkshire.


Berthold Konrad Hermann Albert Speer, commonly known as Albert Speer (listen; March 19, 1905 – September 1, 1981), was an architect, author and high-ranking Nazi German government official, sometimes called "the first architect of the Third Reich".
Speer was Hitler's chief architect before becoming his Minister for Armaments during the war. He reformed Germany's war production to the extent that it continued to increase for over a year despite increasingly intensive Allied bombing. After the war, he was tried at Nuremberg and sentenced to 20 years' imprisonment for his role in the Third Reich. As "the Nazi who said sorry", he was the only senior Nazi figure to admit guilt and express remorse. Following his release in 1966, he became an author, writing two bestselling autobiographical works, and a third about the Third Reich. His two autobiographical works, Inside the Third Reich and Spandau: the Secret Diaries detailed his often close personal relationship with German dictator Adolf Hitler, and have provided readers and historians with an unequalled personal view inside the workings of the Third Reich. Speer died of natural causes in 1981, in London, England.
Speer was born in Mannheim, Germany, the second of three sons of Albert and Lina Speer. Although Speer became an architect, he originally wanted to become a mathematician. Instead, he followed in the footsteps of his father and grandfather and studied architecture. He began his architectural studies at the Karlsruhe Institute of Technology; his decision to study locally instead of at one of the more prestigious institutes was dictated by the inflation of 1923. In 1924 when the inflation had stabilized, Speer transferred his studies to the more esteemed Technical University of Munich. In 1925 he transferred again, this time to the Technical University of Berlin. It was there that he was under the tutelage of Heinrich Tessenow. Speer had a high regard for Tessenow and when he passed his exams in 1927 he became Tessenow's assistant. His duties as assistant involved teaching seminar classes three days a week. Although Tessenow himself never agreed with Nazism, a number of his students did, and it was they who persuaded Speer to attend a Nazi Party rally in a Berlin beer-hall in December 1930.
Speer claims to have been apolitical as a young man; nevertheless, he did attend the rally. He was surprised to find Hitler dressed in a neat blue suit, rather than the brown uniform seen on Nazi Party posters. Speer claimed to have been quite affected, not only with Hitler's proposed solutions to the threat of Communism and his renunciation of the Treaty of Versailles, but also with the man himself. Several weeks later he attended another rally, though this one was presided over by Joseph Goebbels. Speer was disturbed by the way he had whipped the crowd into a frenzy, playing on their hopes. Although Goebbels' performance offended Speer, he could not shake the impressions Hitler made on him. The next day he joined the Nazi Party as member number 474,481.
In the summer of 1922 he got to know Margarete 'Margret' Weber from Heidelberg (1905 - 1987). They married in Berlin on August 28, 1928 despite Speer's mother being against the relationship. Between 1934 and 1942 Margret gave birth to six children: Albert (*1934), Hilde (*1936), Fritz (*1937), Margarete (*1938), Arnold (* 1940, born Adolf, renamed after 1945) and Ernst (*1942).
Speer's first major commission as a Party member came in 1932 when Karl Hanke (whose villa Speer previously worked on) recommended him to Goebbels to help renovate the new District Headquarters in Berlin, and, later, to renovate Goebbels' Propaganda Ministry. Goebbels was impressed with his work and recommended him to Hitler, who assigned him to help Paul Troost renovate the Chancellery in Berlin. Speer's most notable work on this assignment was the addition of the famous balcony from which Hitler often presented himself to crowds that assembled below. Speer subsequently became a prominent member of Hitler's inner circle and a very close friend to him, winning a special place with Hitler that was unique amongst the Nazi leadership. Hitler, according to Speer, was very contemptuous towards anybody he viewed as part of the bureaucracy, and prized fellow artists like Speer with whom he felt a certain kinship, especially as Hitler himself had previously entertained architectural ambitions.
When Troost died in 1934, Speer was chosen to replace him as the Party's chief architect. One of his first commissions after promotion was perhaps the most familiar of his designs: the Zeppelintribüne, the Nuremberg parade grounds seen in Leni Riefenstahl's propaganda masterpiece, Triumph of the Will. In his autobiography, Speer claimed that, upon seeing the original design, he made a derogatory remark to the effect that the parade ground would resemble a "rifle club" meet. He was then challenged to create a new design.
The grounds were based on ancient Doric architecture of the Pergamon Altar in Anatolia, but magnified to an enormous scale, capable of holding two hundred and forty thousand people. At the 1934 Party rally on the parade grounds, Speer surrounded the site with one hundred and thirty anti-aircraft searchlights. This created the effect of a "Cathedral of Light", (which referenced columns) or, as it was called by British Ambassador Sir Neville Henderson, a "cathedral of ice". Speer later described this as his greatest work.
In 1935 Speer started a close cooperation with the German-French sculptor Arno Breker. They were friends over decades until the death of Speer.
Nuremberg was also to be the site of many more official Nazi buildings, most of which were never built; for example, the German Stadium would have held another four hundred thousand spectators as the site of the Aryan Games, a proposed replacement for the Olympic Games. While planning these buildings, Speer invented the theory of "ruin value." According to this theory, enthusiastically supported by Hitler, all new buildings would be constructed in such a way that they would leave aesthetically pleasing ruins thousands of years in the future. Such ruins would be a testament to the greatness of the Third Reich, just as ancient Greek or Roman ruins were symbols of the greatness of their civilizations. In practice, this theory manifested itself in his marked preference for monumental stone construction, rather than the use of steel frames and ferroconcrete.
In 1937 Speer designed the German Pavilion for the 1937 international exposition in Paris. Speer's work was located directly across from the Soviet Pavilion and was designed to represent a massive defence against the onslaught of Communism. Both pavilions were awarded gold medals for their designs.
Speer was also directed to make plans to rebuild Berlin, which was to become the capital of a "Greater Germany"—Welthauptstadt Germania. The first step in these plans was the Olympic Stadium for the 1936 Summer Olympics, designed by Werner March. Speer also designed the new Reich Chancellery, which included a vast hall designed to be twice as long as the Hall of Mirrors in the Palace of Versailles. Hitler wanted him to build a third, even larger Chancellery, although it was never begun. The second Chancellery was damaged by the Battle of Berlin in 1945 and was eventually demolished by the Soviet occupiers after the war.
Almost none of the other buildings planned for Berlin were ever built. Berlin was to be reorganised along a central three-mile- (five km) long avenue. At the north end, Speer planned to build the Volkshalle—an enormous domed building, based on St. Peter's Basilica in Rome. The dome of the building would have been impractically large; it would be over 700 ft high and 800 ft in diameter, 17 times larger than the dome of St. Peter's. At the southern end of the avenue would be an arch based on the Arc de Triomphe in Paris, but again, much larger; it would be almost 400 ft high, and the Arc de Triomphe would have been able to fit inside its opening. The outbreak of World War II in 1939 led to the abandonment of these plans.
Part of the land for the boulevard was to be found by building two major railway stations, one just north and one just south of the boulevard. This would free up many of the tracks in between. However, according to Speer in The Spandau Diaries, 80,000 buildings would have to be destroyed to complete his plans.
While the north-south axis was not completed, an east-west axis, focused upon the Brandenburg Gate was completed and remains in Berlin today. While none of the buildings designed by Speer during the Nazi era still stand in Berlin, some lampposts remain.
It has been alleged that Speer was responsible for the forced evictions of Jews from their houses to make room for his grand plans, and for re-housing only Aryans affected by this work. These allegations are, however, disputed. He was also listed as being present at the 1943 Posen Conference, a charge Speer later contested by saying that he had in fact left early.
Speer did have an architectural rival: Hermann Giesler, whom Hitler also favoured. There were frequent clashes between the two in regard to architectural matters and in closeness to Hitler.
Hitler was always a strong supporter of Speer, in part because of Hitler's own frustrated artistic and architectural visions. A strong affinity developed between Hitler and the ambitious young architect early in their professional relationship. For Speer, serving as architect for the head of the German state and being given virtual carte blanche as to expenses, presented a tremendous opportunity. For Hitler, Speer seemed to be capable of translating Hitler's grandiose visions into tangible designs which expressed what Hitler felt were National Socialist principles.
After Minister of Armaments and War Production Fritz Todt was killed in a plane crash in 1942, Hitler appointed Speer as his successor in all of his posts. Hitler's affinity for Speer and the architect's efficiency and avoidance of party squabbling are believed to have been considerations in Speer's promotion. In his autobiography, Speer recounts that the power-hungry but lazy Hermann Göring raced to Hitler's headquarters upon word of Todt's death, hoping to claim the office. Hitler instead presented Göring with the fait accompli of Speer's appointment.
Faced with this new responsibility, Speer tried to put the German economy on a war footing comparable to that of the Allied nations, but found himself incessantly hindered by party politics and lack of cooperation from the Nazi hierarchy. Nevertheless, by slowly centralising almost all industry control and cutting through the dense bureaucracy, he succeeded in multiplying war production four times over the next two and a half years, and it reached its peak in 1944 during the height of the Allied strategic bombing campaign. Another big hurdle in his way was the Nazi policy of excluding women from factory work, a serious hindrance in war production and a problem not experienced by Germany's enemies, all of whom made use of the female workforce. To fill this gap, Speer made heavy use of foreign labour as well as forced labour, the latter mainly from the various types of prisoners in the Third Reich.
Speer was considered one of the more "rational" members of the Nazi hierarchy, in contrast with Hitler, Göring, Goebbels, and Himmler. Speer's name was found on the list of members of a post-Hitler government envisioned by the conspirators behind the 1944 July 20 plot to kill Hitler. However, the list had a question mark and the annotation "if possible" by his name, which Speer credits with helping save his life from the extensive purges that followed the scheme's failure. By his own account, Speer considered assassinating Hitler in 1945 by releasing poison gas into the air intake vent on the Führerbunker, but the plan, such as it was, was frustrated for a number of reasons. Independent evidence for this is sparse. Some credit his revelation of this plan at the Nuremberg trials as being pivotal in sparing him the death sentence, which the Soviets had pushed for.
On 13 January, Speer gave a presentation to army corps commanders in a camp near Berlin. According to Speer, Allied bombing was not the biggest problem for German industry. He pointed out that German industry had produced 218,000 rifles in December 1944 alone, nearly double the monthly average in 1941. The production of automatic weapons was up by four times and tank production was up by nearly five times. In addition, the tanks produced were much heavier.
Speer talked for over forty minutes reeling off production statistics. German industry's problem, according to Speer, was Germany's shortage of fuel. Speer did not mention to the corps commanders anything about the shortage of ammunition or the growing reliance on slave labour.
Hitler continued to consider Speer trustworthy, though this trust waned near the war's end as Speer, at considerable risk, campaigned clandestinely to prevent the implementation of Hitler's Nero Decree. The Nero Decree was issued on 19 March and it promoted a scorched earth policy on both German soil and occupied territories. Speer worked in association with General Gotthard Heinrici, whose troops fighting in the east retreated to the American-held lines and surrendered there instead of following Hitler's orders to make what would have been a suicidal effort to hold off the Soviets from Berlin.
Speer even confessed to Hitler shortly before the dictator's suicide that he had disobeyed, and indeed actively hindered Hitler's "scorched earth" decree. According to Speer's autobiography, Speer visited the Führerbunker towards the end and stated gently but bluntly to Hitler that the war was lost and expressed his opposition to the systematic destruction of Germany while reaffirming his affection and faith in Hitler. This conversation, it is said, brought Hitler to tears. On 23 April, Speer left the Führerbunker. Now in disfavour, on 29 April, Speer was excluded from the new cabinet Hitler outlined in his final political testament. This document specified that Speer was to be replaced by his subordinate, Karl-Otto Saur.
Immediately after the war, there seemed to be little indication that Speer would be charged with war crimes. Speer travelled unprotected and openly participated in the so-called Flensburg government for weeks, in the presence of Allied officers. Upon request, he held a series of widely-attended lectures for officials of the Allied occupying powers on various topics, including mistakes made by the Nazi government in industrial and economic affairs and the effectiveness of the Allied strategic bombing campaigns. Some journalists and spectators even expected Speer to be appointed by the occupying powers to help restore Germany's economy. He was taken to Versailles, to Eisenhower's then-headquarters. However, any such speculation ended when he was arrested and sent to Nuremberg for trial.
According to his memoirs, Speer was greeted civilly upon arrival at Nuremburg Prison by prison Commandant Colonel Burton C. Andrus, who was known for treating Nazi war criminals under his jurisdiction with icy disdain. The same memoir mentions Andrus apologizing to Speer for his policy of strictness with the prisoners under his jurisdiction.
At the Nuremberg Trials, Speer was one of the few officials to express remorse. He was sentenced to 20 years' imprisonment, most of which he would serve at Spandau Prison, West Berlin, largely for his use of slave labour.
According to interviews after his imprisonment, as well as his memoirs, Speer adopted a "see no evil" attitude towards the Nazi atrocities. For example, he claimed to have learned of unspecified disturbing events at Auschwitz through his friend Karl Hanke. He then purposely avoided visiting the camp or trying to get more information about what was taking place. In his autobiography, he claims that he had no direct involvement or knowledge of the Holocaust, although he admits having blinded himself to its existence and expresses remorse for this. He certainly was aware, at least, of harsh conditions for the slave labour, and some critics believe that his books understate his role in the atrocities of the era. Moreover, documents uncovered by the Berlin historian Susanne Willems suggest that Speer knew a great deal more about the atrocities than he claimed to.
Speer's acknowledgement of guilt was nuanced. He acknowledged guilt for being a high official of a criminal government, without acknowledging guilt for any crimes committed by himself. His self-described crimes seem to be more acts of omission, including failure to make inquiry into the Holocaust, and failure to challenge Hitler. He painted himself as a nonpolitical technocrat. However, according to The Guardian, Speer revealed in a letter he wrote in 1971 to Hélène Jeanty, the widow of a Belgian resistance leader, that he knew of Himmler's plans to exterminate all the Jews, in spite of his earlier claims to have left Himmler's Posen speech early. In the letter he says, "There is no doubt - I was present as Himmler announced on October 6, 1943, that all Jews would be killed".
During his time in prison, Speer painstakingly documented his experiences in his secret prison diary, which was later released as Spandau: The Secret Diaries. He described his time in prison as consisting mainly of a mind-numbing and pedantically enforced daily routine; incessant petty personal rivalry between the seven prisoners; a pervasive and bloated prison bureaucracy; and, as three prisoners were released early due to ill-health, many false hopes of his own early release. Speer and most of the prisoners had established secret lines of communication to the outside world via sympathetic prison staff. Speer made full use of this by, amongst other things, writing innumerable letters to his family (which were restricted to one outgoing page per month under official regulation) and even having money spent on his behalf from a special bank account for a variety of benign purposes.
Speer, as recounted in his diary, made a deliberate effort to make as productive use of his time as possible. In the first decade, he wrote the first draft of his tell-all memoirs. He considered this to be his "duty" to history and his people as the sole surviving member of Hitler's inner circle, in possession of knowledge and a degree of objectivity that no one else had. As the prison directors both forbade the writing of a memoir and recorded each sheet of paper given to the prisoners, he wrote much of his memoir secretly on toilet paper, tobacco wrappings, and any other material he could get his hands on, and then had the pages systematically smuggled out.
All the while Speer devoted much of his energy and time towards reading books from the prison's library, which was organised by fellow prisoner and ex-Grand Admiral Erich Raeder. The prisoners could also have books sent over from the local branch of the Berlin library, and, later, from the central library. Speer was, more so than the others, a voracious reader and he completed well over 500 books in the first three years alone. His tastes ranged from Greek drama to famous plays to architectural books and journals, partly from which he collected information for a book he intended to write on the history and function of windows in architecture.
Later, Speer took to the prison garden for enjoyment and work. Heretofore the garden was divided up into small personal plots for each prisoner with the produce of the garden being used in the prison kitchen. When regulations began to slacken in this regard, Speer was allowed to build an ambitious garden, complete with a meandering path, rock garden, and a wide variety of flowers. The garden was even, humorously, centred around a "north-south axis", which had been the core design element of Speer and Hitler's plan for a new Berlin. To maintain his physical fitness and his ability for imagination, Speer then took up a virtual "walking tour of the world" by ordering geography and travel books from the local library and walking laps in the prison garden visualising his journey. Meticulously calculating every metre travelled, and mapping distances to the real-world geography, he began in northern Germany, went through the Balkans, Persia, India, and Siberia, then crossed the Bering Strait and continued southwards, finally ending his sentence in central Mexico.
While Speer was incarcerated, his Nuremberg counsel, Dr. Hans Flächsner, remained as his attorney. His major work during this time was stalling the de-Nazification proceedings against Speer. While Speer could not have been subject to further incarceration, the property upon which his family survived during that time could have been confiscated. The proceedings were eventually ended by West Berlin Mayor and future Chancellor Willy Brandt. Flächsner would accompany Margarete Speer to Spandau to greet Speer on his release.
Speer's release from prison in 1966 was a worldwide media event. Abandoning plans to return to architecture (two proposed partners died shortly before his release) he then revised and published two autobiographical books based on the diary entries he had made in prison as well as a third about the SS, which was less well-received. His books, most notably Inside the Third Reich and The Spandau Diaries, provide a unique and personal look into the personalities of the Nazi era, and have become much valued by historians. Speer was aided in shaping the works by Joachim Fest and Wolf-Jobst Siedler from the publishing house Ullstein. Speer died of a cerebral hemorrhage in London, England, on September 1, 1981.
Speer himself appeared in the ITV television series The World at War which was first broadcast in 1973. Speer appeared in a number of episodes including the 12th episode entitled "Whirlwind", in which he admitted that he regarded the bombing of Germany by the RAF's Bomber Command as a second front. In a number of the other episodes he spoke at length of his relationship with Hitler and how he became Minister of War Armaments Production after Fritz Todt was killed in a plane crash. Speer revealed that he was meant to have been on the plane along with Todt, and was informed half an hour after the news was given to Hitler he was summoned to Hitler to take on all of Todt's offices.
He also revealed that, unlike most of the senior OKW commanders and Reichministers, he had direct access to Hitler. He claimed that he was only informed of the goings on within the Concentration Camps by a Gauleiter. He also contributed Dudley Saward's Official Biography of Bomber Harris the Commander of Bomber Command by giving a number of interviews and access to his files which stated the effects of the bombing had not only on manufacturing but on how artillery pieces were being directed to the defence of Germany and not to the Eastern Front.
Speer's daughter Hilde (married Schramm) became a noted left-wing parliamentarian. Speer's eldest son, Albert, became a successful architect in his own right. Second daughter Margarete (married Nissen) became a photographer and Arnold, Speer's second youngest son became a community doctor.


Alliaceae is a family of herbaceous perennial flowering plants. They are monocots, part of order Asparagales. The family has been widely but not universally recognised; in the past, the plants involved were often treated as belonging to the family Liliaceae, and still are by some botanists.
Note that quite a few of the plants that were once included in family Alliaceae are assigned to the family Themidaceae by both APG and APG II.
The most important genus is Allium, which includes several important food plants, including onions (Allium cepa), chives (A. schoenoprasum), garlic (A. sativum and A. scordoprasum), and leeks (A. porrum).
The genera Androstephium, Bessera, Bloomeria, Brodiaea, Dandya, Dichelostemma, Milla, Petronymphe, Triteleia, and Triteleiopsis are now treated in the family Themidaceae.


The family Asteraceae or Compositae, known as the aster, daisy or sunflower family, is the second largest family of flowering plants, after Orchidaceae, in terms of number of species.
The name 'Asteraceae' is derived from the type genus Aster, while 'Compositae', an older but still valid name, means composite and refers to the unique inflorescence. The study of this family is known as synantherology.
According to the Royal Botanical Gardens of Kew the family comprises more than 1,600 genera and 23,000 species. The largest genera are Senecio (1,500 species), Vernonia (1,000 species), Cousinia (600 species), Centaurea (600 species). The circumscription of the genera is often problematic and some of these have been frequently divided into minor subgroups.
Asteraceae are cosmopolitan, but most common in the temperate regions and tropical mountains.
The family has been universally recognised and placed in the order Asterales.
Traditionally two subfamilies were recognised: Asteroideae (or 'Tubuliflorae') and Cichorioideae (or 'Liguliflorae'). The latter is paraphyletic and has been divided into many minor groups in most newer systems. The article is based the subdivisions proposed by the APG system.
A tentative cladogram is shown below. The diamond denotes a very poorly supported branching (<50%), the dot a poorly supported branching (<80%).
It is noteworthy that the four subfamilies Asteroideae, Cichorioideae, Carduoideae and Mutisioideae comprise 99% of the specific diversity of the whole family (appr. 70%, 14%, 11% and 3% respectively).
Asteraceae are most usually herbs, but some shrubs, trees and climbers do exist. They are generally easy to distinguish, mainly because of their unique inflorescence and share many apomorphies.
The leaves and the stems very often contain secretory canals with resin or latex (particularly common among the Cichorioideae). The leaves can be alternate, opposite, or whorled. They may be simple, but are often deeply lobed or otherwise incised, often conduplicate or revolute. The margins can be entire or dentate.
The most evident characteristic of Asteraceae is perhaps their inflorescence: a specialised capitulum, technically called a calathid or calathidium, but generally referred to as flower head or, alternatively, simply capitulum. The capitulum is a contracted raceme composed of numerous individual sessile flowers, called the florets, that share the same receptacle.
The capitulum of the Asteraceae has evolved many characteristics that make it look superficially like a big single flower. This kind of flower-like inflorescences are quite widespread amongst plants and have been given the name of pseudanthia.
Many bracts form an involucre under the basis of the capitulum; these are called "phyllaries", or "involucral bracts". They may simulate the sepals of the pseudanthium. These are mostly herbaceous but can also be brightly coloured (e.g. Helichrysum) or have a scarious texture. The bracts can be free or fused, and arranged in one to many rows, overlapping like the tiles of a roof (imbricate) or not (this variation is important in identification of tribes and genera).
Each floret may itself be subtended by a bract, called a "palea" or "receptacular bract". These bracts as a group are often called "chaff". The presence or absence of these bracts, their distribution on the receptacle, and their size and shape are all important diagnostic characteristics for genera and tribes.
The florets primitively have five petals and may be actinomorphic or zygomorphic. The disc florets are usually actinomorphic, their petals are fused so that the corolla is tubular and they are either very short or long with deeply lobed petals. The latter is the only kind of floret in the Carduoideae, while the first kind is more widespread. In the Mutisioideae disc florets are bilabiate (3+2 scheme). On the other hand, the ray florets are always highly zygomorphic and are characterised by the presence of a ligule. In the Asteroideae and other minor subfamilies they are usually borne on the circumference of the capitulum and have a 3+2 scheme: three very long fused petals form the ligule and the other two are more or less reduced. The Cichorioidea have only ray florets, which have a 5+0 scheme. The 4+1 scheme is found in the Barnadesioideae. Sometimes some marginal florets may have no petals at all (filiform floret).
The calyx of the florets may be absent, but when present it is always modified into a pappus of two or more teeth, scales or bristles and is often involved in the dispersion of the seeds. As with the bracts, the nature of the pappus is an important diagnostic.
There are usually five stamens. The filaments are fused to the corolla, while the anthers are are generally connate (syngenesious anthers), thus forming a sort of tube around the style (theca). They commonly have basal and/or apical appendages. Pollen is released inside the tube and is collected around the growing style, expelled with a sort of pump mechanism (nüdelspritze) or a brush.
The pistil is made of two connate carpels. The style has two lobes; stigmatic tissue may be located in the interior surface or form two lateral lines. The ovary is inferior and has only one ovule, basal placentation.
The fruit of the Asteraceae is a specialised type of achene, sometimes called cypsela (plural cypselae). One seed per fruit is formed. It may sometimes be flat, winged or spiny and it adheres to the persistent pappus. Its morphology is often used to help determine plant relationships at the genus and species level. The seeds usually have little or lack endosperm.
Asteraceae generally store energy in the form of inulin.
They produce iso/chlorogenic acid, sesquiterpene lactones, pentacyclic triterpene alcohols, various alkaloids, acetylenes (cyclic, aromatic, with vinyl end groups), tannins. They have terpenoid essential oils which never contain iridoids.
Asteraceae are especially common in open and dry environments.
Many members of the Asteraceae are pollinated by insects, but anemophyly is also present (e.g. Ambrosia, Artemisia). There are many apomictic species in the family.
Seeds are ordinarily dispersed intact with the fruiting body, the cypsela. Wind dispersal is common (anemochory) assisted by a hairy pappus. Another common variation is (epizoochory), in which the dispersal unit, a single cypsela (e.g. Bidens) or entire capitulum (e.g. Arctium) provided with hooks, spines or some equivalent structure, sticks to the fur or plumage of an animal (or even to clothes, like in the photo) just to fall off later far from its mother plant.
Diversification of Asteraceae may have been within 42-36 million years, the stem group perhaps being up to 49 million years old.
It is still unknown whether the precise cause of their great success was the development of the calathid, their ability to store energy as fructans (mainly inulin), which is an advantage in relatively dry zones, or some combination of these and possibly other factors.
Commercially important plants in the Asteraceae include the food crops Lactuca sativa (lettuce), Cichorium (chicory), Cynara scolymus (globe artichoke), Helianthus annuus (sunflower), Smallanthus sonchifolius (yacón), Carthamus tinctorius (safflower) and Helianthus tuberosus (Jerusalem artichoke).
Other commercially important species include Compositae used as herbs and in herbal teas and other beverages. Chamomile which comes from two different species, the annual Matricaria recutita or German chamomile, and the perennial Chamaemelum nobile, also called Roman chamomile. Calendula, also called the pot marigold is grown commercially for herbal teas and the potpourri industry. Echinacea (Echinacea purpurea), used as a medicinal tea. Winter tarragon, also called Mexican mint marigold, Tagetes lucida is commonly grown and used as a tarragon substitute in climates where tarragon will not survive. Finally, the wormwood genus Artemisia includes absinthe (A. absinthium) and tarragon (A. dracunculus).
Industrial use of Compositae is also known. Common in all commercial poultry feed, marigold (Tagetes patula) is grown primarily in Mexico. Marigold oil, extracted from Tagetes minuta" is used by the metric ton in the cola and cigarette industry.
Plants in Asteraceae are medically important in areas that don't have access to Western medicine. They are also commonly featured in medical and phytochemical journals because the sesquiterpene lactone compounds contained within them are an important cause of allergic contact dermatitis. Allergy to these compounds is the leading cause of allergic contact dermatitis in florists in the US. Pollen from Ragweed Ambrosia is among the main causes of so called hay fever in the United States.
Many members of the family are grown as ornamental plants for their flowers and some are important ornamental crops for the cut flower industry. Some examples are Chrysanthemum, Gerbera, Calendula, Dendranthema, Argyranthemum, Dahlia, Tagetes, Zinnia and many others.
Many members of Asteraceae are copious nectar producers and are useful for evaluating pollinator populations during their bloom. Centaurea (knapweed), Helianthus annuus (domestic sunflower), and some species of Solidago (goldenrod) are major "honey plants" for beekeepers. Solidago produces relatively high protein pollen, which helps honey bees overwinter.
Some members of the Asteraceae are economically important as weeds. Notably in the United States are the ragwort, Senecio jacobaea, groundsel Senecio vulgaris and Taraxacum (dandelion).
The genera Tanacetum, Chrysanthemum and Pulicaria contain species with insecticidal properties.
Parthenium argentatum (Guayule) is a source of hypoallergenic latex.


The Apiaceae or Umbelliferae (both names are allowed by the ICBN) is a family of usually aromatic plants with hollow stems, commonly known as umbellifers. It includes cumin, parsley, carrot, coriander / cilantro, dill, caraway, fennel, parsnip and other relatives. It is a large family with about 300 genera and more than 3,000 species. The earlier name Umbelliferae derives from the inflorescence being in the form of a compound "umbel", and has the same root as the word "umbrella", for obvious reasons.
The small flowers are radially symmetrical with 5 small sepals, 5 petals and 5 stamens.
The family includes some highly toxic plants, such as hemlock. Many plants in this family, such as wild carrot have estrogenic properties, and have been used as folk medicine for birth control. Most notable for this use is the extinct giant fennel, silphium. The cultivated plants in this category are almost all considered good companion plants, as the umbrella of tiny flowers attracts omnivorous beneficial insects, especially parasitic wasps and predatory flies, which then will hunt insect pests on nearby crops.
The family is closely related to Araliaceae and the boundaries between these families remain unclear. Some recent systems include Araliaceae in an expanded Apiaceae but this has not been widely followed. Hydrocotyle and Trachymene, traditionally included in Apiaceae, are now generally included in Araliaceae.
Many members of this plant group are cultivated, for various purposes. The plant structure includes a tap root, which on more than one occasion has been bred to grow large enough to be useful in food, as with parsnips, carrots, and hamburg root parsley. Plants of this category also are adapted to conditions that encourage heavy concentrations of essential oils, so that some are used as flavorfull/aromatic herbs, including parsley, cilantro, and dill. The plentiful seeds of the umbers, likewise, are sometimes used in cuisine, as with coriander, fennel, cumin, and caraway.
Almost every widely cultivated plant of this group is a companion plant. In large part, this is because the tiny flowers forming the umbers, for which the group is named, are perfectly suited for parasitic wasps, and predatory flies, which actually drink nectar when not reproducing. They then will prey upon insect pests on nearby plants.
Some of the plants, too, are herbs that produce enough scent to possibly dilute the odors of nearby plants, or the pheromones or emitted by insects that find those plants, which would otherwise attract more pests.


away from the neuron's cell body or soma.
Axons are in effect the primary transmission lines of the nervous system, and as bundles they help make up nerves. Individual axons are microscopic in diameter (typically about 1μm across), but may up to multiple feet long. The longest axons in the human body, for example, are those of the sciatic nerve, which run from the base of the spine to the big toe of each foot. These single-cell fibers of the sciatic nerve may extend a meter or even longer.
In vertebrates, the axons of many neurons are sheathed in myelin, which is formed by either of two types of glial cells: Schwann cells ensheathing peripheral neurons and oligodendrocytes insulating those of the central nervous system. Along myelinated nerve fibers, gaps in the sheath known as nodes of Ranvier occur at evenly-spaced intervals, enabling an especially rapid mode of electrical impulse propagation called saltation. The demyelination of axons is what causes the multitude of neurological symptoms found in the disease Multiple Sclerosis.
The axons of some neurons branch to form axon collaterals, that can be divided into a number of smaller branches called telodendria. Along these the bifurcated impulse travels simultaneously to signal more than one other cell.
The physiology can be described by the Hodgkin-Huxley Model, extended to vertebrates in Frankenhaeuser-Huxley equations.
Peripheral nerve fibers can be classified based on axonal conduction velocity, mylenation, fiber size etc. For example, there are slow-conducting unmyelinated C fibers and faster-conducting myelinated Aδ fibers. More complex mathematical modeling continues to be done today.
Different sensory receptors are innervated by different types of nerve fibers. Muscles and associated sensory receptors are innvervated by type I and II sensory fibers, while cutaneous receptors are innervated by Aβ, Aδ and C fibers.
Growing axons move through their environment via the growth cone, which is at the tip of the axon. The growth cone has a broad sheet like extension called lamellipodia which contain protrusions called filopodia. The filopodia are the mechanism by which the entire process adheres to surfaces and explores the surrounding environment. Actin plays a major role in the mobility of this system.
Environments with high levels of cell adhesion molecules or CAM's create an ideal environment for axonal growth. This seems to provide a "sticky" surface for axons to grow along. Examples of CAM's specific to neural systems include N-CAM, neuroglial CAM or NgCAM, TAG-1, MAG, and DCC, all of which are part of the immunoglobulin superfamily. Another set of molecules called extracellular matrix adhesion molecules also provide a sticky substrate for axons to grow along. Examples of these molecules include laminin, fibronectin, tenascin, and perlecan. Some of these are surface bound to cells and thus act as short range attractants or repellents. Others are difusible ligands and thus can have long range effects.
Cells called guidepost cells assist in the guidance of neuronal axon growth. These cells are typically other, sometimes immature, neurons.
Some of the first intracellular recordings in a nervous system were made in the late 1930's by K. Cole and H. Curtis. Alan Hodgkin and Andrew Huxley also employed the squid giant axon (1939) and by 1952 they had obtained a full quantitative description of the ionic basis of the action potential, leading the formulation of the Hodgkin-Huxley Model.
Hodgkin and Huxley were awarded jointly the Nobel Prize for this work in 1963.
The formulas detailing axonal conductance were extended to vertebrates in the Frankenhaeuser-Huxley equations. Erlanger and Gasser later developed the classification system for peripheral nerve fibers, based on axonal conduction velocity, mylenation, fiber size etc.
Even recently our understanding of the biochemical basis for action potential propagation has advanced, and now includes many details about individual ion channels.
Concussion is considered a mild form of diffuse axonal injury.


The Aramaic alphabet is an abjad, a consonantal alphabet, used for writing Aramaic. It developed out of the Phoenician alphabet, and became distinctive from it by the eighth century BCE. As with other abjads, the letters all represent consonants, some of which are matres lectionis, which also indicate long vowels.
The Aramaic alphabet is historically significant since virtually all modern Indian and Middle Eastern writing systems use a script that can be traced back to it, as do some East Asian and Southeast Asian writing systems. This is primarily due to the widespread usage of the Aramaic language as both a lingua franca and the official language of the Persian Empire, Babylonia, and Assyria. The holy texts of Judaism and Islam, as well as certain Christian and Buddhist texts are written in scripts which are known descendants of Aramaic. The Brahmic family of scripts, which is used in Hinduism, Sikhism, and some versions of Buddhism, holds a disputed link with Aramaic.
The earliest inscriptions in the Aramaic language use the Phoenician alphabet. Over time, the alphabet developed into the form shown below. Aramaic gradually became the lingua franca throughout the Middle East, with the script displacing cuneiform as the official writing system of the existing empires. Its widespread usage led to the gradual adoption of the Aramaic alphabet for writing the Hebrew language. Formerly, Hebrew had been written using an alphabet closer in form to that of Phoenician (the Paleo-Hebrew alphabet).
The Hebrew and Nabataean alphabets are little changed in style from the Aramaic alphabet. The development of cursive versions of Aramaic led to the creation of the Syriac, Palmyrenean and Mandaic alphabets. These scripts formed the basis of the Arabic, Sogdian, Orkhon and Mongolian alphabets. Controversially, it is claimed that the Aramaic alphabet may be the forebear of the Indic alphabets on the basis of certain strong similarities between the Aramaic and Brāhmī script.
Today, Biblical Aramaic, Jewish Neo-Aramaic dialects and the Aramaic language of the Talmud are written in the Hebrew alphabet. Syriac and Christian Neo-Aramaic dialects are written in the Syriac alphabet. Mandaic is written in the Mandaic alphabet.
Redrawn from A Grammar of Biblical Aramaic, Franz Rosenthal; forms are as used in Egypt, 5th century BCE. Names are as in Biblical Aramaic.
The letters Waw and Yudh were sometimes used to indicate the long vowels û and î respectively (often also ô and ê respectively). These letters which stand for both consonant and vowel sounds are known as matres lectionis. The letter Alaph has some of the characteristics of a mater lectionis: in initial positions it indicates an initial vowel, and word finally it represents the vowels â or ê. Among Jews, influence of Hebrew spelling often led to the use of He instead of Alaph in word final positions. The practice of using certain letters to hold vowel values spread to child writing systems of Aramaic, such as Hebrew and Arabic, where they are still used today.



As We May Think is an essay by Vannevar Bush, first published in The Atlantic Monthly in July 1945. Bush argued that as humans turned from war, scientific efforts should shift from increasing physical abilities to making all previous collected human knowledge more accessible.
The article was a reworked and expanded version of his 1939 Mechanization and the Record. The system, which he called memex, was described as based on what was thought, at the time, to be the wave of the future: Ultra high resolution microfilm reels, coupled to multiple screen viewers and cameras, by electromechanical controls. The Atlantic Monthly article was followed, in November 1945, by a Life magazine article which showed illustrations of the proposed memex desk and automatic typewriter.

"American shot" is a translation of a phrase from French film criticism, "plan américain" and refers to a medium-long ("knee") film shot of a group of characters, who are arranged so that all are visible to the camera. The usual arrangement is for the actors to stand in an irregular line from one side of the screen to the other, with the actors at the end coming forward a little and standing more in profile than the others. The purpose of the composition is to allow complex dialogue scenes to be played out without changes in camera position. In some literature, this is simply referred to as a 3/4 shot.
The French critics thought it was characteristic of American films of the 1930s or 1940s; however, it was mostly characteristic of cheaper American movies, such as Charlie Chan mysteries where people collected in front of a fireplace or at the foot of the stairs in order to explain what happened a few minutes ago.

Acute disseminated encephalomyelitis (ADEM) is an immune mediated disease of brain. It usually occurs following a viral infection but may appear following vaccination, bacterial or parasitic infection, or even appear spontaneously. As it involves autoimmune demyelination, it is similar to multiple sclerosis, and is considered part of the Multiple sclerosis borderline. The incidence rate is about 0.8 per 100,000 people per year. Although it occurs in all ages, most reported cases are in children and adolescents, with the average age around 5 to 8 years old. The mortality rate may be as high as 5%, full recovery is seen in 50 to 75% of cases, while up to 70 to 90% recover with some minor residual disability. The average time to recover is one to six months.
ADEM produces multiple inflammatory lesions in the brain and spinal cord, particularly in the white matter. Usually these are found in the subcortical and central white matter and cortical gray-white junction of both cerebral hemispheres, cerebellum, brainstem, and spinal cord, but periventricular white matter and gray matter of the cortex, thalami and basal ganglia may also be involved. In rare cases, ADEM seems to follow from organ transplantation. The risk of ADEM from measels vaccination is about 1 to 2 per million, which is far lower than the risk of developing ADEM from an actual measels infection, which is about 1 per 1000 for measles (and 1 per 5000 for rubella). Measels infection also appears to lead to worse ADEM outcomes than cases associated with measels immunization. Some vacines, later shown to have been contaminated with host animal CNS tissue, have ADEM incident rates as high as 1 in 600.
ADEM has an abrupt onset and a monophasic course. Symptoms usually begin 1-3 weeks after infection or vaccination. Major symptoms include fever, headache, drowsiness, seizures and coma. Although initially the symptoms are usually mild, they worsen rapidly over the course of hours to days, with the average time to maximum severity being about four and a half days.
No controlled clinical trials have been conducted on ADEM treatment, but aggressive treatment aimed at rapidly reducing inflammation of the CNS is standard. The widely accepted first-line treatment is high doses of intravenous corticosteroids, such as methylprednisolone or dexamethasone, followed by 3-6 weeks of gradually lower oral doses of prednisolone. Patients treated with methylprednisolone have shown better outcomes than those treated with dexamethasone. Oral tapers of less than three weeks duration show a higher chance of relapsing, and tend to show poorer outcomes. Other antiinflamatory and immunosuppressive therapies have been reported to show beneficial effect, such as plasmapheresis, high doses of intravenous immunoglobulin (IVIG), mitoxantrone and cyclophosphamide. These are considered alternative therapies, used when corticosteroids cannot be used, or fail to show an effect.
In a study of 16 children with ADEM, 10 recovered completely after high-dose methylprednisolone, one severe case that failed to respond to steroids recovered completely after IVIg; the five most severe cases -with ADAM and severe peripheral neuropathy- were treated with combined high-dose methylprednisolone and immunoglobulin, two remained paraplegic, one had motor and cognitive handicaps, and two recovered. A recent review of IVIg treatment of ADEM (of which the previous study formed the bulk of the cases) found that 70% of children showed complete recovery after treatment with IVIg, or IVIg plus corticosteroids.
Full recovery is seen in 50 to 75% of cases, ranging to 70 to 90% recovery with some minor residual disability (typically assessed using measures such as mRS or EDSS), average time to recover is one to six months. The mortality rate may be as high as 5%. Poorer outcomes are associated with unresponsiveness to steroid therapy, unusually severe neurological symptoms, or sudden onset. Children tend to have more favorable outcomes than adults, and cases presenting without fevers tend to have poorer outcomes. The latter effect may be due to either protective effects of fever, or that diagnosis and treatment is sought more rapidly when fever is present.
Residual motor deficits are estimated to remain in about 8 to 30% of cases, the range in severity from mild clumsiness to ataxia and hemiparesis.
Patients with demylinating illnesses, such as MS, have been show cognitive deficits even when there is minimal physical disability. Research suggests that similar effects are seen after ADEM, but that the deficits are less severe than those seen in MS. A study of six children with ADEM (mean age at presentation 7.7 years) were tested for a range of neurocognitive tests after an average of 3.5 years of recovery. All six children performed in the normal range on most tests, including verbal IQ and performance IQ, but performed at least one standard deviation below age norms in at least one cognitive domain, such as complex attention (one child), short-term memory (one child) and internalizing behaviour/affect (two children). Group means for each cognitive domain were all within one standard deviation of age norms, demonstrating that, as a group, they were normal. These deficits were less severe than those seen in similar aged children with a diagnosis of MS.
While ADEM and MS both involve autoimmune demylenation, they differ in many clinical, genetic, imaging, and histopathological differences. Some authors consider MS and it's borderline forms to constitute a spectrum, differing only in chronocity, severity, and clinical course, while others consider them discretely different diseases.


Ataxia From Greek α- (used as a negative prefix) + -τάξις (order), meaning "lack of order". It is a neurological sign and symptom consisting of gross incoordination of muscle movements. Ataxia is an aspecific clinical manifestation implying dysfunction of parts of the nervous system that coordinate movement, such as the cerebellum. Several possible causes exist for these patterns of neurological dysfunction. The "International Ataxia Awareness Day" is observed on September 25th each year. Dystaxia refers to difficulty in controlling voluntary movements.
The term cerebellar ataxia is employed to indicate ataxia due to dysfunction of the cerebellum. This causes a variety of elementary neurological deficits, such as antagonist hypotonia, asynergy, dysmetria, dyschronometria, and dysdiadochokinesia. How and where these abnormalities manifest depend on which cerebellar structures are lesioned, and whether the lesion is bilateral or unilateral.
Vestibulo-cerebellar dysfunction presents with postural instability, in which the person tends to separate the feet on standing to gain a wider base, and avoid oscillations (especially posterior-anterior ones); instability is therefore worsened when standing with the feet together (irrespective of whether the eyes are open or closed: this is a negative Romberg's test).
Spino-cerebellar dysfunction presents with a wide-based "drunken sailor" gait, characterised by uncertain start and stop, lateral deviations, and unequal steps.
Cerebro-cerebellar dysfunction presents with disturbances in carrying out voluntary movements, including intention tremor (coarse trembling, accentuated over the execution of voluntary movements, possibly involving the head and eyes as well as the limbs and torso), peculiar writing abnormalities (large, unequal letters, irregular underlining), and a peculiar pattern of dysarthria (slurred speech, sometimes characterised by explosive variations in voice intensity despite a regular rhythm).
with an unsteady "stomping" gait with heavy heel strikes, as well as postural instability that is characteristically worsened when the lack of proprioceptive input cannot be compensated by visual input, such as in poorly lit environments. Doctors can evidence this during physical examination by having the patient stand with his / her feet together and eyes shut, which will cause the patient's instability to markedly worsen, producing wide oscillations and possibly a fall (this is called a positive Romberg's test). Worsening of the finger-pointing test with the eyes closed is another feature of sensory ataxia. Also, when the patient is standing with arms and hands extended toward the examiner, if the eyes are closed, the patient's finger will tend to "fall down" and be restored to the horizontal extended position by sudden extensor contractions ("ataxic hand").
The term vestibular ataxia is employed to indicate ataxia due to dysfunction of the vestibular system, which in acute and unilateral cases is associated with prominent vertigo, nausea and vomiting. In slow-onset, chronic bilateral cases of vestibular dysfunction, these characteristic manifestations may be absent, and dysequilibrium may be the sole presentation.
The three types of ataxia have overlapping causes, and can therefore either coexist or occur in isolation.
Any type of focal lesion of the central nervous system (such as stroke, brain tumour, multiple sclerosis will cause the type of ataxia corresponding to the site of the lesion: cerebellar if in the cerebellum, sensory if in the dorsal spinal cord (and rarely in the thalamus or parietal lobe), vestibular if in the vestibular system (including the vestibular areas of the cerebral cortex).
Exogenous substances that cause ataxia mainly do so because they have a depressant effect on central nervous system function. The most common example is ethanol, which is capable of causing overlapping cerebellar and vestibular ataxia. Other examples include both prescription drugs (e.g. most antiepileptic drugs have cerebellar ataxia as a possible unwanted effect) and recreational drugs (e.g. ketamine, PCP).
Vitamin B12 deficiency may cause, among several neurological abnormalities, overlapping cerebellar and sensory ataxia.
peripheral neuropathies may cause generalised or localised sensory ataxia (e.g. a limb only) depending on the extent of the neuropathic involvement. Spinal disorders of various types may cause sensory ataxia from the lesioned level below, when they involve the dorsal columns.
Non-hereditary causes of cerebellar degeneration include chronic ethanol abuse, paraneoplastic cerebellar degeneration, high altitude cerebral oedema, coeliac disease, and normal pressure hydrocephalus.
Ataxia may depend on hereditary disorders consisting of degeneration of the cerebellum and/or of the spine; most cases feature both to some extent, and therefore present with overlapping cerebellar and sensory ataxia, even though one is often more evident than the other. Hereditary disorders causing ataxia include autosomal dominant ones such as spinocerebellar ataxia, episodic ataxia, and dentatorubropallidoluysian atrophy, as well as autosomal recessive disorders such as Friedreich's ataxia (sensory and cerebellar, with the former predominating), ataxia-telangiectasia (sensory and cerebellar, with the latter predominating), and abetalipoproteinaemia. An example of X-linked ataxic condition is the rare fragile X-associated tremor/ataxia syndrome.
There is no specific treatment for ataxia as such, although there may be for the underlying cause. The disability of ataxia may be reduced by physical therapy, including exercises, along with leg braces or shoe splints, if foot alignment has been affected; a cane or walker is often used in the effort to prevent falls.

Abdul Alhazred is a fictional character created by American horror writer H. P. Lovecraft. He is the so-called "Mad Arab" credited with authoring the imaginary book Kitab al-Azif (the Necronomicon), and as such an integral part of Cthulhu Mythos lore.
The name Abdul Alhazred is a pseudonym that Lovecraft created in his youth, which he took on after reading 1001 Arabian Nights at the age of about five years. The name was invented either by Lovecraft, or by Albert Baker the Phillips family lawyer. Abdul is a common Arabic name component (but never a name by itself; additionally the ending -ul and the beginning Al- are redundant), but Alhazred may allude to Hazard", a name from Lovecraft's family tree. It might also have been a pun on "all-has-read", since Lovecraft was an avid reader in youth.
Abdul Alhazred is not a real Arabic name, and seems to contain the Arabic definite article morpheme al- twice in a row (anomalous in terms of Arabic grammar). The more proper Arabic form might be Abd-el-Hazred or Abdul Hazred. In Arabic translations, his name has appeared as Abdullah Alḥaẓred (عبدالله الحظرد): Arabic ḥaẓraحظر = "he fenced in", "he prohibited". Hazred could come from the Persian or Arabic word "Hazrat" meaning Great Lord with a twist that makes it sound like "red" and "hazard" both indicative of danger.
The phrase "mad Arab", sometimes with both words capitalized in Lovecraft's stories, is used so commonly before Alhazred's name that it almost constitutes a title. A reference to the "Mad Arab" in Cthulhu Mythos fiction is invariably a synonym for Abdul Alhazred.
August Derleth later made alterations to the biography of Alhazred, such as redating his death to 731. Derleth also changed Alhazred's final fate, as described in his short story "The Keeper of the Key", first published in May 1951. In the story, Professor Laban Shrewsbury (a recurring Derleth character) and his assistant at the time, Nayland Colum, discover Alhazred's burial site.
While the two are heading a caravan from Salalah, Oman, they cross the border into Yemen and find the unexplored desert area that the Necronomicon calls "Roba el Ehaliyeh" or "Roba el Khaliyeh" — presumably a reference to the Empty Quarter or "Rub al Khali".
At the center of the area they discover the Nameless City (the setting of the Lovecraft story of the same name) and in Derleth's text the domain of the Great Old One Hastur. Shrewsbury, an old agent of Hastur and the devoted enemy of Hastur's half-brother, Cthulhu, crosses its gates in search of Alhazred's burial site.
He indeed finds Alhazred's burial chamber and learns of his fate. Alhazred had been kidnapped in Damascus and brought to the Nameless City, where he had earlier studied and learned some of the Necronomicon's lore. As punishment for betraying their secrets, Alhazred was tortured. Then they blinded him, severed his tongue and executed him.
Although the entrance to the chamber warns against disturbing him, Shrewsbury opens Alhazred's sarcophagus anyway, finding that only rugs, bones, and dust remain of Alhazred. However, the sarcophagus also contains Alhazred's personal, incomplete copy of the Necronomicon, written in the Arabic alphabet. Shrewsbury then uses necromancy to recall Alhazred's spirit and orders it to draw a map of the world as he knew it. After obtaining the map, which reveals the location of R'lyeh and other secret places, Shrewsbury finally lets Alhazred return to his eternal rest.

Augusta Ada King, Countess of Lovelace (December 10, 1815 London, England – November 27, 1852 Marylebone, London, England ), born Augusta Ada Byron, is mainly known for having written a description of Charles Babbage's early mechanical general-purpose computer, the analytical engine. She is also known as the "first programmer", though she might more accurately described as the first publisher of a program, as she published a program written by Babbage. She was also a keen promotor of computing seeing how influential its possibilities, though unrealized as yet, might be.
Ada was the first legitimate child of the poet Lord Byron and his wife, Annabella (full name Anne Isabella Milbanke). She was named after Byron's half-sister, Augusta Leigh, whose child he was rumoured to have fathered. Ada was born on December 10, 1815, London, England. On January 16, 1816, Annabella left Byron, taking 1-month old Ada with her. On April 21, Byron signed the Deed of Separation and left England for good a few days later.
Ada never met her younger half-sister, Allegra Byron, daughter of Lord Byron and Claire Clairmont, who died at the age of five in 1822. Ada did have some contact with Elizabeth Medora Leigh, the daughter of Byron's half-sister Augusta Leigh. Ada and Medora were told by Ada's mother that Byron was Medora's father.
Ada lived with her mother, as is apparent in her father's correspondence concerning her. Lady Byron was also highly interested in mathematics, which dominated her life, even after marriage. Her obsession with rooting out any of the insanity of which she accused Lord Byron was one of the reasons why Annabella taught Ada mathematics at an early age. Ada was privately home schooled in mathematics and science by William Frend, William King and Mary Somerville. One of her later tutors was Augustus De Morgan. An active member of London society, she was a member of the Bluestockings in her youth.
In 1835 she married William King, 8th Baron King, later 1st Earl of Lovelace. They had three children; Byron born 12 May 1836, Annabella (Lady Anne Blunt) born 22 September 1837 and Ralph Gordon born 2 July 1839. The family lived at Ockham Park, at Ockham, Surrey. Her full name and title for most of her married life was The Right Honourable Augusta Ada, Countess of Lovelace. She is widely known in modern times simply as Ada Lovelace, or by her maiden name, Ada Byron.
Ada apparently was a hard drinker and gambled heavily. At the time of her death she owed £2000. Additionally, she flirted with other men, and numerous scandals were apparently covered up by her husband.
She knew and was taught by Mary Somerville, noted researcher and scientific author of the 19th century, who introduced her in turn to Charles Babbage on June 5, 1833. Other acquaintances were Sir David Brewster, Charles Wheatstone, Charles Dickens and Michael Faraday.
Ada met and corresponded with Charles Babbage on many occasions, including socially and in relation to Babbage's Difference Engine and Analytical Engine. Their relationship was not of a romantic nature.
Ada was one of the few people who fully understood Babbage's ideas and created a program for the Analytical Engine. Had the Analytical Engine ever actually been built, her program would have been able to calculate a sequence of Bernoulli numbers. Based on this work, Lovelace is now widely credited with being the first computer programmer.
in short but the Enchantress of Numbers.
The level of impact of Ada on Babbage's engines are the subject of debate. The debate is difficult to resolve due to Charles Babbage's tendency to not acknowledge (either verbally or in writing) the influence of other people in his work.
Ada Lovelace was bled to death at the age of 36 by her physicians, while trying to cure her uterine cancer. She perished at the same age as her father. She left two sons and a daughter, Lady Anne Blunt, famous in her own right as a traveller in the Middle East and a breeder of Arabian horses, co-founder of the Crabbet Arabian Stud.
Lovelace was buried next to the father she never knew at the Church of St. Mary Magdalene in Hucknall, Nottingham. Over one hundred years after her death, in 1953, Ada Lovelace's notes on Babbage's Analytical Engine were republished after being forgotten. The engine has now been recognized as an early model for a computer and Ada Lovelace's notes as a description of a computer and software.
The computer language Ada, created by the U.S. Defense Department, was named after Lovelace. The reference manual for the language was approved on December 10, 1980, Ada's birthday, and the Department of Defense Military Standard for the language, "MIL-STD-1815" was given the number of the year of her birth. In addition Lovelace's image can be seen on the Microsoft product authenticity hologram stickers. Since 1998, the British Computer Society has awarded a medal in her name. and in 2008 initiated an annual competition for women students of computer science.

and Andrew D. Gordon in 1998, and used to describe and theorise about concurrent systems that include mobility. Here mobility means both computation carried out on mobile devices (i.e. networks that have a dynamic topology), and mobile computation (i.e. executable code that is able to move around the network). The ambient calculus provides a unified framework for modeling both kinds of mobility. It is used to model interactions in such concurrent systems as the Internet.
Since its inception, the ambient calculus has grown into a family of closely related ambient calculi.
The Ambient calculus provides a reduction semantics that formally defines what the results of these operations are.
Communication within (i.e. local to) an ambient is anonymous and asynchronous. Output actions release names or capabilities into the surrounding ambient. Input actions capture a value from the ambient, and bind it to a variable. Non-local I/O can be represented in terms of these local communications actions by a variety of means. One approach is to use mobile "messenger" agents that carry a message from one ambient to another (using the capabilities described above). Another approach is to emulate channel-based communications by modeling a channel in terms of ambients and operations on those ambients. The three basic ambient primitives, namely in, out, and open are expressive enough to simulate name-passing channels in the π-calculus.

August William Derleth (February 24 1909 – July 4 1971) was an American writer and anthologist. Though best remembered as H. P. Lovecraft's primary publisher, and for his own contributions to the Cthulhu Mythos genre of horror, Derleth was a prolific writer in several genres, including historical fiction and detective fiction.
The son of William Julius Derleth and his wife Rose Louise Volk, he grew up in Sauk City, Wisconsin. At the age of 16, he sold his first story to Weird Tales magazine. Derleth wrote all throughout his four years at the University of Wisconsin-Madison and received a B.A. in 1930. During this time he served briefly as editor of Mystic Magazine.
In the mid-1930s he organised a Ranger's Club for young people, served as clerk and president of the local Board of Education, served as a parole officer, organised a local Men's Club and a Parent-Teacher Association. He also lectured in American Regional Literature at the University of Wisconsin.
In 1941 he became literary editor of The Capital Times newspaper in Madison, a post he held until his resignation in 1960.
Derleth was married April 6 1953 to Sandra Evelyn Winters; they were divorced six years later in 1959. He retained custody of their two children, April Rose and Walden William. In 1960, Derleth began editing and publishing a magazine called Hawk and Whippoorwill, dedicated to poems of man and nature.
He died on July 4, 1971 and is buried in St. Aloysius Cemetery in Sauk City.
Derleth was a contemporary and friend of H. P. Lovecraft — when Lovecraft wrote about "le Comte d'Erlette" in his fiction, it was in homage to Derleth. Derleth invented the term Cthulhu Mythos to describe the fictional universe described in the series of stories shared by Lovecraft and other writers in his circle. Derleth's own writing emphasized the struggle between good and evil, in line with his own Christian worldview and in contrast with Lovecraft's depiction of an amoral universe. Derleth also treated Lovecraft's Old Ones as representatives of elemental forces, creating new entities to flesh out this framework.
When Lovecraft died in 1937, Derleth and Donald Wandrei put together a collection of that author's stories and tried to get them published. With existing publishers showing little interest, they founded Arkham House in 1939 to do it themselves. The name of the company comes from Lovecraft's fictional town of Arkham, Massachusetts, which featured in many of his stories.
In 1939 Arkham House published The Outsider and Others, a huge collection that contained most of Lovecraft's short stories then known to exist. Derleth and Wandrei soon decided to expand Arkham House and began a regular publishing schedule after its second book, Someone in the Dark in 1941, a collection of some of Derleth's own horror stories.
A significant number of H. P. Lovecraft fans find themselves dissatisfied with Derleth's invention of the term Cthulhu Mythos and his belief that Lovecraft's fiction has an overall pattern, influenced by Derleth's Christianity. Other complaints deal with the "posthumous collaborations". Still there is little but praise for Derleth for his founding of Arkham House and for successful effort to rescue Lovecraft from literary obscurity.
Derleth wrote more than 150 short stories and more than 100 books during his lifetime. Included among that number were several novels about a Sherlock Holmes-like British detective named Solar Pons. His other series included the Sac Prairie Saga and the Wisconsin Saga and the Judge Peck series.
He also wrote introductions to several collections of classic early 20th century comics such as Buster Brown, Little Nemo in Slumberland, and Katzenjammer Kids, as well as a book of children's poetry entitled "A Boy's Way". He also wrote under the pseudonyms Stephen Grendon, Kenyon Holmes and Tally Mason.
Derleth's papers and comic book collection were donated to the Wisconsin Historical Society in Madison. They have been organized by the State Archives that is located there.


The Alps (; ; ; ; ) is the name for one of the great mountain range systems of Europe, stretching from Austria and Slovenia in the east, through Italy, Switzerland, Liechtenstein and Germany to France in the west. The word "Alps" was taken via French from Latin Alpes (meaning "the Alps"), which may be influenced by the Latin words albus (white) or altus (high) or more likely a Latin rendering of a Celtic or Ligurian original.
The highest mountain in the Alps is Mont Blanc, at 4808 m, on the Italian-French border. All the main peaks of the Alps can be found in the list of mountains of the Alps and list of Alpine peaks by prominence.
The Alps are generally divided into the Western Alps and the Eastern Alps. The division is along the line between Lake Constance and Lake Como, following the Rhine. The Western Alps are higher, but their central chain is shorter and curved; they are located in Italy, France and Switzerland. The Eastern Alps (main ridge system elongated and broad) belong to Austria, Germany, Italy, Liechtenstein, Slovenia and Switzerland. The highest peaks of the Western Alps are Mont Blanc, 4808 m, Mont Blanc de Courmayeur 4748 m, the Dufourspitze 4634 m and the other summits of the Monte Rosa group, and the Dom, 4545 m. The highest peak in the Eastern Alps is Piz Bernina, 4049 m.
The border between the Central Alps and the Southern Limestone Alps is the Periadriatic Seam. The Northern Limestone Alps are separated from the Central Eastern Alps by the Grauwacken Zone.
The geologic subdivision is different and makes no difference between the Western and Eastern Alps: Helveticum in the north, Penninicum and Austroalpine system in the centre and south of the Periadriatic seam the Southern Alpine system and parts of the Dinarides (see Alpine Geology).
The "main chain of the Alps" follows the watershed from the Mediterranean Sea to the Wienerwald, passing over many of the highest and most famous peaks in the Alps. From the Colle di Cadibona to Col de Tende it runs westwards, before turning to the north-west and then, near the Colle della Maddalena, to the north. Upon reaching the Swiss border, the line of the main chain heads approximately east-north-east, a heading it follows until its end near Vienna.
The Alps do not form an impassable barrier; they have been traversed for war and commerce, and later by pilgrims, students and tourists. Crossing places by road, train or foot are called passes. These are depressions in the mountains to which a valley leads from the plains and hilly pre-mountainous zones.
The Alps are a classic example of what happens when a temperate area at lower altitude gives way to higher elevation terrain. Elevations around the world which have cold climates similar to those found in polar areas have been called alpine. A rise from sea level into the upper regions of the atmosphere causes the temperature to decrease. The effect of mountain chains on prevailing winds is to carry warm air belonging to the lower region into an upper zone, where it expands in volume at the cost of a proportionate loss of heat, often accompanied by the precipitation of moisture in the form of snow or rain.
The Alps arose as a result of the pressure exerted on sediments of the Tethys Ocean basin as its Mesozoic and early Cenozoic strata were pushed against the stable Eurasian landmass by the northward-moving African landmass. Most of this occurred during the Oligocene and Miocene epochs. The pressure formed great recumbent folds, or nappes, that rose out of what had become the Tethys Sea and pushed northward, often breaking and sliding one over the other to form gigantic thrust faults. Crystalline rocks, which are exposed in the higher central regions, are the rocks forming Mont Blanc, the Matterhorn, and high peaks in the Pennine Alps and Hohe Tauern.
The landscape seen today is mostly formed by glaciation during the past two million years. At least five ice ages have done much to change the region, scooping out the lakes and rounding off the limestone hills along the northern border. Glaciers have been retreating during the past 10,000 years, leaving large granite erratics scattered in the forests in the region. As the last ice age ended, it is believed that the climate changed so rapidly that the glaciers retreated back into the mountains in a span of about 200 to 300 years.
Little is known of the early dwellers in the Alps, save from the scanty accounts preserved by Roman and Greek historians and geographers. A few details have come down to us of the conquest of many of the Alpine tribes by Augustus.
During the Second Punic War in 218 BC, The Carthaginian general Hannibal successfully crossed the alps along with an army numbering 38,000 infantry, 8,000 cavalry, and 37 war elephants. This was one of the most celebrated achievements of any military force in ancient warfare.
The successive emigration and occupation of the Alpine region by various Teutonic tribes from the 5th to the 6th centuries are known only in outline, because to them, as to the Frankish kings and emperors, the Alps offered a route to other places rather than a permanent residence.
It is not until the final breakup of the Carolingian Empire in the 10th and 11th centuries that it becomes possible to trace out the local history of the Alps.
The higher regions of the Alps were long left to the exclusive attention of the people of the adjoining valleys, even when Alpine travellers (as distinguished from Alpine climbers) began to visit these valleys. The two men who first explored the regions of ice and snow were H.B. de Saussure (1740-1799) in the Pennine Alps, and the Benedictine monk of Disentis, Placidus a Spescha (1752-1833), most of whose ascents were made before 1806, in the valleys at the sources of the Rhine.
A natural vegetation limit with altitude is given by the presence of the chief deciduous trees — oak, beech, ash and sycamore maple. These do not reach exactly to the same elevation, nor are they often found growing together; but their upper limit corresponds accurately enough to the change from a temperate to a colder climate that is further proved by a change in the wild herbaceous vegetation. This limit usually lies about 1200 m above the sea on the north side of the Alps, but on the southern slopes it often rises to 1500 m, sometimes even to 1700 m.
This region is not always marked by the presence of the characteristic trees. Human interference has nearly exterminated them in many areas, and, except for the beech forests of the Austrian Alps, forests of deciduous trees are rarely found. In many districts where such woods once existed, they have been replaced by the Scots pine and Norway spruce, which are less sensitive to the ravages of goats who are the worst enemies of such trees. The mean annual temperature of this region differs little from that of the British Islands; but climatic conditions are widely different. In the Alps, snow usually stays for several months, until spring and summer, which are considerably warmer on average than those seasons in Britain.
Species common to the Alps. These are most numerous in the 15% of the Alps that are protected in parks and reserves.


Albert Camus () (November 7, 1913 – January 4, 1960) was a French-Algerian author and philosopher who won the Nobel prize in 1957. He is often associated with existentialism, but Camus refused this label. On the other hand, as he wrote in his essay The Rebel, his whole life was devoted to opposing the philosophy of nihilism. On the subject of his belief or not in God, he writes in the third volume of his notebooks: "I do not believe in God and I am not an atheist".
His most important phrase for the future was: "All of us, among the ruins, are preparing a renaissance beyond the limits of nihilism. But few of us know it". Albert Camus founded in 1949 the Group for International Liaisons in the Revolutionary Union Movement, according to the book Albert Camus, une vie of Olivier Todd.
Camus preferred to be known as a man and a thinker, rather than as a member of a school or ideology. He preferred persons over ideas. In an interview in 1945, Camus rejected any ideological associations: "No, I am not an existentialist. Sartre and I are always surprised to see our names linked…". In his collection of essays The Nuptials he wrote that he was a son of Greece.
Camus was the second-youngest recipient of the Nobel Prize for Literature (after Rudyard Kipling) when he became the first African-born writer to receive the award, in 1957. He is also the shortest-lived of any literature laureate to date, having died in an automobile accident only three years after receiving the award.
Albert Camus was born on November 7, 1913 in Mondovi, Algeria to a French-Algerian (pied-noir) settler family. His mother was of Spanish extraction and was half-deaf. His father, Lucien, died in the Battle of the Marne in 1914 during the First World War, while serving as a member of the Zouave infantry regiment. Camus lived in poor conditions during his childhood in the Belcourt section of Algiers. In 1923, he was accepted into the lycée and eventually to the University of Algiers. However, he contracted tuberculosis in 1930, which put an end to his football activities (he had been a goalkeeper for the university team) and forced him to make his studies a part-time pursuit. He took odd jobs including private tutor, car parts clerk and work for the Meteorological Institute. He completed his licence de philosophie (BA) in 1935; in May of 1936, he successfully presented his thesis on Plotinus, Néo-Platonisme et Pensée Chrétienne, for his "diplôme d'études supérieures" (roughly equivalent to an M.A. by thesis).
Camus joined the French Communist Party in the Spring of 1935, apparently because of concerns about the political situation in Spain (which eventually resulted in the Spanish Civil War) rather than in support for Marxist-Leninist doctrine. In 1936, the independence-minded Algerian Communist Party (PCA) was founded. Camus joined the activities of the Algerian People's Party (Le Parti du Peuple Algérien), which got him into trouble with his Communist party comrades. As a result, he was denounced as a Trotskyite and expelled from the party in 1937. Camus went on to be associated with the French anarchist movement. The anarchist Andre Prudhommeaux first introduced him at a meeting in 1948 of the Cercle des Etudiants Anarchistes (Anarchist Student Circle) as a sympathiser who was familiar with anarchist thought. Camus went on to write for anarchist publications such as Le Libertaire, La révolution Proletarienne and Solidaridad Obrera (the organ of the anarcho-syndicalist CNT). Camus also stood with the anarchists when they expressed support for the uprising of 1953 in East Germany. He again stood with the anarchists in 1956, first with the workers’ uprising in Poznan, Poland, and then later in the year with the Hungarian Revolution.
In 1934, he married Simone Hie, a morphine addict, but the marriage ended due to infidelity on both sides. In 1935, he founded Théâtre du Travail — "Worker's Theatre" — (renamed "Théâtre de l'Equipe" ("Team's Theatre") in 1937), which survived until 1939. From 1937 to 1939 he wrote for a socialist paper, Alger-Républicain, and his work included an account of the peasants who lived in Kabylie in poor conditions, which apparently cost him his job. From 1939 to 1940, he briefly wrote for a similar paper, Soir-Republicain. He was rejected by the French army because of his tuberculosis.
In 1940, Camus married Francine Faure, a pianist and mathematician. Although he loved Francine, he had argued passionately against the institution of marriage, dismissing it as unnatural. Even after Francine gave birth to twins, Catherine and Jean, on September 5, 1945, he continued to joke wearily to friends that he was not cut out for marriage. Francine suffered numerous infidelities, particularly a public affair with the Spanish actress Maria Casares. In the same year Camus began to work for Paris-Soir magazine. In the first stage of World War II, the so-called Phony War stage, Camus was a pacifist. However, he was in Paris to witness how the Wehrmacht took over. On December 15, 1941, Camus witnessed the execution of Gabriel Péri, an event that Camus later said crystallized his revolt against the Germans. Afterwards he moved to Bordeaux alongside the rest of the staff of Paris-Soir. In the same year he finished his first books, The Stranger and The Myth of Sisyphus. He returned briefly to Oran, Algeria in 1942.
During the war Camus joined the French Resistance cell Combat, which published an underground newspaper of the same name. This group worked against the Nazis, and in it Camus assumed the nom de guerre "Beauchard". Camus became the paper's editor in 1943, and when the Allies liberated Paris, Camus reported on the last of the fighting. He was, however, one of the few French editors to publicly express opposition to the use of the atomic bomb in Hiroshima soon after the event on August 8, 1945. He eventually resigned from Combat in 1947, when it became a commercial paper. It was then that Camus became acquainted with Jean-Paul Sartre.
After the war, Camus began frequenting the Café de Flore on the Boulevard Saint-Germain in Paris with Sartre. Camus also toured the United States to lecture about French thinking. Although he leaned left politically, his strong criticisms of Communist doctrine did not win him any friends in the Communist parties and eventually also alienated Sartre.
In 1949 his tuberculosis returned and he lived in seclusion for two years. In 1951 he published The Rebel, a philosophical analysis of rebellion and revolution which made clear his rejection of communism. The book upset many of his colleagues and contemporaries in France and led to the final split with Sartre. The dour reception depressed him and he began instead to translate plays.
Camus' first significant contribution to philosophy was his idea of the absurd, the result of our desire for clarity and meaning within a world and condition that offers neither, which he explained in The Myth of Sisyphus and incorporated into many of his other works, such as The Stranger and The Plague. Despite the split from his "study partner," Sartre, some still argue that Camus falls into the existentialist camp. However, he rejected that label himself in his essay Enigma and elsewhere (see: The Lyrical and Critical Essays of Albert Camus). The current confusion may still arise as many recent applications of existentialism have much in common with many of Camus' practical ideas (see: Resistance, Rebellion, and Death). However, the personal understanding he had of the world (e.g. "a benign indifference," in The Stranger), and every vision he had for its progress (i.e. vanquishing the "adolescent furies" of history and society, in The Rebel) undoubtedly sets him apart.
He maintained his pacifism and resistance to capital punishment anywhere in the world. One of his most significant contributions to the movement against capital punishment was an essay collaboration with Arthur Koestler, the writer, intellectual and founder of the League Against Capital Punishment.
When the Algerian War began in 1954 it presented a moral dilemma for Camus. He identified with pied-noirs, and defended the French government on the grounds that the revolt in Algeria was really an integral part of the 'new Arab imperialism' led by Egypt and an 'anti-Western' offensive orchestrated by Russia to 'encircle Europe' and 'isolate the United States'. Although favouring greater Algerian autonomy or even federation, though not full-scale independence, he believed that the pied-noirs and Arabs could co-exist. During the war he advocated civil truce that would spare the civilians, which was rejected by both sides who regarded it as foolish. Behind the scenes, he began to work clandestinely for imprisoned Algerians who faced the death penalty.
From 1955 to 1956 Camus wrote for "L'Express. In 1957 he was awarded the Nobel Prize in literature, officially not for his novel The Fall, published the previous year, but for his writings against capital punishment in the essay Réflexions sur la Guillotine". When he spoke to students at the University of Stockholm, he defended his apparent inactivity in the Algerian question and stated that he was worried what could happen to his mother who still lived in Algeria. This led to further ostracism by French left-wing intellectuals.
In 1949 Camus founded the Group for International Liaisons in the Revolutionary Union Movement (according to the book Albert Camus, une vie by Olivier Todd). With George Orwell, he opposed totalitarian regimes in the East and the West.
As he wrote in "L'Homme révolté" (in the chapter about The Thought on Midday) he was a follower of the ancient Greek "Solar Tradition" (la pensée solaire). So, not only he was the leader of the French resistance movemet "Combat" but he also set up in 1947-8 the Revolutionary Union Movement (Groupes de liaison internationale - GLI) which was formed in 1949 and can be described as a trade union movement in the context of revolutionary syndicalism (Syndicalisme révolutionnaire). For more, see the book : Alfred Rosmer et le mouvement révolutionnaire internationale by Christian Gras).
His colleagues were Nicolas Lazarévitch, Louis Mercier, Roger Lapeyre, Paul Chauvet, Auguste Largentier, Jean de Boë (see the article: "Nicolas Lazarévitch, Itinéraire d'un syndicaliste révolutionnaire" by Sylvain Boulouque in the review Communisme, n° 61, 2000). His main aim was to express the positive side of Surrealism and Existentialism, rejecting the negativity and the nihilism of Andre Breton and Jean-Paul Sartre.
In 1944 Camus founded the "French Committee for the European Federation" (Comite Francais pour la Federation Europeene -CFFE) declaring that Europe "can only evolve along the path of economic progress, democracy and peace if the nation states become a federation".
From 1943, Albert Camus had correspondence with Altiero Spinelli who founded the European Federalist Movement in Milan (see Ventotene Manifesto and the book "Unire l'Europa, superare gli stati", Altiero Spinelli nel Partito d'Azione del Nord Italia e in Francia dal 1944 al 1945-annexed a letter by Altiero Spinelli to Albert Camus).
In 22-25 March, 1945, the first conference of the European Federalist Movement was organised in Paris with the participation of Albert Camus, George Orwell, Emmanuel Mounier, Lewis Mumford, André Philip, Daniel Mayer, François Bondy and Altiero Spinelli (see the book "The Biography of Europe" by Pan Drakopoulos). This specific branch of the European Federalist Movement disintegrated in 1957 after the domination of Winston Churchill's ideas about the European integration.
3 essays by Dr. Miho Takashima in the International Journal of Humanities ("Revolt and Equilibrium: A Comparative Study of Nineteen Eighty-Four and L'Homme Révolté, the Views and Struggles of Orwell and Camus", "Art and Representation: A Comparative Study of George Orwell and Albert Camus on their Literary Works" and "George Orwell and Albert Camus: A Comparative Study – Their Views and Dilemmas in the Politics of the 1930s and 40s") explore the relation between the work of the French writer Albert Camus and the English writer George Orwell.
Takashima argues that Orwell – perhaps intentionally, in order to warn the intellectual elite - compromised with "Big Brother", while Camus confronted with "Plague". This is observed not only in the comparison between "1984" and "The Man in Revolt" but, especially, in Camus' play "The State of Siege".
This theatrical play was written together with the novel The Plague and the essay The Rebel/Man in Revolt. It is the work which - according to Camus himself - represents him best and is a response to George Orwell's 1984. The hero, Diego, opposes the totalitarian dictator nameed Plague, and dies in order to set a Spanish town free from the Inquisition.
"L’ Etat de Siege’’ ("The State of Siege") is a work against totalitarianism, written in the same epoch when Camus' idol, the English writer George Orwell, wrote 1984. The play includes an allegorical reference to the end of Orwell's novel (where the hero, Winston Smith, makes a compromise with Big Brother).
The original title of L' Etat de Siege was THE HOLY INQUISITION IN CADIX. In the French edition of the book, Camus has included a remarkable essay under the title "Why Spain?". In this polemical text, he answers his Catholic Christian friend Gabriel Marcel who criticised him for setting the plot in Spain. Here Camus expresses his opposition to the totalitarian regimes of the West, and to the behaviour of the Vatican and the Pope during World War II. The most important phrase of this essay is "Why Guernica, Gabriel Marcel?".
The Greek journalist Christos Papachristopoulos theorises that this play is based on Aeschylus' lost tragedy, Prometheus the Fire-Bringer - Προμηθεύς Πυρφόρος (see NationMaster Encyclopedia).
Camus died on January 4, 1960 in an automobile accident near Sens, in a place named "Le Grand Fossard" in the small town of Villeblevin. In his coat pocket lay an unused train ticket. It is possible that he had planned to travel by train, but decided to go by car instead.
The driver of the Facel Vega car, Michel Gallimard — his publisher and close friend — also perished in the accident. Camus was interred in the Lourmarin Cemetery, Lourmarin, Vaucluse, Provence-Alpes-Côte d'Azur, France.
He was survived by his twin children, Catherine and Jean, who hold the copyrights to his work.
After his death, two of Camus' works were published posthumously. The first, entitled A Happy Death published in 1970, featured a character named Meursault, as in The Stranger, but there is some debate as to the relationship between the two stories. The second posthumous publication was an unfinished novel, The First Man, that Camus was writing before he died. The novel was an autobiographical work about his childhood in Algeria and was published in 1995.
Many writers have written on the Absurd, each with his or her own interpretation of what the Absurd actually is and their own ideas on the importance of the Absurd. For example, Sartre recognizes the absurdity of individual experience, while Kierkegaard explains that the absurdity of certain religious truths prevent us from reaching God rationally. Camus was not the originator of Absurdism and regretted the continued reference to him as a philosopher of the absurd. He shows less and less interest in the Absurd shortly after publishing Le Mythe de Sisyphe (The Myth of Sisyphus). To distinguish Camus' ideas of the Absurd from those of other philosophers, people sometimes refer to the Paradox of the Absurd, when referring to "Camus' Absurd.
His early thoughts on the Absurd appeared in his first collection of essays, L'Envers et l'endroit (The Two Sides Of The Coin) in 1937. Absurd themes appeared with more sophistication in his second collection of essays, Noces (Nuptials), in 1938. In these essays Camus does not offer a philosophical account of the Absurd, or even a definition; rather he reflects on the experience of the Absurd. In 1942 he published the story of a man living an Absurd life as L'Étranger (The Stranger), and in the same year released Le Mythe de Sisyphe (The Myth of Sisyphus"), a literary essay on the Absurd. He had also written a play about a Roman Emperor, Caligula, pursuing an Absurd logic. However, the play was not performed until 1945. The turning point in Camus' attitude to the Absurd occurs in a collection of four letters to an anonymous German friend, written between July 1943 and July 1944. The first was published in the Revue Libre in 1943, the second in the Cahiers de Libération in 1944, and the third in the newspaper Libertés, in 1945. All four letters have been published as Lettres à un ami allemand (Letters to a German Friend) in 1945, and have appeared in the collection Resistance, Rebellion, and Death.
In his essays Camus presented the reader with dualisms: happiness and sadness, dark and light, life and death, etc. His aim was to emphasize the fact that happiness is fleeting and that the human condition is one of mortality. He did this not to be morbid, but to reflect a greater appreciation for life and happiness. In Le Mythe, this dualism becomes a paradox: We value our lives and existence so greatly, but at the same time we know we will eventually die, and ultimately our endeavours are meaningless. While we can live with a dualism (I can accept periods of unhappiness, because I know I will also experience happiness to come), we cannot live with the paradox (I think my life is of great importance, but I also think it is meaningless). In Le Mythe, Camus was interested in how we experience the Absurd and how we live with it. Our life must have meaning for us to value it. If we accept that life has no meaning and therefore no value, should we kill ourselves?
Meursault, the Absurdist hero of "L'Étranger," is a murderer who is executed for his crime. Caligula ends up admitting his Absurd logic was wrong and is killed by an assassination he has deliberately brought about. However, while Camus possibly suggests that Caligula's Absurd reasoning is wrong, the play's anti-hero does get the last word, as the author similarly exalts Meursault's final moments.
Camus' understanding of the Absurd promotes public debate; his various offerings entice us to think about the Absurd and offer our own contribution. Concepts such as cooperation, joint effort and solidarity are of key importance to Camus.
Camus made a significant contribution to a viewpoint of the Absurd, and always rejected nihilism as a valid response. "If nothing had any meaning, you would be right. But there is something that still has a meaning." Second Letter to a German Friend, December 1943.
It then follows that existentialism tends to view human beings as subjects in an indifferent, objective, often ambiguous, and "absurd" universe, in which meaning is not provided by the natural order, but rather can be created, however provisionally and unstably, by human beings' actions and interpretations.
Camus' well-known falling out with Sartre is linked to this opposition to totalitarianism. Camus detected a reflexive totalitarianism in the mass politics espoused by Sartre in the name of radical Marxism. This was apparent in his work "L'Homme Révolté (The Rebel) which not only was an assault on the Soviet police state, but also questioned the very nature of mass revolutionary politics. Camus continued to speak out against the atrocities of the Soviet Union, a sentiment captured in his 1957 speech, The Blood of the Hungarians, commemorating the anniversary of the 1956 Hungarian Revolution, an uprising crushed in a bloody assault by the Red Army.
Albert Camus characterizes his justification of the absurd through the experiences of a protagonist who simply does not conform to the system. His inherent honesty disturbs the status quo; Meursault’s inability to lie cannot seamlessly integrate him within society and in turn threatens the simple fabrics of human mannerisms expected of a structurally ordered society. Consequently, the punishment for his crime is not decided on the basis of murder, but rather for the startling indifference towards his mother’s recent demise. Even after a conflicting spiritual discussion with a pastor inciting Meursault to consider a possible path towards redemption, the latter still refuses to take upon salvation and symbolizes his ultimatum by embracing the "gentle indifference of the world;" an act which only furthers his solidarity with a society incapable of realizing his seemingly inhumane and misanthropic behavior.
The plague is an undeniable part of life. It is omnipresent, just like death was always an impeding factor in The Stranger. Albert Camus once again questions the meaning of the moral concepts justifying humanity and human suffering within a religious framework. For Camus, the rationale behind Christian doctrine is useless; as mortal beings, we cannot successfully rationalize the impending and inescapable death sentence forced upon every human. The plague, which befalls upon Oran, is a concrete and tangible facilitator of death. Ultimately, the plague enables people to understand that their individual suffering is meaningless. As the epidimic "evolves" within the seasons, so do the citizens of Oran, who instead of willfully giving up to a disease they have no control over, decide to fight against their impending death, thus unwillingly creating optimism in the midst of hopelessness. This is where Camus channels his thoughts behind the importance of solidarity: although the plague is still primarily an agent of death, it provides the uncanny opportunity for people to realize that individual suffering is absurd. In the midst of complete suffering, the challenging response adopted by the majority of the citizens of Oran demonstrates an inexplicable humanistic connection between distraught and distant characters. Only by taking the choice to fight an irreversible epidemic are people able to create the ever-lacking meaning to a life destined for execution the moment of its creation.
Several of Camus' works have been adapted into movies. The Stranger has been adapted into an Italian 1967 movie by Luchino Visconti, and also to a 2001 Turkish adaptation titled Yazgi (Fate) by Zeki Demirkubuz. The Plague was adapted to a 1992 film titled La Peste by Luis Puenzo and set in modern day America.


Dame Agatha Mary Clarissa, Lady Mallowan, DBE (15 September 1890 – 12 January 1976), commonly known as Agatha Christie, was an English crime fiction writer of novels, short stories and plays. She also wrote romance novels under the name Mary Westmacott, but is best remembered for her 80 detective novels and her successful West End theatre plays. Her works, particularly featuring detectives Hercule Poirot or Miss Jane Marple, have given her the title the 'Queen of Crime' and made her one of the most important and innovative writers in the development of the genre.
Christie has been called — by the Guinness Book of World Records, among others — the best-selling writer of books of all time and the best-selling writer of any kind, along with William Shakespeare. Only the Bible is known to have outsold her collected sales of roughly four billion copies of novels. UNESCO states that she is currently the most translated individual author in the world with only the collective corporate works of Walt Disney Productions superseding her. (See). As an example of her broad appeal, she is the all-time best-selling author in France, with over 40 million copies sold in French (as of 2003) versus 22 million for Emile Zola, the nearest contender.
Her stage play, The Mousetrap, holds the record for the longest initial run in the world, opening at the Ambassadors Theatre in London on 25 November 1952, and as of 2008 is still running after more than 20,000 performances. In 1955, Christie was the first recipient of the Mystery Writers of America's highest honor, the Grand Master Award, and in the same year, Witness for the Prosecution was given an Edgar Award by the MWA, for Best Play. Most of her books and short stories have been filmed, some many times over (Murder on the Orient Express, Death on the Nile, 4.50 From Paddington), and many have been adapted for television, radio, video games and comics.
In 1998, the control of the rights to most of the literary works of Agatha Christie passed to the company Chorion, when it purchased a majority 64% share in Agatha Christie Limited.
Agatha Christie was born as Agatha Mary Clarissa Miller in Torquay, Devon, to an American father and an English mother. She never claimed United States citizenship. Her father was Frederick Alvah Miller, a rich American stockbroker, and her mother was Clarissa Margaret Boehmer, the daughter of a British army captain. Christie had a sister, Margaret Frary Miller (1879 – 1950), called Madge, eleven years her senior, and a brother, Louis Montant Miller (1880 – 1929), called Monty, ten years older than Christie. Her father died when she was eleven years old. Her mother taught her at home, encouraging her to write at a very young age. At the age of 16 she went to Mrs Dryden's finishing school in Paris to study singing and piano.
Her first marriage, an unhappy one, was in 1914 to Colonel Archibald Christie, an aviator in the Royal Flying Corps. The couple had one daughter, Rosalind Hicks, and divorced in 1928. It was during this marriage that she published her first novel in 1920, The Mysterious Affair at Styles.
During World War I she worked at a hospital and then a pharmacy, a job that influenced her work; many of the murders in her books are carried out with poison.
On 8 December 1926, while living in Sunningdale in Berkshire, she disappeared for ten days, causing great interest in the press. Her car was found in a chalk pit in Newland's Corner, Surrey. She was eventually found staying at the Swan Hydro (now the Old Swan hotel) in Harrogate under the name of the woman with whom her husband had recently admitted to having an affair. She claimed to have suffered a nervous breakdown and a fugue state caused by the death of her mother and her husband's infidelity. Opinions are still divided as to whether this was a publicity stunt. Public sentiment at the time was negative, with many feeling that an alleged publicity stunt had cost the taxpayers a substantial amount of money. A 1979 film, Agatha, starring Vanessa Redgrave as Christie, recounted a fictionalised version of the disappearance.
In 1930, Christie married the archaeologist Sir Max Mallowan. Mallowan was 14 years younger than Christie, and a Roman Catholic, while she was of the Anglican faith. Their marriage was happy in the early years, and endured despite Mallowan's many affairs in later life, notably with Barbara Parker, whom he married in 1977, the year after Christie's death.
In 1971 she was made a Dame Commander of the Order of the British Empire.
Agatha Christie died on 12 January 1976, at age 85, from natural causes, at Winterbrook House in the north of Cholsey parish, adjoining Wallingford in Oxfordshire (formerly Berkshire). She is buried in the nearby St. Mary's Churchyard in Cholsey.
Christie's only child, Rosalind Hicks, died on 28 October 2004, also aged 85, from natural causes. Christie's grandson, Mathew Prichard, was heir to the copyright to some of his grandmother's literary work (including The Mousetrap) and is still associated with Agatha Christie Limited.
Agatha Christie's first novel The Mysterious Affair at Styles was published in 1920 and introduced the long-running character detective Hercule Poirot, who appeared in 30 of Christie's novels and 50 short stories.
Her other well known character, Miss Marple, was introduced in The Murder at the Vicarage in 1930, and was based on Christie's grandmother.
During World War II, Christie wrote two novels intended as the last cases of these two great detectives, Hercule Poirot and Jane Marple, respectively. They were Curtain and Sleeping Murder. Both books were sealed in a bank vault for over thirty years, and were released for publication by Christie only at the end of her life, when she realised that she could not write any more novels. These publications came on the heels of the success of the film version of Murder on the Orient Express in 1974.
Like Arthur Conan Doyle with Sherlock Holmes, Christie was to become increasingly tired of her detective, Poirot. In fact, by the end of the 1930s, Christie confided to her diary that she was finding Poirot "insufferable", and by the 1960s she felt that he was an "an ego-centric creep". However, unlike Conan Doyle, Christie resisted the temptation to kill her detective off while he was still popular. She saw herself as an entertainer whose job was to produce what the public liked, and what the public liked was Poirot.
In contrast, Christie was fond of Miss Marple. However it is interesting to note that the Belgian detective’s titles outnumber the Marple titles by more than two to one. This is largely because Christie wrote numerous Poirot novels early in her career, while The Murder at the Vicarage remained the sole Marple novel until the 1940s.
Christie never wrote a novel or short story featuring both Poirot and Miss Marple.
Poirot is the only fictional character to have been given an obituary in The New York Times, following the publication of Curtain in 1975.
Following the great success of Curtain, Christie gave permission for the release of Sleeping Murder sometime in 1976, but died in January 1976 before the book could be released. This may explain some of the inconsistencies compared to the rest of the Marple series — for example, Colonel Arthur Bantry, husband of Miss Marple's friend, Dolly, is still alive and well in Sleeping Murder (which, like Curtain, was written in the 1940s) despite the fact he is noted as having died in books published earlier. It may be that Christie simply did not have time to revise the manuscript before she died. Miss Marple fared better than Poirot, since after solving the mystery in Sleeping Murder she returns home to her regular life in St. Mary Mead.
On an edition of Desert Island Discs in 2007, Brian Aldiss recounted how Agatha Christie told him that she wrote her books up to the last chapter, and then decided who the most unlikely suspect was. She would then go back and make the necessary changes to "frame" that person.
In addition to her novels Christie wrote and published 160 short stories in her career. Almost all of these were written for publication in fiction magazines with over half of them first appearing in the 1920s. They were then published in book form in various collections, some of which were identical in the UK and US (e.g. The Labours of Hercules) and others where publication took place in one market but not the other.
Twelve of the stories which were published in The Sketch magazine in 1924 under the sub-heading of The Man who was No. 4 were further joined into one continuous narrative in the novel The Big Four in 1927. Four further stories, The Submarine Plans (1923), Christmas Adventure (1923), The Mystery of the Baghdad Chest (1932) and The Second Gong (1932), were expanded into longer narratives by Christie (respectively The Incredible Theft, The Adventure of the Christmas Pudding, The Mystery of the Spanish Chest and "Dead Man's Mirror although the shorter versions of all four have also been published in the UK).
Only one short story remains unpublished in the UK in book form: Three Blind Mice (1948) on which a Christie placed a moratorium whilst the stage play based on the story, The Mousetrap, was still running in the West End.
In the US, the stories The Incredible Theft and Christmas Adventure have not been published in book form.
In addition, various collections have been published over the years which re-print short stories which have previously appeared in other collections e.g. Surprise, Surprise! (1965 in the US). On occasion, in among the reprinted material, these collections have sometimes contained the first book printing of an individual story e.g. The Market Basing Mystery in the UK version of Thirteen for Luck! (1966) which later appeared in the same market in Poirot's Early Cases.
HarperCollins began issuing a series of comic strip adaptations of Christie's work on July 16 2007.
In 2004, the Japanese broadcasting company Nippon Housou Kyoukai turned Poirot and Marple into animated characters in the anime series "Agatha Christie's Great Detectives Poirot and Marple", introducing Mabel West (daughter of Miss Marple's mystery-writer nephew Raymond West, a canonical Christie character) and her duck Oliver as new characters.


The Plague (Fr. La Peste) is a novel by Albert Camus, published in 1947, that tells the story of medical workers finding solidarity in their labour as the Algerian city of Oran is swept by a plague. It asks a number of questions relating to the nature of destiny and the human condition. The characters in the book, ranging from doctors to vacationers to fugitives, all help to show the effects the plague has on a populace.
The novel is believed to be based in the cholera epidemic that killed a large percentage of Oran's population in 1849 after French colonization. Oran and it environs were struck by the plague multiple times before Camus published this novel. According to a research report by the Center for Disease Control and Prevention, Oran was decimated by the plague in 1556 and 1678, but outbreaks after European colonization in 1921 (185 cases), 1931 (76 cases), and 1944 (95 cases) were very far from the scale of the epidemic described in the novel.
The Plague is considered an existentialist classic despite Camus' objection to the label. The narrative tone is similar to Kafka's, especially in The Trial, where individual sentences potentially have multiple meanings, the material often pointedly resonating as stark allegory of phenomenal consciousness and the human condition. Camus included a dim-witted character misreading The Trial as a mystery novel as an oblique homage. The novel has been read as a metaphorical treatment of the French resistance to Nazi occupation during World War II.
Although Camus's approach in the book is severe, his narrator emphasizes the ideas that we ultimately have no control, irrationality of life is inevitable, and he further illustrates the human reaction towards the ‘absurd’. The Plague represents how the world deals with the philosophical notion of the Absurd, a theory which Camus himself helped to define.
The text of The Plague is divided into five parts.
In the town of Oran, thousands of rats, initially going unnoticed by the populace, began to die in the streets. A hysteria develops soon after, causing the local newspapers to report the incident. Authorities responding to public pressure order the collection and cremation of the rats, unaware that the collection itself was the catalyst for the spread of the bubonic plague.
The main character, Dr. Rieux, lives comfortably in an apartment building when strangely the building's concierge, M. Michel, a confidante, dies from a fever. Dr. Rieux consults his colleague, Castel, about the illness until they come to the conclusion that a plague is sweeping the town. They both approach fellow doctors and town authorities about their theory, but are eventually dismissed on the basis of one death. However, as more and more deaths quickly ensue, it becomes apparent that there is an epidemic.
Authorities are slow to accept that the situation is serious and quibble over the appropriate action to take. Official notices enacting control measures are posted, but the language used is optimistic and downplays the seriousness of the situation. A "special ward" is opened at the hospital, but its 80 beds are filled within three days. As the death toll begins to rise, more desperate measures are taken. Homes are quarantined, corpses and burials are strictly supervised. A supply of plague serum finally arrives, but there is only enough to treat existing cases and the country's emergency reserves are depleted. When the daily number of deaths jumps to 30, the town is sealed and an outbreak of plague is officially declared.
The town is sealed off. The town gates are shut, rail travel is prohibited, and all mail service is suspended. The use of telephone lines is restricted only to "urgent" calls, leaving short telegrams as the only means of communicating with friends or family outside the town. The separation affects daily activity and depresses the spirit of the townspeople, who begin to feel isolated and introverted, and the plague begins to affect various characters.
One character, Raymond Rambert, devises a plan to escape the city to join his wife in Paris after city officials refused his request to leave. He befriends some criminals so that they may smuggle him out of the city. Another character, Father Paneloux, uses the plague as an opportunity to advance his stature in the town by suggesting that the plague was an act of God for the citizens' sinful nature. His diatribe falls on the ears of many citizens of the town, who turned to religion in droves and who would not have done so in normal circumstances. Cottard, a criminal fearful of being arrested, becomes wealthy as a major smuggler. Meanwhile, Dr. Rieux, a vacationer Jean Tarrou, and a civil servant Joseph Grand exhaustively treat patients in their homes and in the hospital.
Rambert informs Tarrou of his escape plan, but when Tarrou tells him that others in the city, including Dr. Rieux, also have loved ones outside the city that they are not allowed to see, Rambert becomes sympathetic and changes his mind. He then decides to join Tarrou and Dr. Rieux to help fight the epidemic.
At the peak of the plague's destruction, the townspeople eventually give up on their personal concerns and band together to help each other. When a child dies from the plague, Dr. Rieux criticizes Father Paneloux's first sermon about God's vengeance for sinful behaviour, citing the innocence of children. This inspires Father Paneloux to deliver a second sermon, however not to directly address the innocence, but to suggest that death was, in Paneloux's opinion, an expression of God's will. Therefore, the child's death is a "test" for Christians who have to choose between following God wholly or not at all. Paneloux also implies that all those who died from the plague were sinful. Then he too was stricken with illness, dying with a crucifix in his hands.
When the plague ends, the townspeople return to their daily routine becoming self-absorbed and ignorant again. Rambert reunites with his wife; Cottard, not being able to make a living outside of the plague, is captured by the police; Tarrou dies just before the plague ends. Dr. Rieux learns that his wife died from illness though she was outside the city.
In the first part of The Plague, Rieux overhears a conversation concerning an Algerian man being shot to death on a beach. This is in all probability a reference to the plot of Camus's earlier novel The Stranger.

Applied ethics is a discipline of philosophy that attempts to apply 'theoretical' ethics, such as utilitarianism, social contract theory, and deontology, to real world dilemmas. Topics falling within the discipline include medical ethics, legal ethics, environmental ethics, computer ethics, corporate social responsibility, or business ethics.
Many considerations of applied ethics also come into play in human rights discussions.
Applied ethics seeks to engage formal ethics in attempts to solve actual dilemmas. In doing so, it illuminates the potential for disagreement over the way theories and principles should be applied. Strict, principle-based ethical approaches often result in solutions to specific problems that are not universally acceptable. Drawing on medical ethics for an example, a strict deontological approach would never permit the deception of a patient about their condition, whereas a utilitarian approach would involve consideration of the consequences of so doing, and might permit lying to a patient if the result of the deception was 'good'. The example demonstrates that a deontologist can derive a different solution to a dilemma than a utilitarian.
One modern approach which attempts to overcome the seemingly impossible divide between deontology and utilitarianism is case-based reasoning, also known as casuistry. Casuistry does not begin with theory, rather it starts with the immediate facts of a particular case. While casuistry makes use of ethical theory, it does not view ethical theory as the most important feature of moral reasoning. Casuists, like Albert Jonsen and Stephen Toulmin (The Abuse of Casuistry 1988), challenge the traditional paradigm of applied ethics. Instead of starting from theory and applying theory to a particular case, casuists start with the particular case itself and then ask what morally significant features (including both theory and practical considerations) ought to be considered for that particular case. In their observations of medical ethics committees, Jonsen and Toulmin note that a consensus on particularly problematic moral cases often emerges when participants focus on the facts of the case, rather than on ideology or theory. Thus, a Rabbi, a Catholic priest, and an agnostic might agree that, in this particular case, the best approach is to withhold extraordinary medical care, while disagreeing on the reasons that support their individual positions. By focusing on cases and not on theory, those engaged in moral debate increase the possibility of agreement.

Karl Adolf Eichmann (March 19, 1906–June 1, 1962), often referred to as "the architect of the Holocaust", was a high-ranking Nazi and SS-Obersturmbannführer (equivalent to Lieutenant Colonel). Due to his organizational talents and ideological reliability, he was charged by Obergruppenführer Reinhard Heydrich with the task of facilitating and managing the logistics of mass deportation of Jews to ghettos and extermination camps in Nazi-occupied Eastern Europe. After the war, he traveled to Argentina using a fraudulently obtained laissez-passer issued by the International Red Cross and lived there under a false identity. He was captured by Israeli Mossad agents in Argentina and tried in Israeli court on fifteen criminal charges, including crimes against humanity and war crimes. He was convicted and hanged.
Born in Solingen, Germany, Adolf Eichmann was the son of a businessman and industrialist, Adolf Karl Eichmann, and Maria née Schefferling. In 1914, his family moved to Linz, Austria, after his mother died. During the First World War, Eichmann's father served in the Austro-Hungarian Army. At the war's conclusion, Eichmann's father returned to the family and had a business in Linz. Eichmann himself left high school (Realschule) without having graduated and began a training to become a mechanic, which he also discontinued. In 1923 he started working in the mining company of his father, from 1925 to 1927 he worked as a salesclerk for the Oberösterreichische Elektrobau AG and then until spring 1933 Eichmann worked as district agent for the Vacuum Oil Company AG, a subsidiary of Standard Oil. In July 1933 he moved back to Germany.
Eichmann married Veronica Liebl (1909–97) on March 21, 1935. The couple had four sons: Klaus Eichmann, (b. 1936 in Berlin), Horst Adolf Eichmann, (b. 1940 in Vienna), Dieter Helmut Eichmann, (b. 1942 in Prague), and Ricardo Francisco Eichmann, (b. 1955 in Buenos Aires).
On the advice of family friend Ernst Kaltenbrunner, Eichmann joined the Austrian branch of the NSDAP (member number 889 895) and of the SS, enlisting on April 1 1932, as an SS-Anwärter. He was accepted as a full SS member that November, appointed an SS-Mann, and assigned the SS number 45326.
For the next year, Eichmann was a member of the Allgemeine SS and served in a mustering formation operating from Salzburg.
In 1933 when the Nazis came to power, Eichmann returned to Germany and submitted an application to join the active duty SS regiments. He was accepted, and in November 1933, was promoted to Scharführer and assigned to the administrative staff of the Dachau concentration camp.
By 1934, Eichmann requested transfer into the Sicherheitspolizei (Security Police) which had, by that time, become a very powerful and feared organization. Eichmann's transfer was granted in November 1934, and he was assigned to the headquarters of the Sicherheitsdienst (SD) in Berlin. Eichmann was promoted to Hauptscharführer in 1935 and, in 1937, commissioned as an SS-Untersturmführer.
In 1937, Eichmann was sent to the British Mandate of Palestine with his superior Herbert Hagen to assess the possibilities of massive Jewish emigration from Germany to Palestine. They landed in Haifa but could obtain only a transit visa so they went on to Cairo. There, they met Feival Polkes, an agent of the Haganah, who discussed with them the plans of the Zionists and tried to enlist their assistance in facilitating Jewish emigration from Europe. According to an answer Eichmann gave at his trial, he had also planned to meet Arab leaders in Palestine; this never happened because entry to Palestine was refused by the British authorities.
In 1938, Eichmann was assigned to Austria to help organize SS Security Forces in Vienna after the Anschluss of Austria into Germany. Through this effort, Eichmann was promoted to SS-Obersturmführer (1st lieutenant) and, by the end of 1938, Eichmann had been selected by the SS leadership to form the Central Office for Jewish Emigration, charged with forcibly deporting and expelling Jews from Austria. Through this work, Eichmann became a student of Judaism, even studying Hebrew.
At the start of World War II, Eichmann had been promoted to SS-Hauptsturmführer (captain) and had made a name for himself with his Office for Jewish Emigration. Through this work Eichmann made several contacts in the Zionist movement, which he worked with to speed up Jewish emigration from the Third Reich.
Eichmann returned to Berlin in 1939 after the formation of the Reich Central Security Office (RSHA). In December 1939, he was assigned to head RSHA Referat IV B4, the RSHA department that dealt with Jewish affairs and evacuation. In August 1940, he released his Reichssicherheitshauptamt: Madagaskar Projekt (Reich Central Security Office: Madagascar Project), a plan for forced Jewish deportation that never materialized. He was promoted to the rank of SS-Sturmbannführer in late 1940, and less than a year later to Obersturmbannführer.
In 1942, Reinhard Heydrich ordered Eichmann to attend the Wannsee Conference as recording secretary, where Germany's anti-Semitic measures were set down into an official policy of genocide. Eichmann was given the position of Transportation Administrator of the "Final Solution to the Jewish Question", which put him in charge of all the trains which would carry Jews to the death camps in the territory of occupied Poland.
In 1944, he was sent to Hungary after Germany had occupied that country in fear of a Soviet invasion. Eichmann at once went to work deporting Jews, sending 400,000 Hungarians to their deaths in the gas chambers.
By 1945, Reichsführer-SS Heinrich Himmler had ordered Jewish extermination halted and evidence of the Final Solution destroyed. Eichmann was appalled by Himmler's turnabout, and continued his work in Hungary against official orders. Eichmann was also working to avoid being called up in the last ditch German military effort, since a year before he had been commissioned as a Reserve Untersturmführer in the Waffen-SS and was now being ordered to active combat duty.
Eichmann fled Hungary in 1945 as the Soviets entered, and he returned to Austria, where he met up with his old friend Ernst Kaltenbrunner. Kaltenbrunner, however, refused to associate with Eichmann since the latter's duties as an extermination administrator had left him a marked man by the Allies.
At the end of World War II, Eichmann was captured by the US Army, who did not know that this man who presented himself as "Otto Eckmann" was in fact a much bigger catch. Early in 1946, he escaped from US custody and hid in various parts of Germany for a few years. In 1948 he obtained a landing permit for Argentina, but did not use it immediately. At the beginning of 1950, Eichmann went to Italy, where he posed as a refugee named Riccardo Klement. With the help of a Franciscan friar who had connections with archbishop Alois Hudal, who organized one of the first ratlines, Eichmann obtained an International Committee of the Red Cross humanitarian passport in Geneva and an Argentine visa, both issued to "Riccardo Klement, technician." (In early May 2007, this fake passport was discovered in court archives in Argentina by a student doing research on Eichmann's abduction. The passport has been handed to the Argentina Holocaust Museum in Buenos Aires.) He boarded a ship heading for Argentina on July 14, 1950. For the next 10 years, he worked in several odd jobs in the Buenos Aires area (from factory foreman, to junior water engineer and professional rabbit farmer). Eichmann also brought his family to Argentina.
In June 2006, old CIA documents regarding Nazis and stay-behind networks dedicated to anti-communism were released. Among the 27,000 documents released, a March 1958 memo from the German BND agency to the CIA stated that Eichmann was reported to have lived in Argentina since 1952, using the alias "Clemens". The CIA took no action on this information, however, because Eichmann's arrest threatened to be an embarrassment to the Americans and Germans by turning public attention to the former Nazis they had recruited after WWII. For example, the West German government at the time, headed by Konrad Adenauer, was worried about what Eichmann might say, especially about the past of Hans Globke, Adenauer's national security adviser, who had worked with Eichmann in the Jewish Affairs department and helped draft the 1935 Nuremberg Laws. At the request of Bonn, the CIA persuaded Life magazine to delete any reference to Globke from Eichmann's memoirs, which it had bought from his family. By the time the CIA and the BND had this information, Israel had temporarily given up looking for Eichmann in Argentina because they could not figure out his alias. Neither the CIA, nor the U.S. government as a whole, at that time had a policy of pursuing Nazi war criminals. In addition to protecting Eichmann and Globke, the CIA also protected Reinhard Gehlen, who recruited hundreds of former Nazi spies for the CIA.
Also instrumental in exposing Eichmann's identity was Lothar Hermann, a worker of Jewish descent who fled to Argentina from Germany following his incarceration in the Dachau concentration camp, where Eichmann had served as an administrator. By the 1950s, Hermann had settled into life in Buenos Aires with his family; his daughter Sylvia became acquainted with Eichmann's family and romantically involved with Klaus, the eldest Eichmann son. Due to Klaus' boastful remarks about his father's life as a Nazi and direct responsibility for the Holocaust, Hermann knew he had struck gold in 1957 after reading a newspaper report about German war criminals - of which Eichmann was one.
Soon after, he sent Sylvia to the Eichmanns' home on a fact-finding mission. She was met at the door by Eichmann himself. She asked for Klaus, and, after learning that he was not home, inquired as to whether she was speaking to his father. Eichmann confirmed this fact. Hermann soon began a correspondence with Fritz Bauer, chief prosecutor for the West German state of Hesse, and provided details about Eichmann's person and life. He contacted Israeli officials, who worked closely with Hermann over the next several years to learn about Eichmann and to formulate a plan to capture him.
In 1960, Mossad discovered that Eichmann was in Argentina and began an effort to locate his exact whereabouts when, through relentless surveillance, it was confirmed that Ricardo Klement was, in fact, Adolf Eichmann. The Israeli government then approved an operation to capture Eichmann and bring him to Jerusalem for trial as a war criminal.
Eichmann was captured by a team of Mossad and Shabak agents in a suburb of Buenos Aires on May 11, 1960, as part of a covert operation. The Mossad agents had arrived in Buenos Aires in April 1960 after Eichmann's identity was confirmed. After surveilling Eichmann for an extensive period of time, a team of Mossad agents waited for him as he arrived home from his work as foreman at a Mercedes Benz factory. One kept lookout waiting for his bus to arrive while two agents pretended to be fixing a broken down car. An unconfirmed fourth would ride on the bus to make sure he would leave. Once Eichmann alighted and began walking the short distance to his home, he was asked by the agent at the car, Zvi Aharoni, for a cigarette. When Eichmann reached in his pocket he was set upon by the two by the car. Eichmann fought but team member Peter Malkin, a Polish Jew and a black belt in karate, knocked Eichmann unconscious with a strike to the back of his neck and bundled him into the car and took him to the safe house. The agents kept him in a safe house until it was judged that he could be taken to Israel without being detected by Argentine authorities. Disguising themselves and a heavily-sedated Eichmann as part of a delegation of Jewish union members, Eichmann was smuggled out of Argentina on board an El Al Bristol Britannia commercial air flight from Argentina to Israel on May 21, 1960.
There was a backup plan in case the plan to kidnap did not go as planned. If the police happened to intervene, one of the agents was to handcuff himself to Eichmann and make full explanations and disclosure. For some time the Israeli government denied involvement in Eichmann's capture, claiming that he had been taken by Jewish volunteers who eagerly turned him over to government authorities. This claim was made due to the influence of anti-Semitic sectors in the Argentinian government and military. Negotiations followed between Prime Minister David Ben-Gurion and Argentinian president Arturo Frondizi, while the abduction was met from radical right sectors with a violent wave of anti-Semitism, carried on the streets by the Tacuara Nationalist Movement (including murders, torture and bombings).
Ben Gurion then announced Eichmann's capture to the Knesset (Israel's parliament) on May 23, receiving a standing ovation in return. Isser Harel, head of the Mossad at the time of the operation, wrote a book about Eichmann's capture entitled The House on Garibaldi Street; some years later a member of the kidnapping team, Peter Malkin, authored Eichmann in My Hands, a book that explores Eichmann's character and motivations but whose veracity has been attacked.
In June 1960, after unsuccessful secret negotiations with Israel, Argentina requested an urgent meeting of the United Nations Security Council, to protest what Argentina regarded as the "violation of the sovereign rights of the Argentine Republic". In the ensuing debate, the Israeli representative Golda Meir argued that the incident was only an "isolated violation of Argentine law" since the abductors were not Israeli agents but private individuals. Eventually the Council passed a resolution which requested Israel "to make appropriate reparation", while stating that "Eichmann should be brought to appropriate justice for the crimes of which he is accused" and that "this resolution should in no way be interpreted as condoning the odious crimes of which Eichmann is accused".
In the subsequent trial and appeal, the Israeli courts avoided the issue of the legality of Eichmann's capture, relying instead on legal precedents that the circumstances of his capture had no bearing on the legality of his trial. The Israeli Court also determined that because "Argentina has condoned the violation of her sovereignty and has waived her claims, including that for the return of the Appellant, any violation of international law that may have been involved in this incident has thus been remedied".
Eichmann's trial in front of an Israeli court in Jerusalem started on April 11, 1961. He was indicted on 15 criminal charges, including charges of crimes against humanity, crimes against the Jewish people and membership of an outlawed organization. In accordance with Israeli criminal procedure, his trial was presided over by three judges: Moshe Landau (president), Benjamin Halevi and Yitzhak Raveh. Gideon Hausner, the Israeli attorney general, acted as chief prosecutor. The three judges sat high atop a plain dais. The building where the trial was held was the newly built auditorium called "Beit Ha'am (House of the People). Eichmann sat inside a bulletproof glass booth, for his own safety.
The legal basis of the charges against Eichmann was the 1950 "Nazi and Nazi Collaborators (Punishment) Law".
Defense witnesses, all of them former high-ranking Nazis, were promised immunity and safe conduct from their German and Austrian homes to testify in Jerusalem for Eichmann's behalf. All of them refused to travel to Israel, but they sent court depositions. None of the depositions supported Eichmann's "following orders" defense, however. One deposition was from Otto Winkelmann, a former senior SS police leader in Budapest in 1944. He stated in his memo that "(Eichmann) had the nature of a subaltern, which means a fellow who uses his power recklessly, without moral restraints. He would certainly overstep his authority if he thought he was acting in the spirit of his commander (Adolf Hitler)". A former brigadier general in the German secret service named Franz Six said in his deposition that Eichmann was an absolute believer in National Socialism and would act to the most extreme of the party doctrine, and that Eichmann had greater power than other department chiefs.
After 14 weeks of testimony with more than 1,500 documents, 100 prosecution witnesses (90 of whom were Nazi concentration camp survivors) and dozens of defense depositions delivered by diplomatic couriers from 16 different countries, the Eichmann trial ended on August 14. At that point, the judges began deliberations in seclusion. On December 11, the three judges announced their verdict: Eichmann was convicted on all counts. On December 15, he was sentenced to death. Eichmann appealed the verdict, mostly relying on legal arguments about Israel's jurisdiction and the legality of the laws under which he was charged. He also claimed that he was protected by the principle of "Acts of State" and repeated his "superior orders" defense. On May 29, 1962 Israel's Supreme Court, sitting as a Court of Criminal Appeal, rejected the appeal and upheld the District Court's judgment on all counts. On May 31, Israeli President Yitzhak Ben-Zvi turned down Eichmann's petition for mercy. A large number of prominent persons sent requests for clemency. Ben-Zvi replied quoting a passage from the First Book of Samuel: "As your sword bereaved women, so will your mother be bereaved among women." (1 Samuel 15:33, Samuel's words to Agag, king of the Amalekites).
Eichmann was hanged a few minutes after midnight on June 1, 1962, at Ramla prison. This remains the only civil execution ever carried out in Israel, which has a general policy of not using the death penalty. Eichmann allegedly refused a last meal, preferring instead a bottle of Carmel, a dry red Israeli wine. He consumed about half of the bottle. He also refused to don the traditional black hood for his execution.
According to an official account, there were two people who would pull the lever simultaneously, so neither would know for sure by whose hand Eichmann died.
Shortly after the execution, Eichmann's body was cremated. The next morning, his ashes were scattered at sea over the Mediterranean, in international waters. This was to ensure that there could be no future memorial and that no nation would serve as his final resting place.
Since Eichmann's death, historians have speculated on certain facts regarding his life. The critical question is how responsible Eichmann was for the implementation of the Holocaust. Some argue that Eichmann knew exactly what he was doing, while others state that he was unfairly judged and that he was doing only his duty as a soldier. Eichmann's son, Rudolph, condemned his father's actions, and said he harbored no resentment toward Israel for executing his father. Eichmann himself said he joined the SS not because he agreed or disagreed with its ethos, but because he needed to build a career.
A third analysis came from political theorist Hannah Arendt, a Jew who fled Germany before Hitler's rise to power, and who reported on Eichmann's trial for The New Yorker. In Eichmann in Jerusalem, a book formed by this reporting, Arendt concluded that, aside from a desire for improving his career, Eichmann showed no trace of an antisemitic personality or of any psychological damage to his character. She called him the embodiment of the "Banality of Evil," as he appeared at his trial to have an ordinary and common personality, displaying neither guilt nor hatred. She suggested that this most strikingly discredits the idea that the Nazi criminals were manifestly psychopathic and different from ordinary people.
Stanley Milgram, who interpreted Arendt's work as stating that even the most ordinary of people can commit horrendous crimes if placed in the right situation and given the correct incentives, wrote: "I must conclude that Arendt's conception of the banality of evil comes closer to the truth than one might dare imagine." Arendt did not, however, suggest that Eichmann was normal or that any person placed in his situation would have done as he did: according to her account, Adolf Eichmann had abdicated his will to make moral choices, and thus his autonomy. Eichmann claimed he was just following orders, and that he was therefore respecting the duties of a "bureaucrat". Arendt thus argued that he had essentially forsaken the conditions of morality, autonomy and the ability to question orders (see Führerprinzip).
In Becoming Eichmann, David Cesarani has claimed that Eichmann was in fact extremely anti-Semitic, and that these feelings were important motivators of his genocidal actions.
A footnote to Eichmann's SS career focuses on the point as to why he was never promoted to the rank of full SS-Colonel, known as Standartenführer. With Eichmann's record and responsibilities, he would have been a prime candidate for advancement. After 1941, however, his SS record contains no evidence that he was ever even recommended for another promotion.
John Zerzan first used the metaphor "Little Eichmann" in 1995. The term was used again by Ward Churchill in his controversial essay about the 9/11 terrorist attacks. The controversy surrounding the essay and his use of the phrase "Little Eichmanns" created notable media coverage throughout the U.S. for years after 2001.

In mathematics, the absolute value (or modulus which is Latin for a small measure) of a real number is its numerical value without regard to its sign. So, for example, 3 is the absolute value of both 3 and −3. In computer programming, the mathematical function used to perform this calculation is usually given the name abs().
Generalizations of the absolute value for real numbers occur in a wide variety of mathematical settings. For example an absolute value is also defined for the complex numbers, the quaternions, ordered rings, fields and vector spaces.
The absolute value is closely related to the notions of magnitude, distance, and norm in various mathematical and physical contexts.
As can be seen from the above definition, the absolute value of a is always either positive or zero, but never negative.
From a geometric point of view, the absolute value of a real number is the distance along the real number line of that number from zero, and more generally the absolute value of the difference of two real numbers is the distance between them. Indeed the notion of an abstract distance function in mathematics can be seen to be a generalization of the absolute value of the difference (see "Distance" below).
can be seen as motivating the following definition.
Similar to the geometric interpretation of the absolute value for real numbers, it follows from the Pythagorean theorem that the absolute value of a complex number is the distance in the complex plane of that complex number from the origin, and more generally, that the absolute value of the difference of two complex numbers is equal to the distance between those two complex numbers.
The latter formula is the complex analogue of proposition 1 mentioned above in the real case..
Since the positive reals form a subgroup of the complex numbers under multiplication, we may think of absolute value as an endomorphism of the multiplicative group of the complex numbers.
The real absolute value function is continuous everywhere. It is differentiable everywhere except for x = 0. It is monotonically decreasing on the interval (-∞, 0] and monotonically increasing on the interval [0, ∞). Since a real number and its negative have the same absolute value, it is an even function, and is hence not invertible.
The complex absolute value function is continuous everywhere but (complex) differentiable nowhere (One way to see this is to show that it does not obey the Cauchy-Riemann equations).
Both the real and complex functions are idempotent.
It is a nonlinear function.
where is the additive inverse of, and is the additive identity element.
The absolute value is closely related to the idea of distance. As noted above, the absolute value of a real or complex number is the distance from that number to the origin, along the real number line, for real numbers, or in the complex plane, for complex numbers, and more generally, the absolute value of the difference of two real or complex numbers is the distance between them.
The above shows that the "absolute value" distance for the real numbers or the complex numbers, agrees with the standard Euclidean distance they inherit as a result of considering them as the one and two-dimensional Euclidean spaces respectively.
The absolute value function has no concavity at any point, the sign function is constant at all points. Therefore the second derivative of |x| with respect to x is zero everywhere except zero, where it is undefined.
The fundamental properties of the absolute value for real numbers given in Proposition 2 above, can be used to generalize the notion of absolute value to an arbitrary field, as follows.
Where denotes the additive identity element of. It follows from positive-definiteness and multiplicativeness that, where denotes the multiplicative identity element of. The real and complex absolute values defined above are examples of absolute values for an arbitrary field.
An absolute value which satisfies any (hence all) of the above conditions is said to be non-Archimedean, otherwise it is said to be Archimedean.
Again the fundamental properties of the absolute value for real numbers can be used, with a slight modification, to generalize the notion to an arbitrary vector space.
The norm of a vector is also called its length or magnitude.
is a norm called the Euclidean norm. When the real numbers R are considered as the one-dimensional vector space R1, the absolute value is a norm, and is the p-norm for any p. In fact the absolute value is the "only" norm on R1, in the sense that, for every norm ||·|| on R1, ||x||=||1||·|x|. The complex absolute value is a special case of the norm in an inner product space. It is identical to the Euclidean norm, if the complex plane is identified with the Euclidean plane R².
 if (i abs. It handles integer, real as well as complex numbers.
cdq extends the sign bit of eax into edx. If eax is nonnegative, then edx becomes zero, and the latter two instructions have no effect, leaving eax unchanged. If eax is negative, then edx becomes 0xFFFFFFFF, or -1. The next two instructions then become a two's complement inversion, giving the absolute value of the negative value in eax.

Arches National Park preserves over 2,000 natural sandstone arches, including the world-famous Delicate Arch, in addition to a variety of unique geological resources and formations.
The park is located near Moab, Utah, and is 119 square miles (309 km²) in size. Its highest elevation is 5,653 feet (1,723 m) at Elephant Butte and its lowest elevation is 4,085 feet (1,245 m) at the visitor center. Since 1970, 42 arches have toppled because of erosion. Arches National Park receives 10 inches (250 mm) of rain a year on average.
The area, administered by the National Park Service, was originally designated as a national monument on April 12, 1929. It was redesignated a national park on November 12, 1971. More than 833,000 people visited it in 2006.
The national park lies atop an underground salt bed, which is the main cause of the formation of the arches and spires, balanced rocks, sandstone fins, and eroded monoliths in the area. Thousands of feet thick in places, this salt bed was deposited over the Colorado Plateau some 300 million years ago when a sea flowed into the region and eventually evaporated. Over millions of years, the salt bed was covered with residue from floods and winds and the oceans that came in intervals. Much of this debris was compressed into rock. At one time this overlying earth may have been one mile thick.
Salt under pressure is unstable, and the salt bed below Arches was no match for the weight of this thick cover of rock. Under such pressure it shifted, buckled, liquefied, and repositioned itself, thrusting the Earth layers upward into domes. Whole sections fell into cavities. In places they turned almost on edge. Faults occurred. The result of one such 2,500-foot displacement, the Moab Fault, is seen from the visitor center.
As this subsurface movement of salt shaped the Earth, surface erosion stripped away the younger rock layers. Except for isolated remnants, the major formations visible in the park today are the salmon-colored Entrada Sandstone, in which most of the arches form, and the buff-colored Navajo Sandstone. These are visible in layer cake fashion throughout most of the park. Over time water seeped into the superficial cracks, joints, and folds of these layers. Ice formed in the fissures, expanding and putting pressure on surrounding rock, breaking off bits and pieces. Winds later cleaned out the loose particles. A series of free-standing fins remained. Wind and water attacked these fins until, in some, the cementing material gave way and chunks of rock tumbled out. Many damaged fins collapsed. Others, with the right degree of hardness and balance, survived despite their missing sections. These became the famous arches.
Humans have occupied the region since the last ice age 10,000 years ago. Fremont people and Ancient Pueblo People lived in the area up until about 700 years ago. Spanish missionaries encountered Ute and Paiute tribes in the area when they first came through in 1775, but the first European-Americans to attempt settlement in the area were the Mormon Elk Mountain Mission in 1855, who soon abandoned the area. Ranchers, farmers, and prospectors later settled Moab in the neighboring riverine valley in the 1880s. Word of the beauty in the surrounding rock formations spread beyond the settlement as a possible tourist destination.
The Arches area was first brought to the attention of the National Park Service by Frank A. Wadleigh, passenger traffic manager of the Denver and Rio Grande Western Railroad. Wadleigh, accompanied by railroad photographer George L. Beam, visited the area in September 1923 at the invitation of Alexander Ringhoffer, a Hungarian-born prospector living in Salt Valley. Ringhoffer had written to the railroad in an effort to interest them in the tourist potential of a scenic area he had discovered the previous year with his two sons and a son-in-law, which he called the "Devil's Garden" (known today as the "Klondike Bluffs"). Wadleigh was impressed by what Ringhoffer showed him, and suggested to Park Service director Stephen T. Mather that the area be made a national monument.
The following year additional support for the monument idea came from Laurence M. Gould, a University of Michigan graduate student studying the geology of the nearby La Sal mountains, who was shown the scenic area by retired local physician Dr. J.W. "Doc" Williams.
A succession of government investigators examined the area, in part due to confusion as to the precise location. In the process the name "Devil's Garden" was transposed to an area on the opposite side of Salt Valley, and Ringhoffer's original discovery was omitted, while another area nearby, known locally as "The Windows", was included. Designation of the area as a national monument was supported by the Park Service from 1926, but was resisted by President Calvin Coolidge's Interior Secretary. Finally in April 1929, shortly after his inauguration, President Herbert Hoover signed a presidential proclamation creating Arches National Monument, consisting of two comparatively small, disconnected sections. The purpose of the reservation under the 1906 Antiquities Act was to protect the arches, spires, balanced rocks, and other sandstone formations for their scientific and educational value. The name "Arches" was suggested by Frank Pinkely, superintendent of the Park Service's southwestern national monuments, following a visit to the Windows section in 1925.
In late 1938, President Franklin D. Roosevelt signed a proclamation which enlarged the Arches to protect additional scenic features and permit development of facilities to promote tourism. A small adjustment was made by President Dwight Eisenhower in 1960 to accommodate a new road alignment.
In early 1969, just before leaving office, President Lyndon B. Johnson signed a proclamation substantially enlarging the Arches. Two years later President Richard Nixon signed legislation enacted by Congress which significantly reduced the area of Arches, but changed its status to a National Park.
Climbing of other features in the park is allowed, but regulated. The revised regulations also prohibit slacklining parkwide. Approved recreational activities include auto touring, backpacking, biking, camping, and hiking, some of which require permits. There are also guided commercial tours and ranger programs.
American writer Edward Abbey was a park ranger at Arches National Monument where he kept journals that became his book Desert Solitaire. The success of this book, as well as the rise in adventure-based recreation, has drawn many hikers, mountain-bikers, and off-road enthusiasts to the area, but activities are limited within park boundaries: camping, foot hiking (along designated trails), and driving only along marked roads.
The opening scenes of the movie Indiana Jones and the Last Crusade were filmed at the park.
There is an abundance of wildlife in Arches NP. The list includes: Spadefoot Toad, Scrub Jay, peregrine falcon, many kinds of Sparrows, Red Fox, Desert Bighorn Sheep, Kangaroo rat, Mule Deer, mountain lion, Midget-Faded Rattlesnake, Yucca Moth, many types of Cyanobacteria, western rattlesnake, and the Western Collard Lizard.
Plants also dominate the landscape in the park. The list of plants consistes of: Prickly pear cactus, Indian RiceGrass, Bunch Grasses, Cheatgrass, Lichen, Mosses, Liverworts, Utah Juniper, Morman Tea, Blackbrush, Cliffrose, Four-winged Saltbrush, Pinyon pine, Stemless woollybase, evening primrose, sand verbena, yucca, and the Sacred Datura.

An analog or analogue signal is any time continuous signal where some time varying feature of the signal is a representation of some other time varying quantity. It differs from a digital signal in that small fluctuations in the signal are meaningful. Analog is usually thought of in an electrical context, however mechanical, pneumatic, hydraulic, and other systems may also convey analog signals.
An analog signal uses some property of the medium to convey the signal's information. For example, an aneroid barometer uses rotary position as the signal to convey pressure information. Electrically, the property most commonly used is voltage followed closely by frequency, current, and charge.
Any information may be conveyed by an analog signal, often such a signal is a measured response to changes in physical phenomena, such as sound, light, temperature, position, or pressure, and is achieved using a transducer.
For example, in sound recording, fluctuations in air pressure (that is to say, sound) strike the diaphragm of a microphone which causes corresponding fluctuations in a voltage or the current in an electric circuit. The voltage or the current is said to be an "analog" of the sound.
Since an analogue signal has a theoretically infinite resolution, it will always have a higher resolution than any digital system where the resolution is in discrete steps. In practice, as analogue systems become more complex, effects such as non linearity and noise ultimately degrade analogue resolution to such extent that digital systems surpass it. In analogue systems it is difficult to detect when such degradation occurs, but in digital systems, degradation can not only be detected, but corrected as well.
The primary disadvantage of analog signaling is that any system has noise – i.e. random variation. As the signal is copied and re-copied, or transmitted over long distances, these random variations become dominant. Electrically, these losses can be diminished by shielding, good connections, and several cable types such as coaxial or twisted pair.
The effects of noise make signal loss and distortion impossible to recover, since amplifying the signal to recover attenuated parts of the signal amplifies the noise as well. Even if the resolution of an analog signal is higher than a comparable digital signal, in many cases, the difference is overshadowed by the noise in the signal.
Another method of conveying an analog signal is to use modulation. In this, some base signal (e.g. a sinusoidal carrier wave) has one of its properties modulated: amplitude modulation involves altering the amplitude of a sinusoidal voltage waveform by the source information, frequency modulation changes the frequency. Other techniques, such as changing the phase of the base signal also work.
Analog circuits do not involve quantisation of information into digital format. The concept being measured over the circuit, whether sound, light, pressure, temperature, or an exceeded limit, remains from end to end.
Clocks with hands are called analog; those that display digits are called digital. However, many analog clocks are actually digital since the hands do not move in a smooth continuous motion, but in small steps every second or half a second, or every minute.
See digital for a discussion of digital vs. analog.
Sources: Some of an earlier version of this article was originally taken from Federal Standard 1037C in support of MIL-STD-188.


Arecales is an order of flowering plants. The order has been widely recognised only for the past few decades; until then, the accepted name for the order including these plants was Principes.
This is unchanged from the APG system of 1998, although it used the spelling "commelinoids" instead of commelinids.
The Cronquist system of 1981 made the same choices at the rank of family and order, but assigned the order to the subclass Arecidae in the class Liliopsida (= monocotyledons).
The Thorne system (1992) and the Dahlgren system had made the same choices at the rank of family and order, but assigned the order to the superorder Arecanae in the subclass Liliidae (= monocotyledons).


Ten people, each with a deadly secret, find themselves trapped on an island where they become the subjects of a cruel game in which a person calls him or herself "U.N. Owen" (Unknown). Each person dies one by one along the lines of a nursery rhyme. As they do, china dolls discreetly dissappear as each person dies. No one else is on the island except for these people, so one of them is the murderer.
One choked his little self and then there were Nine.
One overslept himself and then there were Eight.
One said he'd stay there and then there were Seven.
One chopped himself in halves and then there were Six.
A bumblebee stung one and then there were Five.
One got into Chancery and then there were Four.
A red herring swallowed one and then there were Three.
A big bear hugged one and then there were Two.
He went out and hanged himself and then there were none.
Ten figurines of little Soldiers are found in the dining room.
The characters realize they have all been tricked into coming to the island, but now have no way to get back to the mainland. The guests are then murdered, one by one, with each murder referring to a verse of the poem found in their rooms. First to die is Anthony Marston, who dies from cyanide in his drink (one choked his little self). The next morning, Mrs. Rogers never wakes up and is assumed to have received a fatal overdose of sleeping drugs (one overslept himself). At lunchtime, General MacArthur, who had predicted that he would never leave the island alive, is found dead from a blow to the back of his head (one said he'd stay there). In growing panic, the survivors search the island for the murderer or possible hiding places, but find nothing.
They then realize that the murderer must be one of them, and is playing a sadistic game, killing them in a manner paralleling the nursery rhyme, and also removing one of ten little figurines in the dining room after each murder. The survivors have a meeting and discover that none of them has an alibi for any of the deaths. They conclude that the murderer is dispensing his own form of justice.
The next morning, Rogers is found dead in the woodshed, having been struck in the head with a large axe (one chopped himself in half). Later that day, Emily Brent dies from an injection of potassium cyanide – the injection mark on her neck is an allusion to a bee sting (a bumblebee stung one). The hypodermic needle is found outside, thrown from the window along with a smashed china soldier figurine. The five survivors – Dr. Armstrong, Justice Wargrave, Philip Lombard, Vera Claythorne, and Inspector Blore – become increasingly frightened. Wargrave announces that anything on the island that could be used as a weapon should be locked up. They lock up Wargrave's sleeping pills and Armstrong's medical equipment, but Lombard's revolver has gone missing. They spend the afternoon sitting around, watching each other.
Everyone decides to just sit around, with only one leaving at any one time – theoretically, they should all be safe that way. Vera, the one most wracked by guilt, goes up to her room and is frightened by a strand of seaweed that reminds her of the boy she murdered by drowning. Everyone goes to check on her, and when they return to the drawing room, they discover that the Judge has been murdered (one got in Chancery) – but they can't figure out who had the chance to do it. That night, the ex-policeman, Blore, hears someone sneaking out. He searches the remaining rooms, and discover that Armstrong, the doctor, is missing – so he must be the killer.
Vera, Inspector Blore, and Lombard think it best to go outside when morning arrives. Blore later returns to the house to get some sustenance, and a dull thud is heard. When Vera and Philip come to see what happened, they find Blore dead, his head crushed by a heavy marble clock shaped like a bear (a big bear hugged one). Not knowing if Armstrong is dead or alive, they assume that he did it and decide to stay out of the house.
The pair then walk along the cliffs, finding in the process Armstrong's drowned body (a red herring swallowed one). Vera and Lombard then realize that they are the only two left. Even though neither could possibly have murdered the Inspector, their mutual suspicion has driven them to a breaking point and each of them assumes the other to be the murderer.
Vera tricks Lombard into helping her lift Armstrong's body out of reach of the water, and while Lombard is busy, snatches his revolver. Lombard then reaches for his revolver, only to discover that Vera has taken it. She shoots him dead on the beach (out in the sun). Vera then returns to the house, thinking she is finally safe. But when she gets to her room, she discovers a noose hanging there, with a chair under it. Having finally been driven mad by the entire experience (or "hypnotically suggestible") and experiencing horrible feelings of latent guilt for her crimes, Vera hangs herself in the room, kicking the chair out from under her, fulfilling the final verse of the rhyme.
They have concluded from the physical evidence and various characters' diaries and journal entries that Blore, Armstrong, Lombard, and Claythorne were definitely the last to die.
Blore could not have died last, as the clock was definitely dropped onto him from above, and it would have been impossible for him to have it fall on him. Armstrong could not have been last since his drowned body was dragged above the high-tide mark by someone else. Nor could Lombard, since he was shot on the beach and the revolver was found upstairs in the hallway, outside the door of Wargrave's room. That left Vera (whose fingerprints were on the pistol and from whose window the clock was dropped on Blore), who hanged herself from the ceiling; but the chair from which she leapt with the noose around her neck was found pushed against the wall, out of reach from where she might have stood on it.
The man who made all the arrangements for the island was Isaac Morris, a shady dealer known to efficiently cover his tracks when doing business. He was also the one who hired Lombard to go to the island. However, he cannot tell the police anything: he died of an overdose the day the party set sail.
During the period when the killings were taking place and immediately after, no-one could have gotten onto or left the island without being seen and the weather was too bad anyway. This rules out the possibility that "Mr. Owen" was some unidentified person who committed the murders while evading detection by the guests.
Hence, although one of the ten guests must have been the killer, none of them could have been.
A bottle with a letter in it is found by a fishing trawler. The master of the trawler sends it to Scotland Yard. The late Judge Lawrence Wargrave wrote the letter to explain that he had planned the killings because, he writes, ever since he was a child, he had been prone both to sadism and to a fascination with the legal system. Wargrave first freely divulges his own hunger for blood, combined with his desire for strict justice (he never was able to punish someone whom he honestly thought as innocent) and his delight in seeing the guilty punished. When Wargrave was told by his Harley Street physician that he was terminally ill, Wargrave decided to go out in a blaze of drama which would satiate his inner urges, rather than just letting his life slowly trickle away.
Thereafter, he details how he picked his victims, including a drug-dealing hypochondriac, Isaac Morris, whose drugs led to the death of a daughter of friends of Wargrave. Wargrave mostly heard about the cases in the course of his work, and even met the man whose life was ruined after Vera Claythorne, his lover, caused the death of his beloved nephew, wanting to make him the inheritor of the boy's fortune. Wargrave explains how he murdered Morris, Marston, Mr. and Mrs. Rogers, Macarthur, and Emily Brent. He then deceived Dr. Armstrong into pronouncing him "dead", thus allowing the two to meet by the cliffs to discuss a strategy for determining the killer's identity. When Armstrong arrived, Wargrave tricked him into peering over the edge and shoved him over, then went back to the house and pretended to be dead. His trick made it possible for him to kill Blore and orchestrate the deaths of Lombard and Vera.
The conclusion of the judge's letter indicates that he planned to shoot himself while sitting on his bed, so that his body would fall onto the bed as if it had been laid there. He fastened the gun to the doorknob with a piece of elastic cord in such a way that the recoil would snap the gun out into the hallway as the door to his room closed. Thus the police found ten dead bodies and an unsolvable mystery on Soldier Island.
In 1943, Agatha Christie adapted the story for the stage. In the process of doing so, she realized that the novel's grim conclusion would not work dramatically on stage as there would be no one left to tell the tale, so she reworked the ending for Lombard and Vera to be innocent of the crimes of which they were accused, survive, and fall in love. Some of the names were also changed with General Macarthur becoming General McKenzie.
The story was first adapted for the cinema screen in René Clair's successful 1945 production.
Many of the films follow the play's humorous tone and more optimistic ending. A newer version of the play was adapted for stage in October 2005, which followed the book a bit more closely.
The K.B.S. Productions Inc. film, A Study in Scarlet (1933), predates the publication of Ten Little Niggers and follows a strikingly similar plot. It is a Sherlock Holmes movie but bears no resemblance to Arthur Conan Doyle's original story of the same name. In this case, the rhyme refers to "Ten Little Black Boys".
The novel was originally published in Britain under the title Ten Little Niggers in 1939. All references to "Indian" in the story were originally "Nigger": thus the island was called "Nigger Island" rather than "Indian Island" and the rhyme found by each murder victim was also called Ten Little Niggers rather than Ten Little Indians. Modern printings use the rhyme Ten Little Soldiers and "Soldier Island".
For the United States market, the novel was first serialized in the Saturday Evening Post in seven parts from May 20 to July 1, 1939 and then published separately in January 1940. Both publications used the less inflammatory title And Then There Were None. The 1945 motion picture also used this title. In 1946, the play was published under the new title Ten Little Indians (the same title under which it had been performed on Broadway), and in 1964, an American paperback edition also used this title.
British editions continued to use the work's original title until the 1980s and the first British edition to use the alternative title And Then There Were None appeared in 1985 with a reprint of the 1963 Fontana Paperback. Today And Then There Were None is the title most commonly used. However, the original title survives in many foreign-language versions of the novel: for example, the Spanish title is Diez Negritos, while the French title is Dix petits nègres". A Dutch translation available as late as 1981 even used the work's original English title Ten Little Niggers. The 1987 Russian film adaptation has the title Десять негритят ("Desyat' negrityat"). The computer adventure game based on the novel uses "Ten Little Sailor Boys." The 2003 Harper Collins edition changes the name of the island to "Soldiers Island" and the nursery rhyme is changed to "Ten Little Soldiers," and restores the character Philip Lombard's anti-semitic remarks towards Mr. Morris as "Jew" and "Jewboy," previously censored in older editions.


Hercule Poirot ([ɛʀkyl pwaʀo]) is a fictional Belgian detective created by Agatha Christie. Along with Miss Marple, Poirot is one of Christie's most famous and long-lived characters: he appeared in 33 novels and 54 short stories.
Poirot has been portrayed on screen, for films and TV, by various actors including Albert Finney, Peter Ustinov, Ian Holm, Tony Randall, Alfred Molina and David Suchet.
His character was based on two other fictional detectives of the time: Marie Belloc Lowndes' Hercule Popeau and Frank Howel Evans' Monsieur Poiret, a retired French police officer living in London. A more obvious influence on the early Poirot stories is that of Arthur Conan Doyle. In An Autobiography Christie admits that "I was still writing in the Sherlock Holmes tradition – eccentric detective, stooge assistant, with a Lestrade-type Scotland Yard detective, Inspector Japp." For his part Doyle acknowledged basing Sherlock Holmes on the model of Edgar Allan Poe's fictional French detective C. Auguste Dupin, who in his use of "ratiocination" prefigures Poirot's reliance on his "little grey cells".
Poirot's being a Belgian, unlike the above-mentioned models, is clearly the result of the first book being written in 1916 (though only published in 1920). Not only did his coming from a country occupied by Germany provide a very good reason why such a skilled detective would be out of work and available to solve mysteries at an English country house, but also at the time of writing it was considered patriotic to express sympathy with the Belgians – since the invasion of their country had constituted Britain's casus belli for entering World War 1.
His first published appearance was in The Mysterious Affair at Styles (published 1920) and his last was in Curtain (published 1975, the year before Christie died). On publication of this novel, Poirot was the only fictional character to be given an obituary in the New York Times; August 6, 1975 "Hercule Poirot is Dead; Famed Belgian Detective".
By 1930, Agatha Christie found Poirot 'insufferable' and by 1960, she felt that he was a 'detestable, bombastic, tiresome, ego-centric little creep'. Yet the public loved him, and Christie refused to kill him off, claiming that it was her duty to produce what the public liked, and what the public liked was Poirot.
This is how Agatha Christie describes Poirot in "The Murder on the Orient Express" in the very initial pages.
In the later books, the limp is not mentioned. Poirot has dark hair, which he dyes later in life and green eyes that are repeatedly described as shining "like a cat's" when he is struck by a clever idea. Frequent mention is made of his patent-leather shoes, damage to which is frequently a subject of (for the reader, comical) misery on his part. Poirot's appearance, regarded as fastidious during his early career, is hopelessly out of fashion later in his career.
Poirot is extremely punctual and carries a turnip pocket watch almost to the end of his career.
In The Mysterious Affair at Styles, Poirot operates as a fairly conventional, clue-based detective, depending on logic, which is represented in his vocabulary by two common phrases: his use of "the little grey cells" and "order and method". Irritating to Hastings (and, sometimes, to the reader) is the fact that Poirot will sometimes conceal from him important details of his plans, as in The Big Four where Hastings is kept in the dark throughout the climax. This aspect of Poirot is less evident in the later novels, partly because there is rarely a narrator so there is no one for Poirot to mislead.
As early as Murder on the Links", where he still largely depends on clues, Poirot mocks a rival detective who focuses on the traditional trail of clues that had been established in detective fiction by the example of Sherlock Holmes: footprints, fingerprints and cigar ash. From this point on he establishes himself as a psychological detective who proceeds not by a painstaking examination of the crime scene, but by enquiring either into the nature of the victim or the murderer. Central to his behaviour in the later novels is the underlying assumption that particular crimes are only committed by particular types of person.
Poirot's methods focus on getting people to talk. Early in the novels, he frequently casts himself in the role of "Papa Poirot", a benign confessor, especially to young women. Later he lies freely in order gain the confidences of other characters, either inventing his own reason for being interested in the case or a family excuse for pursuing a line of questioning.
In the later novels Christie often uses the word mountebank when Poirot is being assessed by other characters, showing that he has successfully passed himself off as a charlatan or fraud.
Hastings first meets Poirot during his years as a private detective in Europe and almost immediately after they both arrive in England, becomes his life-long partner and appears in many of the novels and stories. Poirot regarded Hastings as a poor private detective, not particularly intelligent, yet helpful in his way of being fooled by the criminal and for his tendency to unknowingly "stumble" onto the truth.
It must also be said that Hastings was a man who was capable of great bravery and courage when the road got rough, facing death unflinchingly when confronted by The Big Four and possessing unwavering loyalty towards Poirot. When forced to choose between Poirot and his wife in that novel, he chose Poirot.
when Hastings arrives in England for business.
The frequently recurring detective novelist Ariadne Oliver is Agatha Christie's humorous self-caricature. Like Agatha Christie, she isn't overly fond of the detective she is most famous for creating – in Ariadne's case a Finn Sven Hjerson. We never learn about her husband but we know that she hates alcohol and public appearances and has a great fondness for apples until she is put off them by the events of the Hallowe’en party. She also has a habit of constantly changing her hairstyle and in every appearance by her much is made of the clothes and hats she wears. She has a maid called Maria who prevents the public adoration from becoming too much of a burden on her employer, but does nothing to prevent her aggravating employer from becoming too much of a burden on others.
She has authored over fifty six novels and she has a great dislike of people taking and modifying her story characters. She is also the only one in Poirot's universe to have noted that "It’s not natural for five or six people to be on the spot when B is murdered and all have a motive for killing B." She first met Poirot in the story Cards on the Table and has been bothering him ever since.
Poirot's secretary, Miss Felicity Lemon, has few human weaknesses. The only two mistakes she is ever recorded making are a typing error during the events of Hickory Dickory Dock and the mis-mailing of an electric bill. Poirot described her as being "Unbelievably ugly and incredibly efficient. Anything that she mentioned as worth consideration usually was worth consideration." She is an expert on nearly everything and plans to create the perfect filing system. She also once worked for the government agent-turned-philanthropist, Parker Pyne. Whether this was during one of Poirot’s numerous retirements or before she entered his employment is unknown.
Japp is an Inspector from Scotland Yard and appears in many of the stories, trying to solve the cases Poirot is working on. Japp is an outgoing, loud and sometimes inconsiderate man by nature and his relationship with the bourgeois Belgian is one of the stranger aspects of Poirot’s world. He first met Poirot in Belgium, 1904, during the Abercrombie Forgery and later that year joined forces again to hunt down a criminal known as Baron Altara. They also meet in England where Poirot often helps Japp solve a case and lets him take the credit in return for special favours. These favours usually entail being supplied with cases that would interest him.
Georges (we are never told his last name) is a classic English valet and first entered Poirot’s employ in 1923 and didn’t leave his side until the 1970s, shortly before Poirot’s death. A competent, matter-of-fact man with an extensive knowledge of the English aristocracy and absolutely no imagination, Georges provides a steady contrast to Hastings.
It is difficult to draw any concrete conclusions about Poirot's family due to the fact that Poirot often supplies false or misleading information about himself or his background in order to assist him in obtaining information relevant to a particular case. In chapter 21 of The Murder of Roger Ackroyd, for example, we learn that he has been talking about a mentally disabled nephew: this proves to be a ruse so that he can find out about homes for the mentally unfit … but that does not mean that Poirot does not have such a nephew. In Dumb Witness, he regales us with stories of his elderly invalid mother as a pretence to investigate the local nurses. In The Big Four Hastings believes that he meets Achille Poirot who (in an apparent parody of Mycroft Holmes) is evidently his smarter brother. On this occasion, Achille is almost certainly Poirot himself in disguise (Poirot speaks in Chapter 18 of having sent Achille "back to the land of myths"), but this does not conclusively demonstrate that Poirot does not have a brother, or even a brother called Achille. Any evidence regarding Poirot for which Poirot himself is the source is therefore most unreliable. Achille Poirot is also mentioned by Dr. Burton in the prelude to The Labours of Hercules.
Poirot was apparently born in Spa, Belgium and, based on the conjecture that he was thirty at the time of his retirement from the Belgian police force at the time of the outbreak of the First World War, it is suggested that he was born in the mid 1880s. This is all extremely vague, as Poirot is thought to be an old man in his dotage even in the early Poirot novels, and in An Autobiography Christie admitted that she already imagined him to be an old man in 1920. (At the time, of course, she had no idea she would be going on writing Poirot books for many decades to come.) Much of the suggested dating for Poirot's age is therefore post-rationalisation on the part of those attempting to make sense of his extraordinarily long career.
Poirot is a Roman Catholic by birth, and retains a strong sense of Catholic morality later in life. Not much is known of Poirot’s childhood other than he once claimed in Three Act Tragedy to have been from a large family with little wealth. In Taken at the Flood, he further claimed to have been raised and educated by nuns, raising the possibility that he (and any siblings) were orphaned.
As an adult, Poirot joined the Belgian police force. Very little mention is made in Christie's work about this part of his life, but in "The Nemean Lion" (1939) Poirot himself refers to a Belgian case of his in which "a wealthy soap manufacturer […] poisoned his wife in order to be free to marry his secretary". We do not know whether this case resulted in a successful prosecution or not; moreover, Poirot is not above lying in order to produce a particular effect in the person to whom he is speaking, so this evidence is not reliable.
Perhaps this is enough evidence to suggest that Poirot's police career was a successful one.
Nevertheless, he regards the case in "The Chocolate Box", which took place in 1893, as his only actual failure of detection. Again, Poirot is not reliable as a narrator of his personal history and there is no evidence that Christie sketched it out in any depth.
It was also in this period that Poirot shot a man who was firing from a roof onto the public below.
Poirot has retired from the Belgian police force by the time that he meets Hastings in 1916 on the case retold in The Mysterious Affair at Styles".
It should be noted that Poirot is a French-speaking Belgian, i.e. a Walloon; but there can hardly be found any occasion where he refers to himself as such, or is so referred to by others. At the time of writing, at least of the earlier books where the character was defined, non-Belgians such as Agatha Christie were far less aware than nowadays of the deep linguistic divide in Belgian society.
During World War I, Poirot left Belgium for Britain as a refugee. It was here, on 16 July 1916, that he again met his lifelong friend, Captain Arthur Hastings, and solved the first of his cases to be published: The Mysterious Affair at Styles. After that case Poirot apparently came to the attention of the British secret service, and undertook cases for the British government, including foiling the attempted abduction of the Prime Minister.
After the war Poirot became a free agent and began undertaking civilian cases. He moved into what became both his home and work address, 56B Whitehaven Mansions, Sandhurst Square, London W1. It was chosen by Poirot for its symmetry. His first case was "The Affair at the Victory Ball", which saw Poirot enter the high society and begin his career as a private detective.
Between the world wars, Poirot traveled all over Europe and the Middle East investigating crimes and murders. Most of his cases happened during this period and he was at the height of his powers at this point in his life. The Murder On the Links saw the Belgian pit his grey cells against a French murderer. In the Middle East he solved the cases of Death on the Nile, and Murder in Mesopotamia with ease and even survived An Appointment with Death. As he passed through Eastern Europe on his return trip, he solved The Murder on the Orient Express. However he did not travel to the Americas or Australia, probably due to his sea sickness.
It was during this time he met the Countess Vera Rossakoff, a glamorous jewel thief. The history of the Countess is, like Poirot's, steeped in mystery. She claims to have been a member of the Russian aristocracy before the Russian Revolution and suffered greatly as a result, but how much of that story is true is an open question. Even Poirot acknowledges that Rossakoff has told several wildly varying accounts of her early life. Poirot later became smitten with the woman and allowed her to escape justice.
Although letting the Countess escape may be morally questionable, that impulse to take the law into his own hands was far from unique. In "The Nemean Lion", he sided with the criminal, Miss Amy Carnaby, and saved her from having to face justice by blackmailing his client Sir Joseph Hoggins, who himself was plotting murder and was unwise enough to let Poirot discover this. Poirot even sent Miss Carnaby two hundred pounds as a final payoff before her dog kidnapping campaign came to an end. In The Murder of Roger Ackroyd he allowed the murderer to escape justice through suicide and then ensured the truth was never known to spare the feelings of the murderer's relatives. In "The Augean Stables" he helped the government to cover up vast corruption, even though it might be considered more honest to let the truth come out.
After his cases in the Middle East, Poirot returned to Britain. Apart from some of the so-called "Labours of Hercules" (see next section) he very rarely traveled abroad during his later career.
There is a great deal of confusion about Poirot's retirement. Most of the cases covered by Poirot's private detective agency take place before his retirement to grow marrows, at which time he solves The Murder of Roger Ackroyd. It has been said that twelve cases related in The Labours of Hercules (1947) must refer to a different retirement, but the fact that Poirot specifically says that he intends to grow marrows indicates that these stories also take place before Roger Ackroyd, and presumably Poirot closed his agency once he had completed them. There is specific mention in "The Capture of Cerberus" to the fact that there has been a gap of twenty years between Poirot's previous meeting with Countess Rossakoff and this one. If the Labours precede the events in Roger Ackroyd, then the Roger Ackroyd case must have taken place around twenty years later than it was published, and so must any of the cases that refer to it. One alternative would be that having failed to grow marrows once, Poirot is determined to have another go, but this is specifically denied by Poirot himself. Another alternative would be to suggest that the Preface to the Labours takes place at one date but that the labours are completed over a matter of twenty years. None of the explanations is especially attractive.
In terms of a rudimentary chronology, Poirot speaks of retiring to grow marrows in Chapter 18 of The Big Four (1927), which places that novel out of published order before Roger Ackroyd. He declines to solve a case for the Home Secretary because he is retired in Chapter One of Peril at End House (1932). He is certainly retired at the time of Three Act Tragedy (1935) but he does not enjoy his retirement and comes repeatedly out of it thereafter when his curiosity is engaged. Nevertheless, he continues to employ his secretary, Miss Lemon, at the time of the cases retold in Hickory Dickory Dock and "Dead Man's Folly", which take place in the mid-1950s. It is therefore better to assume that Christie provided no authoritative chronology for Poirot's retirement, but assumed that he could either be an active detective, a consulting detective or a retired detective as the needs of the immediate case required.
Poirot is less active during the cases that take place at the end of his career. Beginning with Three Act Tragedy (1934), Christie had perfected during the inter-war years a sub-genre of Poirot novel in which the detective himself spent much of the first third of the novel on the periphery of events. In novels such as Taken at the Flood, After the Funeral and Hickory Dickory Dock he is even less in evidence, frequently passing the duties of main interviewing detective to a subsidiary character. In Cat Among the Pigeons" Poirot's entrance is so late as to be almost an afterthought. Whether this was a reflection of his age or of the fact that Christie was by now heartily sick of him it is difficult to assess. There is certainly a case for saying that Crooked House (1949) and Ordeal by Innocence (1957), which are not Poirot novels at all but so easily could have been, represent a logical endpoint of the general diminution of Poirot himself within the Poirot sequence.
Towards the end of his career it becomes clear that Poirot's retirement is no longer a convenient fiction. He assumes a genuinely inactive lifestyle during which he concerns himself with studying famous unsolved cases of the past and reading detective novels. He even writes a book about mystery fiction in which he deals sternly with Edgar Allan Poe and Wilkie Collins. In the absence of a more appropriate puzzle, he solves such inconsequential domestic problems as the presence of three pieces of orange peel in his umbrella stand.
Poirot (and, it is reasonable to suppose, his creator) becomes increasingly bemused by the vulgarism of the up and coming generation's young people. In Hickory Dickory Dock, he investigates the strange goings on in a student hostel, while in the Third Girl he is forced into contact with the smart set of Chelsea youths. In the growing drug and pop culture of the sixties, he proves himself once again, but has become heavily reliant on other investigators (especially the private investigator, Mr. Goby) who provide him with the clues that he can no longer gather for himself.
Poirot dies from complications of a heart condition at the end of "Curtain: Poirot's Last Case. At this point in his life he is suffering from arthritis and uses a wheelchair.
In the book Curtain: Poirot's Last Case Hastings finds a manuscript written by Poirot in which Poirot confesses to murder. He also states that since he has become something that he had always abhorred he stops taking his heart medication, which subsequently causes his death. His implicit last wish is that Hastings should marry Elizabeth Cole: a final instance of the inveterate matchmaking that characterised his entire career.
The Poirot books take readers through the whole of his life in England, from the first book (The Mysterious Affair at Styles), where he is a refugee staying at Styles, to the last Poirot book (Curtain), where he visits Styles once again before his death. In between, Poirot solves cases outside England as well, including his most famous case, Murder on the Orient Express (1934).
Hercule Poirot became famous with the publication, in 1926, of The Murder of Roger Ackroyd, whose surprising solution proved controversial. The novel is still among the most famous of all detective novels: Edmund Wilson alludes to it in the title of his well-known attack on detective fiction, "Who Cares Who Killed Roger Ackroyd?" Aside from Roger Ackroyd, the most critically-acclaimed Poirot novels appeared from 1932 to 1942, including such acknowledged classics as Murder on the Orient Express, The ABC Murders (1935), Cards on the Table (1936), and Death on the Nile (1937). The last of these, a tale of multiple homicide upon a Nile steamer, was judged by the celebrated detective novelist John Dickson Carr to be among the ten greatest mystery novels of all time.
The 1942 novel Five Little Pigs (aka Murder in Retrospect), in which Poirot investigates a murder committed sixteen years before by analyzing various accounts of the tragedy, is a Rashomon-like performance that critic and mystery novelist Robert Barnard called the best of the Christie novels.
For a list of novels and short stories featuring Hercule Poirot, please see Hercule Poirot in Literature.
Austin Trevor debuted the role of Poirot on film in the 1931 movie Alibi. The film was based on the stage play Alibi which had been adapted by Michael Morton from the novel The Murder of Roger Ackroyd.
Trevor reprised the role of Poirot twice, in Black Coffee and Lord Edgware Dies. Trevor said once that he was probably cast as Poirot simply because he could do a French accent.
Albert Finney played Poirot in 1974 in the cinematic version of Murder on the Orient Express. His portrayal was considered by many to be the definitive Poirot until David Suchet took up the role. It was a very faithful adaptation of the novel and was, at the time, the most successful British film ever made. It received the stamp of approval from Agatha Christie herself. Finney is, so far, the only actor to receive an Academy Award nomination for playing Poirot, though he did not win.
Peter Ustinov played Poirot a total of six times, starting with Death on the Nile (1978). He reprised the role in Evil Under the Sun (1982) and Appointment With Death" (1988).
David Suchet has starred in many Hercule Poirot films and four new ones – Cards on the Table, The Mystery of the Blue Train, After the Funeral and Taken At The Flood" – were shown in the UK in March/April 2006. For more information about the ongoing UK television series starring David Suchet, see Agatha Christie's Poirot.
In 2004, NHK (a Japanese TV network) produced a 39 episode anime series titled "Agatha Christie's Great Detectives Poirot and Marple", as well as a manga series under the same title released in 2005.
The series, adapting several of the best-known Poirot and Marple stories, ran from July 4, 2004 through May 15, 2005, and is now being shown as re-runs on NHK and other networks in Japan. Poirot was voiced by Satomi Kōtarō and Miss Marple was voiced by Yachigusa Kaoru.
There have been a number of radio adaptations of the Poirot stories, most recently on BBC Radio 4 (and regularly repeated on BBC 7) starring John Moffatt.
Poirot was also parodied in The Goodies episode Daylight Robbery on the Orient Express.
The British television show Count Duckula features a parody of Hercule Poirot (in passing) known as Mr. Hercules Parrot, arm in arm with a character called Miss Marbles.
Although not strictly a reference to Poirot, the new series Christé and Doyle will feature a lead role similar to that of Hercule Poirot. With the name of the character being similar to that of Poirot's creator Agatha Christie and his being half Belgian, Christé also shares many of Poirot's methods and characteristics, the series is expected to begin filming in the late summer in Sandhurst.
An episode of Animaniacs featured Yakko Warner as "Hercule Yakko." The episode involved the theft of a diamond on a train, involving much of the series' cast as suspects.
In the movie Spiceworld, Hercule Poirot (Hugh Laurie) is about to blame a weapons-packing Emma Bunton, but after she flashes him an innocent smile, Poirot instead accuses an innocent man of the crime.
In Sherlock Holmes: The Awakened, Poirot appears as a young boy on the train transporting Holmes and Watson. Holmes helps the boy in opening a puzzle-box, with Watson giving the boy advice about using his "little grey cells", giving the impression that Poirot first heard the line here. Poirot would go on to use the "little grey cells" line countless times throughout Agatha Christie's fiction.
In an episode of Muppets Tonight, Jason Alexander played Hercule Poirot, believed by the Muppets to be Hercules Poirot, with superhuman powers.
The Belgian brewery Brasserie Ellezelloise makes a highly rated stout called Hercule with a moustachioed charicature of Hercule Poirot on the label.
Dave Stone has created two parodies of Poirot named Dupont. The first, Andre Dupont, appears in the Detective-Judge Armitage story Dowager Duchess of Ghent. The second, Emile Dupont, appears in the Bernice Summerfield novel Ship of Fools.
The "decipherer of enigmas" in José Carlos Somoza's novel The Athenian Murders is named Herakles Pontor.
In the English version of Geronimo Stilton series, the main protagonist has a friend named "Hercule Poirat".
In the anime and manga series Case Closed, Richard Moore's detective agency is located above the Poirot cafè.


Jane Marple, usually known as Miss Marple, is a fictional character appearing in twelve of Agatha Christie's crime novels. Miss Marple is an elderly spinster who acts as an amateur detective, and lives in the village of St. Mary Mead. She has been portrayed numerous times on screen, and is one of the most famous of Christie's creations. Her first published appearance was in issue 350 of The Royal Magazine for December 1927 with the first printing of the short story "The Tuesday Night Club" which later became the first chapter of The Thirteen Problems (1932). Her first appearance in a full-length novel was in The Murder at the Vicarage in 1930.
Miss Jane Marple is an elderly woman who lives in the little English village of St. Mary Mead. She looks like an ordinary old lady, dressed neatly in tweed and is frequently seen knitting or pulling weeds in her garden. Miss Marple sometimes comes across as confused or "fluffy", but when it comes to solving mysteries, she has a sharp logical mind. In the detective story tradition, she often embarrasses the local "professional" police by solving mysteries that have them stumped.
The name Miss Marple was derived from the name of the railway station in Marple, on the Manchester to Sheffield Hope Valley line, at which Agatha Christie was once delayed long enough to have actually noticed the sign.
The character of Jane Marple in the first Miss Marple book, The Murder at the Vicarage, is markedly different from how she appears in later books. This early version of Miss Marple is a gleeful gossip and not an especially nice woman. The citizens of St. Mary Mead like her but are often tired by her nosy nature and how she seems to expect the worst of everyone. In later books she becomes more modern and a kinder person.
Miss Marple never married and has no close living relatives. Vicarage introduced Miss Marple's nephew, the "well-known author" Raymond West. His wife Joan (initially called Joyce), a modern artist, was introduced in 1933 in The Thirteen Problems. Raymond tends to be overconfident in himself and underestimates Miss Marple's mental powers. In her later years, Miss Marple has a live-in companion named Cherry Baker, who was first introduced in "The Mirror Crack'd From Side To Side'.
Miss Marple is able to solve difficult crimes not only because of her shrewd intelligence, but because St. Mary Mead, over her lifetime, has given her seemingly infinite examples of the negative side of human nature. No crime can arise without reminding Miss Marple of some parallel incident in the history of her time. Miss Marple's acquaintances are sometimes bored by her frequent analogies to people and events from St. Mary Mead, but these analogies often lead Miss Marple to a deeper realization about the true nature of a crime.
Miss Marple also had a remarkably thorough education, including some art courses that involved study of human anatomy through the study of human cadavers. Although she looks like a sweet, frail old woman, Miss Marple is not afraid of dead bodies and is not easily intimidated. She also has a remarkable ability to latch onto a casual comment and connect it to the case at hand.
This education, history, and experience are hinted at in the Margaret Rutherford films, in which Miss Marple mentions her awards at marksmanship and fencing (although these hints are played for comedic value).
Christie wrote a concluding novel to her Marple series, Sleeping Murder, in 1940. She locked it away in a bank vault so it would be safe if she was killed in The Blitz. The novel was not published until shortly after Christie's death in 1976, some thirty-six years after it was originally written. Sleeping Murder created some discrepancies in the timeline of the series, as characters who were killed off by Christie in previously published novels reappeared alive.
While Miss Marple is described as 'an old lady' in many of the stories, her age is never mentioned. About thirty years pass between her first and last mysteries and many characters grow and age. An example would be the Vicar's son. In a Murder at the Vicarage, the Vicar's wife if pregnant. In "The Mirror Crack'd from Side to Side, about twenty years later, it is mentioned that the son is now grown, successful and has a career. The effects of aging are seen on Miss Marple, such as needing vacation after illness in A Caribbean Mystery or finding she can no longer knit due to poor eyesight in The Mirror Crack'd from Side to Side". It would be safe to assume that Miss Marple was only about fifty or sixty in A Murder at the Vicarage, which would not be old by modern standards but would have been considered elderly in the 1930's. This would make Miss Marple about eighty or ninety in her final mysteries.
Miss Marple also appears in "Greenshaw's Folly", a short story traditionally included as part of the Poirot collection The Adventure of the Christmas Pudding (1960). Four stories in the Three Blind Mice collection (1950) feature Miss Marple: "Strange Jest", "Tape-Measure Murder", "The Case of the Caretaker", and "The Case of the Perfect Maid".
Although popular from her first appearance in 1930, Jane Marple had to wait thirty-two years for her first big-screen appearance. When she made it, the results were found disappointing to Christie purists and Christie herself. Murder, She Said (1962, directed by George Pollock) was the first of four British MGM productions starring Dame Margaret Rutherford, a magnificent comic actress but too boisterous and loud to fit the prim and birdlike character Christie created in her novels. This first film was based on the 1957 novel 4:50 from Paddington (U.S. title, What Mrs. McGillicuddy Saw!), and the changes made in the plot were typical of the series. In the film, Mrs. McGillicuddy does not see anything because there is no Mrs. McGillicuddy. Miss Marple herself sees an apparent murder committed on a train running alongside hers. Likewise, it is Miss Marple herself who poses as a maid to find out the facts of the case, not a young friend of hers who has made a business of it.
The other Rutherford films (all directed by George Pollock) were Murder at the Gallop (1963), based on the 1953 Hercule Poirot novel After the Funeral; Murder Most Foul (1964), based on the 1952 Poirot novel "Mrs McGinty's Dead; and Murder Ahoy! (1964), not based on any Christie work. Rutherford also appeared briefly as Miss Marple in the spoof Hercule Poirot adventure The Alphabet Murders" (1965).
The Rutherford films are frequently repeated on television in Germany, and in that country Miss Marple is generally identified with Rutherford's quirky portrayal.
In 1980, Angela Lansbury played Miss Marple in "The Mirror Crack'd" (EMI, directed by Guy Hamilton), based on Christie's 1962 novel. However, Lansbury is only on screen for a short time, the bulk of the film being taken up with the machinations of an all-star cast that included Elizabeth Taylor, Rock Hudson, Geraldine Chaplin, Tony Curtis, and Kim Novak. Edward Fox appeared as Inspector Craddock, who did Miss Marple's legwork.
In 1983, Estonian stage and film actress Ita Ever starred in the Russian language film adaptation of Agatha Christie's novel A Pocket Full of Rye (using the Russian edition's translated title, The Secret of the Blackbirds) as the character of Miss Marple.
American stage and screen legend Helen Hayes portrayed Miss Marple in two American made-for-TV movies, both for CBS: A Caribbean Mystery (1983) and Murder with Mirrors (1984). Sue Grafton contributed to the screenplay of the former. Hayes's Marple was benign and chirpy.
American TV was the setting for the first dramatic portrayal of Miss Marple. Gracie Fields, a legendary British actress, played her in a 1956 episode of Goodyear TV Playhouse based on A Murder Is Announced, the 1950 Christie novel.
In 1970, the character of Miss Marple was portrayed by Inge Langen in a West German television adaptation of The Murder at the Vicarage (Mord im Pfarrhaus).
From 1984 to 1992, the BBC adapted all of the original Miss Marple novels as a series titled Miss Marple. Joan Hickson played the lead role. (Coincidentally, Hickson had played a cook in the first film in which Margaret Rutherford played Miss Marple.) These programs, which are actually a set of 12 feature-length TV movies rather than a TV series in the usual sense, followed the plots of the original novels more closely than previous film and television adaptations had, and Joan Hickson has come to be regarded by many as the definitive Miss Marple (indeed Agatha Christie herself once remarked years earlier that she would like Joan Hickson to play Miss Marple).
Angela Lansbury, after playing Miss Marple in "The Mirror Crack'd, went on to star in the TV series Murder, She Wrote" as Jessica Fletcher, a mystery novelist who also solves crimes. The character was based in part on Miss Marple and another Christie character, Ariadne Oliver.
In 2004, ITV first broadcast new adaptations of Agatha Christie's books under the title "Agatha Christie's Marple, usually referred to as Marple, with Geraldine McEwan in the lead role until her retirement after the third series. She will be replaced with actress Julia McKenzie. The series is infamous for its frequent plot and character changes (such as incorporating lesbian affairs, changing killer identities, and re-naming or removing a number of characters). Two series have so far aired, with a third still having to finish airing in the UK.
From 2004 to 2005, Japanese TV network NHK produced a 39 episode anime series titled Agatha Christie's Great Detectives Poirot and Marple", which features both Miss Marple and Hercule Poirot.
BBC Radio 4 dramatised all of the novels from 1993-2001 with June Whitfield as Miss Marple.


April is the fourth month of the year in the Gregorian Calendar, and one of four months with the maximum length of 30 days. April was originally the second month of the Roman calendar, before January and February were added by King Numa Pompilius about 700 BC. It became the fourth month of the calendar year (the year when twelve months are displayed in order) during the time of the decemvirs about 450 BC, when it also was given 29 days. The Julian calendar reform of 46 BC gave April 30 days, effective in 45 BC.
The derivation of the name (Latin Aprilis) is uncertain. The traditional etymology from the Latin aperire, "to open," in allusion to its being the season when trees and flowers begin to "open," is supported by comparison with the modern Greek use of ἁνοιξις (opening) for spring. Since most of the Roman months were named in honor of divinities, and as April was sacred to Venus, the Festum Veneris et Fortunae Virilis being held on the first day, it has been suggested that Aprilis was originally her month Aphrilis, from her Greek name Aphrodite (Aphros), or from the Etruscan name Apru. Jacob Grimm suggests the name of a hypothetical god or hero, Aper or Aprus.
The Anglo-Saxons called April Oster-monath or Eostur-monath, the period sacred to Eostre or Ostara, the pagan Saxon goddess of spring, from whose name is derived the modern Easter. St George's day is the twenty-third of the month; and St Mark's Eve, with its superstition that the ghosts of those who are doomed to die within the year will be seen to pass into the church, falls on the twenty-fourth. In China the symbolical ploughing of the earth by the emperor and princes of the blood takes place in their third month, which frequently corresponds to our April; and in Japan the feast of Dolls is celebrated in the same month. April is known to be "National Poetry Month" The Finnish called this month Huhtikuu, or 'Burnwood Month', when the wood for beat and burn clearing of farmland was felled.
The month of April begins (astrologically) with the sun in the sign of Aries and ends in the sign of Taurus. Astronomically speaking, the sun begins in the constellation of Pisces and ends in the constellation of Aries. The signs of the zodiac do not necessarily coincide with the actual constellations for which they are named. The precession of the equinoxes, a phenomenon discovered c. 130 BC by Hipparchus and known to Ptolemy, results in a shift between the two systems of about one degree every 70 years. The vernal equinox lay near the beginning of the Aries constellation around 500 BC, consistent with a Babylonian origin of the system.
The "days of April" ("journées d'avril) is a name appropriated in French history to a series of insurrections at Lyons, Paris and elsewhere, against the government of Louis Philippe in 1834, which led to violent repressive measures, and to a famous trial known as the procès d'avrill.
The birthstone of April is the diamond. In The Wasteland", T. S. Eliot called April "the cruellest month".


August is the eighth month of the year in the Gregorian Calendar and one of seven Gregorian months with the length of 31 days. August begins (astrologically) with the sun in the sign of Leo and ends in the sign of Virgo. Astronomically speaking, the sun begins in the constellation of Cancer and ends in the constellation of Leo.
This month was originally named Sextilis in Latin, because it was the sixth month in the ancient Roman calendar, which started in March about 750 BC under Romulus. It became the eighth month either when January and February were added to the beginning of the year by King Numa Pompilius about 700 BC or when those two months were moved from the end to the beginning of the year by the decemvirs about 450 BC (Roman writers disagree). It was renamed in honor of Augustus in 8 BC because several of the most significant events in his rise to power, culminating in the fall of Alexandria, which fell in this month. August originally had 29 days in the Roman Republican calendar, but two days were added to it by Augustus beginning 45 BC giving it its modern total of 31 days. Augustus did not take a day from February when Sextilis was renamed in his honor. See Month lengths. August's flower is the gladiolus or poppy, and its birthstone is the peridot.


Aaron’s function included the duties of speaker and implied personal dealings with the Egyptian royal court on behalf of Moses, who was always the central moving figure. The part played by Aaron in the events that preceded the Exodus was, therefore, ministerial, and not directive. He, along with Moses, performed "signs" before his people which impressed them with a belief in the reality of the divine mission of the brothers. Exodus 4:15-16.
At the time when the tribe of Levi was set apart for the priestly service, Aaron was anointed and consecrated to the priesthood, arrayed in the robes of his office, and instructed in its manifold duties Exodus 28 KJV, and Exodus 29 KJV.
All scholars admit that in Aaron's High Priesthood the sacred writer intended to describe a model, the prototype, so to say, of the Jewish High Priest, "phod". God, on Mount Sinai instituting a worship, and also instituted an order of priests.
According to the patriarchal customs, the First Born son in every family used to perform the functions connected with God's worship, "phod". It might have been expected, consequently, that Rueben's family would be chosen by God for the ministry of the new altar. However, according to the biblical narrative, it was Aaron, however, who was the object of God's choice. To what jealousies this gave rise later, has been indicated above. The office of the Aaronites was at first merely to take care of the lamp that should ever burn before the veil of the tabernacle Exodus 27:21. A more formal calling soon followed (Exodus 28:1). Aaron and his sons, distinguished from the Common People by their sacred functions, were likewise to receive holy vestments suitable to their office.
Aaron offered the different sacrifices and performed the many ceremonies of the consecration of the new priests, according to the divine instructions (Exodus 29), and repeated these rites for seven days, during which Aaron and his sons were entirely separated from the rest of the people. When, on the eighth day, the High Priest had inaugurated his office of sacrifice by killing the animals, he blessed the people, very likely according to the prescriptions of Num. vi, 24-26, and, with Moses, entered into the tabernacle so as to take possession thereof. As they "came forth and blessed the people. And the glory of the Lord appeared to all the multitude: And behold a fire, coming forth from the Lord, devoured the holocaust, and the fat that was upon the altar: which when the multitude saw, they praised the Lord, falling on their faces" (Leviticus 9:23, 24). So was the institution of the Aaronic priesthood inaugurated and solemnly ratified by the Lord.
From the time of the sojourn at Mount Sinai, where he became the anointed priest of Israel, Aaron ceased to be the minister of Moses, his place being taken by Joshua. He is mentioned in association with Miriam in a jealous complaint against the exclusive claims of Moses as the Lord’s prophet. The presumption of the murmurers was rebuked, and Miriam was smitten with tzara'as. Aaron entreated Moses to intercede for her, at the same time confessing the sin and folly that prompted the uprising. Aaron himself was not struck with the plague on account of sacerdotal immunity; and Miriam, after seven days’ quarantine, was healed and restored to favor Numbers 12, Micah (6:4) a prophet in Judaism, mentions Moses, Aaron, and Miriam as the leaders of Israel after the Exodus (a judgment wholly in accord with the tenor of the narratives). In the present instance it is made clear by the express words of the oracle Numbers 12:6-8 that Moses was unique among men as the one with whom the Lord spoke face to face. The failure to recognize or concede this prerogative of their brother was the sin of Miriam and Aaron.
The validity of the exclusive priesthood of the family of Aaron was attested after the ill-fated rebellion of Korah, who was a first cousin of Aaron. When the earth had opened and swallowed up the leaders of the insurgents Numbers 16:25-35. Eleazar, the son of Aaron, was commissioned to take charge of the censers of the dead priests. And when the plague had broken out among the people who had sympathized with the rebels, Aaron, at the command of Moses, took his censer and stood between the living and the dead till the plague was stayed Numbers 17:1-15, 16:36-50.
Another memorable transaction followed. Each of the tribal princes of Israel took a rod and wrote his name upon it, and the twelve rods were laid up over night in the tent of meeting. On the morrow Aaron’s rod was found to have budded and blossomed and borne ripe almonds Numbers 17:8. The miracle proved merely the prerogative of the tribe of Levi; but now a formal distinction was made in perpetuity between the family of Aaron and the other Levites. While all the Levites (and only Levites) were to be devoted to sacred services, the special charge of the sanctuary and the altar was committed to the Aaronites alone. The scene of this enactment is unknown, nor is the time mentioned.
Aaron, like Moses, was not permitted to enter Canaan with the others. The reason alleged is that the two brothers showed impatience at Meribah (Kadesh) in the last year of the desert pilgrimage (Num. xx. 12, 13), when they, or rather Moses, brought water out of a rock to quench the thirst of the people. The action was construed as displaying a want of deference to the Lord, since they had been commanded to speak to the rock, whereas Moses struck it with the wonder-working rod (Num. xx. 7-11). Of the death of Aaron we have two accounts. The principal one gives a detailed statement to the effect that, soon after the above incident, Aaron, with his son Eleazar and Moses, ascended Mount Hor. There Moses stripped him (Aaron) of his priestly garments, and transferred them to Eleazar. Aaron died on the summit of the mountain, and the people mourned for him thirty days (Num. xx. 22-29; compare xxxiii. 38, 39). The other account is found in Deut. x. 6, where Moses is reported as saying that Aaron died at Mosera and was buried there. Mosera is not on Mount Hor, since the itinerary in Num. xxxiii. 31-37 records seven stages between Moseroth (Mosera) and Mount Hor.
The older prophets and prophetical writers beheld in their priests the representatives of a religious form inferior to the prophetic truth; men without the spirit of God and lacking the will-power requisite to resist the multitude in its idolatrous proclivities. Thus Aaron, the typical priest, ranks far below Moses: he is but his mouthpiece, and the executor of the will of God revealed through Moses, although it is pointed out that it is said fifteen times in the Pentateuch that "the Lord spoke to Moses and Aaron." Under the influence of the priesthood which shaped the destinies of the nation under Persian rule, a different ideal of the priest was formed, as is learned from Malachi 2:4-7; and the prevailing tendency was to place Aaron on a footing equal with Moses. "At times Aaron, and at other times Moses, is mentioned first in Scripture—this is to show that they were of equal rank," says Mekilta בא, 1; expressly infers this when introducing in his record of renowned men the glowing description of Aaron’s ministration.
The rabbis also dwell with special laudation on the brotherly sentiment which united Aaron and Moses. When the latter was appointed ruler and Aaron high priest, neither betrayed any jealousy; instead they rejoiced in one another's greatness. When Moses at first declined to go to Pharaoh, saying: "O my Lord, send, I pray thee, by the hand of him whom thou wilt send" (Exodus iv. 13), he was unwilling to deprive Aaron, his brother, of the high position the latter had held for so many years; but the Lord reassured him, saying: "Behold, when he seeth thee, he will be glad in his heart" (). Indeed, Aaron was to find his reward, says Simon bar Yochai; for that heart which had leaped with joy over his younger brother's rise to glory greater than his was decorated with the Urim and Thummim, which were to "be upon Aaron's heart when he goeth in before the Lord" (Canticles Rabbah i. 10). Moses and Aaron met in gladness of heart, kissing each other as true brothers (Ex. iv. 27; compare Song of Songs, viii. 1), and of them it is written: "Behold how good and how pleasant [it is] for brethren to dwell together in unity!" (Ps. cxxxiii. 1). Of them it is said (Ps. lxxxv. 10): "Mercy and truth are met together; righteousness and peace have kissed [each other]"; for Moses stood for righteousness, according to Deuteronomy xxxiii. 21, and Aaron for peace, according to. Again, mercy was personified in Aaron, according to Deuteronomy xxxiii. 8, and truth in Moses, according to Numbers xii. 7.
When Moses poured the oil of anointment upon the head of Aaron, Aaron modestly shrank back and said: "Who knows whether I have not cast some blemish upon this sacred oil so as to forfeit this high office." Then the Shekhinah spake the words: "Behold the precious ointment upon the head, that ran down upon the beard of Aaron, that even went down to the skirts of his garment, is as pure as the dew of Hermon" ().
Recently, the tradition that Kohanim are actually descended from a single patriarch Aaron was found to be apparently consistent with genetic testing. Since all direct male lineage shares a common Y chromosome, testing was done across sectors of the Jewish population to see if there was any commonality between their Y chromosomes. Many of the results were found to cluster rather closely around a particular DNA signature, which the researchers named the Cohen modal haplotype, implying that many of the Kohanim do share a distinctive common ancestry. This information was also used (perhaps prematurely) to support the claim of the Lemba (a sub-Saharan tribe) that they were in fact, a tribe of Jews.
The sons of Aaron were Eleazar, Ithamar, Nadab and Abihu. A priestly descendant of Aaron is an Aaronite or Cohen. A Levite is a non-Aaronic descendant of Levi assigned to assist the Levitical priests of the family of Aaron in the care of the tabernacle and later of the temple.
Aaron is considered a type of Christ, the high priest of the new dispensation. In the Eastern Orthodox Church and the Maronite Church he is commemorated on September 4 with Moses. He is commemorated as one of the Holy Forefathers in the Calendar of Saints of the Armenian Apostolic Church on July 30.
In the LDS church, the Aaronic order is the lesser order of priesthood, comprising the grades (from lowest to highest) of deacon, teacher and priest. The chief office of the Aaronic priesthood is the presiding bishopric; the head of the priesthood is the bishop. Each ward has one or more quorums of each office of the Aaronic priesthood.
Aaron is believed to be a Prophet in Islam and is known as Harun, which is the Arabic name for Aaron. His role also found an analogue in the person of Ali, to whom Muhammad said: Will you not be pleased that you will be to me like Aaron was to Moses?
A significant difference in the Quran is the fact that Aaron was not involved with the creation of the Golden Calf, but did not prevent it as he feared for his life at the hands of the idol-makers.






The Feast of St. Basil the Confessor in the Greek Orthodox Church.










In chemistry, an alcohol is any organic compound in which a hydroxyl group (-OH) is bound to a carbon atom of an alkyl or substituted alkyl group. The general formula for a simple acyclic alcohol is CnH2n+1OH.
In layman's terms, the word alcohol (, "al-kuḥl") usually refers to ethanol, also known as grain alcohol or (older) spirits of wine, or to any alcoholic beverage. Ethanol is a colorless, volatile liquid with a mild odor which can be obtained by the fermentation of sugars. (Industrially, it is more commonly obtained by ethylene hydration — the reaction of ethylene with water in the presence of phosphoric acid.) Ethanol is the most widely used depressant in the world, and has been for thousands of years. This sense underlies the term alcoholism (addiction to alcohol).
Other alcohols are usually described with a clarifying adjective, as in isopropyl alcohol (propan-2-ol) or wood alcohol (methyl alcohol, or methanol). The suffix -ol appears in the "official" IUPAC chemical name of all alcohols.
There are three major subsets of alcohols: primary (1°), secondary (2°) and tertiary (3°), based upon the number of carbon atoms the C-OH group's carbon (shown in red) is bonded to. Ethanol is a simple 'primary' alcohol. The simplest secondary alcohol is isopropyl alcohol (propan-2-ol), and a simple tertiary alcohol is tert-butyl alcohol (2-methylpropan-2-ol).
The phenols with parent compound phenol have a hydroxyl group (attached to a benzene ring) just like alcohols, but differ sufficiently in properties as to warrant a separate treatment.
Carbohydrates (sugars) and sugar alcohols are an important class of compounds containing multiple alcohol functional groups. For example, sucrose (common sugar) contains eight hydroxyl groups per molecule and sorbitol has six. Most of the attributes of these polyols, from nomenclature, to occurrence, use and toxicity, are sufficiently different from simple aliphatic alcohols as to require a separate treatment.
The simplest and most commonly used alcohols are methanol and ethanol. Methanol was formerly obtained by the distillation of wood and called "wood alcohol." It is now a cheap commodity, the chemical product of carbon monoxide reacting with hydrogen under high pressure. Methanol is intoxicating but not directly poisonous. It is toxic by its breakdown (toxication) by the enzyme alcohol dehydrogenase in the liver by forming formic acid and formaldehyde which cause permanent blindness by destruction of the optic nerve.
Apart from its familiar role in alcoholic beverages, ethanol is also used as a highly controlled industrial solvent and raw material. To avoid the high taxes on ethanol for consumption, additives are added to make it unpalatable (such as denatonium benzoate — "Bitrex") or poisonous (such as methanol). Ethanol in this form is known generally as denatured alcohol; when methanol is used, it may be referred to as methylated spirits ("Meths") or "surgical spirits".
In the IUPAC system, the name of the alkane chain loses the terminal "e" and adds "ol", e.g. "methanol" and "ethanol". When necessary, the position of the hydroxyl group is indicated by a number between the alkane name and the "ol": propan-1-ol for CH3CH2CH2OH, propan-2-ol for CH3CH(OH)CH3. Sometimes, the position number is written before the IUPAC name: 1-propanol and 2-propanol. If a higher priority group is present (such as an aldehyde, ketone or carboxylic acid), then it is necessary to use the prefix "hydroxy", for example: 1-hydroxy-2-propanone (CH3COCH2OH).
Common names for alcohols usually takes name of the corresponding alkyl group and add the word "alcohol", e.g. methyl alcohol, ethyl alcohol or tert-butyl alcohol. Propyl alcohol may be n-propyl alcohol or isopropyl alcohol depending on whether the hydroxyl group is bonded to the 1st or 2nd carbon on the propane chain. Isopropyl alcohol is also occasionally called sec-propyl alcohol.
As mentioned above alcohols are classified as primary (1°), secondary (2°) or tertiary (3°), and common names often indicate this in the alkyl group prefix. For example (CH3)3COH is a tertiary alcohol is commonly known as tert-butyl alcohol. This would be named 2-methylpropan-2-ol under IUPAC rules, indicating a propane chain with methyl and hydroxyl groups both attached to the middle (#2) carbon.
The introduction of the word to European terminology in alchemy dates to the 12th century, by Latin translations of works of Rhazes (865-925), who described the art of distillation.
The word's meaning became restricted to "spirit of wine" (ethanol) in the 18th century, and was again extended to the family of substances so called in modern chemistry from 1850.
The current Arabic name for alcohol is الكحول al-kuḥūl, re-introduced from western usage, while the Classical Arabic word is الغول al-ġawl (e.g. sura 37:47), literally "spirit" (the word al-ġawl is also the origin of the English word "ghoul", and the name of the star Algol).
The hydroxyl group generally makes the alcohol molecule polar. Those groups can form hydrogen bonds to one another and to other compounds. This hydrogen bonding means that alcohols can be used as protic solvents. Two opposing solubility trends in alcohols are: the tendency of the polar OH to promote solubility in water, and of the carbon chain to resist it. Thus, methanol, ethanol, and propanol are miscible in water because the hydroxyl group wins out over the short carbon chain. Butanol, with a four-carbon chain, is moderately soluble because of a balance between the two trends. Alcohols of five or more carbons (Pentanol and higher) are effectively insoluble in water because of the hydrocarbon chain's dominance. All simple alcohols are miscible in organic solvents.
Because of hydrogen bonding, alcohols tend to have higher boiling points than comparable hydrocarbons and ethers. The boiling point of the alcohol ethanol is 78.29 °C, compared to 69 °C for the hydrocarbon Hexane (a common constituent of gasoline), and 34.6 °C for Diethyl ether.
Alcohols, like water, can show either acidic or basic properties at the O-H group. With a pKa of around 16-19 they are generally slightly weaker acids than water, but they are still able to react with strong bases such as sodium hydride or reactive metals such as sodium. The salts that result are called alkoxides, with the general formula RO- M+.
Alcohols can also undergo oxidation to give aldehydes, ketones or carboxylic acids, or they can be dehydrated to alkenes. They can react to form ester compounds, and they can (if activated first) undergo nucleophilic substitution reactions. The lone pairs of electrons on the oxygen of the hydroxyl group also makes alcohols nucleophiles. For more details see the reactions of alcohols section below.
Alcohols can be used as a beverage (ethanol only), as fuel and for many scientific, medical, and industrial utilities. Ethanol in the form of alcoholic beverages has been consumed by humans since pre-historic times. A 50% v/v solution of ethylene glycol in water is commonly used as an antifreeze.
Some alcohols, mainly ethanol and methanol, can be used as an Alcohol fuel. Fuel performance can be increased in forced induction internal combustion engines by injecting alcohol into the air intake after the turbocharger or supercharger has pressurized the air. This cools the pressurized air, providing a denser air charge, which allows for more fuel, and therefore more power.
Alcohols have applications in industry and science as reagents or solvents. Because of its low toxicity and ability to dissolve non-polar substances, ethanol can be used as a solvent in medical drugs, perfumes, and vegetable essences such as vanilla. In organic synthesis, alcohols serve as versatile intermediates.
Ethanol can be used as an antiseptic to disinfect the skin before injections are given, often along with iodine. Ethanol-based soaps are becoming common in restaurants and are convenient because they do not require drying due to the volatility of the compound. Alcohol is also used as a preservative for specimens.
It is inevitable that all humans always have some amount of alcohol in their bodies at all times, even if they never drink alcoholic beverages in their lives. This is because of a process called endogenous ethanol production. Many of the bacteria in the intestines use alcohol fermentation as a form of respiration. This metabolic method produces alcohol as a waste product, in the same way that metabolism results in the formation of carbon dioxide and water. Thus, human bodies always contain some quantity of alcohol produced by these benign bacteria.
Several methods exist for the preparation of alcohols in the laboratory.
Alcohols can behave as weak acids, undergoing deprotonation. The deprotonation reaction to produce an alkoxide salt is either performed with a strong base such as sodium hydride or n-butyllithium, or with sodium or potassium metal.
It should be noted, though, that the bases used to deprotonate alcohols are strong themselves. The bases used and the alkoxides created are both highly moisture sensitive chemical reagents.
The acidity of alcohols is also affected by the overall stability of the alkoxide ion. Electron-withdrawing groups attached to the carbon containing the hydroxyl group will serve to stabilize the alkoxide when formed, thus resulting in greater acidity. On the other hand, the presence of electron-donating group will result in a less stable alkoxide ion formed. This will result in a scenario whereby the unstable alkoxide ion formed will tend to accept a proton to reform the original alcohol.
With alkyl halides alkoxides give rise to ethers in the Williamson ether synthesis.
In the Barton-McCombie deoxygenation an alcohol is deoxygenated to an alkane with tributyltin hydride or a trimethylborane-water complex in a radical substitution reaction.
Alcohols are themselves nucleophilic, so R−OH2+ can react with ROH to produce ethers and water in a dehydration reaction, although this reaction is rarely used except in the manufacture of diethyl ether.
More useful is the E1 elimination reaction of alcohols to produce alkenes. The reaction generally obeys Zaitsev's Rule, which states that the most stable (usually the most substituted) alkene is formed. Tertiary alcohols eliminate easily at just above room temperature, but primary alcohols require a higher temperature.
A more controlled elimination reaction is the Chugaev elimination with carbon disulfide and iodomethane.
In order to drive the equilibrium to the right and produce a good yield of ester, water is usually removed, either by an excess of H2SO4 or by using a Dean-Stark apparatus. Esters may also be prepared by reaction of the alcohol with an acid chloride in the presence of a base such as pyridine.
Other types of ester are prepared similarly- for example tosyl (tosylate) esters are made by reaction of the alcohol with p-toluenesulfonyl chloride in pyridine.
Primary alcohols (R-CH2-OH) can be oxidized either to aldehydes (R-CHO) or to carboxylic acids (R-CO2H), while the oxidation of secondary alcohols (R1R²CH-OH) normally terminates at the ketone (R1R²C=O) stage. Tertiary alcohols (R1R²R³C-OH) are resistant to oxidation.
The direct oxidation of primary alcohols to carboxylic acids normally proceeds via the corresponding aldehyde, which is transformed via an aldehyde hydrate (R-CH(OH)2) by reaction with water before it can be further oxidized to the carboxylic acid.
Often it is possible to interrupt the oxidation of a primary alcohol at the aldehyde level by performing the reaction in absence of water, so that no aldehyde hydrate can be formed.
Allylic and benzylic alcohols can be oxidized in presence of other alcohols using certain selective oxidants such as manganese dioxide (MnO2).
Reagents useful for the oxidation of secondary alcohols to ketones, but normally inefficient for oxidation of primary alcohols to aldehydes, include chromium trioxide (CrO3) in a mixture of sulfuric acid and acetone (Jones oxidation) and certain ketones, such as cyclohexanone, in the presence of aluminium isopropoxide (Oppenauer oxidation).
Alcohols possessing two hydroxy groups located on adjacent carbons —that is, 1,2-diols— suffer oxidative breakage at a carbon-carbon bond with some oxidants such as sodium periodate (NaIO4) or lead tetraacetate (Pb(OAc)4), resulting in generation of two carbonyl groups.
Alcohols often have an odor described as 'biting' that 'hangs' in the nasal passages. Ethanol in the form of alcoholic beverages has been consumed by humans since pre-historic times, for a variety of hygienic, dietary, medicinal, religious, and recreational reasons. The consumption of large doses result in drunkenness or intoxication (which may lead to a hangover as the effect wears off) and, depending on the dose and regularity of use, can cause acute respiratory failure or death and with chronic use has medical repercussions. Because alcohol impairs judgment, it can often be a catalyst for reckless or irresponsible behavior. The LD50 of ethanol in rats is 11,300 mg/kg. This ratio would correspond to an () man drinking 65 shots of 80 proof alcohol or 46 half litre bottles of beer with 5% abv, although the LD50 does not translate directly to humans. It is generally agreed that a fatal dose in humans would be about a third that of rats, or about 22 drinks all consumed in one sitting for a () man.
Other alcohols are substantially more poisonous than ethanol, partly because they take much longer to be metabolized, and often their metabolism produces even more toxic substances. Methanol, or wood alcohol, for instance, is oxidized by alcohol dehydrogenase enzymes in the liver to the poisonous formaldehyde, which can cause blindness or death.
An effective treatment to prevent formaldehyde toxicity after methanol ingestion is to administer ethanol. Alcohol dehydrogenase has a higher affinity for ethanol, thus preventing methanol from binding and acting as a substrate. Any remaining methanol will then have time to be excreted through the kidneys. Remaining formaldehyde will be converted to formic acid and excreted.


Achill Island () in County Mayo is the largest island of Ireland, and is situated off the west coast. It has a population of 2,700. Its area is. Achill is attached to the mainland by Michael Davitt Bridge, between the villages of Gob an Choire (Achill Sound) and Poll Raithní (Pollranny), so it is possible to drive onto the island. This is a causeway and swing bridge which allows the passage of small boats. A bridge was first completed here in 1887, and replaced by the current structure in 1949. Other centres of population include the villages of Keel, Dooagh, Dumha Éige(Dooega) and Dugort. The parish's Gaelic football pitch and two secondary schools are on the mainland at Poll Raithní (Polranny). Early settlements are believed to have been established on Achill around 3000 BCE. A paddle dating from this period was found at the crannog near Dookinella.
The island is 87 per cent peat bog. The parish of Achill also includes the Curraun peninsula. The people of Curraun consider themselves Achill people, and most natives of Achill refer to this area as being "in Achill". In the summer of 1996, the RNLI decided to station a lifeboat at Kildownet.
It is believed that at the end of the Neolithic Period (around 4000 BCE), Achill had a population of 500–1,000 people. The island would have been mostly forest until the Neolithic people began crop cultivation. Settlement increased during the Iron Age, and the dispersal of small forts around the coast indicate the warlike nature of the times. Granuaile maintained a castle at Kildownet in the 16th century.
In the 17th and 18th centuries, there was much migration to Achill from other parts of Ireland, particularly Ulster, due to the political and religious turmoil of the time. For a while there were two different dialects of Irish being spoken on Achill. This led to many townlands being recorded as having two names during the 1824 Ordnace Survey, and some maps today give different names for the same place. Achill Irish still has many traces of Ulster Irish.
Despite some unsympathetic development, the island retains some striking natural beauty. The cliffs of Croaghaun on the northern coast of the island are the highest sea cliffs in Europe but are inaccessible by road. On the western tip near Achill Head is Keem Bay. Keel Beach is quite popular with tourists and some locals as a surfing location. Another extreme point of the island is Moytoge Head, which with its rounded appearance drops dramatically down to the ocean. An old British observation post, built during World War I to prevent the Germans from landing arms for the Irish Republican Army, is still standing on Moytoge.
The mountain Slievemore (672 metres) rises dramatically in the centre of the island and the Atlantic drive (along the south/west of the island) has some dramatically beautiful views. On the slopes of Slievemore, there is an abandoned village ("The Deserted Village") The Deserted Village at Slievemore is traditionally thought to be a remnant village from An Gorta Mór (The Great Hunger, see Irish Potato Famine (1845–1849)).
Recent archaeological research suggests the village was occupied year-round at least as early as the 19th century, though it is known to have served as a seasonally occupied booley village by the first half of the 20th century. A booley village is a village occupied only during part of the year, such as a resort community, a lake community, or (as the case on Achill) a place to live while tending flocks or herds of ruminants during winter or summer pasturing. Specifically, the people of Dooagh and Pollagh would migrate in the summer to Slievemore (Transhumance), and then go back to Dooagh in the fall.
Just west of the deserted village is an old Martello tower, again built by the British to warn of any possible French invasion. The area also boasts an approximately 5000-year old Neolithic tomb. Achillbeg (Acaill Beag, Little Achill) is a small island just off Achill's southern tip. Its inhabitants were resettled on Achill in the 1960s.
While a number of attempts at setting up small industrial units on the island have been made, the economy of the island is largely dependent on tourism. Subventions from Achill people working abroad, in particular in England, Scotland and the United States allowed many families to remain living in Achill throughout the 19th and 20th centuries. Since the advent of Ireland's "Celtic Tiger" economy fewer Achill people are forced to look for work abroad. Agriculture plays a small role and is only profitable because of European subsidies. The fact that the island is mostly bog means that it is limited; largely to sheep farming. In the past, fishing was a significant activity but this aspect of the economy is small now. At one stage, the island was known for its shark fishing, basking shark in particular was fished for its valuable liver oil. There was a big spurt of growth in tourism in the 1960s and 1970s before which life was tough and difficult on the island. Since that heyday, the common perception is that tourism in Achill has been slowly declining.
Currently the biggest employers on the island are 2 hotels and a call centre.
Achill railway station opened on 13 May 1895, but finally closed on 1 October 1937.
Bus Eireann provide daily commutes to Westport and beyond throughout the Islands scattered villages.
In 2006, the population was 2,700. The island's population has declined enormously since the mid nineteenth century.
Because of the inhospitable climate, very few houses date from before the 20th century. An example of the style of earlier housing can be seen in the "Deserted Village" ruins near the graveyard at the foot of Slievemore. Even the houses in this village represent a relatively comfortable class of dwelling as, even as recently as a hundred years ago, some people still used "Beehive" style houses (small circular single roomed dwellings with a hole in ceiling to let out smoke). Many of the oldest and most picturesque inhabited cottages date from the activities of the Congested Districts Board for Ireland—a body set up around the turn of the 20th century in Ireland to improve the welfare for inhabitants of small villages and towns. Most of the homes in Achill at the time were very small and tightly packed together in villages. The CDB subsidised the building of new, more spacious (though still small by modern standards) homes outside of the traditional villages.
Some of the recent building development on the island (over the last 30 years or so) has been contentious and in many cases is not as sympathetic to the landscape as the earlier style of whitewashed raised gable cottages. Because of generous tax incentives, many holiday homes home been built over the last ten years. This building boom has brought benefits but at a cost. On the one hand it has provided much-needed employment for the local people, has increased the demand and value for suitable development land and has allows the island to support more tourists. On the other hand, many of these houses have been built in prominent scenic areas and have damaged traditional views of the island while lying empty for most of the year. They may also be contributing to the declining fortunes for the traditional beneficiaries of tourism - bed and breakfasts, pubs and guesthouses.
The artist Paul Henry stayed on the island for a number of years in the early 1900s and some of his most famous paintings are of the dramatic landscape of the island. The Nobel Prize winning author, Heinrich Böll, visited the island and wrote of his experience in his "Irish Journal" (Irisches Tagebuch). The Bölls later bought a cottage near Dugort and lived in it periodically until 2001 when they donated it to be used as an artists' residence. Graham Greene also spent time on Achill Island.

Irwin Allen Ginsberg () (June 3, 1926 – April 5 1997) was an American poet. Ginsberg is best known for Howl (1956), a long poem celebrating his friends of the Beat Generation and attacking what he saw as the destructive forces of materialism and conformity in the United States at the time.
As a young teenager, Ginsberg began to write letters to The New York Times about political issues such as World War II and workers' rights. When he was in junior high school, he accompanied his mother by bus to her therapist. The trip disturbed Ginsberg — he mentioned it and other moments from his childhood in his long autobiographical poem "Kaddish for Naomi Ginsberg (1894-1956)." While in high school, Ginsberg began reading Walt Whitman; he said he was inspired by his teacher's passion in reading.
In 1943, Ginsberg graduated from Eastside High School and briefly attended Montclair State University before entering Columbia University on a scholarship from the Young Men's Hebrew Association of Paterson, (1949). While at Columbia, Ginsberg contributed to the Columbia Review literary journal, the Jester humor magazine, won the Woodberry Poetry Prize and served as president of the Philolexian Society, the campus literary and debate group.
In Ginsberg's freshman year at Columbia he met fellow undergraduate Lucien Carr, who introduced him to a number of future Beat writers including Jack Kerouac, William S. Burroughs, and John Clellon Holmes. They bonded because they saw in one another excitement about the potential of the youth of America, a potential which existed outside the strict conformist confines of post-WWII McCarthy-era America. Ginsberg and Carr talked excitedly about a "New Vision" (a phrase adapted from Arthur Rimbaud) for literature and America. Carr also introduced Ginsberg to Neal Cassady, for whom Ginsberg had a long infatuation. Kerouac later described the meeting between Ginsberg and Cassady in the first chapter of his 1957 novel On the Road. Kerouac saw them then as the dark (Ginsberg) and light (Cassady) side of their "New Vision." Kerouac's perception had to do partly with Ginsberg's association with Communism (though Ginsberg himself was never a Communist); Kerouac called Ginsberg "Carlo Marx" in On the Road. This was a source of strain in their relationship since Kerouac grew increasingly distrustful of Communism.
In 1948 in an apartment in Harlem, Ginsberg had an auditory hallucination of William Blake reading his poems "Ah, Sunflower," "The Sick Rose," and "Little Girl Lost" (later referred to as his "Blake vision"). Ginsberg was reading these poems at the time, and he said he was very familiar with them; at one point he claimed he heard them being read by what sounded like the voice of God but what he interpreted as the voice of Blake. He had at that moment pivotal revelations that defined his understanding of the universe. He believed that he witnessed then the interconnectedness of the universe. He looked at lattice work on the fire escape and realized some hand had crafted that; he then looked at the sky and intuited that some hand had crafted that also, or rather that the sky was the hand that crafted itself. He explained that this hallucination was not inspired by drug use, but said he sought to recapture that feeling later with various drugs.
Also in New York, Ginsberg met Gregory Corso in the Pony Stable Bar, one of New York's first openly lesbian bars. Corso, recently released from prison, was supported by the Pony Stable patrons and was writing poetry there the night of their meeting. Ginsberg claims he was immediately attracted to Corso, who was straight but understanding of homosexuality after three years in prison. Ginsberg was even more struck by reading Corso's poems, realizing Corso was "spiritually gifted." Ginsberg introduced Corso to the rest of his inner circle. In their first meeting at the Pony Stable, Corso showed Ginsberg a poem about a woman who lived across the street from him, and sunbathed naked in the window. Amazingly, the woman just happened to be Ginsberg's girlfriend during one of his forays into heterosexuality. Ginsberg and Corso remained life-long friends and collaborators.
It was also during this period that Ginsberg was romantically involved with Elise Cowen.
In 1954 in San Francisco, Ginsberg met Peter Orlovsky, (7 years his junior) with whom he fell in love and who remained his life-long lover, and with whom he eventually shared his interest in Tibetan Buddhism.
Also in San Francisco Ginsberg met members of the San Francisco Renaissance and other poets who would later be associated with the Beat Generation in a broader sense. Ginsberg's mentor William Carlos Williams wrote an introductory letter to San Francisco Renaissance figurehead Kenneth Rexroth, who then introduced Ginsberg into the San Francisco poetry scene. There, Ginsberg also met three accomplished poets and Zen enthusiasts who were friends at Reed College: Gary Snyder, Philip Whalen, and Lew Welch.
Wally Hedrick — a painter and co-founder of the Six Gallery — approached Ginsberg in the summer of 1955 and asked him to organize a poetry reading at the Six Gallery. At first, Ginsberg refused, but once he’d written a rough draft of Howl, he changed his "fucking mind," as he put it. Ginsberg advertised the event as "Six Poets at the Six Gallery." One of the most important events in Beat mythos, known simply as "The Six Gallery reading" took place on October 7, 1955. The event, in essence, brought together the East and West Coast factions of the Beat Generation. Of more personal significance to Ginsberg: that night was the first public reading of "Howl," a poem that brought worldwide fame to Ginsberg and to many of the poets associated with him. An account of that night can be found in Kerouac's novel The Dharma Bums, describing how change was collected from audience members to buy jugs of wine, and Ginsberg reading passionately, drunken, with arms outstretched. A taped recording of the reading of 'Howl' that Ginsberg gave at Reed College has recently been rediscovered and will appear on their multimedia website from 9am PST 15 February 2008.
Ginsberg's principal work, "Howl," is well-known for its opening line: "I saw the best minds of my generation destroyed by madness, starving hysterical naked.." "Howl" was considered scandalous at the time of its publication, due to the rawness of its language, which is frequently explicit. Shortly after its 1956 publication by San Francisco's City Lights Bookstore, it was banned for obscenity. The ban became a cause célèbre among defenders of the First Amendment, and was later lifted after Judge Clayton W. Horn declared the poem to possess redeeming social importance.
Ginsberg claimed at one point that all of his work was an extended biography (like Kerouac's Duluoz Legend). Howl is not only a biography of Ginsberg's experiences before 1955, but a history of the Beat Generation. Ginsberg also later claimed that at the core of Howl were his unresolved emotions about his schizophrenic mother. Though Kaddish deals more explicitly with his mother (so explicitly that a line-by-line analysis would be simultaneously overly-exhaustive and relatively unrevealing), Howl in many ways is driven by the same emotions. Though references in most of his poetry reveal much about his biography, his relationship to other members of the Beat Generation, and his own political views, "Howl," his most famous poem, is still perhaps the best place to start. See Howl.
In 1957, Ginsberg surprised the literary world by abandoning San Francisco. After a spell in Morocco, he and Peter Orlovsky joined Gregory Corso in Paris. Corso introduced them to a shabby lodging house above a bar at 9 rue Gît-le-Coeur that was to become known as the Beat Hotel. They were soon joined by William Burroughs and others. It was a productive, creative time for all of them. There, Ginsberg finished his epic poem "Kaddish," Corso composed "Bomb" and "Marriage," and Burroughs (with help from Ginsberg and Corso) put together Naked Lunch, from previous writings. This period was documented by the photographer Harold Chapman, who moved in at about the same time, and took pictures constantly of the residents of the "hotel" until it closed in 1963.
Though "Beat" is most accurately applied to Ginsberg and his closest friends (Corso, Orlovsky, Kerouac, Burroughs, etc.), the term "Beat Generation" has become associated with many of the other poets Ginsberg met and became friends with in the late 1950s and early 1960s. A key feature of this term seems to be a friendship with Ginsberg. Friendship with Kerouac or Burroughs might also apply, but both writers later strove to disassociate themselves from the name "Beat Generation." Part of their dissatisfaction with the term came from the mistaken identification of Ginsberg as the leader. Ginsberg never claimed to be the leader of a movement. He did, however, claim that many of the writers with whom he had become friends in this period shared many of the same intentions and themes. Some of these friends include: Bob Kaufman; LeRoi Jones before he became Amiri Baraka, who, after reading "Howl," wrote a letter to Ginsberg on a sheet of toilet paper; Diane DiPrima; poets associated with the Black Mountain College such as Robert Creeley and Denise Levertov; poets associated with the New York School such as Frank O'Hara and Kenneth Koch.
Later in his life, Ginsberg formed a bridge between the beat movement of the 1950s and the hippies of the 1960s, befriending, among others, Timothy Leary, Ken Kesey, Rod McKuen, and Bob Dylan.
Ginsberg's spiritual journey began early on with his spontaneous visions, and continued with an early trip to India and a chance encounter on a New York City street with Chögyam Trungpa Rinpoche (they both tried to catch the same cab), a Tibetan Buddhist meditation master of the Vajrayana school, who became his friend and life-long teacher. Ginsberg helped Trungpa in founding the Jack Kerouac School of Disembodied Poetics at Naropa University in Boulder, Colorado.
Ginsberg was also involved with Hinduism. He befriended A.C. Bhaktivedanta Swami Prabhupada, the founder of the Hare Krishna movement in the Western world, a relationship that is documented by Satsvarupa Gosvami in his biographical account 'Srila Prabhupada Lilamrta'. Ginsberg donated money, materials, and his reputation to help the Swami establish the first temple, and toured with him to promote his cause. Ginsberg also claimed to be the first person on the North American continent to chant the Hare Krishna mantra. He was mourned by the Hare Krishnas upon his passing in 1997.
Music and chanting were both important parts of Ginsberg's live delivery during poetry readings. He often accompanied himself on a harmonium, and was often accompanied by a guitarist. Attendance to his poetry readings was generally standing room only for most of his career, no matter where in the world he appeared.
Ginsberg won the National Book Award for his book The Fall of America. In 1993, the French Minister of Culture awarded him the medal of Chevalier des Arts et des Lettres (the Order of Arts and Letters).
Allen Ginsberg gave what is thought to be his last reading at The Booksmith in San Francisco on December 16, 1996. He died on April 5, 1997, surrounded by family and friends in his East Village loft in New York City, succumbing to liver cancer via complications of hepatitis. He was 70 years old. Ginsberg continued to write through his final illness, with his last poem, "Things I'll Not Do (Nostalgias)," written on March 30.
Ginsberg is buried in his family plot in Gomel Chesed Cemetery, one of a cluster of Jewish cemeteries at the corner of McClellan Street and Mt. Olivet Avenue near the city lines of Elizabeth and Newark, New Jersey. The family plot, located toward the western edge of the cemetery at the far end of the walk from the third gate along Mt. Olivet Avenue, is marked by a large Ginsberg and Litzky stone, and Ginsberg himself and each family member have smaller markers. Though the grave itself and the cemetery are neither picturesque nor otherwise notable (Ginsberg's grave is located near the rear fence of the flat cemetery, which is in the midst of an industrial area), and it has not become a major place of pilgrimage, there is a steady trickle of visitors as indicated by a handful of stones always on his marker and the occasional book or other item left by other poets and admirers.
Ginsberg's willingness to talk about taboo subjects is what made him a controversial figure in the conservative 1950s and a significant figure in the 1960s. But Ginsberg continued to broach controversial subjects throughout the 1970s, '80s, and '90s. When explaining how he approached controversial topics, he often pointed to Herbert Huncke: he said that when he first got to know Huncke in the 1940s, Ginsberg saw that he was sick from his heroin addiction, but at the time heroin was a taboo subject and Huncke was left nowhere to go for help.
Likewise, he continuously attempted to force the world into a dialogue about controversial subjects because he thought that no change could be made in a polite silence.
Ginsberg also played a key role in ensuring that a 1965 protest of the Vietnam war, which took place at the Oakland-Berkeley city line and drew several thousand marchers, was not violently interrupted by the California chapter of the notorious motorcycle gang, the Hells Angels, and their leader, Sonny Barger.
The day prior to the scheduled march, the Hell's Angels attacked the front line of a smaller scale protest where a confrontation between police and demonstrators was brewing. The Hell's Angels came in on motorcycles and slashed banners while yelling "Go back to Russia, you fucking communists!" at the protesters. The Hell's Angels then vowed to disrupt the larger protest the next day.
Ginsberg traveled to Barger's home in Oakland to talk the situation through. It is rumored that he offered Barger and other members of the Hell's Angels LSD as a gesture of friendship and goodwill. In the end, Barger and the other Hell's Angels that were present came away deeply impressed by the courage of Ginsberg and his companion Ken Kesey. They vowed not to attack the next day's protest march and furthermore deemed Ginsberg a man who was worth helping out.
He was present the night of the massive Tompkins Square Park Police Riot in 1988 and provided an eyewitness account to The New York Times. It was shortly after the Tompkins Square Park riots that he was involved in a fracas with the Mentofreeist group and was assaulted by its leader, Vargus Pike, who was arrested. He was later released when Ginsberg, sporting a black eye, refused to press charges.
In 1965 Ginsberg was deported from Cuba for publicly protesting against Cuba's anti-marijuana stance; ironically Ginsberg admired Castro along with many other Marxist figures from the 20th century.
The Cubans sent him to Czechoslovakia, where one week after being named the King of a May Day parade, Ginsberg was labeled an "immoral menace" by the Czech government because of his free expression of radical ideas, and was then deported. Many important figures from Communist Bloc countries such as Vaclav Havel point to Ginsberg as an important inspiration to strive for freedom. According to biographer Jonah Raskin, despite his often stark opposition to communist orthodoxy Ginsberg held "his own idiosyncratic version of communism".
In addition, the character of Ginsberg in Jack Kerouac's On the Road is named Carlo Marx, a possible reference to his early beliefs.
One contribution that is often considered his most significant and most controversial was his openness about homosexuality. Ginsberg was an early proponent of freedom for men who loved other men, having already in 1943 discovered within himself "mountains of homosexuality." He expressed this desire openly and graphically in his poetry. He also struck a note for gay marriage by listing Peter Orlovsky, his lifelong companion, as his spouse in his Who’s Who entry. Later homosexual writers saw his frank talk about homosexuality as an opening to speak more openly and honestly about something often before only hinted at or spoken of in metaphor.
Also, in writing about sexuality in graphic detail and in his frequent use of language seen as indecent he challenged — and ultimately changed — obscenity laws. He was a staunch supporter of others whose expression challenged obscenity laws (William S. Burroughs and Lenny Bruce, for example).
Ginsberg also spoke out in defense of the freedom of expression of NAMBLA. Ginsberg stated "I joined NAMBLA in defense of free speech.." In "Thoughts on NAMBLA," published in Deliberate Prose, Ginsberg elaborated on these thoughts, stating "NAMBLA's a forum for reform of those laws on youthful sexuality which members deem oppressive, (it is) a discussion society not a sex club." Ginsberg expressed the opinion that the appreciation of youthful bodies and "the human form divine" has been a common theme throughout the history of culture, "from Rome's Vatican, to Florence's Uffizi galleries, to New York's Metropolitan Museum of Art," and that laws regarding the issue needed to be more openly discussed. Ginsberg left the organization when he felt that his point on freedom of speech in America had been made.
Though he had intentions to be a labor lawyer, Ginsberg wrote poetry for most of his life. Most of his very early poetry was written in formal rhyme and meter like his father or like his idol William Blake. His admiration for the writing of Jack Kerouac inspired him to take poetry more seriously. Though he took odd jobs to support himself, in 1955, upon the advice of a psychiatrist, Ginsberg dropped out of the working world to devote his entire life to poetry. Soon after, he wrote "Howl," the poem that brought him and his friends much fame and allowed him to live as a professional poet for the rest of his life.
Since Ginsberg's poetry is intensely personal, and since much of the vitality of those associated with the beat generation comes from mutual inspiration, much credit for style, inspiration, and content can be given to Ginsberg's friends.
Ginsberg claimed throughout his life that his biggest inspiration was Kerouac's concept of "spontaneous prose". He believed literature should come from the soul without conscious restrictions. However, Ginsberg was much more prone to revise than Kerouac. For example, when Kerouac saw the first draft of "Howl" he disliked the fact that Ginsberg had made editorial changes in pencil (transposing "negro" and "angry" in the first line, for example). Kerouac only wrote out his concepts of Spontaneous Prose at Ginsberg's insistence because Ginsberg wanted to learn how to apply the technique to his poetry.
An important figure when considering inspiration for "Howl" is Carl Solomon. The full title is "Howl for Carl Solomon." Solomon was a Dada and Surrealism enthusiast (he introduced Ginsberg to Artaud) who suffered bouts of depression. Solomon wanted to commit suicide, but he thought a form of suicide appropriate to dadaism would be to go to a mental institution and demand a lobotomy. The institution refused, giving him many forms of therapy, including electroshock therapy. Much of the final section of the first part of "Howl" is a description of this.
Ginsberg used Solomon as an example of all those ground down by the machine of "Moloch." Moloch, to whom the second section is addressed, is a Levantine god to whom children were sacrificed. Ginsberg may have gotten the name from the Kenneth Rexroth poem "Thou Shalt Not Kill," a poem about the death of one of Ginsberg's heroes, Dylan Thomas. But Moloch is mentioned a few times in the Torah and references to Ginsberg's Jewish background are not infrequent in his work. Ginsberg said the image of Moloch was inspired by peyote visions he had of the Francis Drake Hotel in San Francisco which appeared to him as a skull; he took it as a symbol of the city (not specifically San Francisco, but all cities). Ginsberg later acknowledged in various publications and interviews that behind the visions of the Francis Drake Hotel were memories of the Moloch of Fritz Lang's film Metropolis (1927) and of the woodcut novels of Lynd Ward. Moloch has subsequently been interpreted as any system of control, including the conformist society of post-World War II America focused on material gain, which Ginsberg frequently blamed for the destruction of all those outside of societal norms.
Ginsberg's poetry was strongly influenced by Modernism (specifically Ezra Pound, T. S. Eliot, Hart Crane, and most importantly William Carlos Williams), Romanticism (specifically Percy Shelley and John Keats), the beat and cadence of jazz (specifically that of bop musicians such as Charlie Parker), and his Kagyu Buddhist practice and Jewish background. He considered himself to have inherited the visionary poetic mantle handed down from the English poet and artist William Blake, and the American poet Walt Whitman. The power of Ginsberg's verse, its searching, probing focus, its long and lilting lines, as well as its New World exuberance, all echo the continuity of inspiration that he claimed.
Carl Solomon introduced him to Antonin Artaud ("To Have Done with the Judgement of God" and "Van Gogh: The Man Suicided by Society"), and Jean Genet (Our Lady of the Flowers). Philip Lamantia introduced him to other Surrealists and Surrealism continued to be an influence (for example, sections of Kaddish were inspired by Andre Breton's "Free Union"). Ginsberg claimed that the anaphoric repetition of "Howl" and other poems was inspired by Christopher Smart in such poems as "Jubilate Agno." Ginsberg claims other more traditional influences, such as: Franz Kafka, Herman Melville, Fyodor Dostoevsky, Edgar Allan Poe, and even Emily Dickinson.
From the study of his idols and mentors and the inspiration of his friends — not to mention his own experiments — Ginsberg developed an individualistic style that's easily identified as Ginsbergian. Howl came out during a potentially hostile literary environment less welcoming to poetry outside of tradition; there was a renewed focus on form and structure among academic poets and critics partly inspired by New Criticism (see "Open Form vs. Closed Form" in the Beat Generation section). Consequently, Ginsberg often had to defend his choice to break away from traditional poetic structure, often citing Williams, Pound, and Whitman as precursors. Ginsberg's style may have seemed to critics chaotic or unpoetic, but to Ginsberg it was an open, ecstatic expression of thoughts and feelings that were naturally poetic. He believed strongly that traditional formalist considerations were archaic and didn't apply to reality. Though some, Diana Trilling for example, have pointed to Ginsberg's occasional use of meter (for example the anapest of "who came back to Denver and waited in vain"), Ginsberg denied any intention toward meter and claimed instead that meter follows the natural poetic voice, not the other way around; he said, as he learned from Williams, that natural speech is occasionally dactylic, so poetry that imitates natural speech will sometimes fall into a dactylic structure but only ever accidentally. Like Williams, Ginsberg's line breaks were often determined by breath: one line in "Howl," for example, should be read in one breath. Ginsberg claimed he developed such a long line because he had long breaths (saying perhaps it was because he talked fast, or he did yoga, or he was Jewish). The long line could also be traced back to his study of Walt Whitman; Ginsberg claimed Whitman's long line was a dynamic technique few other poets had ventured to develop further. Whitman is often compared to Ginsberg because their poetry sexualized aspects of the male form — though there is no direct evidence Whitman was homosexual. They had very different politics, Whitman being a nationalist and Ginsberg demonstratively anti-nationalist.
Many of his early long line experiments contain some sort of anaphoric repetition, or repetition of a "fixed base" (for example "who" in "Howl," "America" in "America"), and this has become a recognizable feature of Ginsberg's style. However, he said later this was a crutch because he lacked confidence in his style; he didn't yet trust "free flight." In the 60s, after employing it in some sections of Kaddish ("caw" for example) he, for the most part, abandoned the anaphoric repetition.
Several of his earlier experiments with methods for formatting poems as a whole become regular aspects of his style in later poems. In the original draft of "Howl," each line is in a "stepped triadic" format reminiscent of Williams (see "Ivy Leaves," for example). He abandoned the "stepped triadic" when he developed his long line, but the stepped lines showed up later, most significantly in the travelogues of The Fall of America. "Howl" and "Kaddish," arguably his two most important poems, are both organized as an inverted pyramid, with larger sections leading to smaller sections. In "America," he experimented with a mix of longer and shorter lines.
"cover Heaven's corners..
to meet the Weaving Girl..

In mathematics, a field F is said to be algebraically closed if every polynomial in one variable of degree at least 1, with coefficients in F, has a zero (root) in F.
has no zero in F. By contrast, the fundamental theorem of algebra states that the field of complex numbers is algebraically closed. Another example of an algebraically closed field is the field of (complex) algebraic numbers.
The field F is algebraically closed if and only if the only irreducible polynomials in the ring F[x] are those of degree one.
The assertion "the polynomials of degree one are irreducible" is trivially true for any field. If F is algebraically closed and p(x) is an irreducible polynomial of F[x], then it has some root a and therefore p(x) is a multiple of x &minus; a. Since p(x) is irreducible, this means that p(x) = k(x &minus; a), for some k &isin; F \ {0}. On the other hand, if F is not algebraically closed, then there is some non-constant polynomial p(x) in F[x] without roots in F. Let q(x) be some irreducible factor of p(x). Since p(x) has no roots in F, q(x) also has no roots in F. Therefore, q(x) has degree greater than one, since every first degree polynomial has one root in F.
The field F is algebraically closed if and only if every polynomial p(x) of degree n ≥ 1, with coefficients in F, splits into linear factors. In other words, there are elements k, x1, x2, …, xn of the field F such that p(x) = k(x &minus; x1)(x &minus; x2) &middot;&middot;&middot; (x &minus; xn).
It F has this property, then clearly every non-constant polynomial in F[x] has some root in F; in other words, F is algebraically closed. On the other hand, that the property stated here holds for F if F is algebraically closed follows from the previous property together with the fact that, for any field F, any polynomial p(x) in F[x] can be written as a product of irreducible polynomials.
The field F is algebraically closed if and only if it has no proper algebraic extension.
If F has no proper algebraic extension, let p(x) be some irreducible polynomial in F[x]. Then the quotient of F(x) modulo the ideal generated by p(x) is an algebraic extension of F whose degree is equal to the degree of p(x). Since it is not a proper extension, its degree is 1 and therefore the degree of p(x) is 1.
On the other hand, if F has some proper algebraic extension K, then the minimal polynomial of an element a in K \ F is irreducible and its degree is greater than 1.
The field F is algebraically closed if and only if, for each natural number n, every linear map from Fn into itself has some eigenvector.
The field F is algebraically closed if and only if every rational function in one variable x, with coefficients in F, can be written as the sum of a polynomial function with rational functions of the form a/(x &minus; b)n, where n is a natural number, and a and b are elements of F.
If F is algebraically closed then, since the irreducible polynomials in F[x] are all of degree 1, the property stated above holds by the theorem on partial fraction decomposition.
can be written as a quotient of two polynomials in which the denominator is a product of first degree polynomials. Since p(x) is irreducible, it must divide this product and, therefore, it must also be a first degree polynomial.
If F is an algebraically closed field and n is a natural number, then F contains all nth roots of unity, because these are (by definition) the n (not necessarily distinct) zeroes of the polynomial xn &minus; 1. A field extension that is contained in an extension generated by the roots of unity is a cyclotomic extension, and the extension of a field generated by all roots of unity is sometimes called its cyclotomic closure. Thus algebraically closed fields are cyclotomically closed. The converse is not true. Even assuming that every polynomial of the form xn &minus; a splits into linear factors is not enough to assure that the field is algebraically closed.
If a proposition which can be expressed in the language of first-order logic is true for an algebraically closed field, then it is true for every algebraically closed field with the same characteristic. Furthermore, if such a proposition is valid for an algebraically closed field with characteristic 0, then not only it is valid for all other algebraically closed field with characteristic 0 as there is some natural number N such that the proposition is valid for every algebraically closed field with characteristic p when p < N.
Every field F has some extension which is algebraically closed. Among all such extensions there is one and (up to isomorphism) only one which is an algebraic extension of F; it is called the algebraic closure of F.




Anatoly Yevgenyevich Karpov (; born May 23, 1951) is a Russian chess grandmaster and former World Champion. He was undisputed World Champion from 1975 to 1985, repeatedly challenged to regain the title from 1986 to 1990, then was FIDE World Champion from 1993 to 1999.
His tournament successes include 161 first-place finishes. He had a peak Elo rating of 2780.
Since 2005 he has been a member of the Public Chamber of Russia. He has lately been involved in several humanitarian causes, such as advocating the use of iodised salt.
Karpov was born on May 23, 1951 at Zlatoust in the Urals region of the former Soviet Union, and learned to play chess at the age of four. He has been an excellent student throughout his life. His early rise in chess was swift, as he was a Candidate Master by age 11. At age 12, he was accepted into Mikhail Botvinnik's prestigious chess school. Ironically, Botvinnik had this to say about the young Karpov: "The boy doesn't have a clue about chess, and there's no future at all for him in this profession." Karpov acknowledged that his understanding of chess theory was very confused at that time, and wrote later that the homework which Botvinnik assigned really helped him, since it required that he consult chess books and work diligently. Karpov improved so quickly that he became the youngest Soviet National Master in history at 15 in 1966; this tied the record established by Boris Spassky in 1952 at the same age.
Karpov won the title in his first international chess tournament (Trinec 1966-67) several months later. In 1967 he won a European Junior Invitational tournament at Groningen. Karpov won a Gold Medal for academic excellence in high school, and entered Moscow State University in 1968 to study Mathematics. He later transferred to Leningrad State University, eventually graduating from there in Economics. One reason for the transfer was to be closer to his coach, Grandmaster Semyon Furman, who lived in Leningrad. In his writings, Karpov credits Furman as a major influence on his development as a world-class player.
In 1969 Karpov became the first Soviet player since Boris Spassky (1955) to win the World Junior Chess Championship, with a score in the finals of 10 out of 11 at Stockholm. Soon afterwards he tied for 4th place at an international tournament in Caracas, Venezuela, and became a Grandmaster.
The early 1970s showed a big improvement in his game. He won the 1971 Alekhine Memorial tournament ahead of a star-filled field, for his first significant adult victory. His Elo rating shot up from 2540 in 1971 to 2660 in 1973, when he came in 2nd in the USSR Chess Championship, and placed first in the Leningrad Interzonal Tournament. The latter qualified him for the 1974 Candidates' Tournament, which determined who was allowed to challenge the reigning World Champion, Bobby Fischer.
Karpov beat Lev Polugaevsky by +3=5 in the first Candidates' match, to face former World Champion Boris Spassky in the next round. Karpov was on record saying that he believed Spassky would easily beat him and win the Candidates' cycle to face Fischer, and that he (Karpov) would win the following Candidates' cycle in 1977.
Most expected the Spassky-Karpov match to be a one-sided rout by the ex-champ Spassky. Although Spassky won the first game as Black in good style, tenacious and aggressive play from Karpov secured him a match win by +4-1=6. Karpov was certainly not hurt by the fact that Spassky's chief opening analyst, 1955 Soviet Champion Efim Geller, defected to Karpov's side several months before the match.
The Candidates' final was set in Moscow against fellow Soviet Viktor Korchnoi, a notable fighting player. Korchnoi was a Leningrad resident who had frequently sparred with Karpov after the latter moved there, and the two had played a drawn six-game training match in 1971. Intense games were fought, including one "opening laboratory" win against the Sicilian Dragon. Karpov went up 3-0, but tired towards the end and allowed Korchnoi two wins, making for a nervy finish. However, Karpov prevailed +3-2=19. Thus he won the right to challenge Fischer for the World Championship.
Though the world championship match between the young Soviet prodigy and the already retired American Fischer was highly anticipated, the match never came about. Fischer drew up a list of ten demands, chief among them the provisions that draws wouldn't count, the first to ten victories wins, and if the score was tied 9—9 the champion would retain the crown. This means that the challenger needed two wins more than the reigning champion, because the narrowest possible win for him is 10–8. FIDE, the International Chess Federation, flatly refused at first, but eventually conceded the first two. However, Fischer demanded all or nothing, and when FIDE refused to give in to the third demand, Fischer resigned his crown, to the huge disappointment of the chess world. Karpov later attempted to set up another match with Fischer, but all the negotiations fell through. Fischer never did play Karpov and scorned him as an inferior player. This thrust the young Karpov into the role of World Champion without having defeated the reigning champion.
When Kasparov was in a bitter struggle for the world championship with Karpov, he often reminded others that Karpov won the title by default. But while preparing a monumental book series Kasparov: My Great Predecessors, Kasparov argued that Karpov would have had the better chances, because he had beaten Spassky convincingly and was a new breed of tough professional, and indeed had higher quality games, while Fischer had been inactive for three years. Spassky thought that Fischer would have won in 1975 but Karpov would have qualified again and beaten Fischer in 1978.
Karpov participated in nearly every major tournament for the next ten years. He convincingly won the very strong Milan tournament in 1975, and captured his first of three Soviet titles in 1976. He created the most phenomenal streak of tournament wins against the strongest players in the world. This tournament success even eclipsed the pre-war tournament record of Alexander Alekhine. Karpov held the record for most consecutive tournament victories (9) until it was shattered by Garry Kasparov (14).
In 1978, Karpov's first title defence was against Viktor Korchnoi, the opponent he had defeated in the previous Candidates' tournament. The situation was vastly different from the previous match, because in the intervening years Korchnoi had defected from the Soviet Union. The match was played at Baguio in the Philippines, and a vast array of psychological tricks were used during the match, from Karpov's Dr. Zukhar who allegedly attempted to hypnotize Korchnoi during the game, to Korchnoi's mirror glasses to ward off the hypnotic stare, Korchnoi's offering to play under the Jolly Roger flag when he was denied the right to play under Switzerland's, to Karpov's yogurt supposedly being used to send him secret messages, to Korchnoi inviting two local cult members (on trial for attempted murder) into the hall as members of his team.
The off-board antics are better remembered than the actual chess match. Karpov took an early lead, but Korchnoi staged an amazing comeback very late in the match, and came very close to winning. Karpov narrowly won the last game to take the match 6–5, with 21 draws.
Three years later Korchnoi re-emerged as the Candidates' winner against German finalist Dr. Robert Hübner to challenge Karpov in Merano, Italy. This time the psychological trick was the arrest of Korchnoi's son for evading conscription. Again the politics off the board overshadowed the games, but this time Karpov easily won (11–7, +6 -2 =10) in what is remembered as the "Massacre at Merano".
Karpov's tournament career reached a peak at the exceptional Montreal "Tournament of Stars" tournament in 1979, where he ended joint first with Mikhail Tal ahead of a field of superb grandmasters like Jan Timman, Ljubomir Ljubojevic, Boris Spassky, and Lubomir Kavalek. He dominated Las Palmas 1977 with an incredible 13.5 / 15. He also won the prestigious Bugojno tournament in 1978 and 1980, the Linares tournament in 1981 and 1994, the Tilburg tournament in 1977, 1979, 1980, 1982, and 1983, and the Soviet Championship in 1976, 1983, and 1988.
Karpov represented the Soviet Union at six Chess Olympiads, in all of which the USSR won the team gold medal. He played first reserve at Skopje 1972, winning the board prize with 13/15. At Nice 1974, he advanced to board one and again won the board prize with 12/14. At La Valletta 1980, he was again board one and scored 9/12. At Lucerne 1982, he scored 6.5/8 on board one. At Dubai 1986, he scored 6/9 on board two. His last was Thessaloniki 1988, where on board two he scored 8/10. In Olympiad play, Karpov lost only two games out of 68 played.
To illustrate Karpov's dominance over his peers as champion, his score was +11 -2 =20 versus Spassky, +5 =12 versus Robert Hübner, +6 -1 =16 versus Ulf Andersson, +3 -1 =10 versus Vasily Smyslov, +1 =16 versus Mikhail Tal, +10 -2 =13 versus Ljubojevic.
Karpov had cemented his position as the world's best player and world champion when Garry Kasparov arrived on the scene. In their first World Championship match in 1984, held in Moscow, Karpov quickly built a 4-0 lead, and needed only two more wins to keep his title. Instead, the next 17 games were drawn, and it took Karpov until Game 27 to finally win another game. In Game 31, Karpov had a winning position but failed to take advantage and settled for a draw. He lost the next game, but drew the next 14. In particular, Karpov held a solidly winning position in Game 41, but again blundered terribly and had to settle for a draw. After Kasparov won Games 47 and 48, FIDE President Florencio Campomanes controversially terminated the match, citing the health of the players. Karpov appeared to be in worse health, having lost 10 kg (22 lb) over the course of the match, and lost the last two games. The match, which had lasted an unprecedented five months, with five wins for Karpov, three for Kasparov, and a staggering forty draws.
A rematch was set for later in 1985, also in Moscow. In a hard fight, Karpov had to win game 24 of the 1985 match to retain his title, but lost it and the title 11 to 13 (+3 -5 =16), ending his ten-year reign as champion.
Karpov remained a formidable opponent (and the world #2) until the early 1990s. He fought Kasparov in three more World Championship matches in 1986 (held in London and Leningrad), 1987 (held in Seville), and 1990 (held in New York City and Lyon). All three matches were extremely close: the scores were 11.5 to 12.5 (+4 -5 = 15), 12 to 12 (+4 -4 =16), and 11.5 to 12.5 (+3 -4 =17). In all three matches Karpov had winning chances up to the very last games. In particular, the 1987 Seville match featured an astonishing blunder by Kasparov in the 23rd game, and should have led to Karpov's reclaiming the title. Instead, in the final game, needing only a draw to win the title, Karpov cracked under pressure from the clock at the end of the first session of play, allowing Kasparov to adjourn the game a pawn up. After a further mistake in the second session, Karpov was slowly ground down and resigned on move 64, ending the match and allowing Kasparov to keep the title.
In their five world championship matches, Karpov has 19 wins, 21 losses, and 104 draws in 144 games.
Karpov is on record saying that had he had the opportunity to fight Fischer for the crown like Kasparov had the opportunity to fight him, he (Karpov) could have been a much better player as a result.
It came as a surprise, then, that Karpov lost a Candidates Match against Nigel Short in 1992. But in 1993, Karpov reacquired the FIDE World Champion title when Kasparov and Short split from FIDE. Karpov defeated Jan Timman – the loser of the Candidates' final against Short. Once again he had become World Champion, and once again he did so controversially, only winning the title because of the absence of Kasparov and Short.
The next major meeting of Kasparov and Karpov was the 1994 Linares chess tournament. The field, in eventual finishing order, was Karpov, Kasparov, Shirov, Bareev, Kramnik, Lautier, Anand, Kamsky, Topalov, Ivanchuk, Gelfand, Illescas, Judit Polgar, and Beliavsky; with an average ELO rating of 2685, the highest ever to that point, meaning it was the first Category XVIII tournament ever held. Impressed by the strength of the tournament, Kasparov had said several days before the tournament that the winner could rightfully be called the world champion of tournaments. Perhaps spurred on by this comment, Karpov played the best tournament of his life. He was undefeated and earned 11 points out of 13 possible (the best world-class tournament winning percentage since Alekhine won San Remo in 1930), dominating second-place Kasparov and Shirov by a huge 2.5 points. Many of his wins were spectacular (in particular, his win over Topalov is considered possibly the finest of his career). This performance against the best players in the world put his ELO rating tournament performance at 2985, the highest performance rating of any chess player in any tournament in all of chess history.
Karpov defended his FIDE title against Gata Kamsky (+6 -3 =9) in 1996. However, in 1998, FIDE largely scrapped the old system of Candidates' Matches, instead having a large knock-out event in which a large number of players contested short matches against each other over just a few weeks. In the first of these events, champion Karpov was seeded straight into the final, defeating Viswanathan Anand (+4 -2 =2). But subsequently the champion had to qualify like other players. Karpov resigned his title in anger at the new rules in 1999.
Karpov's outstanding classical tournament play has been seriously limited since 1995, since he prefers to be more involved in politics of his home country of Russia. He had been a member of the Supreme Soviet Commission for Foreign Affairs and the President of the Soviet Peace Fund before the Soviet Union broke up. In addition, he had been involved in several disputes with FIDE and became increasingly disillusioned with chess. In the January 2008 FIDE rating list, he is 60th in the world with an ELO rating of 2655.
Karpov usually limits his play to exhibition events, and has revamped his style to specialize in rapid chess. In 2002 he won a match against Kasparov, defeating him in a rapid time control match 2.5-1.5. In 2006, he tied for first with Kasparov in a blitz tournament, ahead of Korchnoi and Judit Polgar.

The aspect ratio of a two-dimensional shape is the ratio of its longer dimension to its shorter dimension. It is also applied to two characteristic dimensions of a three-dimensional shape, especially for the longest and shortest 'axes' or for symmetrical objects (e.g. rods) that are described by just two measures (e.g. length and diameter). In such cases, the aspect ratio may evaluate to a value less than one (e.g. consider very short and very long rods). The aspect ratio of a torus is the ratio of the major axis R to the minor axis r.


Automobile racing (also known as auto racing, motor racing, or car racing) is a sport involving racing automobiles. Auto racing began in 1895, and is now one of the world's most popular sports.
Racing began soon after the construction of the first successful petrol-fueled autos. In 1894, the first contest was organized by Paris magazine Le Perit Journal, a reliability test to determine best performance. But the race was changed to Paris to Rouen 1894. Competitors included factory vehicles from Karl Benz's Benz & Cie. and Gottlieb Daimler and Wilhelm Maybach's DMG.
In 1895, one year later, the first real race was staged in France, from Paris to Bordeaux. First over the line was Émile Levassor but he was disqualified because his car was not a required four-seater.
An international competition began with the Gordon Bennett Cup in auto racing.
The first auto race in the United States took place in Evanston, Illinois on November 28, 1895 over an 87.48-km (54.36 mile) course, with Frank Duryea winning in 10 hours and 23 minutes, beating three petrol-fueled and two electric cars. The first trophy awarded was the Vanderbilt Cup.
With auto construction and racing dominated by France, the French automobile club ACF staged a number of major international races, usually from or to Paris, connecting with another major city in Europe or France.
These very successful races ended in 1903 when Marcel Renault was involved in a fatal accident near Angouleme in the Paris-Madrid race. Nine fatalities caused the French government to stop the race in Bordeaux and ban open-road racing.
The 1930s saw the transformation from high-priced road cars into pure racers, with Delage, Auto Union, Mercedes-Benz, Delahaye, and Bugatti constructing streamlined vehicles with engines producing up to 450 kW (612 hp), aided by multiple-stage supercharging. From 1928-1930 and again in 1934-1936, the maximum weight permitted was 750 kg, a rule diametrically opposed to current racing regulations. Extensive use of aluminium alloys was required to achieve light weight, and in the case of the Mercedes, the paint was removed to satisfy the weight limitation, producing the famous Silver Arrows.
Single-seater (open-wheel) racing is one of the most popular forms of motorsport, with cars designed specifically for high-speed racing. The wheels are not covered, and the cars often have aerofoil wings front and rear to produce downforce and enhance adhesion to the track. In Europe and Asia, open wheeled racing is commonly referred to as "Formula", with appropriate hierarchical suffixes. In North America, the "Formula" terminology is not followed (with the exception of F1). The sport is usually arranged to follow an "international" format (such as F1), a "regional" format (such as the Formula 3 Euro Series), or a "domestic", or county-specific format (such as the German Formula 3 championship, or the British Formula Ford).
The best-known variety of single-seater racing, Formula One, involves an annual World Championship for drivers and constructors of around 18 races a year featuring major international car and engine manufacturers, and independent constructors, such as Ferrari, Mercedes-Benz (McLaren), Williams, BMW (Sauber), Toyota, Honda, Renault, Red Bull Racing - in an ongoing battle of technology and driver skill and talent. The sport is one of the top five watched sporting events in the world, alongside the FIFA World Cup, the Olympic Games, the Super Bowl and the UEFA European Football Championship. Formula One is, by any measure, the most expensive sport in the world, with some teams spending in excess of $400 million per year. Formula One is widely considered to be the pinnacle of motorsports, with the F1 Drivers' Championship being one of, and the oldest among, only three World Championships awarded each year by the FIA (the others being the World Touring Car Championship and the World Rally Championship). What separates Formula 1 from all other forms of open wheel racing, is the basic premise of F1 revolves around the very important issue that each team is a "constructor". That is, the chassis of the car must be designed and manufactured in-house, and chassis can not be supplied to competitors on a "customer" basis. Engines are usually funded and/or developed by established major motor manufacturers, and can be supplied exclusively to just one team, or may be offered as "customer" engines, often to the smaller, lower-ranked teams.
In North America, the cars used in the National Championship (currently Champ Car (formerly CART, or Championship Auto Racing Teams) and the Indy Racing League IndyCar Series) have traditionally been similar though to a lower level of sophistication as F1 cars with more restrictions on technology aimed at helping to control costs.
Other international single-seater racing series are the A1 Grand Prix (unofficially often referred to as the "world cup of motorsport"), and the GP2 (formerly known as Formula 3000 and Formula Two). Regional series include Formula Nippon (specifically in Asia), Formula Renault 3.5 (also known as the World Series by Renault, succession series of World Series by Nissan), Formula Three, Formula Palmer Audi and Formula Atlantic. Domestic, or country-specific series include Formula Three, Formula Renault, Formula Ford with the leading introductory series being Formula BMW.
There are other categories of single-seater racing, including kart racing, which employs a small, low-cost machine on small tracks. Many of the current top drivers began their careers in karts. Formula Ford once represented a popular first open-wheel category for up-and-coming drivers stepping up from karts and now the Formula BMW series is the preferred option as it has introduced an areo package and slicks, allowing the junior drivers to gain experience in a race car with dynamics closer F1.
Students at colleges and universities can also take part in single seater racing through the SAE Formula Student competition, which involves designing and building a single seater car in a multidisciplinary team, and racing it at the competition. This also develops other soft skills such as teamwork whilst promoting motorsport and engineering.
In 2006, producer Todd Baker was responsible for creating the world's first all-female Formula racing team. The group was an assemblage of drivers from different racing disciplines, and formed for an MTV reality pilot which was shot at Mazda Raceway Laguna Seca.
In December, 2005 the FIA gave approval to Superleague Formula racing, set to debut in 2008. This will be open-wheel, single-seat stock car racing around Grand Prix racetracks. The teams will be owned and run by prominent sports clubs such as AC Milan and FC Porto. The race weekend will follow the GP2 format of Saturday qualifying and two Sunday races, one featuring a reverse grid.
Touring car racing is a style of road racing that is run with production derived race cars. It often features exciting, full-contact racing due to the small speed differentials and large grids.
The V8 Supercars originally from Australia, British Touring Car Championship, Deutsche Tourenwagen Masters originally from Germany, and the World Touring Car Championship held with 2 non-European races (previously the European Touring Car Championship) are the major touring car championships conducted worldwide, along with a European Touring Cup, a one day event open to Super 2000 specification touring cars from Europe's many national championships.
The Sports Car Club of America's SPEED World Challenge Touring Car and GT championships are dominant in North America while the venerable British Touring Car Championship continues in the United Kingdom. America's historic Trans-Am Series is undergoing a period of transition, but is still the longest-running road racing series in the U.S. The National Auto Sport Association also provides a venue for amateurs to compete in home-built factory derived vehicles on various local circuits.
Production car racing or known in the US as showroom stock, is an economical and rules restricted version of touring car racing, mainly to restrict costs.
Many series follow the Group N regulation with a few exceptions. There are several different series that are run all over the world, most notably, Japan's Super Taikyu and IMSA's Firehawk Series which ran between the 1980s to 1990s all over the United States.
One-make, or single marque, championships often employ production-based cars from a single manufacturer or even a single model from a manufacturer's range. There are numerous notable one-make formulae from various countries and regions, some of which – such as the Porsche Supercup and, previously, IROC – have fostered many distinct national championships. Single marque series are often found at club level, to which the production-based cars, limited modifications, and close parity in performance are very well suited. There are also single-chassis single seater formulae, such as Formula Ford, Formula Saab, Formula BMW, and defunct Formula Vee, usually as "feeder" series for "senior" race formula (in the fashion of farm teams).
Stock car racing, the North American equivalent to touring car racing, is the most-popular form of auto racing (in terms of viewership) on that continent. Usually conducted on ovals, the cars may slightly resemble production cars but are in fact purpose-built racing machines which are built to tight specifications. Early stock cars were actual production vehicles; the car to be raced was often driven from track to track. The modern car however is far removed from the production model which it represents, making the term "stock car" somewhat incorrect.
The largest stock car racing governing body is NASCAR. NASCAR's premier series is the Sprint Cup Series, its most famous races being the Daytona 500 and the Brickyard 400. NASCAR also runs several feder series. The Nationwide Series, and Craftsman Truck Series (a pickup truck racing series) conduct races across the entire continental United States. The NASCAR Canadian Tire Series conducts races across Canada and the NASCAR Corona Series conducts races across Mexico. NASCAR also governs several smaller regional series.
NASCAR also governs the Whelen Modified Tour. Modified cars are best described as hybrids of stock cars and open-wheel cars. They are heavily altered from stock, with powerful engines, large tires, tubular chassis and light bodies. The Whelen Modified tour is NASCAR's oldest series.
There are also other stock car governing bodies, such as Automobile Racing Club of America and United Speed Alliance Racing.
British Stock car racing is a form of Short Oval Racing. This takes place on shale or tarmac tracks in either clockwise or anti-clockwise direction depending on the class, some of which allow contact. Races are organized by local promoters and all drivers are registered with BRISCA and have their own race number. What classes exist depends on the promoter, so events in Scotland at Cowdenbeath can be very different from an event at Wimbledon Stadium in London.
Rallying, or rally racing, involves two classes of car. The modified Group A, but road legal, production based cars and the Group N Production cars compete on (closed) public roads or off-road areas run on a point-to-point format where participants and their co-drivers "rally" to a set of points, leaving in regular intervals from start points. A rally is typically conducted over a number of 'special stages' of any terrain, which entrants are often allowed to scout beforehand at reduced speeds compiling detailed shorthand descriptions of the track or road as they go. These detailed descriptions are known as 'pace notes'. During the actual rally, the co-driver reads the pace notes aloud (using an in-helmet intercom system) to the driver, enabling them to complete each stage as quickly as possible. Competition is based on lowest total elapsed time over the course of an event's special stages, including penalties.
The top series is the World Rally Championship (WRC), but there also regional championships and many countries have their own national championships. Some famous rallies include the Monte Carlo Rally, Rally Argentina, Rally Finland and Rally GB. Another famous event (actually best described as a "rally raid") is the Paris-Dakar Rally. There are also many smaller, club level, categories of rallies which are popular with amateurs, making up the "grass roots" of motor sports.
Targa is a tarmac-based road rally which is run all around the world. This began with the Targa Florio. There are many races including Targa Tasmania held on the island state of Tasmania, Australia, run annually since 1992. The event takes its name from the Targa Florio, a former motoring event held on the island of Sicily. The competition concept is drawn directly from the best features of the Mille Miglia, the Coupe des Alpes and the Tour de Corse. Other events around the world include the Targa Newfoundland based in Canada, Targa West based in Western Australia, Targa New Zealand and other smaller events.
In drag racing, the objective is to complete a given straight-line distance, from a standing start, ahead of a vehicle in a parallel lane. This distance is traditionally ¼ mile (400 m), though 1/8 mile (200 m) has become popular since the 1990s. The vehicles may or may not be given the signal to start at the same time, depending on the class of racing. Vehicles range from the everyday car to the purpose-built dragster. Speeds and elapsed time differ from class to class. Average street cars cover the ¼ mile in from 15 to 20 seconds whereas a top fuel dragster takes 4.5 seconds or less, reaching speeds of up to 530 km/h (330 mph). Drag racing was organized as a sport by Wally Parks in the early 1950s through the NHRA (National Hot Rod Association), the largest motorsports sanctioning body in the world. The NHRA was formed to discourage street racing.
Launching, a top fuel dragster will accelerate at 4.5 g (44 m/s²), and when braking parachutes are deployed the deceleration is 4 g (39 m/s²), more than the Space Shuttle experinces. A top fuel car can be heard over 8 miles (13 km) away and generates a reading of 1.5 to 2 on the Richter scale.
Drag racing is two cars head-to-head, the winner proceeding to the next round. Professional classes are all first to the finish line wins. Sportsman racing is handicapped (slower car getting a head start) using an index (a lowest e.t. allowed), and cars running under (quicker than) their index "break out" and lose. The slowest cars, bracket racers, are also handicapped, but rather than an index, they use a "dial-in".
In sports car racing, production versions of sports and/or GT cars, and purpose-built prototype cars compete within their respective classes on closed circuits. The races are often conducted over long distances, at least 1000 km, and cars are driven by teams of two or three drivers (and sometimes more in the US), switching every now and then. Due to the performance difference between production based sports cars and sports racing prototypes, one race usually involves several racing classes. In the US the American Le Mans Series (ALMS) was organized in 1999, featuring GT1, GT2, and two prototype classes, LMP1 (Le Mans Prototype 1) and LMP2. Manufacturers such as Audi and Acura/Honda field or support entries in the Prototype class. Another series based on Le Mans began in 2004, the Le Mans Endurance Series, which included four 1000 km races at tracks in Europe. A competing body, Grand-Am, which began in 2000, sanctions its own endurance series the Rolex Sports Car Series.
Famous sports car races include the 24 Hours of Le Mans, the 24 Hours of Daytona, 24 Hours of Spa-Franchorchamps, the 12 Hours of Sebring, and the 1000-mile Petit Le Mans at Road Atlanta.
In off-road racing, various classes of specially modified vehicles, including cars, compete in races through off-road environments. In North America these races often take place in the desert, such as the famous Baja 1000.
Although often seen as the entry point for serious racers into the sport, kart racing, or karting, can be an economic way for amateurs to try racing and is also a fully fledged international sport in its own right. World-famous F1-drivers like Michael Schumacher or Fernando Alonso and most of the typical starting grid of a modern Grand Prix took up the sport at around the age of eight, with some testing from age three. Several former motorcycle champions have also taken up the sport, notably Wayne Rainey, who was paralysed in a racing accident and now races a hand-controlled kart. As one of the cheapest ways to go racing, karting is seeing its popularity grow worldwide.
Go-karts, or just "karts" - seem very distant from normal road cars, with diminutive frames and wheels, but a small engine combined with very light weight make for a quick machine. The tracks are also on a much smaller scale, making kart racing more accessible to the average enthusiast.
As modern motor racing is centered on modern technology with a lots of corporate sponsors and politics involved, historical racing tends to be the opposite. As it relies on cars of a particular era it is more hobbyist oriented, reducing corporate sponsorship and politics. Events are regulated to only allow cars of a certain era to participate. The only modern equipment used is related to safety and timing. A historical event can be of various different motorsport disciplines. Notably some of the most famous events of them all are the Goodwood Festival of Speed and Goodwood Revival in Britain and Monterey Historic in the United States. Championships range from "grass root" Austin Seven racing to the FIA Thoroughbred Grand Prix Championship for classic Formula One chassis.
While there are several professional teams and drivers in historical racing, this branch of auto sport tends to be contested by wealthy car owners and is thus more amateur and laid back in its approach.
In open-wheel, stock-car and other types of circuit auto races, flags are displayed to indicate the general status of a race and to communicate instructions to competitors in a race. While the flags have changed from the first years (e.g. red used to start a race), these are generally accepted for today.
In auto racing, the racing setup or car setup is the set of adjustments made to the vehicle in order to optimize its behaviour (performance, handling, reliability, etc.). Adjustments can occur in suspensions, brakes, transmissions, engines, tires, and many others.


Automobile racing (also known as auto racing, motor racing, or car racing) is a sport involving racing automobiles. Auto racing began in 1895, and is now one of the world's most popular sports.
Racing began soon after the construction of the first successful petrol-fueled autos. In 1894, the first contest was organized by Paris magazine Le Perit Journal, a reliability test to determine best performance. But the race was changed to Paris to Rouen 1894. Competitors included factory vehicles from Karl Benz's Benz & Cie. and Gottlieb Daimler and Wilhelm Maybach's DMG.
In 1895, one year later, the first real race was staged in France, from Paris to Bordeaux. First over the line was Émile Levassor but he was disqualified because his car was not a required four-seater.
An international competition began with the Gordon Bennett Cup in auto racing.
The first auto race in the United States took place in Evanston, Illinois on November 28, 1895 over an 87.48-km (54.36 mile) course, with Frank Duryea winning in 10 hours and 23 minutes, beating three petrol-fueled and two electric cars. The first trophy awarded was the Vanderbilt Cup.
With auto construction and racing dominated by France, the French automobile club ACF staged a number of major international races, usually from or to Paris, connecting with another major city in Europe or France.
These very successful races ended in 1903 when Marcel Renault was involved in a fatal accident near Angouleme in the Paris-Madrid race. Nine fatalities caused the French government to stop the race in Bordeaux and ban open-road racing.
The 1930s saw the transformation from high-priced road cars into pure racers, with Delage, Auto Union, Mercedes-Benz, Delahaye, and Bugatti constructing streamlined vehicles with engines producing up to 450 kW (612 hp), aided by multiple-stage supercharging. From 1928-1930 and again in 1934-1936, the maximum weight permitted was 750 kg, a rule diametrically opposed to current racing regulations. Extensive use of aluminium alloys was required to achieve light weight, and in the case of the Mercedes, the paint was removed to satisfy the weight limitation, producing the famous Silver Arrows.
Single-seater (open-wheel) racing is one of the most popular forms of motorsport, with cars designed specifically for high-speed racing. The wheels are not covered, and the cars often have aerofoil wings front and rear to produce downforce and enhance adhesion to the track. In Europe and Asia, open wheeled racing is commonly referred to as "Formula", with appropriate hierarchical suffixes. In North America, the "Formula" terminology is not followed (with the exception of F1). The sport is usually arranged to follow an "international" format (such as F1), a "regional" format (such as the Formula 3 Euro Series), or a "domestic", or county-specific format (such as the German Formula 3 championship, or the British Formula Ford).
The best-known variety of single-seater racing, Formula One, involves an annual World Championship for drivers and constructors of around 18 races a year featuring major international car and engine manufacturers, and independent constructors, such as Ferrari, Mercedes-Benz (McLaren), Williams, BMW (Sauber), Toyota, Honda, Renault, Red Bull Racing - in an ongoing battle of technology and driver skill and talent. The sport is one of the top five watched sporting events in the world, alongside the FIFA World Cup, the Olympic Games, the Super Bowl and the UEFA European Football Championship. Formula One is, by any measure, the most expensive sport in the world, with some teams spending in excess of $400 million per year. Formula One is widely considered to be the pinnacle of motorsports, with the F1 Drivers' Championship being one of, and the oldest among, only three World Championships awarded each year by the FIA (the others being the World Touring Car Championship and the World Rally Championship). What separates Formula 1 from all other forms of open wheel racing, is the basic premise of F1 revolves around the very important issue that each team is a "constructor". That is, the chassis of the car must be designed and manufactured in-house, and chassis can not be supplied to competitors on a "customer" basis. Engines are usually funded and/or developed by established major motor manufacturers, and can be supplied exclusively to just one team, or may be offered as "customer" engines, often to the smaller, lower-ranked teams.
In North America, the cars used in the National Championship (currently Champ Car (formerly CART, or Championship Auto Racing Teams) and the Indy Racing League IndyCar Series) have traditionally been similar though to a lower level of sophistication as F1 cars with more restrictions on technology aimed at helping to control costs.
Other international single-seater racing series are the A1 Grand Prix (unofficially often referred to as the "world cup of motorsport"), and the GP2 (formerly known as Formula 3000 and Formula Two). Regional series include Formula Nippon (specifically in Asia), Formula Renault 3.5 (also known as the World Series by Renault, succession series of World Series by Nissan), Formula Three, Formula Palmer Audi and Formula Atlantic. Domestic, or country-specific series include Formula Three, Formula Renault, Formula Ford with the leading introductory series being Formula BMW.
There are other categories of single-seater racing, including kart racing, which employs a small, low-cost machine on small tracks. Many of the current top drivers began their careers in karts. Formula Ford once represented a popular first open-wheel category for up-and-coming drivers stepping up from karts and now the Formula BMW series is the preferred option as it has introduced an areo package and slicks, allowing the junior drivers to gain experience in a race car with dynamics closer F1.
Students at colleges and universities can also take part in single seater racing through the SAE Formula Student competition, which involves designing and building a single seater car in a multidisciplinary team, and racing it at the competition. This also develops other soft skills such as teamwork whilst promoting motorsport and engineering.
In 2006, producer Todd Baker was responsible for creating the world's first all-female Formula racing team. The group was an assemblage of drivers from different racing disciplines, and formed for an MTV reality pilot which was shot at Mazda Raceway Laguna Seca.
In December, 2005 the FIA gave approval to Superleague Formula racing, set to debut in 2008. This will be open-wheel, single-seat stock car racing around Grand Prix racetracks. The teams will be owned and run by prominent sports clubs such as AC Milan and FC Porto. The race weekend will follow the GP2 format of Saturday qualifying and two Sunday races, one featuring a reverse grid.
Touring car racing is a style of road racing that is run with production derived race cars. It often features exciting, full-contact racing due to the small speed differentials and large grids.
The V8 Supercars originally from Australia, British Touring Car Championship, Deutsche Tourenwagen Masters originally from Germany, and the World Touring Car Championship held with 2 non-European races (previously the European Touring Car Championship) are the major touring car championships conducted worldwide, along with a European Touring Cup, a one day event open to Super 2000 specification touring cars from Europe's many national championships.
The Sports Car Club of America's SPEED World Challenge Touring Car and GT championships are dominant in North America while the venerable British Touring Car Championship continues in the United Kingdom. America's historic Trans-Am Series is undergoing a period of transition, but is still the longest-running road racing series in the U.S. The National Auto Sport Association also provides a venue for amateurs to compete in home-built factory derived vehicles on various local circuits.
Production car racing or known in the US as showroom stock, is an economical and rules restricted version of touring car racing, mainly to restrict costs.
Many series follow the Group N regulation with a few exceptions. There are several different series that are run all over the world, most notably, Japan's Super Taikyu and IMSA's Firehawk Series which ran between the 1980s to 1990s all over the United States.
One-make, or single marque, championships often employ production-based cars from a single manufacturer or even a single model from a manufacturer's range. There are numerous notable one-make formulae from various countries and regions, some of which – such as the Porsche Supercup and, previously, IROC – have fostered many distinct national championships. Single marque series are often found at club level, to which the production-based cars, limited modifications, and close parity in performance are very well suited. There are also single-chassis single seater formulae, such as Formula Ford, Formula Saab, Formula BMW, and defunct Formula Vee, usually as "feeder" series for "senior" race formula (in the fashion of farm teams).
Stock car racing, the North American equivalent to touring car racing, is the most-popular form of auto racing (in terms of viewership) on that continent. Usually conducted on ovals, the cars may slightly resemble production cars but are in fact purpose-built racing machines which are built to tight specifications. Early stock cars were actual production vehicles; the car to be raced was often driven from track to track. The modern car however is far removed from the production model which it represents, making the term "stock car" somewhat incorrect.
The largest stock car racing governing body is NASCAR. NASCAR's premier series is the Sprint Cup Series, its most famous races being the Daytona 500 and the Brickyard 400. NASCAR also runs several feder series. The Nationwide Series, and Craftsman Truck Series (a pickup truck racing series) conduct races across the entire continental United States. The NASCAR Canadian Tire Series conducts races across Canada and the NASCAR Corona Series conducts races across Mexico. NASCAR also governs several smaller regional series.
NASCAR also governs the Whelen Modified Tour. Modified cars are best described as hybrids of stock cars and open-wheel cars. They are heavily altered from stock, with powerful engines, large tires, tubular chassis and light bodies. The Whelen Modified tour is NASCAR's oldest series.
There are also other stock car governing bodies, such as Automobile Racing Club of America and United Speed Alliance Racing.
British Stock car racing is a form of Short Oval Racing. This takes place on shale or tarmac tracks in either clockwise or anti-clockwise direction depending on the class, some of which allow contact. Races are organized by local promoters and all drivers are registered with BRISCA and have their own race number. What classes exist depends on the promoter, so events in Scotland at Cowdenbeath can be very different from an event at Wimbledon Stadium in London.
Rallying, or rally racing, involves two classes of car. The modified Group A, but road legal, production based cars and the Group N Production cars compete on (closed) public roads or off-road areas run on a point-to-point format where participants and their co-drivers "rally" to a set of points, leaving in regular intervals from start points. A rally is typically conducted over a number of 'special stages' of any terrain, which entrants are often allowed to scout beforehand at reduced speeds compiling detailed shorthand descriptions of the track or road as they go. These detailed descriptions are known as 'pace notes'. During the actual rally, the co-driver reads the pace notes aloud (using an in-helmet intercom system) to the driver, enabling them to complete each stage as quickly as possible. Competition is based on lowest total elapsed time over the course of an event's special stages, including penalties.
The top series is the World Rally Championship (WRC), but there also regional championships and many countries have their own national championships. Some famous rallies include the Monte Carlo Rally, Rally Argentina, Rally Finland and Rally GB. Another famous event (actually best described as a "rally raid") is the Paris-Dakar Rally. There are also many smaller, club level, categories of rallies which are popular with amateurs, making up the "grass roots" of motor sports.
Targa is a tarmac-based road rally which is run all around the world. This began with the Targa Florio. There are many races including Targa Tasmania held on the island state of Tasmania, Australia, run annually since 1992. The event takes its name from the Targa Florio, a former motoring event held on the island of Sicily. The competition concept is drawn directly from the best features of the Mille Miglia, the Coupe des Alpes and the Tour de Corse. Other events around the world include the Targa Newfoundland based in Canada, Targa West based in Western Australia, Targa New Zealand and other smaller events.
In drag racing, the objective is to complete a given straight-line distance, from a standing start, ahead of a vehicle in a parallel lane. This distance is traditionally ¼ mile (400 m), though 1/8 mile (200 m) has become popular since the 1990s. The vehicles may or may not be given the signal to start at the same time, depending on the class of racing. Vehicles range from the everyday car to the purpose-built dragster. Speeds and elapsed time differ from class to class. Average street cars cover the ¼ mile in from 15 to 20 seconds whereas a top fuel dragster takes 4.5 seconds or less, reaching speeds of up to 530 km/h (330 mph). Drag racing was organized as a sport by Wally Parks in the early 1950s through the NHRA (National Hot Rod Association), the largest motorsports sanctioning body in the world. The NHRA was formed to discourage street racing.
Launching, a top fuel dragster will accelerate at 4.5 g (44 m/s²), and when braking parachutes are deployed the deceleration is 4 g (39 m/s²), more than the Space Shuttle experinces. A top fuel car can be heard over 8 miles (13 km) away and generates a reading of 1.5 to 2 on the Richter scale.
Drag racing is two cars head-to-head, the winner proceeding to the next round. Professional classes are all first to the finish line wins. Sportsman racing is handicapped (slower car getting a head start) using an index (a lowest e.t. allowed), and cars running under (quicker than) their index "break out" and lose. The slowest cars, bracket racers, are also handicapped, but rather than an index, they use a "dial-in".
In sports car racing, production versions of sports and/or GT cars, and purpose-built prototype cars compete within their respective classes on closed circuits. The races are often conducted over long distances, at least 1000 km, and cars are driven by teams of two or three drivers (and sometimes more in the US), switching every now and then. Due to the performance difference between production based sports cars and sports racing prototypes, one race usually involves several racing classes. In the US the American Le Mans Series (ALMS) was organized in 1999, featuring GT1, GT2, and two prototype classes, LMP1 (Le Mans Prototype 1) and LMP2. Manufacturers such as Audi and Acura/Honda field or support entries in the Prototype class. Another series based on Le Mans began in 2004, the Le Mans Endurance Series, which included four 1000 km races at tracks in Europe. A competing body, Grand-Am, which began in 2000, sanctions its own endurance series the Rolex Sports Car Series.
Famous sports car races include the 24 Hours of Le Mans, the 24 Hours of Daytona, 24 Hours of Spa-Franchorchamps, the 12 Hours of Sebring, and the 1000-mile Petit Le Mans at Road Atlanta.
In off-road racing, various classes of specially modified vehicles, including cars, compete in races through off-road environments. In North America these races often take place in the desert, such as the famous Baja 1000.
Although often seen as the entry point for serious racers into the sport, kart racing, or karting, can be an economic way for amateurs to try racing and is also a fully fledged international sport in its own right. World-famous F1-drivers like Michael Schumacher or Fernando Alonso and most of the typical starting grid of a modern Grand Prix took up the sport at around the age of eight, with some testing from age three. Several former motorcycle champions have also taken up the sport, notably Wayne Rainey, who was paralysed in a racing accident and now races a hand-controlled kart. As one of the cheapest ways to go racing, karting is seeing its popularity grow worldwide.
Go-karts, or just "karts" - seem very distant from normal road cars, with diminutive frames and wheels, but a small engine combined with very light weight make for a quick machine. The tracks are also on a much smaller scale, making kart racing more accessible to the average enthusiast.
As modern motor racing is centered on modern technology with a lots of corporate sponsors and politics involved, historical racing tends to be the opposite. As it relies on cars of a particular era it is more hobbyist oriented, reducing corporate sponsorship and politics. Events are regulated to only allow cars of a certain era to participate. The only modern equipment used is related to safety and timing. A historical event can be of various different motorsport disciplines. Notably some of the most famous events of them all are the Goodwood Festival of Speed and Goodwood Revival in Britain and Monterey Historic in the United States. Championships range from "grass root" Austin Seven racing to the FIA Thoroughbred Grand Prix Championship for classic Formula One chassis.
While there are several professional teams and drivers in historical racing, this branch of auto sport tends to be contested by wealthy car owners and is thus more amateur and laid back in its approach.
In open-wheel, stock-car and other types of circuit auto races, flags are displayed to indicate the general status of a race and to communicate instructions to competitors in a race. While the flags have changed from the first years (e.g. red used to start a race), these are generally accepted for today.
In auto racing, the racing setup or car setup is the set of adjustments made to the vehicle in order to optimize its behaviour (performance, handling, reliability, etc.). Adjustments can occur in suspensions, brakes, transmissions, engines, tires, and many others.

processing time: 1.008967
